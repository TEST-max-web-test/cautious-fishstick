{"source": "github", "repo": "pwndbg/pwndbg", "file": ".github/ISSUE_TEMPLATE/bug_report.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/.github/ISSUE_TEMPLATE/bug_report.md", "content": "---\nname: Bug report\nabout: Create a report to help us improve\ntitle: ''\nlabels: bug\nassignees: ''\n\n---\n\n<!--\nBefore reporting a new issue, make sure that we do not have any duplicates already open.\nIf there is one it might be good to take part in the discussion there.\n\nPlease make sure you have checked that the issue persists on LATEST pwndbg version.\n\nBelow is a template for BUG REPORTS.\nDon't include it if this is a FEATURE REQUEST.\n-->\n\n\n### Description\n\n<!--\nBriefly describe the problem you are having in a few paragraphs.\n-->\n\n### Steps to reproduce\n\n<!--\nWhat do we have to do to reproduce the problem?\nIf this is connected to particular C/asm code,\nplease provide the smallest C code that reproduces the issue.\n-->\n\n### My setup\n\n<!--\nShow us your gdb/python/pwndbg/OS/IDA Pro version (depending on your case).\n\nNOTE: We are currently supporting only Ubuntu installations.\nIt is known that pwndbg is not fully working e.g. on Arch Linux (the heap stuff is not working there).\nIf you would like to change this situation - help us improving pwndbg and supporting other distros!\n\nThis can be displayed in pwndbg through `version` command.\n\nIf it is somehow unavailable, use:\n* `show version` - for gdb\n* `py import sys; print(sys.version)` - for python\n* pwndbg version/git commit id\n-->\n", "timestamp": "2025-10-21T13:21:21.482643"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": ".github/ISSUE_TEMPLATE/feature_request.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/.github/ISSUE_TEMPLATE/feature_request.md", "content": "---\nname: Feature request\nabout: Suggest an idea for this project\ntitle: ''\nlabels: feature\nassignees: ''\n\n---\n\n**Is your feature request related to a problem? Please describe.**\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\n\n**Describe the solution you'd like**\nA clear and concise description of what you want to happen.\n\n**Describe alternatives you've considered**\nA clear and concise description of any alternative solutions or features you've considered.\n\n**Additional context**\nAdd any other context or screenshots about the feature request here.\n", "timestamp": "2025-10-21T13:21:21.593529"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "LICENSE.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/LICENSE.md", "content": "The MIT License (MIT)\n\nCopyright (c) 2025 Dominik 'Disconnect3d' Czarnota\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n", "timestamp": "2025-10-21T13:21:23.949986"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "README.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/README.md", "content": "![repository-open-graph](https://github.com/pwndbg/pwndbg/assets/150354584/77b2e438-898f-416f-a989-4bef30759627)\n# pwndbg\n\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg?maxAge=2592000)](https://choosealicense.com/licenses/mit/)\n[![Tests](https://github.com/pwndbg/pwndbg/actions/workflows/tests.yml/badge.svg?branch=dev&event=push)](https://github.com/pwndbg/pwndbg/actions/workflows/tests.yml)\n[![codecov.io](https://codecov.io/github/pwndbg/pwndbg/branch/dev/badge.svg?token=i1cBPFVCav)](https://app.codecov.io/github/pwndbg/pwndbg/tree/dev)\n[![Discord](https://img.shields.io/discord/843809097920413717?label=Discord&style=plastic)](https://discord.gg/x47DssnGwm)\n\n`pwndbg` (/paʊnˈdiˌbʌɡ/) is a GDB and LLDB plug-in that makes debugging suck less,\nwith a focus on features needed by low-level software developers, hardware hackers,\nreverse-engineers and exploit developers.\n\nIt has a boatload of features, see our [Features page](https://pwndbg.re/pwndbg/latest/features/)\nand [CHEATSHEET][CHEATSHEET] (feel free to print it!). If you have any questions you may read the\n[documentation](https://pwndbg.re/pwndbg/latest/) or asks us in our [Discord server](https://discord.gg/x47DssnGwm).\n\n[CHEATSHEET]: https://pwndbg.re/pwndbg/dev/CHEATSHEET.pdf\n\n## Why?\n\nVanilla GDB and LLDB are terrible to use for reverse engineering and exploit development.\nTyping `x/30gx $rsp` or navigating cumbersome LLDB commands is not fun and often provides\nminimal information. The year is 2025, and core debuggers still lack many user-friendly\nfeatures such as a robust hexdump command. WinDbg users are completely lost when they\noccasionally need to bump into GDB or LLDB.\n\nPwndbg is a Python module which can be loaded into GDB or run as a REPL interface for LLDB.\nIt provides a suite of utilities and enhancements that fill the gaps left by these debuggers,\nsmoothing out rough edges and making them more user-friendly.\n\n## Installation\n\nSee [installation instructions](https://pwndbg.re/pwndbg/latest/setup).\n\n## What about ...?\n\nMany past ([gdbinit][gdbinit], [PEDA][PEDA]) and present projects ([GEF][GEF],\n[bata24/GEF][bata24/GEF]) offer great features, but are hard to extend and are packaged\nas large single files ([103KB][gdbinit2], [195KB][peda.py], [423KB][gef.py],\n[4.12MB][bata24/gef.py]). Pwndbg aims to replace them with a faster, cleaner, and\nmore robust implementation.\n\n[gdbinit]: https://github.com/gdbinit/Gdbinit\n[gdbinit2]: https://github.com/gdbinit/Gdbinit/blob/master/gdbinit\n[PEDA]: https://github.com/longld/peda\n[peda.py]: https://github.com/longld/peda/blob/master/peda.py\n[GEF]: https://github.com/hugsy/gef\n[gef.py]: https://github.com/hugsy/gef/blob/main/gef.py\n[bata24/GEF]: https://github.com/bata24/gef\n[bata24/gef.py]: https://github.com/bata24/gef/blob/dev/gef.py\n\n## When to Use GDB or LLDB?\n\nPwndbg supports both GDB and LLDB, and each debugger has its own strengths.\nHere's a quick guide to help you decide which one to use:\n\n| Use Case                                        | Supported Debugger   |\n|-------------------------------------------------|----------------------|\n| Debugging Linux binaries or ELF files           | **GDB**, **LLDB**    |\n| Debugging Mach-O binaries on macOS              | **LLDB**             |\n| Linux kernel debugging (qemu-system)            | **GDB**, **LLDB**    |\n| Linux user-space emulation (qemu-user)          | **GDB**              |\n| Embedded debugging (ARM Cortex M* or RISC-V/32) | **GDB**, **LLDB**    |\n\nPwndbg ensures a consistent experience across both, so switching between them is seamless.\n> The LLDB implementation in pwndbg is still in early-stage and may contain bugs or limitations.<br/>\n> Known issues are tracked in [GitHub Issues][lldb_tracker].\n>\n> If you encounter any problems, feel free to report them or discuss on our [Discord server](https://discord.gg/x47DssnGwm).\n\n[lldb_tracker]: https://github.com/pwndbg/pwndbg/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22LLDB%20Port%22\n\n### Compatibility Table\n| Feature     | Supported Version               | Notes                                |\n|-------------|---------------------------------|--------------------------------------|\n| pwndbg-gdb  | - Python 3.10+ <br/>- GDB 12.1+ | Battle-tested on Ubuntu 22.04/24.04  |\n| pwndbg-lldb | - Python 3.12+ <br/>- LLDB 19+  | Experimental/early-stage support     |\n| qemu-user   | QEMU 8.1+                       | vFile API is needed for vmmap        |\n| qemu-system | QEMU 6.2+                       | Supported version since ubuntu 22.04 |\n\n\n## Contributing\nPull requests are welcome ❤️. Check out the [Contributing Guide](https://pwndbg.re/pwndbg/dev/contributing/).\n\n## Acknowledgements\nPwndbg was originally created by [Zach Riggle](https://github.com/zachriggle), who is no longer with us. We want to thank Zach for all of his contributions to pwndbg and the wider security community.\n", "timestamp": "2025-10-21T13:21:24.442468"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/blog/posts/pwndbg-coding-sprints-report.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/blog/posts/pwndbg-coding-sprints-report.md", "content": "---\ntitle: Pwndbg coding sprints report\ndate: 2022-08-21\nauthors: [disconnect3d]\nslug: pwndbg-coding-sprints-report\ndescription: >\n  Report of the two coding sprints with Pwndbg\n---\n\n(originally posted on https://disconnect3d.pl/2022/08/21/pwndbg-coding-sprints/)\n\nThis blog post is a report of the two coding sprints for the [Pwndbg project](https://github.com/pwndbg/pwndbg) that I organized first on the EuroPython 2022 conference and then, taking inspiration from the previous one, in the Hackerspace Kraków, located in Cracow, Poland.\n\nPS: If you are only looking for a list of things done, scroll down!\n\n<!-- more -->\n\n## Where I got the idea for sprints?\n\nI have recently attended the [EuroPython 2022](https://ep2022.europython.eu) conference and I enjoyed the “sprints” there. In short, a [sprint](https://ep2022.europython.eu/sprints#what-is-a-sprint-) is a semi-organized event, where anyone can announce a project they will be working on and others can join them. This helps both the projects and the event participants to learn about the project and to make first-time contributions. At the EuroPython conference, [there were 16 officially announced projects](https://ep2022.europython.eu/sprints#2022-sprints-listings), but I know that even more projects were being worked on in practice. Of course, other communities or conferences also do this (e.g. [NixCon](https://2022.nixcon.org/#hackday)).\n\nAt the EuroPython conference, I announced my own sprint to work on the Pwndbg project that I maintain. Having no expectations, I felt excited when four people showed up to learn something new and hack together on the project. Later, taking inspiration from it, I organized another sprint, this time in Cracow in the local Hackerspace with even a bigger response. Below, you can read a small report on the two sprints that have happened.\n\n## My general idea for a Pwndbg sprint\nPwndbg is written in Python, so on one hand is easy to hack on, but on the other hand it is a plugin for GDB, a console debugger for native programs (e.g. ones written in C, C++, Go or Rust). The general idea of Pwndbg is to alleviate the pain points of working with and improve the UX of GDB when debugging assembly code, reverse engineering a binary or during exploit development.\n\nSince not everyone is familiar with debuggers or the underlyings of programs execution (e.g. assembly code, CPU registers or stack or heap memory) I knew that I had to make some introduction to those concepts and if possible, prepare a list of simple tasks, so that people can get familiar with the codebase and the tool and contribute something.\n\n\n## EuroPython 2022 sprint\n\nOn the first sprint, four people showed up, mostly having no prior experience with the topic. We started with an introduction to what GDB and Pwndbg are and why and when they are useful.\n\nFor this, I took a small C program that had a buffer overflow bug:\n```c\n#include <stdio.h>\n#include <string.h>\n\nint main(int argc, char* argv[]) {\n    char name[16] = {0};\n\n    // NOTE: We copy the `argv[1]` string which may be of arbitrary length\n    // into the `name` buffer which is only of 16-bytes long. Thus, we can\n    // overwrite the stack memory of the program past the `name` buffer.\n    strcpy(name, argv[1]);\n\n    printf(\"Hello %s!\\n\", name);\n}\n```\n\nThen, after compiling it (`gcc main.c`), we ran the program twice to see that it will crash if we provide a too long string as its argument:\n\n```bash\n$ ./a.out Disconnect3d\nHello Disconnect3d!\n\n$ ./a.out Disconnect3d_at_EuroPython\nHello Disconnect3d_at_EuroPython!\n*** stack smashing detected ***: <unknown> terminated\nAborted (core dumped)\n```\n\nThen, I explained that the \"stack smashing detected\" we see is the \"stack canaries\" (also called \"stack cookies\") exploit mitigation added by compilers. This compiler feature adds a special 8-bytes canary value after the function's local variables located on the stack, so that then a stack frame may look like this:\n\n```\n------------------------------   lower addresses\nchar name[16];                         |\nuint8_t canary[8];                     |\nvoid* function_return_address;         V\n------------------------------   higher addresses\n```\n\nThis local stack canary value is then filled in just after the function’s prologue and is verified against a global value before the function returns to see if the stack was not corrupted (starting from the canary). Of course this may not detect all possible stack memory corruptions but it often makes it impossible to exploit a program (e.g. by changing the return address, also located on the stack), knowing just this vulnerability.\n\nThe stack canary mitigation can also be disabled. And if it were done (by passing in a `-fno-stack-protector` flag during compilation), we would get a different result when running the resulting program:\n\n```bash\n$ gcc -fno-stack-protector buf.c\n\n$ ./a.out Disconnect3d_on_EuroPython\nHello Disconnect3d_on_EuroPython!\nSegmentation fault (core dumped)\n```\n\nNow, the \"stack smashing detected\" is gone, but the program still crashed, because we still corrupted a part of its memory that we shouldn't have touched in a way that made the program do illegal things (e.g. accessing unmapped memory).\n\nDuring the sprint, we also ran a GDB+Pwndbg session to see the exact instructions that placed the canary value on the stack memory, to see that our input string was located just before it and how the canary was checked just before the function was returned.\n\nI am not going to describe all of this here, but you can see some of it in the below asciinema recording.\n\n[![asciicast](https://asciinema.org/a/zuuwfJIZrpu6IjuwWhiNgAdim.svg)](https://asciinema.org/a/zuuwfJIZrpu6IjuwWhiNgAdim)\n\n\n## Hackerspace Kraków sprint\n\nSince the second sprint was an ad-hoc event, I had to organize it myself. As a member of Hackerspace Kraków, I was able to reserve the hackerspace's softroom, which is a perfect place for people to hack on things using their computers. Then, I advertised the event on the [Hackerspace's mailing list](https://groups.google.com/g/hackerspace-krk/c/MP6mX4I5vXY) and on a few other mediums.\n\nI did not expect many people to come, especially that I advertised the sprint ~2 days before the event.\n\nBut... 8 people (!) showed up (excluding me). I prepared a document with some basic information and tasks, which can be found [here](https://hackmd.io/vjfZ4GIYS8eu_j-7q-fkBg) (though, it is in Polish and it was modified during and after the sprint).\n\nI won't lie: most people that came were friends of mine, some of which I play [CTFs](https://en.wikipedia.org/wiki/Capture_the_flag_(cybersecurity)) with. However, not all of them had really used or developed Pwndbg before.\n\n## Accomplishments from the two sprints\n\nOn the EP sprint, since we were just a group of four, we focused on small improvements to the codebase. In total, we did the following:\n* [reviewed and merged the fs/gs_base fetching improvement PR](https://github.com/pwndbg/pwndbg/pull/1030),\n* [pinned the project's dependencies](https://github.com/pwndbg/pwndbg/pull/1033),\n* [updated the unicorn dependency version](https://github.com/pwndbg/pwndbg/pull/1034),\n* [added a \"tip of the day\" feature](https://github.com/pwndbg/pwndbg/pull/1036),\n* [improved the UX of using Pwndbg within a Python virtual environment](https://github.com/pwndbg/pwndbg/pull/1037),\n* and also [worked on enhancing the display of arguments when stopping on a call to the printf functions family](https://github.com/pwndbg/pwndbg/pull/1038).\n\nThe last item from the list was the hardest to jump on and it still requires enhancements until it is merged. Nonetheless, all of this was a nice outcome from the whole sprint :).\n\nOn the second sprint, while we were a bigger group, we had much more limited time (since instead of having ~8 hours, we had just a few). Anyway, we were able to do the following:\n\n* [Cleanup some code leftover after dropping Python 2 support](https://github.com/pwndbg/pwndbg/pull/1052),\n* [Added documentation on how to debug Pwndbg using PyCharm remote debugging](https://github.com/pwndbg/pwndbg/pull/1058),\n* Reviewed and merged the PRs that [sets `$base_heap` variable](https://github.com/pwndbg/pwndbg/pull/1051) and [a tip for it](https://github.com/pwndbg/pwndbg/pull/1053), which may be useful for heap exploitation,\n* [Fix the X30 register display on AARCH64 targets](https://github.com/pwndbg/pwndbg/pull/1054),\n* [Fix `context args` display when PC/IP register pointed to unmapped memory](https://github.com/pwndbg/pwndbg/pull/1055),\n* [Fixed the `xor` and `memfrob` commands and added tests for them (! :D)](https://github.com/pwndbg/pwndbg/pull/1057),\n* [Worked on adding a way to dump memory that can be copied right away as C or Python code](https://github.com/pwndbg/pwndbg/pull/1056) (this needs to be changed to a command flag),\n* Investigated a [potential parsing issue](https://github.com/pwndbg/pwndbg/issues/1050), even looking at GDB's command parsing source code, [implemented potential patch](https://github.com/pwndbg/pwndbg/pull/1062), which only later turned out to be redundant and the issue to be invalid.\n\n## Summary and what's next?\n\nOrganizing those sprints helped me to get back to develop the Pwndbg project more and and attract more people to contribute to it. I also think that more conferences should have this kind of attractions (similarly as more conferences should have lightning talk sessions, heh).\n\nRegarding the Pwndbg sprints, I am organizing another one this week in Cracow on Tuesday, so if you live nearby and are interested in learning about Pwndbg or contributing to the project, feel invited! :)\n\nPS: Thanks a lot to [@arturcygan](https://twitter.com/arturcygan) for reviewing this blog post.\n", "timestamp": "2025-10-21T13:21:26.164126"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/configuration/config.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/configuration/config.md", "content": "<!-- THIS WHOLE FILE IS AUTOGENERATED. DO NOT MODIFY IT. See scripts/generate-docs.sh -->\n\n\n\n\n# config\n\n## **ai-anthropic-api-key**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nAnthropic API key.\n\nDefaults to ANTHROPIC_API_KEY environment variable if not set.\n\n**Default:** ''  \n\n----------\n\n## **ai-history-size**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nMaximum number of questions and answers to keep in the prompt.\n\n\n\n**Default:** 3  \n\n----------\n\n## **ai-max-tokens**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nThe maximum number of tokens to return in the response.\n\nUseful when limiting verbosity or conserving resources. Set to a lower value to restrict output.\n\n**Default:** 100  \n\n----------\n\n## **ai-model**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nThe name of the large language model to query.\n\nChanging this affects the behavior, response quality, and cost (if applicable) of AI responses.\n\n**Default:** 'gpt-3.5-turbo'  \n\n----------\n\n## **ai-ollama-endpoint**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nOllama API endpoint.\n\nDefaults to OLLAMA_ENDPOINT environment variable if not set.\n\n**Default:** ''  \n\n----------\n\n## **ai-openai-api-key**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nOpenAI API key.\n\nWill default to OPENAI_API_KEY environment variable if not set.\n\n**Default:** ''  \n\n----------\n\n## **ai-show-usage**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nWhether to show how many tokens are used with each OpenAI API call.\n\n\n\n**Default:** off  \n\n----------\n\n## **ai-stack-depth**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nRows of stack context to include in the prompt for the ai command.\n\n\n\n**Default:** 16  \n\n----------\n\n## **ai-temperature**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nThe temperature specification for the LLM query.\n\nThis controls the degree of randomness in the response.\n\n**Default:** 0  \n\n----------\n\n## **attachp-resolution-method**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nHow to determine the process to attach when multiple candidates exists.\n\n\n\n**Default:** 'ask'  \n**Valid values:** 'none', 'oldest', 'newest', 'ask'\n\n----------\n\n## **auto-explore-auxv**\n\n\nStack exploration for AUXV information; it may be really slow.\n\n\n\n**Default:** 'warn'  \n**Valid values:** 'warn', 'yes', 'no'\n\n----------\n\n## **auto-explore-pages**\n\n\nWhether to try to infer page permissions when memory maps are missing.\n\nThis command can cause errors.\n\n**Default:** 'warn'  \n**Valid values:** 'yes', 'warn', 'no'\n\n----------\n\n## **auto-explore-stack**\n\n\nStack exploration; it may be really slow.\n\n\n\n**Default:** 'warn'  \n**Valid values:** 'warn', 'yes', 'no'\n\n----------\n\n## **auto-save-search**\n\n\nAutomatically pass --save to \"search\" command.\n\n\n\n**Default:** off  \n\n----------\n\n## **bn-autosync**\n\n\nWhether to automatically run bn-sync every step.\n\n\n\n**Default:** off  \n\n----------\n\n## **bn-il-level**\n\n\nThe IL level to use when displaying Binary Ninja decompilation.\n\n\n\n**Default:** 'hlil'  \n**Valid values:** 'disasm', 'llil', 'mlil', 'hlil'\n\n----------\n\n## **bn-rpc-host**\n\n\nBinary Ninja XML-RPC server host.\n\n\n\n**Default:** '127.0.0.1'  \n\n----------\n\n## **bn-rpc-port**\n\n\nBinary Ninja XML-RPC server port.\n\n\n\n**Default:** 31337  \n\n----------\n\n## **bn-timeout**\n\n\nTime to wait for Binary Ninja XML-RPC, in seconds.\n\n\n\n**Default:** 2  \n\n----------\n\n## **context-backtrace-lines**\n\n\nNumber of lines to print in the backtrace context.\n\n\n\n**Default:** 8  \n\n----------\n\n## **context-clear-screen**\n\n\nWhether to clear the screen before printing the context.\n\n\n\n**Default:** off  \n\n----------\n\n## **context-code-lines**\n\n\nNumber of source code lines to print by the context command.\n\n\n\n**Default:** 10  \n\n----------\n\n## **context-code-tabstop**\n\n\nNumber of spaces that a <tab> in the source code counts for.\n\n\n\n**Default:** 8  \n\n----------\n\n## **context-disasm-lines**\n\n\nNumber of additional lines to print in the disasm context.\n\n\n\n**Default:** 10  \n\n----------\n\n## **context-ghidra**\n\n\nWhen to try to decompile the current function with ghidra.\n\nDoing this is slow and requires radare2/r2pipe or rizin/rzpipe.\n\n**Default:** 'never'  \n**Valid values:** 'always', 'never', 'if-no-source'\n\n----------\n\n## **context-history-size**\n\n\nNumber of context history entries to store.\n\n\n\n**Default:** 50  \n\n----------\n\n## **context-integration-decompile**\n\n\nWhether context should fall back to decompilation with no source code.\n\n\n\n**Default:** on  \n\n----------\n\n## **context-max-threads**\n\n\nMaximum number of threads displayed by the context command.\n\n\n\n**Default:** 4  \n\n----------\n\n## **context-output**\n\n\nWhere Pwndbg should output (\"stdout\" or file/tty).\n\n\n\n**Default:** 'stdout'  \n\n----------\n\n## **context-reserve-lines**\n\n\nWhen to reserve lines after the prompt to reduce context shake.\n\nThe \"if-ctx-fits\" setting only reserves lines if the whole context would still fit vertically in the current terminal window.\nIt doesn't take into account line-wrapping due to insufficient terminal width.\n\n**Default:** 'if-ctx-fits'  \n**Valid values:** 'never', 'if-ctx-fits', 'always'\n\n----------\n\n## **context-sections**\n\n\nWhich context sections are displayed (controls order).\n\n\n\n**Default:** 'regs disasm code ghidra stack backtrace expressions threads heap_tracker'  \n\n----------\n\n## **context-stack-lines**\n\n\nNumber of lines to print in the stack context.\n\n\n\n**Default:** 8  \n\n----------\n\n## **cymbol-editor**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nPath to the editor for editing custom structures.\n\n\n\n**Default:** ''  \n\n----------\n\n## **debug-events**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nDisplay internal event debugging info.\n\n\n\n**Default:** off  \n\n----------\n\n## **decompiler**\n\n\nFramework that your ghidra plugin installed.\n\n\n\n**Default:** 'radare2'  \n**Valid values:** 'radare2', 'rizin'\n\n----------\n\n## **default-visualize-chunk-number**\n\n\nDefault number of chunks to visualize.\n\n\n\n**Default:** 10  \n\n----------\n\n## **dereference-limit**\n\n\nMax number of pointers to dereference in a chain.\n\n\n\n**Default:** 5  \n\n----------\n\n## **disasm-annotations**\n\n\nDisplay annotations for instructions.\n\n\n\n**Default:** on  \n\n----------\n\n## **disasm-inline-symbols**\n\n\nReplacing constant operands with their symbol in the disassembly.\n\n\n\n**Default:** on  \n\n----------\n\n## **disasm-reg-alias**\n\n\nForce the disassembly to use register aliases (e.g. aarch64 x29 -> fp).\n\nThe register aliasing is done by capstone, see:\nhttps://github.com/capstone-engine/capstone/blob/next/docs/cs_v6_release_guide.md#:~:text=None.-,Register%20alias,-Register%20alias%20\n\nEnabling this may make disassembly slower.\n\n**Default:** off  \n\n----------\n\n## **disasm-telescope-depth**\n\n\nDepth of telescope for disasm annotations.\n\n\n\n**Default:** 3  \n\n----------\n\n## **disasm-telescope-string-length**\n\n\nThe number of characters in strings to display in disasm annotations.\n\n\n\n**Default:** 50  \n\n----------\n\n## **emulate**\n\n\nUnicorn emulation of code from the current PC register.\n\nEmulate can be:\n\n1. off             - no emulation is performed\n2. jumps-only      - emulation is done only to resolve branch instructions\n3. on              - emulation is done to resolve registers/memory values etc.\n\nEmulation can slow down Pwndbg. Disabling it may improve performance.\nEmulation requires >1GB RAM being available on the system and ability to allocate RWX memory.\n\n**Default:** 'on'  \n**Valid values:** 'on', 'off', 'jumps-only'\n\n----------\n\n## **emulate-annotations**\n\n\nUnicorn emulation for instruction annotations.\n\nRefers to register and memory value annotations.\n\n**Default:** on  \n\n----------\n\n## **emulate-future-annotations**\n\n\nUnicorn emulation for future instruction's annotations.\n\n\n\n**Default:** on  \n\n----------\n\n## **exception-debugger**\n\n\nWhether to debug exceptions raised in Pwndbg commands.\n\n\n\n**Default:** off  \n\n----------\n\n## **exception-verbose**\n\n\nPrint a full stacktrace for exceptions raised in Pwndbg commands.\n\n\n\n**Default:** off  \n\n----------\n\n## **gcc-compiler-path**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nPath to the gcc/g++ toolchain for generating imported symbols.\n\n\n\n**Default:** ''  \n\n----------\n\n## **gdb-workaround-stop-event**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nAsynchronous stop events to improve 'commands' functionality.\n\nNote that this may cause unexpected behavior with Pwndbg or gdb.execute.\n\nValues explained:\n\n+ `disabled` - Disable the workaround (default).\n+ `disabled-deadlock` - Disable only deadlock detection; deadlocks may still occur.\n+ `enabled` - Enable asynchronous stop events; gdb.execute may behave unexpectedly (asynchronously).\n\n**Default:** 'disabled'  \n**Valid values:** 'disabled', 'disabled-deadlock', 'enabled'\n\n----------\n\n## **go-dump-indent-amount**\n\n\nThe indent amount for go-dump pretty printing.\n\n\n\n**Default:** 4  \n\n----------\n\n## **go-dump-line-width**\n\n\nThe soft line width for go-dump pretty printing.\n\n\n\n**Default:** 80  \n\n----------\n\n## **hexdump-bytes**\n\n\nNumber of bytes printed by hexdump command.\n\n\n\n**Default:** 64  \n\n----------\n\n## **hexdump-group-use-big-endian**\n\n\nUse big-endian within each group of bytes in hexdump command.\n\nWhen `on`, use big-endian within each group of bytes. Only applies to raw bytes, not the ASCII part. See also hexdump-highlight-group-lsb.\n\n**Default:** off  \n\n----------\n\n## **hexdump-group-width**\n\n\nNumber of bytes grouped in hexdump command.\n\nIf -1, the architecture's pointer size is used.\n\n**Default:** -1  \n\n----------\n\n## **hexdump-limit-mb**\n\n\nThe maximum size in megabytes (MB) `hexdump` will read.\n\nSet the maximum size in megabytes (MB) that the `hexdump` command will attempt to read at once.\n    Prevents GDB crashes due to excessive memory allocation requests.\n    Set to 0 for unlimited (use with caution).\n\n**Default:** 10  \n\n----------\n\n## **hexdump-width**\n\n\nLine width of hexdump command.\n\n\n\n**Default:** 16  \n\n----------\n\n## **ida-rpc-host**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nIda xmlrpc server address.\n\n\n\n**Default:** '127.0.0.1'  \n\n----------\n\n## **ida-rpc-port**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nIda xmlrpc server port.\n\n\n\n**Default:** 31337  \n\n----------\n\n## **ida-timeout**\n<small style=\"color: lightgray;\">(only in GDB)</small>\n\n\nTime to wait for ida xmlrpc in seconds.\n\n\n\n**Default:** 2  \n\n----------\n\n## **integration-function-lookup**\n\n\nUse integration to look up function type signatures.\n\n\n\n**Default:** on  \n\n----------\n\n## **integration-provider**\n\n\nWhich provider to use for integration features.\n\n\n\n**Default:** 'none'  \n**Valid values:** 'none', 'binja', 'ida'\n\n----------\n\n## **integration-smart-enhance**\n\n\nUse integration to determine when to disassemble during enhancing.\n\n\n\n**Default:** on  \n\n----------\n\n## **integration-symbol-lookup**\n\n\nWhether to use integration to look up unknown symbols.\n\n\n\n**Default:** on  \n\n----------\n\n## **kernel-vmmap**\n\n\nThe method to get vmmap information when debugging via QEMU kernel.\n\nValues explained:\n\n+ `page-tables` - read /proc/$qemu-pid/mem to parse kernel page tables to render vmmap\n+ `monitor` - use QEMU's `monitor info mem` to render vmmap\n+ `none` - disable vmmap rendering; useful if rendering is particularly slow\n\nNote that the page-tables method will require the QEMU kernel process to be on the same machine and within the same PID namespace. Running QEMU kernel and GDB in different Docker containers will not work. Consider running both containers with --pid=host (meaning they will see and so be able to interact with all processes on the machine).\n\n**Default:** 'page-tables'  \n**Valid values:** 'page-tables', 'monitor', 'none'\n\n----------\n\n## **left-pad-disasm**\n\n\nWhether to left-pad disassembly.\n\n\n\n**Default:** on  \n\n----------\n\n## **max-decimal-number**\n\n\nShow all numbers greater than this in hex.\n\nFor negative numbers, their absolute value is used.\n\nSet the parameter to 'unlimited' if you want all values in decimal.\nSpecially, set the parameter to zero if you want all values in hex.\n\nThe assembly instruction operands come from capstone, and are thus\nnot controlled by this setting. For consistency with them, leave\nthis setting at 9 (the default).\n\n**Default:** 9  \n\n----------\n\n## **max-visualize-chunk-size**\n\n\nMax display size for heap chunks visualization (0 for display all).\n\n\n\n**Default:** 0  \n\n----------\n\n## **nearpc-integration-comments**\n\n\nWhether to show comments from integration provider.\n\n\n\n**Default:** on  \n\n----------\n\n## **nearpc-lines**\n\n\nNumber of additional lines to print for the nearpc command.\n\n\n\n**Default:** 10  \n\n----------\n\n## **nearpc-num-opcode-bytes**\n\n\nNumber of opcode bytes to print for each instruction.\n\n\n\n**Default:** 0  \n\n----------\n\n## **nearpc-opcode-separator-bytes**\n\n\nNumber of spaces between opcode bytes.\n\n\n\n**Default:** 1  \n\n----------\n\n## **nearpc-show-args**\n\n\nWhether to show call arguments below instruction.\n\n\n\n**Default:** on  \n\n----------\n\n## **objc-max-function-arguments**\n\n\nMaximum number of arguments to resolve for an Objective-C method call.\n\n\n\n**Default:** 32  \n\n----------\n\n## **objc-max-function-types-depth**\n\n\nMaximum allowed depth for a type in an Objective-C method call.\n\n\n\n**Default:** 32  \n\n----------\n\n## **safe-linking**\n\n\nWhether glibc uses safe-linking.\n\n\n\n**Default:** auto  \n**Valid values:** on, off, auto.\n\n----------\n\n## **show-compact-regs**\n\n\nWhether to show a compact register view with columns.\n\n\n\n**Default:** off  \n\n----------\n\n## **show-compact-regs-columns**\n\n\nThe number of columns (0 for dynamic number of columns).\n\n\n\n**Default:** 2  \n\n----------\n\n## **show-compact-regs-min-width**\n\n\nThe minimum width of each column.\n\n\n\n**Default:** 20  \n\n----------\n\n## **show-compact-regs-separation**\n\n\nThe number of spaces separating columns.\n\n\n\n**Default:** 4  \n\n----------\n\n## **show-flags**\n\n\nWhether to show flags registers.\n\n\n\n**Default:** off  \n\n----------\n\n## **show-retaddr-reg**\n\n\nWhether to show return address register.\n\n\n\n**Default:** on  \n\n----------\n\n## **show-tips**\n\n\nWhether to display the tip of the day on startup.\n\n\n\n**Default:** on  \n\n----------\n\n## **syntax-highlight**\n\n\nSource code / assembly syntax highlight.\n\n\n\n**Default:** on  \n\n----------\n\n## **telescope-dont-skip-registers**\n\n\nDon't skip a repeated line if a registers points to it.\n\n\n\n**Default:** on  \n\n----------\n\n## **telescope-frame-print-retaddr**\n\n\nPrint one pointer past the stack frame.\n\n\n\n**Default:** on  \n\n----------\n\n## **telescope-framepointer-offset**\n\n\nPrint offset to framepointer for each address, if sufficiently small.\n\n\n\n**Default:** on  \n\n----------\n\n## **telescope-lines**\n\n\nNumber of lines to printed by the telescope command.\n\n\n\n**Default:** 8  \n\n----------\n\n## **telescope-skip-repeating-val**\n\n\nWhether to skip repeating values of the telescope command.\n\n\n\n**Default:** on  \n\n----------\n\n## **telescope-skip-repeating-val-min**\n\n\nMinimum amount of repeated values before skipping lines.\n\n\n\n**Default:** 3  \n\n----------\n\n## **vmmap-prefer-relpaths**\n\n\nShow relative paths by default in vmmap.\n\n\n\n**Default:** on  \n\n----------\n", "timestamp": "2025-10-21T13:21:26.490683"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/configuration/heap.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/configuration/heap.md", "content": "<!-- THIS WHOLE FILE IS AUTOGENERATED. DO NOT MODIFY IT. See scripts/generate-docs.sh -->\n\n\n\n\n# heap\n\n## **glibc**\n\n\nGlibc version for heap heuristics resolution (e.g. 2.31).\n\n\n\n**Default:** ''  \n\n----------\n\n## **global-max-fast**\n\n\nThe address of global_max_fast.\n\n\n\n**Default:** '0'  \n\n----------\n\n## **heap-corruption-check-limit**\n\n\nAmount of chunks to traverse for the bin corruption check.\n\nThe bins are traversed both forwards and backwards.\n\n**Default:** 64  \n\n----------\n\n## **heap-dereference-limit**\n\n\nNumber of chunks to dereference in each bin.\n\n\n\n**Default:** 8  \n\n----------\n\n## **main-arena**\n\n\nThe address of main_arena.\n\n\n\n**Default:** '0'  \n\n----------\n\n## **mp**\n\n\nThe address of mp_.\n\n\n\n**Default:** '0'  \n\n----------\n\n## **ng-search-on-fail**\n\n\nLet the ng-slot* commands search the heap if necessary.\n\nFor freed, avail(able) and corrupted slots, it may be\nimpossible to recover the start of the group and meta.\n\nWhen this option is set to True, the ng-slotu and ng-slots\ncommands will search the heap to try to find the correct meta/group.\n\n**Default:** on  \n\n----------\n\n## **ng-vis-count**\n\n\nDefault count for ng-vis.\n\n\n\n**Default:** 10  \n\n----------\n\n## **resolve-heap-via-heuristic**\n\n=== \"GDB\"\n\n     The strategy to resolve heap via heuristic.\n\n    Values explained:\n\n    + `auto` - Pwndbg will try to use heuristics if debug symbols are missing\n    + `force` - Pwndbg will always try to use heuristics, even if debug symbols are available\n    + `never` - Pwndbg will never use heuristics to resolve the heap\n\n    If the output of the heap related command produces errors with heuristics, you\n    can try manually setting the libc symbol addresses.\n    For this, see the `heap_config` command output and set the `main_arena`, `mp_`,\n    `global_max_fast`, `tcache` and `thread_arena` addresses.\n\n    Note: Pwndbg will generate more reliable results with proper debug symbols.\n    Therefore, when debug symbols are missing, you should try to install them first\n    if you haven't already.\n\n    They can probably be installed via the package manager of your choice.\n    See also: https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html .\n\n    E.g. on Ubuntu/Debian you might need to do the following steps (for 64-bit and\n    32-bit binaries):\n    ```bash\n    sudo apt-get install libc6-dbg\n    sudo dpkg --add-architecture i386\n    sudo apt-get install libc-dbg:i386\n    ```\n    If you used setup.sh on Arch based distro you'll need to do a power cycle or set\n    environment variable manually like this:\n    ```bash\n    export DEBUGINFOD_URLS=https://debuginfod.archlinux.org\n    ```\n\n    In addition, even you have the debug symbols of libc, you might still see the\n    following warning when debugging a multi-threaded program:\n    ```\n    warning: Unable to find libthread_db matching inferior's thread library, thread\n    debugging will not be available.\n    ```\n\n    You'll need to ensure that the correct `libthread_db.so` is loaded. To do this,\n    set the search path using:\n    ```\n    set libthread-db-search-path <path having correct libthread_db.so>\n    ```\n    Then, restart your program to enable proper thread debugging.\n\n    **Default:** 'auto'  \n    **Valid values:** 'auto', 'force', 'never'\n=== \"LLDB\"\n\n     The strategy to resolve heap via heuristic.\n\n    Values explained:\n\n    + `auto` - Pwndbg will try to use heuristics if debug symbols are missing\n    + `force` - Pwndbg will always try to use heuristics, even if debug symbols are available\n    + `never` - Pwndbg will never use heuristics to resolve the heap\n\n    If the output of the heap related command produces errors with heuristics, you\n    can try manually setting the libc symbol addresses.\n    For this, see the `heap_config` command output and set the `main_arena`, `mp_`,\n    `global_max_fast`, `tcache` and `thread_arena` addresses.\n\n    Note: Pwndbg will generate more reliable results with proper debug symbols.\n    Therefore, when debug symbols are missing, you should try to install them first\n    if you haven't already.\n\n    They can probably be installed via the package manager of your choice.\n    See also: https://sourceware.org/gdb/onlinedocs/gdb/Separate-Debug-Files.html .\n\n    E.g. on Ubuntu/Debian you might need to do the following steps (for 64-bit and\n    32-bit binaries):\n    ```bash\n    sudo apt-get install libc6-dbg\n    sudo dpkg --add-architecture i386\n    sudo apt-get install libc-dbg:i386\n    ```\n    If you used setup.sh on Arch based distro you'll need to do a power cycle or set\n    environment variable manually like this:\n    ```bash\n    export DEBUGINFOD_URLS=https://debuginfod.archlinux.org\n    ```\n\n    **Default:** 'auto'  \n    **Valid values:** 'auto', 'force', 'never'\n\n----------\n\n## **tcache**\n\n\nThe address pointed by tcache.\n\n\n\n**Default:** '0'  \n\n----------\n\n## **thread-arena**\n\n\nThe address pointed by thread_arena.\n\n\n\n**Default:** '0'  \n\n----------\n", "timestamp": "2025-10-21T13:21:26.610252"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/configuration/index.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/configuration/index.md", "content": "# Configuration\n\nPwndbg can be configured in various ways. You can tune features, control what it displays, how it displays it, and even what is going on under the hood.\n\nThere are three \"scopes\" of configuration parameters currently:\n\n1. [the config scope](./config.md) - for generic parameters\n2. [the heap scope](./heap.md) - for heap-related parameters\n3. [the theme scope](./theme.md) - for Pwndbg theming\n\nTo see the parameters belonging to these scopes, use the [`config`](../commands/pwndbg/config.md), [`heap-config`](../commands/pwndbg/heap-config.md), and [`theme`](../commands/pwndbg/theme.md) commands respectively. You can also use the [`configfile`](../commands/pwndbg/configfile.md) and [`themefile`](../commands/pwndbg/themefile.md) commands to save your live configuration to a file which you can then load in your `~/.(gdb/lldb)init` file (after sourcing Pwndbg!).\n\nTo see the value of any parameter, use `show param-name`. To set the value, use `set param-name param-value`. To see a more detailed description of the parameter use `help set param-name`.\n\nIf you wish to use a theme different from the default one, check out [pwndbg/pwndbg-themes](https://github.com/pwndbg/pwndbg-themes). If you made a theme yourself, feel free to open a PR!\n", "timestamp": "2025-10-21T13:21:26.796029"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/configuration/theme.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/configuration/theme.md", "content": "<!-- THIS WHOLE FILE IS AUTOGENERATED. DO NOT MODIFY IT. See scripts/generate-docs.sh -->\n\n\n\n\n# theme\n\n## **backtrace-address-color**\n\n\nColor for backtrace (address).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **backtrace-frame-label**\n\n\nFrame number label for backtrace.\n\n\n\n**Default:** ''  \n\n----------\n\n## **backtrace-frame-label-color**\n\n\nColor for backtrace (frame label).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **backtrace-prefix**\n\n\nPrefix for current backtrace label.\n\n\n\n**Default:** '►'  \n\n----------\n\n## **backtrace-prefix-color**\n\n\nColor for prefix of current backtrace label.\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **backtrace-symbol-color**\n\n\nColor for backtrace (symbol).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **banner-color**\n\n\nColor for banner line.\n\n\n\n**Default:** 'blue'  \n\n----------\n\n## **banner-separator**\n\n\nRepeated banner separator character.\n\n\n\n**Default:** '─'  \n\n----------\n\n## **banner-title-color**\n\n\nColor for banner title.\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **banner-title-position**\n\n\nBanner title position.\n\n\n\n**Default:** 'center'  \n**Valid values:** 'center', 'left', 'right'\n\n----------\n\n## **banner-title-surrounding-left**\n\n\nBanner title surrounding char (left side).\n\n\n\n**Default:** '[ '  \n\n----------\n\n## **banner-title-surrounding-right**\n\n\nBanner title surrounding char (right side).\n\n\n\n**Default:** ' ]'  \n\n----------\n\n## **bn-decomp-style**\n\n\nDecompilation highlight theme for Binary Ninja.\n\n\n\n**Default:** 'dark'  \n**Valid values:** 'dark', 'light'\n\n----------\n\n## **chain-arrow-color**\n\n\nColor of chain formatting (arrow).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **chain-arrow-left**\n\n\nLeft arrow of chain formatting.\n\n\n\n**Default:** '◂—'  \n\n----------\n\n## **chain-arrow-right**\n\n\nRight arrow of chain formatting.\n\n\n\n**Default:** '—▸'  \n\n----------\n\n## **chain-contiguous-marker**\n\n\nContiguous marker of chain formatting.\n\n\n\n**Default:** '...'  \n\n----------\n\n## **chain-contiguous-marker-color**\n\n\nColor of chain formatting (contiguous marker).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **code-prefix**\n\n\nPrefix marker for 'context code' command.\n\n\n\n**Default:** '►'  \n\n----------\n\n## **code-prefix-color**\n\n\nColor for 'context code' command (prefix marker).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **comment-color**\n\n\nColor for comment.\n\n\n\n**Default:** 'gray'  \n\n----------\n\n## **context-flag-bracket-color**\n\n\nColor for flags register (bracket).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **context-flag-changed-color**\n\n\nColor for flags register (flag changed).\n\n\n\n**Default:** 'underline'  \n\n----------\n\n## **context-flag-set-color**\n\n\nColor for flags register (flag set).\n\n\n\n**Default:** 'green,bold'  \n\n----------\n\n## **context-flag-unset-color**\n\n\nColor for flags register (flag unset).\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **context-flag-value-color**\n\n\nColor for flags register (register value).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **context-register-changed-color**\n\n\nColor for registers label (change marker).\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **context-register-changed-marker**\n\n\nChange marker for registers label.\n\n\n\n**Default:** '*'  \n\n----------\n\n## **context-register-color**\n\n\nColor for registers label.\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **disable-colors**\n\n\nWhether to color the output or not.\n\n\n\n**Default:** off  \n\n----------\n\n## **disasm-branch-color**\n\n\nColor for disasm (branch/call instruction).\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **disasm-branch-off**\n\n\nMarker for branches that will NOT be taken.\n\n\n\n**Default:** '✘'  \n\n----------\n\n## **disasm-branch-on**\n\n\nMarker for branches that WILL be taken.\n\n\n\n**Default:** '✔'  \n\n----------\n\n## **enhance-comment-color**\n\n\nColor of value enhance (comment).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **enhance-integer-value-color**\n\n\nColor of value enhance (integer).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **enhance-string-value-color**\n\n\nColor of value enhance (string).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **enhance-unknown-color**\n\n\nColor of value enhance (unknown value).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **go-dump-debug**\n\n\nColor for 'go-dump' command's debug info when --debug is specified.\n\n\n\n**Default:** 'blue'  \n\n----------\n\n## **hexdump-address-color**\n\n\nColor for hexdump command (address label).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **hexdump-ascii-block-separator**\n\n\nBlock separator char of the hexdump command.\n\n\n\n**Default:** '│'  \n\n----------\n\n## **hexdump-byte-separator**\n\n\nSeparator of single bytes in hexdump (does NOT affect group separator).\n\n\n\n**Default:** ' '  \n\n----------\n\n## **hexdump-colorize-ascii**\n\n\nWhether to colorize the hexdump command ascii section.\n\n\n\n**Default:** on  \n\n----------\n\n## **hexdump-highlight-group-lsb**\n\n\nHighlight LSB of each group.\n\nApplies only if hexdump-use-big-endian actually changes byte order.\n\n**Default:** 'underline'  \n\n----------\n\n## **hexdump-normal-color**\n\n\nColor for hexdump command (normal bytes).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **hexdump-offset-color**\n\n\nColor for hexdump command (offset label).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **hexdump-printable-color**\n\n\nColor for hexdump command (printable characters).\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **hexdump-separator-color**\n\n\nColor for hexdump command (group separator).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **hexdump-special-color**\n\n\nColor for hexdump command (special bytes).\n\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **hexdump-zero-color**\n\n\nColor for hexdump command (zero bytes).\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **highlight-breakpoints**\n\n\nWhether to highlight breakpoints.\n\n\n\n**Default:** on  \n\n----------\n\n## **highlight-color**\n\n\nColor added to highlights like source/pc.\n\n\n\n**Default:** 'green,bold'  \n\n----------\n\n## **highlight-pc**\n\n\nWhether to highlight the current instruction.\n\n\n\n**Default:** on  \n\n----------\n\n## **highlight-source**\n\n\nWhether to highlight the closest source line.\n\n\n\n**Default:** on  \n\n----------\n\n## **memory-code-color**\n\n\nColor for executable memory.\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **memory-data-color**\n\n\nColor for all other writable memory.\n\n\n\n**Default:** 'purple'  \n\n----------\n\n## **memory-guard-color**\n\n\nColor added to all guard pages (no perms).\n\n\n\n**Default:** 'cyan'  \n\n----------\n\n## **memory-heap-color**\n\n\nColor for heap memory.\n\n\n\n**Default:** 'blue'  \n\n----------\n\n## **memory-rodata-color**\n\n\nColor for all read only memory.\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **memory-stack-color**\n\n\nColor for stack memory.\n\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **memory-wx-color**\n\n\nColor added to all WX memory.\n\n\n\n**Default:** 'underline'  \n\n----------\n\n## **message-breakpoint-color**\n\n\nColor of breakpoint messages.\n\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **message-debug-color**\n\n\nColor of debug messages.\n\n\n\n**Default:** 'blue'  \n\n----------\n\n## **message-error-color**\n\n\nColor of error messages.\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **message-exit-color**\n\n\nColor of exit messages.\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **message-hint-color**\n\n\nColor of hint and marker messages.\n\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **message-info-color**\n\n\nColor of info messages.\n\n\n\n**Default:** 'white'  \n\n----------\n\n## **message-notice-color**\n\n\nColor of notice messages.\n\n\n\n**Default:** 'purple'  \n\n----------\n\n## **message-signal-color**\n\n\nColor of signal messages.\n\n\n\n**Default:** 'bold,red'  \n\n----------\n\n## **message-status-off-color**\n\n\nColor of off status messages.\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **message-status-on-color**\n\n\nColor of on status messages.\n\n\n\n**Default:** 'green'  \n\n----------\n\n## **message-success-color**\n\n\nColor of success messages.\n\n\n\n**Default:** 'green'  \n\n----------\n\n## **message-system-color**\n\n\nColor of system messages.\n\n\n\n**Default:** 'light-red'  \n\n----------\n\n## **message-warning-color**\n\n\nColor of warning messages.\n\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **nearpc-address-color**\n\n\nColor for nearpc command (address).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **nearpc-argument-color**\n\n\nColor for nearpc command (target argument).\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **nearpc-branch-marker**\n\n\nBranch marker line for nearpc command.\n\n\n\n**Default:** '    ↓'  \n\n----------\n\n## **nearpc-branch-marker-color**\n\n\nColor for nearpc command (branch marker line).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **nearpc-branch-marker-contiguous**\n\n\nContiguous branch marker line for nearpc command.\n\n\n\n**Default:** ' '  \n\n----------\n\n## **nearpc-breakpoint-color**\n\n\nColor for nearpc command (breakpoint marker).\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **nearpc-breakpoint-prefix**\n\n\nBreakpoint marker for nearpc command.\n\n\n\n**Default:** 'b+'  \n\n----------\n\n## **nearpc-integration-comments-color**\n\n\nColor for nearpc command (integration comments).\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **nearpc-prefix**\n\n\nPrefix marker for nearpc command.\n\n\n\n**Default:** '►'  \n\n----------\n\n## **nearpc-prefix-color**\n\n\nColor for nearpc command (prefix marker).\n\n\n\n**Default:** 'none'  \n\n----------\n\n## **nearpc-symbol-color**\n\n\nColor for nearpc command (symbol).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **nearpc-syscall-name-color**\n\n\nColor for nearpc command (resolved syscall name).\n\n\n\n**Default:** 'red'  \n\n----------\n\n## **prompt-alive-color**\n\n\nPrompt alive color.\n\n\n\n**Default:** 'bold,green'  \n\n----------\n\n## **prompt-color**\n\n\nPrompt color.\n\n\n\n**Default:** 'bold,red'  \n\n----------\n\n## **prop-name-color**\n\n\nColor used to highlight the name in name-value pairs.\n\n\nUsed heavily in mallocng commands.\n\n\n**Default:** 'bold'  \n\n----------\n\n## **prop-title-color**\n\n\nColor used to highlight the title of name-value pair groups.\n\n\nUsed heavily in mallocng commands.\n\n\n**Default:** 'green'  \n\n----------\n\n## **prop-value-color**\n\n\nColor used to highlight the value in name-value pairs.\n\n\nUsed heavily in mallocng commands.\n\n\n**Default:** 'yellow'  \n\n----------\n\n## **syntax-highlight-style**\n\n\nSource code / assembly syntax highlight stylename of pygments module.\n\n\n\n**Default:** 'monokai'  \n\n----------\n\n## **telescope-offset-color**\n\n\nColor of the telescope command (offset prefix).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **telescope-offset-delimiter**\n\n\nOffset delimiter of the telescope command.\n\n\n\n**Default:** ':'  \n\n----------\n\n## **telescope-offset-delimiter-color**\n\n\nColor of the telescope command (offset delimiter).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **telescope-offset-separator**\n\n\nOffset separator of the telescope command.\n\n\n\n**Default:** '│'  \n\n----------\n\n## **telescope-offset-separator-color**\n\n\nColor of the telescope command (offset separator).\n\n\n\n**Default:** 'normal'  \n\n----------\n\n## **telescope-register-color**\n\n\nColor of the telescope command (register).\n\n\n\n**Default:** 'bold'  \n\n----------\n\n## **telescope-repeating-marker**\n\n\nRepeating values marker of the telescope command.\n\n\n\n**Default:** '... ↓'  \n\n----------\n\n## **telescope-repeating-marker-color**\n\n\nColor of the telescope command (repeating values marker).\n\n\n\n**Default:** 'normal'  \n\n----------\n", "timestamp": "2025-10-21T13:21:26.973386"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/adding-a-command.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/adding-a-command.md", "content": "# Adding a Command\n## Command skeleton\nTo add a command to Pwndbg, create a new python file in `pwndbg/commands/my_command.py` where `my_command` is the name of the command you want to add.  The most basic command looks like this:\n```python\nimport argparse\nimport pwndbg.commands\n\nparser = argparse.ArgumentParser(description=\"Command description.\")\nparser.add_argument(\"arg\", type=str, help=\"An example argument.\")\n\n@pwndbg.commands.Command(parser, category=pwndbg.commands.CommandCategory.MISC)\ndef my_command(arg: str) -> None:\n    \"\"\"Print the argument\"\"\"\n    print(f\"Argument is {arg}\")\n```\nNext, import this file in the `load_commands` function in `pwndbg/commands/__init__.py`.\n\nThat's all you need to get it working!\n```text\npwndbg> my-command foo\nArgument is foo\n```\n## Getting started\nLet's see what arguments the `@pwndbg.commands.Command` decorator takes. It is defined in `pwndbg/commands/__init__.py`:\n```python\n    def __init__(\n        self,\n        parser_or_desc: argparse.ArgumentParser | str,\n        *,  # All further parameters are not positional\n        category: CommandCategory,\n        command_name: str | None = None,\n        aliases: List[str] = [],\n        examples: str = \"\",\n        notes: str = \"\",\n        only_debuggers: Set[pwndbg.dbg_mod.DebuggerType] = None,\n        exclude_debuggers: Set[pwndbg.dbg_mod.DebuggerType] = None,\n\t) -> None:\n\t\t# ...\n```\nWe will cover the first four arguments now, and come back to the rest later.\n\nIf your command takes no arguments you can pass the description of the command as the first argument (`parser_or_desc`) to the constructor. Otherwise you will be passing an [`argparse.ArgumentParser`](https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser) object there.\n\nThe only other required argument is `category`. The `category` determines how commands are grouped together in the output of the [`pwndbg`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/pwndbg/) command and in the [documentation](https://pwndbg.re/pwndbg/dev/commands/). Peruse the list of all commands inside a debugger (by running the `pwndbg` command) and decide in which category your command fits best. The enum of all command categories is defined at the top of the `pwndbg/commands/__init__.py` file.\n### Picking a command name\nNext, the `command_name` argument. It is optional because if it is not specified the command name will be the same as the function you used to define the command (except the underscores are replaced with dashes). As such, it is generally not needed to specify this argument.\n\nThat being said, it is important to pick a good name for your command. Ideally your command name should be one to two words that are *not* delimited by a dash (e.g. `errno`, `libcinfo`, `buddydump`) since that is easiest to remember and type.\n\nIf your command is porting behavior from some other debugger or tool, you should consider using the same name they use so users don't need to relearn it when switching.\n\nIf the command name contains three or more words, you should use dashes to make it more legible. If that is the case, or if the name is long, consider providing an alias that makes it quicker to type (like `vis-heap-chunks [vis]`).\n\nYou provide aliases to a command by specifying a list of strings to the `aliases` argument. Again, you may provide aliases to help users transitioning from other tools/debuggers (e.g. `nearpc [pdisass, u]`).\n## The arguments your command will take\nWe are using [`argparse.ArgumentParser`](https://docs.python.org/3/library/argparse.html#argparse.ArgumentParser) from the python standard library to define command arguments. Take a look at the python documentation to see how it works. Let's take a look at an example from the source (the [`setflag`](https://pwndbg.re/pwndbg/dev/commands/register/setflag/) command):\n```python\nparser = argparse.ArgumentParser(description=\"Modify the flags register.\")\n\nparser.add_argument(\n\t\"flag\",\n\ttype=str,\n\thelp=\"Flag for which you want to change the value\"\n )\n\nparser.add_argument(\n    \"value\",\n    type=int,\n    help=\"Value to which you want to set the flag - only valid options are 0 and 1\",\n)\n```\nFor usage inside Pwndbg, to instantiate an `argparse.ArgumentParser` object, you must pass the `description` argument and may pass the `epilog` argument. Everything else, including `prog`, `usage`, `formatter_class` etc. will be set up by Pwndbg (by the `@pwndbg.commands.Command` decorator). Here we see only the `description` was provided.\n\nAdd arguments to your command with [`parser.add_argument`](https://docs.python.org/3/library/argparse.html#the-add-argument-method). Again, consult the python documentation for an explanation. One nice thing specific to Pwndbg is that by setting an argument's `type` to `int`, it will also accept debugger values and symbols that can resolve to an int. For instance:\n```python\npwndbg> setflag ZF (1-1)\nSet flag ZF=0 in flag register eflags (old val=0x206, new val=0x206)\npwndbg> setflag ZF $rdi\nSet flag ZF=1 in flag register eflags (old val=0x246, new val=0x246)\npwndbg> setflag ZF (int)main^(int)main\nSet flag ZF=0 in flag register eflags (old val=0x246, new val=0x206)\n```\nBe careful when deciding which arguments are positional, and which are optional. Especially take care if you have positional arguments which are not required, think about which of those will be specified more often by users and put them first.\n\nYour function signature should match the arguments you defined with argparse (and their order!), unsurprisingly the `setflag` function has this signature:\n```python\ndef setflag(flag: str, value: int) -> None:\n```\nYou can see the help of your command with `my_command -h` or `help my_command`, so for `setflag`:\n```\npwndbg> help setflag\nusage: setflag [-h] flag value\n\nModify the flags register.\n\npositional arguments:\n  flag        Flag for which you want to change the value\n  value       Value to which you want to set the flag - only valid options are 0 and 1\n\noptions:\n  -h, --help  show this help message and exit\n\nExamples:\nOn X86/X64:\n    setflag ZF 1        -- set zero flag\n    setflag CF 0        -- unset carry flag\n\nOn ARM:\n    setflag Z 0         -- unset the Z cpsr/xpsr flag\n\nTo see flags registers:\n    info reg eflags     -- on x86/x64\n    info reg cpsr/xpsr  -- on ARM (specific register may vary)\n\nNotes:\nThis command supports flags registers that are defined for architectures in the pwndbg/regs.py file.\n\nAlias: flag\n```\nEh? Where is all that extra text coming from? Well the `Alias: flag` line is being automatically generated by Pwndbg but...\n## Examples, notes, and debugger support\nComing back to the arguments of the `pwndbg.commands.Command` constructor:\n```python\n    def __init__(\n        self,\n        parser_or_desc: argparse.ArgumentParser | str,\n        *,  # All further parameters are not positional\n        category: CommandCategory,\n        command_name: str | None = None,\n        aliases: List[str] = [],\n        examples: str = \"\",  #  <--- we left off here\n        notes: str = \"\",\n        only_debuggers: Set[pwndbg.dbg_mod.DebuggerType] = None,\n        exclude_debuggers: Set[pwndbg.dbg_mod.DebuggerType] = None,\n\t) -> None:\n\t\t# ...\n```\nYou may supply the `examples` and `notes` arguments to add additional text at the end of the command's help. It is defined like so for `setflag`:\n```python\n@pwndbg.commands.Command(\n    parser,\n    aliases=[\"flag\"],\n    category=CommandCategory.REGISTER,\n    examples=\"\"\"\nOn X86/X64:\n    setflag ZF 1        -- set zero flag\n    setflag CF 0        -- unset carry flag\n\nOn ARM:\n    setflag Z 0         -- unset the Z cpsr/xpsr flag\n\nTo see flags registers:\n    info reg eflags     -- on x86/x64\n    info reg cpsr/xpsr  -- on ARM (specific register may vary)\n    \"\"\",\n    notes=\"\"\"\nThis command supports flags registers that are defined for architectures in the pwndbg/regs.py file.\n    \"\"\",\n)\n@pwndbg.commands.OnlyWhenRunning\ndef setflag(flag: str, value: int) -> None:\n\t# ....\n```\nWhen writing this (and the command description for that matter), you should consider what it will [look like in the documentation](https://pwndbg.re/pwndbg/dev/commands/register/setflag/) after being parsed as markdown.\n\nAs for `only_debuggers` and `exclude_debuggers`, you must use (usually one of) them if your command does not work an all debuggers that Pwndbg supports. For instance, if it uses some features from `pwndbg.gdblib` (which should be avoided if at all possible). In such a case, you probably also need to conditionally import it in the `load_commands` function.\n## Can your command be invoked all the time?\nIn most cases a command cannot be legally invoked at every moment in a debugging session, or for every debugging session. For instance, you can't use heap commands if the heap isn't initialized yet, you can't use kernel commands if you're not debugging a kernel.\n\nTo make sure these cases are properly handled, Pwndbg provides certain decorators. They are defined in `pwndbg/commands/__init__.py`. Check the source to see an up-to-date list, but here are some important ones:\n```\nOnlyWhenRunning\nOnlyWhenLocal\nOnlyWithFile\nOnlyWhenQemuKernel\nOnlyWhenUserspace\nOnlyWithKernelDebugInfo\nOnlyWithKernelDebugSymbols\nOnlyWhenPagingEnabled\nOnlyWithTcache\nOnlyWhenHeapIsInitialized\nOnlyWithResolvedHeapSyms\n```\nFeel free to add more of these decorators yourself!\n\nAnother very important one is `OnlyWithArch`, defined in `pwndbg/aglib/proc.py`. Does your command work on all architectures? If not, make sure to specify this decorator and pass in the architectures which you do support.\n## Actually implementing the command\nThere is no single right way to do it. You will want to read the source of some similar commands and see how they work. Check out the [general developer notes](dev-notes.md), and feel free to ask a question on the [discord server](https://discord.gg/x47DssnGwm). Good luck!\n", "timestamp": "2025-10-21T13:21:27.296307"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/adding-a-parameter.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/adding-a-parameter.md", "content": "# Adding a Configuration Option\nConfiguration options are also called \"parameters\" in the source. Let's take a look at an existing parameter `gdb-workaround-stop-event` defined in `pwndbg/gdblib/events.py`.\n```python\nDISABLED = \"disabled\"\nDISABLED_DEADLOCK = \"disabled-deadlock\"\nENABLED = \"enabled\"\n\ngdb_workaround_stop_event = config.add_param(\n    \"gdb-workaround-stop-event\",\n    DISABLED,\n    \"asynchronous stop events to improve 'commands' functionality\",\n    help_docstring=f\"\"\"\nNote that this may cause unexpected behavior with Pwndbg or gdb.execute.\n\nValues explained:\n\n+ `{DISABLED}` - Disable the workaround (default).\n+ `{DISABLED_DEADLOCK}` - Disable only deadlock detection; deadlocks may still occur.\n+ `{ENABLED}` - Enable asynchronous stop events; gdb.execute may behave unexpectedly (asynchronously).\n    \"\"\",\n    param_class=pwndbg.lib.config.PARAM_ENUM,\n    enum_sequence=[DISABLED, DISABLED_DEADLOCK, ENABLED],\n)\n```\nTo understand it, let's also look at the signature of the `Config.add_param` function defined in `pwndbg/lib/config.py`:\n```python\n    def add_param(\n        self,\n        name: str,\n        default: Any,\n        set_show_doc: str,\n        *,\n        help_docstring: str = \"\",\n        param_class: int | None = None,\n        enum_sequence: Sequence[str] | None = None,\n        scope: Scope = Scope.config,\n    ) -> Parameter:\n\t    # ...\n```\nSo, the first argument specifies the name by which the parameter will be used inside the debugger. The second argument specifies the default value of the parameter.\n## set_show_doc\nThe third argument is a very brief description of what the parameter is for. The argument is called `set_show_doc` due to how it is used in GDB.\n```text\npwndbg> set gdb-workaround-stop-event enabled\nSet asynchronous stop events to improve 'commands' functionality to 'enabled'.\n   |------------------------------------------------------------|\n```\n```text\npwndbg> show gdb-workaround-stop-event\nAsynchronous stop events to improve 'commands' functionality is 'enabled'. [...]\n|-----------------------------------------------------------|\n```\nIt is therefore recommended to use a noun phrase rather than describe an action. However, it sometimes may be necessary to break this rule to retain the brevity of the description.\n\nThe `set_show_doc` argument should be short because it is displayed with the `config` family of commands.\n```text\npwndbg> config\nName                               Documentation                                                            Value (Default)\n----------------------------------------------------------------------------------------------------------------------------\nai-anthropic-api-key               Anthropic API key                                                        ''\nai-history-size                    maximum number of questions and answers to keep in the prompt            3\nai-max-tokens                      the maximum number of tokens to return in the response                   100\nai-model                           the name of the large language model to query                            'gpt-3.5-turbo'\nai-ollama-endpoint                 Ollama API endpoint                                                      ''\nai-openai-api-key                  OpenAI API key                                                           ''\nai-show-usage                      whether to show how many tokens are used with each OpenAI API call       off\nai-stack-depth                     rows of stack context to include in the prompt for the ai command        16\nai-temperature                     the temperature specification for the LLM query                          0\nattachp-resolution-method          how to determine the process to attach when multiple candidates exists   'ask'\nauto-explore-auxv                  stack exploration for AUXV information; it may be really slow            'warn'\nauto-explore-pages                 whether to try to infer page permissions when memory maps are missing    'warn'\nauto-explore-stack                 stack exploration; it may be really slow                                 'warn'\nauto-save-search                   automatically pass --save to \"search\" command                            off\nbn-autosync                        whether to automatically run bn-sync every step                          off\n[...]\n```\nBecause of the various contexts in which a parameter can be show, the first letter of the `set_show_doc` string should be lowercase (unless the first word is a name or an abbreviation) and there should be no punctuation at the end. This way, Pwndbg and GDB can more easily modify the string to fit it into these contexts.\n## help_docstring\nWhile `help_docstring` is not mandatory, it is highly recommended to use it. Put a detailed explanation of what the parameter does here, and explain any caveats. This string does not have a size limit and is shown with the following command in GDB and LLDB:\n```text\npwndbg> help set gdb-workaround-stop-event\nSet asynchronous stop events to improve 'commands' functionality.\nNote that this may cause unexpected behavior with Pwndbg or gdb.execute.\n\nValues explained:\n\n+ `disabled` - Disable the workaround (default).\n+ `disabled-deadlock` - Disable only deadlock detection; deadlocks may still occur.\n+ `enabled` - Enable asynchronous stop events; gdb.execute may behave unexpectedly (asynchronously).\n\nDefault: 'disabled'\nValid values: 'disabled', 'disabled-deadlock', 'enabled'\n```\nNote that the last two lines are automatically generated by Pwndbg.\n\nWhen writing this explanation, it is important to take into account how it will be displayed [in the documentation](https://pwndbg.re/pwndbg/dev/configuration/) after being parsed as markdown. See what `gdb-workaround-stop-event` looks like here: https://pwndbg.re/pwndbg/dev/configuration/config/#gdb-workaround-stop-event . If there wasn't an empty line between `Values explained:` and ``+ `disabled`..`` the list wouldn't have rendered properly.\n## param_class\nThis argument describes the type of the parameter. It will be used by GDB to perform input validation when the parameter is being set so it is important to set this to the correct value. The possible values are defined in `pwndbg/lib/config.py`, use the most restrictive one that fits:\n```python\n# Boolean value. True or False, same as in Python.\nPARAM_BOOLEAN = 0\n# Boolean value, or 'auto'.\nPARAM_AUTO_BOOLEAN = 1\n# Signed integer value. Disallows zero.\nPARAM_INTEGER = 2\n# Signed integer value.\nPARAM_ZINTEGER = 3\n# Unsigned integer value. Disallows zero.\nPARAM_UINTEGER = 4\n# Unsigned integer value.\nPARAM_ZUINTEGER = 5\n# Unlimited ZUINTEGER.\nPARAM_ZUINTEGER_UNLIMITED = 6\n# String value. Accepts escape sequences.\nPARAM_STRING = 7\n# String value, accepts only one of a number of possible values, specified at\n# parameter creation.\nPARAM_ENUM = 8\n# String value corresponding to the name of a file, if present.\nPARAM_OPTIONAL_FILENAME = 9\n```\nFor more information (for instance about what `None` or `\"unlimited\"` mean) see https://sourceware.org/gdb/current/onlinedocs/gdb.html/Parameters-In-Python.html .\n### enum_sequence\nIf the `param_class` is set to `pwndbg.lib.config.PARAM_ENUM` then the `enum_sequence` argument must be supplied as well. It should constitute an array of legal values. GDB and (our) LLDB (driver) won't allow setting the parameter to any other value. The legal values will be automatically displayed at the end of `help_docstring` as previously shown.\n\nIf it isn't immediately obvious what the enum values do, explain them in `help_docstring` using same format that `gdb-workaround-stop-event` uses.\n## scope\nThe `scope` argument has the default value of `pwndbg.lib.config.Scope.config` and is used to group parameters. The legal values are:\n```python\nclass Scope(Enum):\n    # If you want to add another scope here, don't forget to add\n    # a command which prints it!\n    config = 1\n    theme = 2\n    heap = 3\n```\nThe parameters of each scope are printed using a different command. The `config` scope is printed with [`config`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/config/), the `heap` scope is printed with [`heap-config`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/heap-config/) and the `theme` scope is printed with [`theme`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/theme/). The `config` and `theme` scopes also have corresponding [`configfile`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/configfile/) and [`themefile`](https://pwndbg.re/pwndbg/dev/commands/pwndbg/themefile/) commands which export the values of all the parameters from those scopes.\n### The `theme` scope\nYou should never directly pass this scope to `pwndbg.config.add_param`. Instead use the `pwndbg.color.theme.add_param` and `pwndbg.color.theme.add_color_param` wrapper commands like this:\n```python\n# pwndbg/aglib/nearpc.py\nnearpc_branch_marker = pwndbg.color.theme.add_param(\n    \"nearpc-branch-marker\", \"    ↓\", \"branch marker line for nearpc command\"\n)\n```\n```python\n# pwndbg/color/context.py\nconfig_highlight_color = theme.add_color_param(\n    \"highlight-color\", \"green,bold\", \"color added to highlights like source/pc\"\n)\n```\n## Using the parameter in code\nUsually when a parameter is defined its value is also set to a variable, for instance `gdb_workaround_stop_event = ...` in the initial example. This isn't necessary, as all registered parameters are available as `pwndbg.config.<parameter_name_except_with_underscores>` so in our example, we could also access the `gdb-workaround-stop-event` parameter as `pwndbg.config.gdb_workaround_stop_event`.\n\nThat being said, defining the variable can reduce code verbosity:\n```python\n# pwndbg/aglib/godbg.py\nline_width = pwndbg.config.add_param(\n    \"go-dump-line-width\", 80, \"the soft line width for go-dump pretty printing\"\n)\n```\nSince the variable is scoped to the `godbg.py` file, its name can be short, and we don't have to write `pwndbg.config.go_dump_line_width` every time.\n### Using color parameters\nNote that the `theme.add_color_param()` function returns a `ColorParameter` object instead of a `Parameter`. The parameter should be used via its `color_function()` method:\n```python\n# pwndbg/aglib/godbg.py\ndef fmt_debug(self, val: str, default: str = \"\") -> str:\n\tif self.debug:\n\t\treturn debug_color.color_function(val)\n\telse:\n\t\treturn default\n```\nThough you will also see `generateColorFunction(debug_color)(val)` being used in the code to the same effect.\n", "timestamp": "2025-10-21T13:21:27.414729"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/dev-notes.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/dev-notes.md", "content": "# Developer Notes\n\n## Random developer notes\n\nFeel free to update the list below!\n\n* If you want to play with Pwndbg functions under GDB, you can always use GDB's `pi` which launches python interpreter or just `py <some python line>`.\n\n* If you want to do the same in LLDB, you should type `lldb`, followed by `script`, which brings up an interactive Python REPL. Don't forget to `import pwndbg`!\n\n* Do not access debugger-specific functionality - eg. anything that uses the `gdb`, `lldb`, or `gdblib` modules - from outside the proper module in `pwndbg.dbg`.\n\n* Use `aglib` instead of `gdblib`, as the latter is [in the process of being removed](https://github.com/pwndbg/pwndbg/issues/2489). Both modules should have nearly identical interfaces, so doing this should be a matter of typing `pwndbg.aglib.X` instead of `pwndbg.gdblib.X`. Ideally, an issue should be opened if there is any functionality present in `gdblib` that's missing from `aglib`.\n\n* We have our own `pwndbg.config.Parameter` - read about it in [Adding a Configuration Option](adding-a-parameter.md).\n\n* The dashboard/display/context we are displaying is done by `pwndbg/commands/context.py` which is invoked through GDB's and LLDB's prompt hook, which are defined, respectively, in `pwndbg/gdblib/prompt.py` as `prompt_hook_on_stop`, and in `pwndb/dbg/lldb/hooks.py` as `prompt_hook`.\n\n* We change a bit GDB settings - this can be seen in `pwndbg/dbg/gdb.py` under `GDB.setup` - there are also imports for all Pwndbg submodules.\n\n* Pwndbg has its own event system, and thanks to it we can set up code to be invoked in response to them. The event types and the conditions in which they occurr are defined and documented in the `EventType` enum, and functions are registered to be called on events with the `@pwndbg.dbg.event_handler` decorator. Both the enum and the decorator are documented in `pwndbg/dbg/__init__.py`.\n\n* We have a caching mechanism ([\"memoization\"](https://en.wikipedia.org/wiki/Memoization)) which we use through Python's decorators - those are defined in `pwndbg/lib/cache.py` - just check its usages\n\n* To block a function before the first prompt was displayed use the `pwndbg.decorators.only_after_first_prompt` decorator.\n\n* Memory accesses should be done through `pwndbg/aglib/memory.py` functions.\n\n* Process properties can be retrieved thanks to `pwndbg/aglib/proc.py` - e.g. using `pwndbg.aglib.proc.pid` will give us current process pid\n\n\n* We have a wrapper for handling exceptions that are thrown by commands - defined in `pwndbg/exception.py` - current approach seems to work fine - by using `set exception-verbose on` - we get a stacktrace. If we want to debug stuff we can always do `set exception-debugger on`.\n\n* Some of Pwndbg's functionality require us to have an instance of `pwndbg.dbg.Value` - the problem with that is that there is no way to define our own types in either GDB or LLDB - we have to ask the debugger if it detected a particular type in this particular binary (that sucks). We do that in `pwndbg/aglib/typeinfo.py` and it works most of the time. The known bug with that is that it might not work properly for Golang binaries compiled with debugging symbols.\n\n## Support for Multiple Debuggers\n\nPwndbg is a tool that supports multiple debuggers, and so using debugger-specific functionality\noutside of `pwndbg.dbg.X` is generally discouraged, with one imporant caveat, that we will get into\nlater. When adding code to Pwndbg, one must be careful with the functionality being used.\n\n### The Debugger API\n\nOur support for multiple debuggers is primarily achieved through use of the Debugger API, found\nunder `pwndbg/dbg/`, which defines a terse set of debugging primitives that can then be built upon\nby the rest of Pwndbg. It comprises two parts: the interface, and the implementations. The interface\ncontains the abstract classes and the types that lay out the \"shape\" of the functionality that may\nbe used by the rest of Pwndbg, and the implementations, well, _implement_ the interface on top of each\nsupported debugger.\n\nAs a matter of clarity, it makes sense to think of the Debugger API as a debugger-agnostic version\nof the `lldb` and `gdb` Python modules. Compared to both modules, it is much closer in spirit to\n`lldb` than to `gdb`.\n\nIt is important to note that a lot of care must be exercised when adding things to the Debugger API,\nas one must always add implementations for all supported debuggers of whatever new functionality is\nbeing added, even if only to properly gate off debuggers in which the functionality is not supported.\nAdditionally, it is important to keep the Debugger API interfaces as terse as possible in order to\nreduce code duplication. As a rule of thumb, if all the implementations of an interface are expected\nto share code, that interface is probably better suited for `aglib`, and it should be further broken\ndown into its primitives, which can then be added to the Debugger API.\n\nSome examples of debugging primitives are memory reads, memory writes, memory map acquisition,\nsymbol lookup, register reads and writes, and execution frames. These are all things that one can\nfind in both the GDB and LLDB APIs.\n\nThe entry point for the Debugger API is `pwndbg.dbg`, though most process-related methods are accessed\nthrough a `Process` object. Unless you really know what you're doing, you're going to want to use the\nobjected yielded by `pwndbg.dbg.selected_inferior()` for this.\n\n### `aglib`\n\nAlong with the Debugger API, there is also `aglib`, found under `pwndbg/aglib/`, in which lives\nfunctionality that is both too broad for a single command, and that can be shared between multiple\ndebuggers. Things like QEMU handling, ELF and dynamic section parsing, operating system functionality,\ndisassembly with capstone, heap analysis, and more, all belong in `aglib`.\n\nIn order to facilitate the process of porting Pwndbg to the debugger-agnostic interfaces, and also\nbecause of its historical roots, `aglib` is intended to export the exact same functionality provided\nby `gdblib`, but on top of a debugger-agnostic foundation.\n\nIf it helps, one may think of `aglib` like a `pwndbglib`. It takes the debugging primitives provided\nby the Debugger API and builds the more complex and interesting bits of functionality found in\nPwndbg on top of them.\n\n### Mappings from GDB and LLDB to the Debugger API\n\nHere are some things one may want to do, along with how they can be achieved in the GDB, LLDB, and\nPwndbg Debugger APIs.\n\n=== \"GDB\"\n    Setting a breakpoint at an address:\n    ```python\n    gdb.Breakpoint(\"*<address>\")\n    ```\n    Querying for the address of a symbol:\n    ```python\n    int(gdb.lookup_symbol(<name>).value().address)\n    ```\n    Setting a watchpoint at an address:\n    ```python\n    gdb.Breakpoint(f\"(char[{<size>}])*{<address>}\", gdb.BP_WATCHPOINT)\n    ```\n\n=== \"LLDB\"\n    Setting a breakpoint at an address:\n    ```python\n    lldb.target.BreakpointCreateByAddress(<address>)\n    ```\n    Querying for the address of a symbol:\n    ```python\n    lldb.target.FindSymbols(<name>).GetContextAtIndex(0).symbol.GetStartAddress().GetLoadAddress(lldb.target)\n    ```\n    Setting a watchpoint at an address:\n    ```python\n    lldb.target.WatchAddress(<address>, <size>, ...)\n    ```\n\n=== \"Debugger API\"\n    ```python\n    # Fetch a Process object on which we will operate.\n    inf = pwndbg.dbg.selected_inferior()\n    ```\n    Setting a breakpoint at an address:\n    ```python\n    inf.break_at(BreakpointLocation(<address>))\n    ```\n    Querying for the address of a symbol:\n    ```python\n    inf.lookup_symbol(<name>)\n    ```\n    Setting a watchpoint at an address:\n    ```python\n    inf.break_at(WatchpointLocation(<address>, <size>))\n    ```\n\n### Exception to use of Debugger-agnostic interfaces\n\nSome commands might not make any sense outside the context of a single debugger. For these commands,\nit is generally okay to talk to the debugger directly. However, they must be properly marked as\ndebugger-specific and their loading must be properly gated off behind the correct debugger. They\nshould ideally be placed in a separate location from the rest of the commands in `pwndbg/commands/`.\n\n## Porting public tools\n\nIf porting a public tool to Pwndbg, please make a point of crediting the original author. This can be added to [CREDITS.md](https://github.com/pwndbg/pwndbg/blob/dev/CREDITS.md) noting the original author/inspiration, and linking to the original tool/article. Also please be sure that the license of the original tool is suitable to porting into Pwndbg, such as MIT.\n\n## Minimum Supported Versions\n\nOur goal is to fully support all Ubuntu LTS releases that have not reached end-of-life, with support for other\nplatforms on a best-effort basis. Currently that means all code should work on Ubuntu 22.04, and 24.04 with GDB\n12.1 and later. This means that the minimum supported Python version is 3.10, and we cannot use any newer\nPython features unless those features are backported to this minimum version.\n\nNote that while all code should run without errors on these supported LTS versions, it's fine if older versions\ndon't support all of the features of newer versions, as long as this is handled correctly and this information\nis shown to the user. For example, we may make use of some GDB APIs in newer versions that we aren't able to\nprovide alternative implementations for in older versions, and so in these cases we should inform the user that\nthe functionality can't be provided due to the version of GDB.\n\nThe `lint.sh` script described in the previous section runs [`vermin`](https://github.com/netromdk/vermin) to\nensure that our code does not use any features that aren't supported on Python 3.10.\n", "timestamp": "2025-10-21T13:21:27.535836"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/improving-annotations.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/improving-annotations.md", "content": "# Improving Annotations\n\nAlongside the disassembled instructions in the dashboard, Pwndbg also has the ability to display annotations - text that contains relevent information regarding the execution of the instruction. For example, on the x86 `MOV` instruction, we can display the concrete value that gets placed into the destination register. Likewise, we can indicate the results of mathematical operations and memory accesses. The annotation in question is always dependent on the exact instruction being annotated - we handle it in a case-by-case basis.\n\nThe main hurdle in providing annotations is determining what each instruction does, getting the relevent CPU registers and memory that are accessed, and then resolving concrete values of the operands. We call the process of determining this information \"enhancement\", as we enhance the information provided natively by GDB.\n\nThe Capstone Engine disassembly framework is used to statically determine information about instructions and their operands. Take the x86 instruction `sub rax, rdx`. Given the raw bytes of the machine instructions, Capstone creates an object that provides an API that, among many things, exposes the names of the operands and the fact that they are both 8-byte wide registers. It provides all the information necessary to describe each operand. It also tells the general 'group' that a instruction belongs to, like if its a JUMP-like instruction, a RET, or a CALL. These groups are architecture agnostic.\n\nHowever, the Capstone Engine doesn't fill in concrete values that those registers take on. It has no way of knowing the value in `rdx`, nor can it actually read from memory.\n\nTo determine the actual values that the operands take on, and to determine the results of executing an instruction, we use the Unicorn Engine, a CPU emulator framework. The emulator has its own internal CPU register set and memory pages that mirror that of the host process, and it can execute instructions to mutate its internal state. Note that the Unicorn Engine cannot execute syscalls - it doesn't have knowledge of a kernel.\n\nWe have the ability to single-step the emulator - tell it to execute the instruction at the program counter inside the emulator. After doing so, we can inspect the state of the emulator - read from its registers and memory. The Unicorn Engine itself doesn't expose information regarding what each instruction is doing - what is the instruction (is it an `add`, `mov`, `push`?) and what registers/memory locations is it reading to and writing from? - which is why we use the Capstone engine to statically determine this information.\n\nUsing what we know about the instruction based on the Capstone engine - such as that it was a `sub` instruction and `rax` was written to - we query the emulator after stepping in to determine the results of the instruction.\n\nWe also read the program counter from the emulator to determine jumps and so we can display the instructions that will actually be executed, as opposed to displaying the instructions that follow consecutively in memory.\n\n## Enhancing\n\nEverytime the inferior process stops (and when the `disasm` context section is displayed), we display the next handful of assembly instructions in the dashboard so the user can understand where the process is headed. The exact amount is determined by the `context-disasm-lines` setting.\n\nWe will be enhancing the instruction at the current program counter, as well as all the future instructions that are displayed. The end result of enhancement is that we get a list of `PwndbgInstruction` objects, each encapsulating relevent information regarding the instructions execution.\n\nWhen the process stops, we instantiate the emulator from scratch. We copy all the registers from the host process into the emulator. For performance purposes, we register a handler to the Unicorn Engine to lazily map memory pages from the host to the emulator when they are accessed (a page fault from within the emulator), instead of immediately copying all the memory from the host to the emulator.\n\nThe enhancement is broken into a couple stops:\n\n1. First, we resolve the values of all the operands of the instruction before stepping the emulator. This means we read values from registers and dereference memory depending on the operand type. This gives us the values of operands before the instruction executes.\n2. Then, we step the emulator, executing a single instruction.\n3. We resolve the values of all operands again, giving us the `after_value` of each operand.\n4. Then, we enhance the \"condition\" field of PwndbgInstructions, where we determine if the instruction is conditional (conditional branch or conditional mov are common) and if the action is taken.\n5. We then determine the `next` and `target` fields of PwndbgInstructions. `next` is the address that the program counter will take on after using the GDB command `nexti`, and `target` indicates the target address of branch/jump/PC-changing instructions.\n6. With all this information determined, we now effectively have a big switch statement, matching on the instruction type, where we set the `annotation` string value, which is the text that will be printed alongside the instruction in question.\n\nWe go through the enhancement process for the instruction at the program counter and then ensuing handful of instructions that are shown in the dashboard.\n\n## When to use emulation / reasoning about process state\n\nIn general, the code aims to be organized in a way as to allow as many features as possible even in the absence of emulation. If there is information that can be determined statically, then we try to expose it as an alternative to emulation. This is so we can display annotations even when the Unicorn Engine is disabled. For example, say we come to a stop, and are faced with enhancing the following three instructions in the dashboard:\n\n```asm\n1.     lea    rax, [rip + 0xd55]\n2. >   mov    rsi, rax      # The host process program counter is here\n3.     mov    rax, rsi\n```\n\nInstruction 1, the `lea` instruction, is already in the past - we pull our enhanced PwndbgInstruction for it from a cache.\n\nInstruction 2, the first `mov` instruction, is where the host process program counter is at. If we did `stepi` in GDB, this instruction would be executed. In this case, there is two ways we can determine the value that gets written to `rsi`.\n\n1. After stepping the emulator, read from the emulators `rsi` register.\n2. Given the context of the instruction, we know the value in `rsi` will come from `rax`. We can just read the `rax` register from the host. This avoids emulation.\n\nThe decision on which option to take is implemented in the annotation handler for the specific instruction. When possible, we have a preference for the second option, because it makes the annotations work even when emulation is off.\n\nThe reason we could do the second option, in this case, is because we could reason about the process state at the time this instruction would execute. This instruction is about to be executed (`Program PC == instruction.address`). We can safely read from `rax` from the host, knowing that the value we get is the true value it takes on when the instruction will execute. It must - there are no instructions in-between that could have mutated `rax`.\n\nHowever, this will not be the case while enhancing instruction 3 while we are paused at instruction 2. This instruction is in the future, and without emulation, we cannot safely reason about the operands in question. It is reading from `rsi`, which might be mutated from the current value that `rsi` has in the stopped process (and in this case, we happen to know that it will be mutated). We must use emulation to determine the `before_value` of `rsi` in this case, and can't just read from the host processes register set. This principle applies in general - future instructions must be emulated to be fully annotated. When emulation is disable, the annotations are not as detailed since we can't fully reason about process state for future instructions.\n\n## What if the emulator fails?\n\nIt is possible for the emulator to fail to execute an instruction - either due to a restrictions in the engine itself, or the instruction inside segfaults and cannot continue. If the Unicorn Engine fails, there is no real way we can recover. When this happens, we simply stop emulating for the current step, and we try again the next time the process stops when we instantiate the emulator from scratch again.\n\n## Caching annotations\n\nWhen we are stepping through the emulator, we want to remember the annotations of the past couple instructions. We don't want to `nexti`, and suddenly have the annotation of the previously executed instruction deleted. At the same time, we also never want stale annotations that might result from coming back to point in the program to which we have stepped before, such as the middle of a loop via a breakpoint.\n\nNew annotations are only created when the process stops, and we create annotations for next handful of instructions to be executed. If we `continue` in GDB and stop at a breakpoint, we don't want annotations to appear behind the PC that are from a previous time we were near the location in question. To avoid stale annotations while still remembering them when stepping, we have a simple caching method:\n\nWhile we are doing our enhancement, we create a list containing the addresses of the future instructions that are displayed.\n\nFor example, say we have the following instructions with the first number being the memory address:\n\n```gdb\n   0x555555556259 <main+553>    lea    rax, [rsp + 0x90]\n   0x555555556261 <main+561>    mov    edi, 1                          EDI => 1\n   0x555555556266 <main+566>    mov    rsi, rax\n   0x555555556269 <main+569>    mov    qword ptr [rsp + 0x78], rax\n   0x55555555626e <main+574>    call   qword ptr [rip + 0x6d6c]    <fstat64>\n\n ► 0x555555556274 <main+580>    mov    edx, 5                  EDX => 5\n   0x555555556279 <main+585>    lea    rsi, [rip + 0x3f30]     RSI => 0x55555555a1b0 ◂— 'standard output'\n   0x555555556280 <main+592>    test   eax, eax\n   0x555555556282 <main+594>    js     main+3784                   <main+3784>\n\n   0x555555556288 <main+600>    mov    rsi, qword ptr [rsp + 0xc8]\n   0x555555556290 <main+608>    mov    edi, dword ptr [rsp + 0xa8]\n```\n\nIn this case, our `next_addresses_cache` would be `[0x555555556279, 0x555555556280, 0x555555556282, 0x555555556288, 0x555555556290]`.\n\nThen, the next time our program comes to a stop (after using `si`, `n`, or any GDB command that continues the process), we immediately check if the current program counter is in this list. If it is, then we can infer that the annotations are still valid, as the program has only executed a couple instructions. In all other cases, we delete our cache of annotated instructions.\n\nWe might think \"why not just check if it's the next address - 0x555555556279 in this case? Why a list of the next couple addresses?\". This is because when source code is available, `step` and `next` often skip a couple instructions. It would be jarring to remove the annotations in this case. Likewise, this method has the added benefit that if we stop somewhere, and there happens to be a breakpoint only a couple instructions in front of us that we `continue` to, then previous couple annotations won't be wiped.\n\n## Other random annotation details\n\n- We don't emulate through CALL instructions. This is because the function might be very long.\n- We resolve symbols during the enhancement stage for operand values.\n- The folder [`pwndbg/aglib/disasm`](https://github.com/pwndbg/pwndbg/tree/dev/pwndbg/aglib/disasm) contains the code for enhancement. It follows an object-oriented model, with `arch.py` implementing the parent class with shared functionality, and the per-architecture implementations are implemented as subclasses in their own files.\n- `pwndbg/aglib/nearpc.py` is responsible for getting the list of enhanced PwndbgInstruction objects and converting them to the output seen in the 'disasm' view of the dashboard.\n\n## Adding or fixing annotations\n\nWe annotate on an instruction-by-instruction basis. Effectively, imagine a giant `switch` statement that selects the correct handler to create an annotation based on the specific instruction. Many instruction types can be grouped and annotated using the same logic, such as `load`, `store`, and `arithmetic` instructions.\n\nSee [`pwndbg/aglib/disasm/aarch64.py`](https://github.com/pwndbg/pwndbg/tree/dev/pwndbg/aglib/disasm/aarch64.py) as an example. We define sets that group instructions using the unique Capstone ID for each instruction, and inside the constructor of `DisassemblyAssistant` we have a mapping of instructions to a specific handler. The `_set_annotation_string` function will match the instruction to the correct handler, which set the `instruction.annotation` field.\n\nIf there is a bug in an annotation, the first order of business is finding its annotation handler. To track down where we are handling the instruction, you can search for its Capstone constant. For example, the RISC-V store byte instruction, `sb`, is represented as the Capstone constant `RISCV_INS_SB`. Or, if you are looking for the handler for the AArch64 instruction SUB, you can search the disasm code for `_INS_SUB` to find where we reference the appropriate Capstone constant for the instruction and following the code to the function that ultimately sets the annotation.\n\nIf an annotation is causing a crash, is it most likely due to a handler making an incorrect assumption on the number of operands, leading to a `list index out of range` error. One possible source of this is that a given instruction has multiple different disassembly representations. Take the RISC-V `JALR` instruction. It can be represented in 3 ways:\n\n```asm\njalr rs1        # return register is implied as ra, and imm is implied as 0\njalr rs1, imm   # return register is implied as ra\njalr rd, rs1, imm\n```\n\nCapstone will expose the most \"simplified\" one possible, and the underlying list of register operands will change. If the handler doesn't take these different options into account, and rather assumes that `jalr` always has 3 operands, then an index error can occur if the handler accesses `instruction.operands[2]`.\n\n## Bug root cause\n\nWhen encountering an instruction that is behaving strangely (incorrect annotation, or there is a jump target when one shouldn't exist, or the target is incorrect), there are a couple routine things to check.\n\n1\\. Use the `dev-dump-instruction` command to print all the enhancement information. With no arguments, it will dump the info from the instruction at the current address. If given an address, it will pull from the instruction cache at the corresponding location.\n\nIf the issue is not related to branches, check the operands and the resolved values for registers and memory accesses. Verify that the values are correct - are the resolved memory locations correct? Step past the instruction and use instructions like `telescope` and `regs` to read memory and verify if the claim that the annotation is making is correct. For things like memory operands, you can try to look around the resolved memory location in memory to see the actual value that the instruction dereferenced, and see if the resolved memory location is simply off by a couple bytes.\n\nExample output of dumping a `mov` instruction:\n\n```\nmov qword ptr [rsp], rsi at 0x55555555706c (size=4) (arch: x86)\n        ID: 460, mov\n        Raw asm: mov    qword ptr [rsp], rsi\n        New asm: mov    qword ptr [rsp], rsi\n        Next: 0x555555557070\n        Target: 0x555555557070, Target string=, const=None\n        Condition: UNDETERMINED\n        Groups: []\n        Annotation: [0x7fffffffe000] => 0x7fffffffe248 —▸ 0x7fffffffe618 ◂— '/usr/bin/ls'\n        Operands: [['[0x7fffffffe000]': Symbol: None, Before: 0x7fffffffe000, After: 0x7fffffffe000, type=CS_OP_MEM, size=8, access=CS_AC_WRITE]] ['RSI': Symbol: None, Before: 0x7fffffffe248, After: 0x7fffffffe248, type=CS_OP_REG, size=8, access=CS_AC_READ]]]\n        Conditional jump: False. Taken: False\n        Unconditional jump: False\n        Declare unconditional: None\n        Can change PC: False\n        Syscall:  N/A\n        Causes Delay slot: False\n        Split: NO_SPLIT\n        Call-like: False\n```\n\n2\\. Use the Capstone disassembler to verify the number of operands the instruction groups.\n\nTaken the raw instruction bytes and pass them to `cstool` to see the information that we are working with:\n\n```sh\ncstool -d mips 0x0400000c\n```\n\nThe number of operands may not match the visual appearance. You might also check the instruction groups, and verify that an instruction that we might consider a `call` has the Capstone `call` group. Capstone is not 100% correct in every single case in all architectures, so it's good to verify. Report a bug to Capstone if there appears to be an error, and in the meanwhile we can create a fix in Pwndbg to work around the current behavior.\n\n3\\. Check the state of the emulator.\n\nGo to [pwndbg/emu/emulator.py](https://github.com/pwndbg/pwndbg/tree/dev/pwndbg/emu/emulator.py) and uncomment the `DEBUG = -1` line. This will enable verbose debug printing. The emulator will print it's current `pc` at every step, and indicate important events, like memory mappings. Likewise, in [pwndbg/aglib/disasm/arch.py](https://github.com/pwndbg/pwndbg/tree/dev/pwndbg/aglib/disasm/arch.py) you can set `DEBUG_ENHANCEMENT = True` to print register accesses to verify they are sane values.\n\nPotential bugs:\n\n- A register is 0 (may also be the source of a Unicorn segfault if used as a memory operand) - often means we are not copying the host processes register into the emulator. By default, we map register by name - if in Pwndbg, it's called `rax`, then we find the UC constant named `U.x86_const.UC_X86_REG_RAX`. Sometimes, this default mapping doesn't work, sometimes do to differences in underscores (`FSBASE` vs `FS_BASE`). In these cases, we have to manually add the mapping.\n- Unexpected crash - the instruction at hand might require a 'coprocessor', or some information that is unavailable to Unicorn (it's QEMU under the hood).\n- Instructions are just no executing - we've seen this in the case of Arm Thumb instructions. There might be some specific API/way to invoke the emulator that is required for a certain processor state.\n\n## Creating small cross-architecture programs\n\nIf you are encountering a strange behavior with a certain instruction or scenario in a non-native-architecture program, you can use some great functions from `pwntools` to handle the compilation and debugging. This is a great way to create a small reproducible example to isolate an issue.\n\nThe following Python program, when run from inside a `tmux` session, will take some AArch64 assembly, compile it, and run it with GDB attached in a new `tmux` pane. It will search your system for the appropriate cross compiler for the architecture at hand, and run the compiled binary with QEMU.\n\n```python\nfrom pwn import *\n\ncontext.arch = \"aarch64\"\n\nAARCH64_GRACEFUL_EXIT = \"\"\"\nmov x0, 0\nmov x8, 93\nsvc 0\n\"\"\"\n\nout = make_elf_from_assembly(STORE)\n# Debug info\nprint(out)\ngdb.debug(out)\n\npause()\n```\n", "timestamp": "2025-10-21T13:21:27.680280"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/index.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/index.md", "content": "# Contributing Guide\n\n## Contributing Overview\nThank you for your interest in contributing to Pwndbg!\n\nNote that while it is recommended that your pull request (PR) links to an issue (which can be used for discussing the bug / feature), you do not need to be assigned to it - just create the PR and it will be reviewed.\n\nTo start, [install Pwndbg from source and set it up for development](setup-pwndbg-dev.md).\nFor common tasks see:\n\n+ [Adding a command](adding-a-command.md)\n+ [Adding a configuration option](adding-a-parameter.md)\n+ [Improving annotations](improving-annotations.md)\n\nRegardless of the contents of your PR, you will need to [lint](#linting) and [test](#running-tests) your code so make sure to read those sections. It is also likely you will need to [update the documentation](#updating-documentation).\n\nRead [General developer notes](dev-notes.md) to get more familiar with the various systems in place in Pwndbg. If you have any questions don't hesitate to ask us on our [discord server](https://discord.gg/x47DssnGwm)!\n## Linting\nThe `lint.sh` script runs isort, ruff, shfmt, and vermin. isort and ruff (mostly) are able to automatically fix any issues they detect. You may apply all available fixes by running\n```{.bash .copy}\n./lint.sh -f\n```\n!!! note\n    You can find the configuration files for these tools in `pyproject.toml` or by checking the arguments passed inside `lint.sh`.\n\nWhen submitting a PR, the continuous integration (CI) job defined in `.github/workflows/lint.yml` will verify that running `./lint.sh` succeeds, otherwise the job will fail and we won't be able to merge your PR.\n\nIt is recommended to enable the pre-push git hook to run the lint if you haven't already done so. You may re-run `./setup-dev.sh` to set it.\n## Running tests\nYour PR will not be merged without passing the testing CI. Moreover, it is highly recommended you write a new test or update an existing test whenever adding new functionality to Pwndbg. To see how to do this, check out [Writing tests](writing-tests.md).\n\nTo run the tests in the same environment as the testing CI, you can use the following docker commands.\n```{.bash .copy}\n# General (x86_64) test suite\ndocker compose run --rm --build ubuntu24.04-mount ./tests.sh -d gdb -g gdb\n# Cross-architecture tests\ndocker compose run --rm --build ubuntu24.04-mount ./tests.sh -d gdb -g cross-arch-user\n# Kernel tests (x86_64 and aarch64)\ndocker compose run --rm --build ubuntu24.04-mount ./kernel-tests.sh\n# Unit tests\ndocker compose run --rm --build ubuntu24.04-mount ./unit-tests.sh\n```\nThis comes in handy particularly for cross-architecture tests because the docker environment has all the cross-compilers installed. The active `pwndbg` directory is mounted, preventing the need for a full rebuild whenever you update the codebase.\n\nRemove the `-mount` if you want the tests to run from a clean slate (no files are mounted, meaning all binaries are recompiled each time).\n\nIf you wish to focus on some failing tests, you can filter the tests to run by providing an argument to the script, such as `<docker..> ./tests.sh heap`, which will only run tests that contain \"heap\" in the name. See `./tests.sh --help` for more information and other options. You can also do this with the cross-arch and kernel tests.\n\nIf you want to, you may also [run the tests with nix](#running-tests-with-nix) or [run them bare](#running-without-docker).\n\n#### Running tests with nix\nYou will need to build a nix-compatible `gdbinit.py` file, which you can do with\n```{.bash .copy}\nnix build .#pwndbg-dev\n```\nThen simply run the test by adding the `--nix` flag:\n```{.bash .copy}\n./tests.sh --nix [filter]\n```\n#### Running without docker\nIf you wish to improve Pwndbg support for your distribution (or the testing infrastructure) you may run the testing suite without the docker container.\n\nThe commands are analogous to the docker commands.\n```{.bash .copy}\n# General (x86_64) test suite\n./tests.sh -d gdb -g gdb\n# Cross-architecture tests\n./tests.sh -d gdb -g cross-arch-user\n# Kernel tests (x86_64 and aarch64)\n./kernel-tests.sh\n# Unit tests\n./unit-tests.sh\n```\n\n## Updating Documentation\nAll the documentation is written in markdown files in the `./docs/` folder. The docs are built into a website using [mkdocs](https://www.mkdocs.org/) (you may see the configuration in `./mkdocs.yml`), pushed to the gh-pages branch, and published via [github pages](https://pages.github.com/). All of this happens in the CI.\n\nIn general, for your PR to be accepted you will only need to [Update the auto-generated documentation](#update-the-auto-generated-documentation).\n\n### Update the auto-generated documentation\nThe `./docs/commands`, `./docs/functions`, and `./docs/configuration` folders are automatically generated[^1] by extracting the necessary information from the source code. If your changes modify things like a command's description, a configuration's valid values, a [convenience function's](../functions/index.md) arguments - i.e. pretty much anything that's user-facing - you must run\n```{.bash .copy}\n./scripts/generate-docs.sh\n```\nto update the documentation. You need to have a supported version of GDB *and* [LLDB installed](setup-pwndbg-dev.md#running-with-lldb) for this to work. Commit these changes in a separate commit.\n\nIf you forget to do that the CI will detect a discrepency between the documentation and source code (using the `./scripts/verify-docs.sh` script, which you may also invoke yourself) and prevent your PR from being merged (until you push new changes, re-running the CI).\n\n### Manual updates\nOf course, if you wish to update some other part of the documentation, you may simply modify the necessary markdown files. All autogenerated files (or parts of files) will have noticable markers written as markdown comments, for instance:\n```md\n<!-- THIS PART OF THIS FILE IS AUTOGENERATED. DO NOT MODIFY IT. See scripts/generate-docs.sh -->\n```\nIn case you want to add something that cannot be cleanly viewed from the debugger, like a video, screenshot, or long example, every command markdown file also has a dedicated part at the bottom for hand-written text which you can use. The `./scripts/generate-docs.sh` script will never delete these hand-written parts, so if you are for instance renaming a command you will have to transfer this part by copy pasting it to the new file.\n\nIf you wish to preview the documentation locally, you may do so by running:\n```{.bash .copy}\n./scripts/docs-live.sh\n```\nThe build will take some time due to the `Source` section being built. You may disable this by temporarily commenting these lines\n```\n  - api-autonav:\n      modules: ['pwndbg']\n      nav_section_title: \"Source\"\n```\nin the `mkdocs.yml` file. This will provide much faster build times (but make sure not to commit those changes!). Visit `http://127.0.0.1:8000/pwndbg/` to see the docs. Note that the `Home` section will not be available (it is generated in the CI by copying the README.md), and the site will lack the version selector.\n\n[^1]: Actually, the `./docs/configuration/index.md` file is hand-written, and the intro text to the `./docs/functions/index.md` file is defined in the doc generating file's source code.\n", "timestamp": "2025-10-21T13:21:27.791743"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/making-a-gif.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/making-a-gif.md", "content": "# Making a Pwndbg gif\n\n## The rundown\n\nIf you wish to make a gif of your terminal while using Pwndbg (usually to add an example of some command/workflow to the website) you should use [charmbracelet/vhs](https://github.com/charmbracelet/vhs). This ensures a consistent look to the gifs throughout the documentation, makes them easily updateable when UI changes are made, and just makes them more easily reproducable and modifiable in general.\n\n!!! note\n    Here \"gif\" really means \"a video that loops\", in practice it is better to use `.webm` with `.mp4` as a fallback because they are better optimized file formats.\n\nThe workflow to creating a gif is simple. Start a recording:\n```{.bash .copy}\nvhs record > my_thingy.tape\n```\nWhatever you now do in the terminal will be \"recorded\" to the `my_thingy.tape` file. Exit the shell to save the recording. The tape probably isn't ready to use as-is. You will want to add some metadata and fixup some lines.\n??? example\n\n    This is the tape used to generate the gif at https://pwndbg.re/pwndbg/dev/commands/context/context/ :\n    ```bash\n    # https://github.com/charmbracelet/vhs\n\n    Output pwndbg.mp4\n    Output pwndbg.webm\n\n    Set FontSize 24\n    Set Width 1920\n    Set Height 1080\n    Set TypingSpeed 100ms\n\n    Sleep 1s\n    Type \"pwndbg /bin/sh\"\n    Enter\n    Sleep 2s\n    Type \"start\"\n    Enter\n    Sleep 3s\n    Type \"stepsyscall\"\n    Sleep 3s\n    Enter 1\n    Sleep 3s\n    Type \"up\"\n    Sleep 1s\n    Enter 1\n    Sleep 1s\n    Type \"up\"\n    Sleep 1s\n    Enter 1\n    Sleep 1s\n    Type \"up\"\n    Sleep 1s\n    Enter 1\n    Sleep 1s\n    Type \"context\"\n    Sleep 4s\n    Enter 1\n    Sleep 7s\n    Type \"down\"\n    Sleep 1s\n    Enter 1\n    Sleep 1s\n    Type \"ctx\"\n    Sleep 4s\n    Enter 1\n    Sleep 7s\n    ```\n\nYou may now run\n```{.bash .copy}\nvhs my_thingy.tape\n```\nand it will generate a gif with the filename you specified in the tape (the `Output` line in the example).\n\nMake sure to commit the `.tape` file along with the gif.\n\n## Recording in Docker\n\nIf the setup for the gif is not highly involved, you may want to use a Dockerfile to generate the gif to ensure reproducability (or if wish to make sure your environment variables aren't visible during the debugging session). Here is a sample Dockerfile you can modify to your liking:\n```{.Dockerfile .copy}\n# https://github.com/charmbracelet/vhs\nFROM ghcr.io/charmbracelet/vhs\n\n# Install Pwndbg\nRUN apt update && apt install -y git \\\n    && git clone https://github.com/pwndbg/pwndbg.git /pwndbg \\\n    && cd /pwndbg \\\n    && ./setup.sh\n\n# Create a pwndbg executable in PATH so we can run with\n# `pwndbg /bin/sh`.\nRUN echo '#!/bin/sh\\ngdb --quiet \"$@\"' > /usr/local/bin/pwndbg \\\n    && chmod +x /usr/local/bin/pwndbg\n\n# Make sure uv.lock.hash is created so we don't get\n# a message about updating during the gif.\nRUN gdb /bin/sh --batch\n\n# The ENTRYPOINT and CMD are defined in the vhs docker image.\n```\nyou can use a script like this to run it easily.\n```{.bash .copy}\n#!/bin/sh\n\nset -e\n\nIMAGE_NAME=\"vhs-pwndbg\"\n\nrm -f .gdb_history\ndocker build -t \"$IMAGE_NAME\" .\ndocker run --rm -v \"$(pwd)\":/vhs \"$IMAGE_NAME\" my_thingy.tape\n```\n", "timestamp": "2025-10-21T13:21:27.902744"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/setup-pwndbg-dev.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/setup-pwndbg-dev.md", "content": "# Setup Pwndbg for Development\n\n## Installing Pwndbg from source\n\nRun the following:\n```{.bash .copy}\ngit clone https://github.com/pwndbg/pwndbg\ncd pwndbg\n./setup.sh\n```\nOfficially supported is Ubuntu 22.04 and later, but the setup script also supports the following distributions:\n\n* Debian-based OSes (via apt-get)\n* Fedora and Red Hat (via dnf)\n* Clear (via swiped)\n* OpenSUSE LEAP (via zypper)\n* Arch and Manjaro (via community AUR packages)\n* Void (via xbps)\n* Gentoo (via emerge)\n\n!!! tip\n    If you have an older ubuntu version you may still use Pwndbg:\n\n    - for Ubuntu 20.04 use the [2024.08.29 release](https://github.com/pwndbg/pwndbg/releases/tag/2024.08.29)\n    - for Ubuntu 18.04 use the [2023.07.17: ubuntu18.04-final release](https://github.com/pwndbg/pwndbg/releases/tag/2023.07.17)\n\n    however if you wish to contribute, it is recommended you upgrade your distribution.\n\n### Running with GDB\nPwndbg requires GDB 12.1 or later. If the GDB version your distro provides is too old, [build GDB from source](https://sourceware.org/gdb/wiki/BuildingNatively):\n```{.bash .copy}\nsudo apt install libgmp-dev libmpfr-dev libreadline-dev texinfo  # required by build\ngit clone git://sourceware.org/git/binutils-gdb.git\nmkdir gdb-build\ncd gdb-build\n../binutils-gdb/configure --enable-option-checking --disable-nls --disable-werror --with-system-readline --with-python=$(which python3) --with-system-gdbinit=/etc/gdb/gdbinit --enable-targets=all --disable-binutils --disable-ld --disable-gold --disable-gas --disable-sim --disable-gprof\nmake -j $(nproc)\n```\nSince the `./setup.sh` script made it so you source Pwndbg from your `~/.gdbinit`, Pwndbg will start up automatically any time you run `gdb`.\n\n### Running with LLDB\nPwndbg requires LLDB 19 or later. You can get it like this on Ubuntu 24.04:\n```{.bash .copy}\nsudo apt install -y lldb-19 liblldb-19-dev\n```\nbut it will be added to your PATH as `lldb-19` so you should either alias it or export it in your shell:\n```{.bash .copy}\nexport PATH=/usr/lib/llvm-19/bin/:$PATH\n```\nso you can invoke it as `lldb`. Also export this environment variable:\n```{.bash .copy}\nexport LLDB_DEBUGSERVER_PATH=/usr/lib/llvm-19/bin/lldb-server\n```\nPwndbg doesn't use the `lldb` driver binary directly, it drives its own REPL and interacts with LLDB through liblldb.\nYou can run Pwndbg with LLDB by running:\n```{.bash .copy}\nuv run pwndbg-lldb [binary-to-debug]\n```\n\n## The development environment\n\nAfter installing Pwndbg like described above, there are a few ways to set up the development environment. The simplest one is by running:\n```{.bash .copy}\n./setup-dev.sh\n```\nbut you can also use the [docker container](#development-from-docker) or [develop using nix](#development-using-nix).\n\n!!! note\n    For a proper development environment you must be able to run Pwndbg with both GDB and LLDB, otherwise you won't be able to use some important development features (like doc generation).\n\n### Development from docker\nYou can create a Docker image with everything already installed for you. You can use docker compose\n```{.bash .copy}\ndocker compose run -i main\n```\nor build and run the container with\n```{.bash .copy}\ndocker build -t pwndbg .\ndocker run -it --cap-add=SYS_PTRACE --security-opt seccomp=unconfined -v `pwd`:/pwndbg pwndbg bash\n```\n\n### Development using Nix\nPwndbg supports development with Nix which installs all the required\ndevelopment dependencies:\n\n1. Install Nix with [Determinate Nix Installer](https://github.com/DeterminateSystems/nix-installer?tab=readme-ov-file#determinate-nix-installer).\n2. Enter the development shell with `nix develop` or automate this with `direnv`.\n3. Run local changes with `pwndbg` or `pwndbg-lldb`. Run tests with `./tests.sh`.\n", "timestamp": "2025-10-21T13:21:28.013172"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/contributing/writing-tests.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/contributing/writing-tests.md", "content": "# Writing Tests\n\n## Overview\n\n!!! note\n    This is written under the assumption you already know how to [run the tests](../contributing/index.md#running-tests).\n\nIn Pwndbg we have four types of tests: extensive x86_64 GDB tests, cross-architecture tests, linux kernel tests\nand unit-tests. They are all located in subdirectories of [`./tests`](https://github.com/pwndbg/pwndbg/tree/dev/tests).\n\nThe x86_64 tests encompass most of the Pwndbg testing suite. If your tests do not belong in any of the other\ncategories, they should go here. Since we do not yet perform testing on LLDB, these are run from inside GDB\nand are located in the [`./tests/library/gdb`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/gdb/)\ndirectory. They can be run with `./tests.sh -d gdb -g gdb`.\n\nThe cross-architecture tests are run using qemu-user emulation. They test architecture-specific logic and\nare located in the [`./tests/library/qemu-user`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/qemu-user)\ndirectory. They can be run with `./tests.sh -d gdb -g cross-arch-user`.\n\nThe linux kernel tests are run using qemu-system emulation. They are located in the\n[`./tests/library/qemu_system`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/qemu-system)\ndirectory and run for a variety kernel configurations and architectures.\n\nThe unit tests are not run from within a debugger, but rather directly with pytest. They are located\nin the [`./tests/unit_tests/`](https://github.com/pwndbg/pwndbg/tree/dev/tests/unit-tests)\ndirectory.\n\nHere are the options supported by `./tests.sh` which you can get by running `./tests.sh -h`.\n```\nusage: tests.py [-h] -g {gdb,dbg,cross-arch-user} -d {gdb} [-p] [-c] [-v] [-s] [--nix] [--collect-only] [test_name_filter]\n\nRun tests.\n\npositional arguments:\n  test_name_filter      run only tests that match the regex\n\noptions:\n  -h, --help            show this help message and exit\n  -g {gdb,dbg,cross-arch-user}, --group {gdb,dbg,cross-arch-user}\n  -d {gdb}, --driver {gdb}\n  -p, --pdb             enable pdb (Python debugger) post mortem debugger on failed tests\n  -c, --cov             enable codecov\n  -v, --verbose         display all test output instead of just failing test output\n  -s, --serial          run tests one at a time instead of in parallel\n  --nix                 run tests using built for nix environment\n  --collect-only        only show the output of test collection, don't run any tests\n```\n## Writing tests\n\nEach test is a Python function that runs inside of an isolated GDB session.\nUsing a [`pytest`](https://docs.pytest.org/en/latest/) fixture at the beginning of each test,\nGDB will attach to a [`binary`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/gdb/conftest.py)\nor connect to a [`QEMU instance`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/qemu-user/conftest.py).\nEach test runs some commands and uses Python `assert` statements to verify correctness. We can access Pwndbg\nlibrary code like `pwndbg.aglib.regs.rsp` as well as execute GDB commands with `gdb.execute()`.\n\nWe can take a look at [`tests/library/gdb/tests/test_symbol.py`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/gdb/tests/test_symbol.py)\nfor an example of a simple test. Looking at a simplified version of the top-level code, we have this:\n\n```python\nimport gdb\nimport pwndbg\nimport tests\n\nBINARY = tests.get_binary(\"symbol_1600_and_752.out\")\n```\n\nSince these tests run inside GDB, we can import the `gdb` Python library. We also import the `tests` module,\nwhich makes it easy to get the path to the test binaries located in [`tests/gdb-tests/tests/binaries`](https://github.com/pwndbg/pwndbg/tree/dev/tests/gdb-tests/tests/binaries).\nYou should be able to reuse the binaries in this folder for most tests, but if not feel free to add a new one.\n\nHere's a small snippet of the actual test:\n\n```python\ndef test_hexdump(start_binary):\n    start_binary(BINARY)\n    pwndbg.config.hexdump_group_width.value = -1\n\n    gdb.execute(\"set hexdump-byte-separator\")\n    stack_addr = pwndbg.aglib.regs.rsp - 0x100\n```\n\n`pytest` will run any function that starts with `test_` as a new test, so there is no need to register your new\ntest anywhere. The `start_binary` argument is a function that will run the binary you give it, and it will set\nsome common options before starting the binary. Using `start_binary` is recommended if you don't need any\nadditional customization to GDB settings before starting the binary, but if you do it's fine to not use it.\n\n## QEMU Tests\n\nOur `gdb` tests run in x86. To debug other architectures, we use QEMU for emulation and attach to its debug\nport. These tests are located in\n[`tests/library/qemu-user/tests`](https://github.com/pwndbg/pwndbg/tree/dev/tests/library/qemu-user/tests).\nTest creation is identical to our x86 tests - create a Python function with a Pytest fixture name as\nthe parameter (it matches based on the name), and call the argument to start debugging a binary. The\n`qemu_assembly_run` fixture takes in a Python string of assembly code, compiles it in the\nappropriate architecture, and runs it - no need to create an external file or edit a Makefile.\n", "timestamp": "2025-10-21T13:21:28.118811"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/features.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/features.md", "content": "---\nhide:\n  - navigation\n---\n\n<!--\n  This document should give an overview of some of the most interesting\n  features Pwndbg has to offer. Use a lot of screenshots and recordings.\n  Don't go too much in-depth - it is better to write a tutorial in another\n  page of the docs and simply link to it.\n-->\n\n# Features\n\nPwndbg has a great deal of useful features. You can a see all available commands at any time by typing the `pwndbg` command or by checking the [Commands section](commands/index.md) of the documentation. For configuration and theming see the [Configuration section](configuration/index.md). Below is a subset of commands which are easy to capture in screenshots.\n\n## Disassembly and Emulation\n\nPwndbg leverages the [capstone](https://github.com/capstone-engine/capstone) and [unicorn](https://github.com/unicorn-engine/unicorn) engines, along with its own instrospection, to display, annotate and emulate instructions.\n\nOperands of instructions are resolved, conditions evaluated, and only the instructions that will actually be executed are shown.\n\n![](assets/caps/disasm_example.png)\n\nThis is incredibly useful when stepping through jump tables, PLT entries, and ROPping.\n\n![](assets/caps/emulation_rop.png)\n\n## Context\n\nA useful summary of the current execution context is printed every time the debugger stops (e.g. breakpoint or single-step), displaying all registers, the stack, call frames, disassembly, and additionally recursively dereferencing all pointers.  All memory addresses are color-coded to the type of memory they represent.\n\n![](assets/caps/context.png)\n\nA history of previous context output is kept which can be accessed using the `contextprev` and `contextnext` commands.\n\n### Arguments\n\nAll function call sites are annotated with the arguments to those functions.  This works best with debugging symbols, but also works in the most common case where an imported function (e.g. libc function via GOT or PLT) is used.\n\n![](assets/caps/arguments_getenv.png)\n![](assets/caps/arguments_memcpy.png)\n![](assets/caps/arguments_sigsetjmp.png)\n![](assets/caps/arguments_strcpy.png)\n![](assets/caps/arguments_syscall.png)\n![](assets/caps/arguments_xtraceinit.png)\n\n### Splitting / Layouting Context\n\nThe context sections can be distributed among different tty by using the `contextoutput` command. Thus, if you want to make better use of some of the empty space in the default Pwndbg output, you can split the panes in your terminal and redirect the various contexts among them.\n\n![](assets/caps/context_splitting.png)\n\nSee [Splitting the Context](tutorials/splitting-the-context.md) for more information.\n\n### GDB TUI\nThe context sections are available as native [GDB TUI](https://sourceware.org/gdb/current/onlinedocs/gdb.html/TUI.html) windows named `pwndbg_[sectionname]`. There are some predefined layouts coming with Pwndbg which you can select using `layout pwndbg` or `layout pwndbg_code`.\n\n![](assets/caps/context_tui.png)\n\nSee [GDB TUI](tutorials/gdb-tui.md) for more information.\n\n### Watch Expressions\n\nYou can add expressions to be watched by the context. Those expressions are evaluated and shown on every context refresh. For instance by doing `contextwatch execute \"info args\"` we can see the arguments of every function we are in (here we are in `mmap`):\n\n![](assets/caps/cwatch_infoargs.png)\n\nSee [`contextwatch`](commands/context/contextwatch.md) for more information.\n\n## Integrations\n\n### Ghidra\n\nWith the help of [radare2](https://github.com/radareorg/radare2) or [rizin](https://github.com/rizinorg/rizin) it is possible to show the decompiled source code of the ghidra decompiler.\n\nSee [Ghidra Integration](tutorials/decompiler-integration/ghidra-integration.md) for more information.\n\n### IDA Pro/Binary Ninja\n\nPwndbg is capable of integrating with IDA Pro or Binary Ninja by installing an XMLRPC server in the decompiler as a plugin, and then querying it for information.\n\nThis allows extraction of comments, decompiled lines of source, breakpoints, symbols, and synchronized debugging (single-steps update the cursor in the decompiler).\n\n![](assets/caps/ida_context.png){ style=\"width: 70%;\" }\n\nSee [Binary Ninja Integration](tutorials/decompiler-integration/binja-integration.md) or [IDA Integration](tutorials/decompiler-integration/ida-integration.md) for setup information.\n\n## Heap Inspection\n\nPwndbg provides commands for inspecting the heap and the allocator's state. Currently supported are:\n\n+ [glibc malloc](commands/index.md#glibc-ptmalloc2-heap)\n+ [jemalloc](commands/index.md#jemalloc-heap)\n+ [linux's buddy allocator](commands/kernel/buddydump.md)\n+ [linux's SLUB allocator](commands/kernel/slab.md)\n\nSee *some* of the commands for glibc malloc:\n![](assets/caps/heap_vis.png){ style=\"width: 70%;\" }\n![](assets/caps/heap_hi_bins.png){ style=\"width: 70%;\" }\n![](assets/caps/heap_try_free.png)\n![](assets/caps/heap_find_fake_fast.png){ style=\"width: 70%;\" }\n\n## LLDB\n\nWhile most other GDB plugins are well *GDB plugins*, Pwndbg's implementation is debugger-agnostic. You can use Pwndbg with LLDB!\n\n![](assets/caps/lldb.png){ style=\"width: 70%;\" }\n\n## WinDbg Compatibility\n\nFor those coming from a Windows background, Pwndbg has a complete WinDbg compatibility layer.  You can `dd`, `dps`, `eq`, and even `eb $rip 90` to your heart's content.\n\n![](assets/caps/windbg.png){ style=\"width: 70%;\" }\n\n## Go Debugging\n\nPwndbg has support for dumping complex Go values like maps and slices, including automatically parsing out type layouts in certain cases.\n\nSee the [Go debugging guide](tutorials/go-debugging.md) for more information.\n\n## So many commands\n\nGo take a look at [Commands](commands/index.md)! Here is some cool stuff you can do to get you started.\n\n### Process State Inspection\n\nUse the [`procinfo`](commands/process/procinfo.md) command in order to inspect the current process state, like UID, GID, Groups, SELinux context, and open file descriptors! Pwndbg works particularly well with remote GDB debugging like with Android phones.\n\n![](assets/caps/procinfo.png){ style=\"width: 50%;\" }\n![](assets/caps/procinfo_curl.png){ style=\"width: 50%;\" }\n\n### ROP Gadgets\n\nTools for finding rop gadgets statically don't know about everything that will be loaded into the address space and they can make mistakes about which addresses will actually end up executable. You can now rop at runtime with Pwndbg's [`rop`](commands/integrations/rop.md) and [`ropper`](commands/integrations/ropper.md).\n\n![](assets/caps/rop_grep.png){ style=\"width: 70%;\" }\n\n### Search\n\nPwndbg makes [`search`](commands/memory/search.md)ing the target memory space easy, with a complete and easy-to-use interface.  Whether you're searching for bytes, strings, or various sizes of integer values or pointers, it's a simple command away.\n\n![](assets/caps/search.png)\n\n### Finding Leaks\nFinding leak chains can be done using the [`leakfind`](commands/memory/leakfind.md) and [`probeleak`](commands/memory/probeleak.md) commands. They recursively inspect address ranges for pointers, and report on all pointers found.\n\n![](assets/caps/leakfind.png)\n![](assets/caps/probeleak.png)\n\n### Telescope\nInspecting memory dumps is easy with the [`telescope`](commands/memory/telescope.md) command.  It recursively dereferences a range of memory, letting you see everything at once.  As an added bonus, Pwndbg checks all of the available registers to see if they point into the memory range.\n\n![](assets/caps/telescope.png){ style=\"width: 70%;\" }\n\n### Virtual Memory Maps\nPwndbg enhances the standard memory map listing and allows easy searching with [`vmmap`](commands/memory/vmmap.md).\n\n![](assets/caps/vmmap.png){ style=\"width: 70%;\" }\n![](assets/caps/vmmap_rip.png){ style=\"width: 70%;\" }\n\n### Tracking glibc heap allocations\nIt can be very useful to see allocations happening in real time. It can give us a good idea of what the allocation pattern of a program looks like, and allows us to make informed decisions on how to optimize or attack it. The [`track-heap`](commands/linux_libc_elf/track-heap.md) command does just that.\n\n<video style=\"width: 80%;\" autoplay loop muted playsinline alt=\"track-heap example\">\n  <source src=\"../assets/videos/track-heap.webm\" type=\"video/webm\">\n  <source src=\"../assets/videos/track-heap.mp4\" type=\"video/mp4\">\n</video>\n\n### Tracking the GOT\nThe Procedure Linkage Table (PLT) and Global Offset Table (GOT) are very interesting exploitation targets since they contain many often-accessed function pointers. You can track how your program goes through the GOT using the [`track-got`](commands/linux_libc_elf/track-got.md) command.\n\n<video autoplay loop muted playsinline alt=\"track-got example\">\n  <source src=\"../assets/videos/track-got.webm\" type=\"video/webm\">\n  <source src=\"../assets/videos/track-got.mp4\" type=\"video/mp4\">\n</video>\n\n### Attach to a process by name\nThe days of running pidof in a different terminal are over. Use [`attachp`](commands/start/attachp.md) to attach to any process by name, pid, arguments or device file!\n\n![](assets/caps/attachp.png){ style=\"width: 70%;\" }\n", "timestamp": "2025-10-21T13:21:28.217279"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/functions/index.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/functions/index.md", "content": "---\nhide:\n  - navigation\n---\n<!-- THIS WHOLE FILE IS AUTOGENERATED. DO NOT MODIFY IT. See scripts/generate-docs.sh -->\n\n\n\n\n# Functions\n\n\nPwndbg provides a set of functions which can be used during expression evaluation to\nquickly perform common calculations. These can even be passed to other commands as arguments.\nCurrently, they **only work in gdb**.\n\nTo see a list of all functions, including those built into GDB, use `help function`. To see\nthe help of any given function use `help function function_name`. Function invocation must\ninclude a preceding $ sign and must include brackets. For instance, invoke the `environ`\nfunction like so:\n```\npwndbg> p $environ(\"LANG\")\n$2 = (signed char *) 0x7fffffffe6da \"LANG=en_US.UTF-8\"\n```\nIf the result of the function is being passed to a Pwndbg command, make sure to either escape\nthe function argument's quotes, or put the whole function call in quotes.\n```\npwndbg> tele $environ(\"LANG\")\nusage: telescope [-h] [-r] [-f] [-i] [address] [count]\ntelescope: error: argument address: debugger couldn't resolve argument '$environ(LANG)':\n    No symbol \"LANG\" in current context.\npwndbg> tele $environ(\\\"LANG\\\")\n00:0000│  0x7fffffffe6cf ◂— 'LANG=en_US.UTF-8'\n01:0008│  0x7fffffffe6d7 ◂— 'US.UTF-8'\n02:0010│  0x7fffffffe6df ◂— 0x4e49475542454400\n[...]\npwndbg> tele '$environ(\"LANG\")'\n00:0000│  0x7fffffffe6cf ◂— 'LANG=en_US.UTF-8'\n01:0008│  0x7fffffffe6d7 ◂— 'US.UTF-8'\n02:0010│  0x7fffffffe6df ◂— 0x4e49475542454400\n[...]\n```\n## Pwndbg functions\n\n### **argc**\n\n\n``` {.python .no-copy}\nargc() -> int\n```\n\n\nGet the number of program arguments.\nEvaluates to argc.\n\n#### Example\n```\npwndbg> p $argc()\n$1 = 2\npwndbg> argv\n00:0000│  0x7fffffffe288 —▸ 0x7fffffffe659 ◂— '/usr/bin/cat'\n01:0008│  0x7fffffffe290 —▸ 0x7fffffffe666 ◂— 'gdbinit.py'\n02:0010│  0x7fffffffe298 ◂— 0\n```\n\n----------\n\n### **argv**\n\n\n``` {.python .no-copy}\nargv(index: gdb.Value) -> gdb.Value\n```\n\n\nGet the n-th program argument.\nEvaluate argv on the supplied value.\n\n#### Example\n```\npwndbg> p $argv(0)\n$11 = (signed char *) 0x7fffffffe666 \"/usr/bin/sh\"\npwndbg> argv\n00:0000│  0x7fffffffe2a8 —▸ 0x7fffffffe666 ◂— '/usr/bin/sh'\n01:0008│  0x7fffffffe2b0 ◂— 0\n```\n\n----------\n\n### **base**\n\n\n``` {.python .no-copy}\nbase(name_pattern: gdb.Value | str)\n```\n\n\nReturn the base address of the first memory mapping containing the given name.\n\n#### Example\n```\npwndbg> p/x $base(\"libc\")\n$4 = 0x7ffff7d4b000\npwndbg> vmmap libc\n    0x7ffff7d4a000     0x7ffff7d4b000 rw-p     1000  6e000 /usr/lib/libncursesw.so.6.5\n►   0x7ffff7d4b000     0x7ffff7d6f000 r--p    24000      0 /usr/lib/libc.so.6\n►   0x7ffff7d6f000     0x7ffff7ed6000 r-xp   167000  24000 /usr/lib/libc.so.6\n►   0x7ffff7ed6000     0x7ffff7f2b000 r--p    55000 18b000 /usr/lib/libc.so.6\n►   0x7ffff7f2b000     0x7ffff7f2f000 r--p     4000 1e0000 /usr/lib/libc.so.6\n►   0x7ffff7f2f000     0x7ffff7f31000 rw-p     2000 1e4000 /usr/lib/libc.so.6\n    0x7ffff7f31000     0x7ffff7f39000 rw-p     8000      0 [anon_7ffff7f31]\npwndbg> tele $base(\\\"libc\\\")+0x1337\n00:0000│  0x7ffff7d4c337 ◂— 0x80480a04214000f0\n01:0008│  0x7ffff7d4c33f ◂— 0x8040c02204452040\n02:0010│  0x7ffff7d4c347 ◂— 0x20042400000200\n03:0018│  0x7ffff7d4c34f ◂— 0x20 /* ' ' */\n[...]\n```\n\nBeware of accidentally matching the wrong mapping. For instance, if the loaded\nexecutable contained the string \"libc\" anywhere in it's path, it would've been\nreturned.\n\n----------\n\n### **bn_eval**\n\n\n``` {.python .no-copy}\nbn_eval(expr: gdb.Value) -> int | None\n```\n\n\nParse and evaluate a Binary Ninja expression.\n\nRead more about binary ninja expressions here:\nhttps://api.binary.ninja/binaryninja.binaryview-module.html#binaryninja.binaryview.BinaryView.parse_expression\n\nAll registers in the current register set are available as magic variables (e.g. $rip).\nThe $piebase magic variable is also included, with the computed executable base.\n\nThis function cannot see stack local variables.\n\n#### Example\n```\npwndbg> set integration-provider binja\nPwndbg successfully connected to Binary Ninja (4.2.6455 Personal) xmlrpc: http://127.0.0.1:31337\nSet which provider to use for integration features to 'binja'.\npwndbg> p/x $bn_eval(\"10+20\")\n$6 = 0x30\npwndbg> p/x $bn_eval(\"main\")\n$7 = 0x1645\npwndbg> p/x $rebase($bn_eval(\"main\"))\n$8 = 0x555555555645\npwndbg> p some_global_var\nNo symbol \"some_global_var\" in current context.\npwndbg> p/x $rebase($bn_eval(\"some_global_var+$rax\"))\n$9 = 0x5555555586b8\npwndbg> p $rebase($bn_eval(\"some_global_var+$rax\")) == $bn_sym(\"some_global_var\") + $rax\n$10 = 1\npwndbg> p $bn_eval(\"$piebase+some_global_var+$rax\") == $bn_sym(\"some_global_var\") + $rax\n$11 = 1\n```\n\n----------\n\n### **bn_sym**\n\n\n``` {.python .no-copy}\nbn_sym(name_val: gdb.Value) -> int | None\n```\n\n\nLookup a symbol's address by name from Binary Ninja.\n\nThis function sees symbols like functions and global variables,\nbut not stack local variables, use `bn_var` for that.\n\n#### Example\n```\npwndbg> set integration-provider binja\nPwndbg successfully connected to Binary Ninja (4.2.6455 Personal) xmlrpc: http://127.0.0.1:31337\nSet which provider to use for integration features to 'binja'.\npwndbg> p main\nNo symbol \"main\" in current context.\npwndbg> p/x $bn_sym(\"main\")\n$2 = 0x555555555645\npwndbg> b *($bn_sym(\"main\"))\nBreakpoint 1 at 0x555555555645\n```\n\n----------\n\n### **bn_var**\n\n\n``` {.python .no-copy}\nbn_var(name_val: gdb.Value) -> int | None\n```\n\n\nLookup a stack variable's address by name from Binary Ninja.\n\nThis function doesn't see functions or global variables,\nuse `bn_sym` for that.\n\n#### Example\n```\npwndbg> set integration-provider binja\nPwndbg successfully connected to Binary Ninja (4.2.6455 Personal) xmlrpc: http://127.0.0.1:31337\nSet which provider to use for integration features to 'binja'.\npwndbg> p user_choice\nNo symbol \"user_choice\" in current context.\npwndbg> p/x $bn_var(\"user_choice\")\n$4 = 0x7fffffffe118\npwndbg> vmmap $4\n    0x7ffff7ffe000     0x7ffff7fff000 rw-p     1000      0 [anon_7ffff7ffe]\n►   0x7ffffffde000     0x7ffffffff000 rw-p    21000      0 [stack] +0x20118\npwndbg> p/x $bn_var(\"main\")\nTypeError: Could not convert Python object: None.\nError while executing Python code.\n```\n\n----------\n\n### **environ**\n\n\n``` {.python .no-copy}\nenviron(env_name: gdb.Value) -> gdb.Value\n```\n\n\nGet an environment variable by name.\nEvaluate getenv() on the supplied value.\n\n#### Example\n```\npwndbg> p $environ(\"LANG\")\n$2 = (signed char *) 0x7fffffffebfb \"LANG=en_US.UTF-8\"\n```\n\n----------\n\n### **envp**\n\n\n``` {.python .no-copy}\nenvp(index: gdb.Value) -> gdb.Value\n```\n\n\nGet the n-th environment variable.\nEvaluate envp on the supplied value.\n\n#### Example\n```\npwndbg> p $envp(0x3F)\n$13 = (signed char *) 0x7fffffffef7d \"LANG=en_US.UTF-8\"\npwndbg> p $envp(0x3F) == $environ(\"LANG\")\n$14 = 1\n```\n\n----------\n\n### **fsbase**\n\n\n``` {.python .no-copy}\nfsbase(offset: gdb.Value = gdb.Value(0)) -> int\n```\n\n\nGet the value of the FS segment register.\nOnly valid on x86(-64).\n\n#### Example\n```\npwndbg> p/x $fsbase()\n$3 = 0x7ffff7cdab80\npwndbg> p $fs_base == $fsbase()\n$4 = 1\npwndbg> x/gx $fsbase(0x28)\n0x7ffff7cdaba8:     0x4da926e1668e5a00\npwndbg> x/gx $fsbase(0x30)\n0x7ffff7cdabb0:     0x190a86d93bccf0ad\npwndbg> tls\nThread Local Storage (TLS) base: 0x7ffff7cdab80\nTLS is located at:\n    0x7ffff7cda000     0x7ffff7cdc000 rw-p     2000      0 [anon_7ffff7cda]\nDumping the address:\ntcbhead_t @ 0x7ffff7cdab80\n    0x00007ffff7cdab80 +0x0000 tcb                  : 0x7ffff7cdab80\n    0x00007ffff7cdab88 +0x0008 dtv                  : 0x7ffff7cdb4f0\n    0x00007ffff7cdab90 +0x0010 self                 : 0x7ffff7cdab80\n    0x00007ffff7cdab98 +0x0018 multiple_threads     : 0x0\n    0x00007ffff7cdab9c +0x001c gscope_flag          : 0x0\n    0x00007ffff7cdaba0 +0x0020 sysinfo              : 0x0\n    0x00007ffff7cdaba8 +0x0028 stack_guard          : 0x4da926e1668e5a00\n    0x00007ffff7cdabb0 +0x0030 pointer_guard        : 0x190a86d93bccf0ad\n    [...]\npwndbg> canary\n[...]\nCanary    = 0x4da926e1668e5a00 (may be incorrect on != glibc)\n[...]\n```\nFS will usually point to the start of the TLS. If you're not providing an\noffset, it is usually easier to use GDB's builtin $fs_base variable.\n\n----------\n\n### **gsbase**\n\n\n``` {.python .no-copy}\ngsbase(offset: gdb.Value = gdb.Value(0)) -> int\n```\n\n\nGet the value of the GS segment register.\nOnly valid on x86(-64).\n\n#### Example\n```\npwndbg> p/x $gsbase()\n$1 = 0x0\n```\nThe value of the GS register is more interesting when doing kernel debugging:\n```\npwndbg> p/x $gsbase()\n$1 = 0xffff999287a00000\npwndbg> tele $gsbase()\n00:0000│  0xffff999287a00000 ◂— 0\n... ↓     4 skipped\n05:0028│  0xffff999287a00028 ◂— 0xd6aa9b336d52a400\n06:0030│  0xffff999287a00030 ◂— 0\n07:0038│  0xffff999287a00038 ◂— 0\npwndbg> p $gsbase() == $gs_base\n$2 = 1\n```\nIf you're not providing an offset, it is usually easier to use GDB's\nbuiltin $gs_base variable.\n\n----------\n\n### **hex2ptr**\n\n\n``` {.python .no-copy}\nhex2ptr(hex_string: gdb.Value | str) -> int\n```\n\n\nConverts a hex string to a little-endian address and returns the address.\n\n#### Example\n```\npwndbg> p/x $hex2ptr(\"20 74 ed f7 ff 7f\")\n$1 = 0x7ffff7ed7420\npwndbg> p/x $hex2ptr(\"2074edf7ff7f\")\n$2 = 0x7ffff7ed7420\npwndbg> distance '$base(\"libc\")' '$hex2ptr(\"20 74 ed f7 ff 7f\")'\n0x7ffff7d4b000->0x7ffff7ed7420 is 0x18c420 bytes (0x31884 words)\n```\n\nEspecially useful for quickly converting pwntools output.\n\n----------\n\n### **ida**\n\n\n``` {.python .no-copy}\nida(name: gdb.Value) -> int\n```\n\n\nLookup a symbol's address by name from IDA.\nEvaluate ida.LocByName() on the supplied value.\n\nThis functions doesn't see stack local variables.\n\n#### Example\n```\npwndbg> set integration-provider ida\nPwndbg successfully connected to Ida Pro xmlrpc: http://127.0.0.1:31337\nSet which provider to use for integration features to 'ida'.\npwndbg> p main\nNo symbol \"main\" in current context.\npwndbg> p/x $ida(\"main\")\n$1 = 0x555555555645\npwndbg> b *$ida(\"main\")\nBreakpoint 2 at 0x555555555645\n```\n\n----------\n\n### **rebase**\n\n\n``` {.python .no-copy}\nrebase(addr: gdb.Value | int) -> int\n```\n\n\nReturn address rebased onto the executable's mappings.\n\n#### Example\n```\npwndbg> p/x $rebase(0xd9020)\n$1 = 0x55555562d020\npwndbg> vmmap\n0x555555554000     0x55555556f000 r--p    1b000      0 /usr/bin/bash\n0x55555556f000     0x55555562d000 r-xp    be000  1b000 /usr/bin/bash\n0x55555562d000     0x55555565e000 r--p    31000  d9000 /usr/bin/bash\n[...]\npwndbg> p $rebase(0xd9020) == 0x555555554000 + 0xd9020\n$2 = 1\npwndbg> tele $rebase(0xd9020)\n00:0000│  0x55555562d020 ◂— 0x204900636f6c6c61 /* 'alloc' */\n01:0008│  0x55555562d028 ◂— 'have no name!'\n02:0010│  0x55555562d030 ◂— 0x65720021656d616e /* 'name!' */\n03:0018│  0x55555562d038 ◂— 'adline stdin'\n[...]\n```\n\n----------", "timestamp": "2025-10-21T13:21:28.469879"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/setup.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/setup.md", "content": "---\nhide:\n  - navigation\n---\n\n# Setup\n\nThere are multiple ways to install Pwndbg, depending on whether you want to use it [with GDB](#installing-pwndbg-gdb), [with LLDB](#installing-pwndbg-lldb), use a [portable release](#download-the-portable-version), or install it [from source](#installing-from-source).\n\n## Installing pwndbg-gdb\nInstall via curl/sh (Linux/macOS)\n```{.bash .copy}\ncurl -qsL 'https://install.pwndbg.re' | sh -s -- -t pwndbg-gdb\n```\nInstall via Homebrew (macOS)\n```{.bash .copy}\nbrew install pwndbg/tap/pwndbg-gdb\n```\nInstall via the Nix package manager (Linux/macOS)\n```{.bash .copy}\nnix shell github:pwndbg/pwndbg\n```\n### Official Pwndbg packages\nWhen installing with GDB, you may also download a package to install through your package manager of choice. Download the package from the [releases page](https://github.com/pwndbg/pwndbg/releases) and pick the appropriate download from the second table.\n\nRPM-based Systems (CentOS/Alma/Rocky/RHEL):\n```{.bash .copy}\ndnf install ./pwndbg-2025.10.20.x86_64.rpm\n```\nDEB-based Systems (Debian/Ubuntu/Kali):\n```{.bash .copy}\napt install ./pwndbg_2025.10.20_amd64.deb\n```\nAlpine:\n```{.bash .copy}\napk add --allow-untrusted ./pwndbg_2025.10.20_x86_64.apk\n```\nArch Linux:\n```{.bash .copy}\npacman -U ./pwndbg-2025.10.20-1-x86_64.pkg.tar.zst\n```\n### Distro packages\nYou may want to install Pwndbg through your distribution's package manager. This installation method is **not officially supported** because we cannot control the versions of the python dependencies Pwndbg uses in this case. Please use any other installation method when reproducing bug reports (portable package is probably simplest in this case). If a bug reproduces with a distro package but not with any of the supported installation methods, please report it to the package maintainer; if the problem cannot be fixed, let us know and we will add it to a list of known issues below.\n\n=== \"Arch\"\n    ```{.bash .copy}\n    sudo pacman -S pwndbg\n    ```\n    You will also need to source Pwndbg from your `~/.gdbinit`. Add this line to the beginning of that file:\n    ```{.bash .copy}\n    source /usr/share/pwndbg/gdbinit.py\n    ```\n    Pwndbg will be started every time you invoke `gdb` now.\n\n=== \"Gentoo\"\n    ```{.bash .copy}\n    sudo emerge --ask dev-debug/pwndbg\n    ```\n\n----\n\n## Installing pwndbg-lldb\nThese installation methods provide the\n```{.bash .copy}\npwndbg-lldb ./your-binary\n```\ncommand.\n\nInstall via curl/sh (Linux/macOS)\n```{.bash .copy}\ncurl -qsL 'https://install.pwndbg.re' | sh -s -- -t pwndbg-lldb\n```\nInstall via Homebrew (macOS)\n```{.bash .copy}\nbrew install pwndbg/tap/pwndbg-lldb\n```\nInstall via the Nix package manager (Linux/macOS):\n```{.bash .copy}\nnix shell github:pwndbg/pwndbg#pwndbg-lldb\n```\n\n## Download the Portable Version\nYou can download a portable release on the [Pwndbg releases page](https://github.com/pwndbg/pwndbg/releases). There are seperate releases for GDB and LLDB. Use the first table to pick the appropriate download for your system architecture. You can then unpack the archive with:\n```{.bash .copy}\ntar -v -xf <archive-name>\n```\nAnd run Pwndbg with\n```bash\n./pwndbg/bin/pwndbg\n```\nor\n```\n./pwndbg/bin/pwndbg-lldb\n```\ndepending on which version you installed. You may add the appropriate file to your shell's PATH.\n\n### Removing Quarantine Flags (macOS)\n\nWhen first setting up the portable version of Pwndbg in macOS, Gatekeeper will normally try to prevent\nany code in the extracted files from running until the user explicitly allows each file to be run.\nAs we ship many files which would require this, the process of manually granting permission for each\none to be run can get quite tiresome.\n\nIn order to do this to all files at once, you may choose to run the following command, which removes\nthe quarantine flag from all extracted files at once:\n\n```{.bash .copy}\nxattr -rd com.apple.quarantine pwndbg\n```\n\nAssuming that the files were extracted to a folder called `pwndbg`.\n\n## Installing from source\nSee [contributing/Installing Pwndbg from source](contributing/setup-pwndbg-dev.md#installing-pwndbg-from-source), you do not need the \"The development environment\" section.\n", "timestamp": "2025-10-21T13:21:28.837183"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/decompiler-integration/binja-integration.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/decompiler-integration/binja-integration.md", "content": "# Binary Ninja\n## Requirements\nYou need at least the personal edition of Binary Ninja (only tested on version 4.0+) that runs at least Python 3.10 for plugins.\n\n## Setup\nCopy (or symlink) [`binja_script.py`](https://raw.githubusercontent.com/pwndbg/pwndbg/refs/heads/dev/binja_script.py) to your [plugins directory](https://docs.binary.ninja/guide/plugins.html).\n\n## Usage\nTo start the Binary Ninja integration, open the binary you want to debug in Binary Ninja, then go to `Plugins > pwndbg > Start integration on current view`. This will start the XMLRPC server that Pwndbg queries for information.\n\nThen, inside GDB, run `set integration-provider binja`, which will start the integration. You can run `set integration-provider none` to disable it again.\n\n## Features\nThe integration currently syncs symbol names, comments, decompilation, function type signatures, and stack variables.\n\n## Commands\n- `bn-sync`: Navigate the Binary Ninja view to the current instruction\n- `decomp ADDR NLINES`: Displays the decompilation for `NLINES` lines at address `ADDR`.\n\n## Config Options\n- `bn-autosync`: If set to `yes`, every step will automatically run `bn-sync`\n- `bn-il-level`: Sets the IL level to use for decompilation. Valid values are: `disasm`, `llil`, `mlil`, `hlil`\n- `bn-rpc-host`/`bn-rpc-port`: The host and port to connect to for the XMLRPC server\n- `bn-timeout`: The amount, in seconds, to wait for the XMLRPC server to connect\n", "timestamp": "2025-10-21T13:21:29.404880"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/decompiler-integration/ghidra-integration.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/decompiler-integration/ghidra-integration.md", "content": "# Ghidra\n\nUnlike with IDA and Binary Ninja, Ghidra is not considered an \"integration provider\". You cannot synchronise your Ghidra reverse engineering progress to Pwndbg.\nYou can however integrate Ghidra's decompiler into Pwndbg such that the decompiled version of any function you're in is shown in the Pwndbg context.\n\n??? example \"Example Screenshot\"\n    ![](../../assets/caps/tutorials/ghidra_decomp.png)\n\nTo do this, we will need the help of [radare2](https://github.com/radareorg/radare2) or [rizin](https://github.com/rizinorg/rizin).\n\n## Setup\n\n=== \"rizin\"\n    1. Install [rizin](https://github.com/rizinorg/rizin). It must be found by the debugger (within path).\n    2. Install the Ghidra plugin for rizin: [rz-ghidra](https://github.com/rizinorg/rz-ghidra).\n    3. Install [rzpipe](https://pypi.org/project/rzpipe/) and make sure the python used by the debugger can access it.\n    4. Add `set r2decompiler rizin` to your `~/.gdbinit` after Pwndbg is sourced.\n\n    Regarding the third step, if you don't install to your user or system-wide python (but rather a virtual environment), you may add something like this to the beginning of your `~/.gdbinit`:\n    ```\n    python\n    import sys\n    import os\n    from glob import glob\n\n    venv = os.path.expanduser('~/tools/rizin/venv')\n    site_dir_pattern = os.path.join(venv, 'lib', 'python*/site-packages')\n    site_dirs = glob(site_dir_pattern)\n    sys.path.insert(0, site_dirs[0])\n    import rzpipe\n    end\n    ```\n=== \"radare2\"\n    1. Install [radare2](https://github.com/radareorg/radare2). It must be found by the debugger (within path).\n    2. Install the Ghidra plugin for radare2: [r2ghidra](https://github.com/radareorg/r2ghidra).\n    3. Install [r2pipe](https://pypi.org/project/r2pipe/) and make sure the python used by the debugger can access it.\n    4. Add `set r2decompiler radare2` to your `~/.gdbinit` after Pwndbg is sourced.\n\n    Regarding the third step, if you don't install to your user or system-wide python (but rather a virtual environment), you may add something like this to the beginning of your `~/.gdbinit`:\n    ```\n    python\n    import sys\n    import os\n    from glob import glob\n\n    venv = os.path.expanduser('~/tools/radare2/venv')\n    site_dir_pattern = os.path.join(venv, 'lib', 'python*/site-packages')\n    site_dirs = glob(site_dir_pattern)\n    sys.path.insert(0, site_dirs[0])\n    import r2pipe\n    end\n    ```\n\n## Usage\n\nAppend `set context-ghidra if-no-source` to your `~/.gdbinit`. You should be able to see the\n`[ GHIDRA DECOMPILE ]` context now right below your disassembly. If you want to temporarily enable/disable\nit or move around the context sections, see [context-ghidra](../../configuration/config.md#context-ghidra)\nand [contextoutput](../../commands/context/contextoutput.md).\n\nBe warned, the first call to both radare2/r2ghidra and rizin/rz-ghidra are rather slow!\nSubsequent requests for decompiled source will be faster. And it does take up some resources\nas the radare2/rizin instance is kept by r2pipe/rzpipe to enable faster subsequent analysis.\n\nRemark: the plugin tries to guess the correct current line and mark it with \"-->\", but it might\nget it wrong.\n", "timestamp": "2025-10-21T13:21:29.523165"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/decompiler-integration/ida-integration.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/decompiler-integration/ida-integration.md", "content": "# IDA\n\n## Usage\nOpen the same binary with Pwndbg and IDA. Then inside IDA go to `File > Script file` and select the `ida_script.py` file from the Pwndbg root folder. This will start the XMLRPC server that Pwndbg queries for information.\n\nInside the debugger, run `set integration-provider ida`. This will start the integration, you can run `set integration-provider none` to disable it.\n\n## Features\nThe integration will sync IDA's decompilation and show it in the context. You can query for symbols and stack variables using the [`ida`](../../functions/index.md#ida) function.\n\n## Debugger Control\nTo see an up-to-date list of things you can do regarding IDA integration, you may grep for `ida` like so:\n```\npwndbg> pwndbg ida\nfind-fake-fast                             Find candidate fake fast or tcache chunks overlapping the specified address.\nsave-ida                           Save the ida database.\npwndbg> config ida\nattachp-resolution-method          how to determine the process to attach when multiple candidates exists   'ask'\nida-rpc-host                       ida xmlrpc server address                                                '127.0.0.1'\nida-rpc-port                       ida xmlrpc server port                                                   31337\nida-timeout                        time to wait for ida xmlrpc in seconds                                   2\npwndbg> | help function | grep ida\nfunction ida -- Lookup a symbol's address by name from IDA.\n```\nNote that you will see some false positives.\n\nYou can use the [`decomp`](../../commands/integrations/decomp.md) command to use IDA to decompile at an arbitrary address.\n", "timestamp": "2025-10-21T13:21:29.630386"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/env-vars.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/env-vars.md", "content": "## Environment Variables\n\nPwndbg relies on several environment variables to customize its behavior. Below is a list of these variables and their purposes:\n\n- `PATH`: Standard system `PATH` variable used to locate executables.\n- `EDITOR`, `VISUAL`: Used by the `cymbol` command to open an editor.\n- `HOME`, `XDG_CACHE_HOME`: Used by `lib.tempfile` to determine temporary file locations.\n- `PWNDBG_VENV_PATH`: Specifies the virtual environment path for Pwndbg.\n- `NO_COLOR`: Disables colored output in Pwndbg.\n- `PWNDBG_LOGLEVEL`: Initial log level to use for log messages.\n- `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`: Used by the `ai` command for accessing respective AI APIs.\n- `GITHUB_ACTIONS`, `RUN_FLAKY`: Used by `tests_commands.py` to determine the test environment.\n- `PWNDBG_PROFILE`: Enables profiling for benchmarking.\n- `USE_PDB`: Enables Python debugger in tests.\n- `PWNDBG_LAUNCH_TEST`: Used by tests to configure test launching.\n- `PWNDBG_ARCH`, `PWNDBG_KERNEL_TYPE`, `PWNDBG_KERNEL_VERSION`: Used by `gdblib` kernel tests to specify kernel parameters.\n- `SPHINX`: Used by `docs/source/conf.py`, likely to be removed.\n- `PWNLIB_NOTERM=1`: Set by Pwndbg to avoid terminal issues with Pwntools.\n", "timestamp": "2025-10-21T13:21:29.734309"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/gdb-lldb-commands.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/gdb-lldb-commands.md", "content": "# GDB vs LLDB\n\nFor users who are migrating from one debugger to another, here is a table comparison of some of the most common actions and how to do them in GDB and LLDB. Note that both debuggers offer shorthands for typing these commands.\n\n| **Functionality**                             | **GDB Command**                        | **LLDB Command**                                            |\n|-----------------------------------------------|----------------------------------------|-------------------------------------------------------------|\n| **Start Debugging Program**                   | `gdb ./your-program`                   | `lldb ./your-program`                                       |\n| **Set a Breakpoint**                          | `break <function-name>`                | `breakpoint set --name <function-name>`                     |\n| **Set Breakpoint on Address**                 | `break *<address>`                     | `breakpoint set --address <address>`                        |\n| **Set Breakpoint at Line**                    | `break <filename>:<line-number>`       | `breakpoint set --file <filename> --line <line-number>`     |\n| **Set Hardware Breakpoint**                   | `hbreak <function-name>`               | `breakpoint set --hardware --name <function-name>`          |\n| **Set Hardware Breakpoint at Memory**         | `hbreak *<memory-address>`             | `breakpoint set --hardware --address <memory-address>`      |\n| **List All Breakpoints**                      | `info breakpoints`                     | `breakpoint list`                                           |\n| **Delete Breakpoints**                        | `delete <breakpoint-number>`           | `breakpoint delete <breakpoint-number>`                     |\n| **Set Watchpoint**                            | `watch <variable>`                     | `watchpoint set variable <variable>`                        |\n| **Set Conditional Breakpoint**                | `break <function-name> if <condition>` | `breakpoint set --condition \"<condition>\"`                  |\n| **Continue Execution**                        | `continue`                             | `process continue`                                          |\n| **Next Instruction**                          | `next`                                 | `thread step-over`                                          |\n| **Step into a Function**                      | `step`                                 | `thread step-in`                                            |\n| **Step out of a Function**                    | `finish`                               | `thread step-out`                                           |\n| **Print Threads**                             | `info threads`                         | `thread list`                                               |\n| **Select Thread**                             | `thread <thread-id>`                   | `thread select <thread-id>`                                 |\n| **Print Register Values**                     | `info registers`                       | `register read -a`                                          |\n| **Print a Variable**                          | `print <variable>`                     | `print <variable>`                                          |\n| **Display Variable on Every Stop**            | `display <variable>`                   | `expression --watch <variable>`                             |\n| **Examine Memory (Hex)**                      | `x/<num>x <memory-address>`            | `memory read --format x --count <num> <memory-address>`     |\n| **Examine Memory (Integer)**                  | `x/<num>d <memory-address>`            | `memory read --format d --count <num> <memory-address>`     |\n| **Inspect Stack Trace**                       | `backtrace`                            | `thread backtrace`                                          |\n| **Change Register Value**                     | `set $<register-name> = <value>`       | `register write <register-name> <value>`                    |\n| **Check Program Status**                      | `info locals`                          | `frame variable`                                            |\n| **Check Program Info**                        | `info functions`                       | `image lookup --functions`                                  |\n| **Show Disassembly of Function**              | `disas <function-name>`                | `disassemble <function-name>`                               |\n| **Memory Dump (Hex)**                         | `x/<num>xh <memory-address>`           | `memory read --format x --count <num> <memory-address>`     |\n| **Memory Dump (Bytes)**                       | `x/<num>bx <memory-address>`           | `memory read --format b --count <num> <memory-address>`     |\n| **Show Process Information**                  | `info process`                         | `process status`                                            |\n| **Quit Debugging**                            | `quit`                                 | `quit`                                                      |\n| **Run Program with Arguments**                | `run <arg1> <arg2> ...`                | `process launch -- <arg1> <arg2> ...`                       |\n| **Show Current Function**                     | `info frame`                           | `frame info`                                                |\n| **Set Sysroot**                               | `set sysroot <path-to-sysroot>`        | `settings set target.sysroot <path-to-sysroot>`             |\n| **Set Source Directory**                      | `directory <path-to-source-directory>` | `settings set target.source-map <remote-path> <local-path>` |\n| **Set Architecture**                          | `set architecture <arch>`              | `target create --arch <arch> <executable-file>`             |\n| **Show Settings**                             | `show <setting-name>`                  | `settings show <setting-name>`                              |\n| **Set File for Debugging**                    | `file <executable-file>`               | `target create <executable-file>`                           |\n| **Start the Program at the First Instruction**| `starti`                               | `process launch --stop-at-entry`                            |\n| **Enable ASLR**                               | `set disable-randomization off`        | `settings set target.disable-aslr false`                    |\n", "timestamp": "2025-10-21T13:21:29.828540"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/gdb-tui.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/gdb-tui.md", "content": "# GDB TUI\n\n![](../assets/caps/context_tui.png)\n\nThe context sections are available as native [GDB TUI](https://sourceware.org/gdb/current/onlinedocs/gdb.html/TUI.html) windows named `pwndbg_[sectionname]`. There are some predefined layouts coming with Pwndbg which you can select using `layout pwndbg` or `layout pwndbg_code`.\n\nUse `focus cmd` to focus the command window and have the arrow keys scroll through the command history again. `tui disable` to disable TUI mode and go back to CLI mode when running commands with longer output. `ctrl-x + a` toggles between TUI and CLI mode quickly. Hold shift to ignore the TUI mouse integration and use the mouse normally to select text or copy data.\n\nTo create [your own layout](https://sourceware.org/gdb/current/onlinedocs/gdb.html/TUI-Commands.html) and selecting it use normal `tui new-layout` syntax like:\n```\ntui new-layout pwndbg_custom {-horizontal { { -horizontal { pwndbg_code 1 pwndbg_disasm 1 } 2 { {-horizontal pwndbg_legend 8 pwndbg_control 2 } 0 pwndbg_regs 1 pwndbg_stack 1 } 3 } 7 cmd 3 } 3 { pwndbg_backtrace 2 pwndbg_expressions 2 pwndbg_threads 1 } 1 } 1 status 1\nlayout pwndbg_custom\n```\n", "timestamp": "2025-10-21T13:21:29.935869"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/go-debugging.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/go-debugging.md", "content": "# Debugging Go with Pwndbg\n## Basics\nThe `go-dump` command can be used to dump Go values during debugging. It takes the form `go-dump type address_expression`, and supports many different types with the same syntax as Go:\n\n- Integer types: `int`, `int8`, `int16`, `int32`, `int64`, `int128`, and their `uint` counterparts\n- Misc types: `bool`, `rune`, `uintptr`, `string`\n- Floating point types: `float32`, `float64`\n- Complex numbers: `complex64`, `complex128`\n- Interface types: `any` for `interface{}` (the empty interface), and `interface` for all non-empty interfaces\n- Function types: `funcptr` for all function types\n- Pointers: `*ELEM`\n- Slices: `[]ELEM`\n- Arrays: `[LEN]ELEM`\n- Maps: `map[KEY][VAL]` (note that maps in Go are actually pointers to the map, whereas this map is the inner map, so you may need to use `*map[KEY]VAL` to dump a map)\n\nStruct types are also supported, but the syntax is slightly different from Go in order to avoid having to compute offsets (and also to support only having partial field information on structs). Struct types are notated as `OFFSET:FIELD_NAME:TYPE` triples separated by semicolons then enclosed with `struct(SIZE){}`, e.g. `struct(24){0:foo:string;16:bar:int64}` to represent the 24-byte Go struct `struct { foo string; bar int64 }`.\n\nExample:\n```\npwndbg> go-dump map[string]int 0xc0000b20f0\n{\"a\": 1, \"b\": 2, \"c\": 3}\n\npwndbg> go-dump any 0xc0000ace40\n([]struct { a int; b string }) [struct {a: 1, b: \"first\"}, struct {a: 2, b: \"second\"}]\n\npwndbg> go-dump struct(24){0:a:int;8:b:string} 0xc000108120\nstruct {a: 1, b: \"first\"}\n```\n\nSome notable flags include `-p` to enable pretty printing, `-x` to display integers in hex, `-f DECIMALS` to set the number of decimals used to display floats, `-d` to enable debug printing, which displays memory addresses of everything shown in the dump.\n\n## Runtime Type Parsing\nGo's compiler emits type objects for every single type used by the program. This is what enables dumping interface values with `go-dump` without having to specify any additional type information, and can also be leveraged to dump non-interface values if the type can be located. A good way to locate types is by finding the type pointer passed into heap allocation functions like `runtime.newobject` or `runtime.makeslice`.\n\nAfter finding the type pointer, the `go-type` command can be used to inspect a type:\n```\npwndbg> go-type 0x49fbc0\n Name: struct { a int; b string }\n Kind: STRUCT\n Size: 24 (0x18)\nAlign: 8\nParse: struct(24){0:a:int;8:b:string}\nField a:\n    Offset: 0 (0x0)\n    Type name: int\n    Type addr: 0x498ce0\nField b:\n    Offset: 8 (0x8)\n    Type name: string\n    Type addr: 0x498aa0\n```\n\nThe `go-dump` command can also take an address to a type instead of the name of a type:\n```\npwndbg> go-dump 0x49fbc0 0xc000108120\nstruct {a: 1, b: \"first\"}\n```\n", "timestamp": "2025-10-21T13:21:30.038341"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/packaging.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/packaging.md", "content": "# Packaging Pwndbg\n\nPreviously, packagers were required to create a `.skip-venv` file if they wanted to make sure Pwndbg used system installed python packages. Also, they had to deal with the fact that Pwndbg was invoked from the `~/.gdbinit` file.\n\nAs of version 2025.10.10, you don't need to worry about those problems anymore. The entrypoints to Pwndbg are the `pwndbg` and `pwndbg-lldb` commands as defined in the `[project.scripts]` section of the `pyproject.toml` file. The `.skip-venv` file is also not necessary as Pwndbg will detect that a virtual environment is not being used at runtime. The method you use to package any python package will just work with Pwndbg without any workarounds.\n\n!!! info\n    If you're curious, the PR that introduced these changes is [#3199](https://github.com/pwndbg/pwndbg/pull/3119). There is a general packaging thread in #3124. For reference, the Pwndbg package for Gentoo has been updated in this PR: https://github.com/gentoo/gentoo/pull/44181.\n", "timestamp": "2025-10-21T13:21:30.146956"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/pwndbg-users.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/pwndbg-users.md", "content": "# Pwndbg in the wild\n\nHere is a non-exhaustive list of Pwndbg mentions found in the wild. Feel free to open a PR to add more if you find them!\n\n## Talks\n+ [EuroPython 2025 - Pwndbg: Low level debugging and exploit development with Python](https://ep2025.europython.eu/session/pwndbg-low-level-debugging-and-exploit-development-with-python) ([slides](https://docs.google.com/presentation/d/1m9yYOeHxkKznseTakYeKixOUcCEjk7e-goirNE93ISs/), [video](https://www.youtube.com/watch?v=hRvjre7AH-o&t=7100s))\n+ [OffensiveCon24 - How to Fuzz Your Way to Android Universal Root: Attacking Android Binder - by Eugene Rodionov, Zi Fan Tan and Gulshan Singh](https://www.youtube.com/watch?v=U-xSM159YLI&t=1859s)\n\n## Blog posts\n+ [Oops Safari, I think You Spilled Something! @ Exodus Intelligence](https://blog.exodusintel.com/2025/08/04/oops-safari-i-think-you-spilled-something/)\n+ [“Unstripping” binaries: Restoring debugging information in GDB with Pwndbg by Jason An @ Trail of Bits](https://blog.trailofbits.com/2024/09/06/unstripping-binaries-restoring-debugging-information-in-gdb-with-pwndbg/)\n+ [A Winter’s Tale: Improving messages and types in GDB’s Python API by Matheus Branco Borella @ Trail of Bits](https://blog.trailofbits.com/2023/04/18/a-winters-tale-improving-types-and-messages-in-gdbs-python-api/)\n+ [Patch-gapping Google Chrome @ Exodus Intelligence](https://blog.exodusintel.com/2019/09/09/patch-gapping-chrome/)\n+ [Inspecting rdtsc with pwndbg by John Shaughnessy](https://www.johnshaughnessy.com/blog/posts/rdtsc_and_pwndbg)\n\n## Videos\n+ [Intro to pwndbg - CTF Cookbook by SloppyJoePirates CTF Writeups](https://www.youtube.com/watch?v=5judobmDBKI)\n+ [Intro to Binary Exploitation (Pwn) by CryptoCat](https://youtu.be/wa3sMSdLyHw?list=PLHUKi1UlEgOIc07Rfk2Jgb5fZbxDPec94&t=730)\n+ [Bug A Day #8 - pwndbg #2 by Bug-A-Day](https://www.youtube.com/watch?v=mmkewHlDv9I)\n\n## Scripts\n+ [CVE-2022-24834 exploit by ptr-yudai](https://github.com/RICSecLab/exploit-poc-public/blob/main/CVE-2022-24834/exploit.py#L49)\n\n## Magazine articles\n+ [\"Programista\" polish programming magazine - Low level debugging with Pwndbg (in polish)](https://programistamag.pl/programista-42023-109-wrzesienpazdziernik-2023-debugowanie-niskopoziomowe-z-pwndbg/)\n", "timestamp": "2025-10-21T13:21:30.274942"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/pycharm-debugging.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/pycharm-debugging.md", "content": "Debugging with PyCharm\r\n======================\r\n\r\nIn order to debug code with PyCharm you need to configure [remote debugging](https://www.jetbrains.com/help/pycharm/remote-debugging-with-product.html#remote-interpreter).\r\n\r\nPyCharm will start a remote debugging server which will listen for connections\r\nand Pwndbg will then connect to that server, on startup.\r\n\r\nConfiguring the debugging server\r\n--------------------------------\r\n\r\nSelect `Run -> Edit Configurations` and follow the instructions there :)\r\n\r\n* Create a new server with the `+` button.\r\n* Put your IP in `IDE host name` and select a port number.\r\n* Optionally, add a path mapping: `pycharm/pwndbg/dir=machine/pwndbg/dir`\r\n* Uncheck `suspend after connect`\r\n\r\nConfiguring Pwndbg\r\n------------------\r\n\r\n* Select `Run -> Edit Configurations` and install the packages described in that\r\nwindow.\r\n* `pip install pydevd-pycharm~=<your_pycharm_version>`\r\n* Add the following code somewhere where it will execute on GDB startup:\r\n```python\r\nimport pydevd_pycharm\r\npydevd_pycharm.settrace('<your_IP>', port=<port>, stdoutToServer=True, stderrToServer=True)\r\n```\r\n\r\nDebugging\r\n---------\r\n\r\n1. Start the debugging server in PyCharm\r\n2. Run Pwndbg\r\n\r\nWSL2\r\n----\r\n\r\nIn order to debug using WSL2, you need to obtain your Windows IP.\r\nThe easiest way to do that is to run:\r\n```\r\ncat /etc/resolv.conf\r\n```\r\nand then to pick the value in the `nameserver` line.\r\nThen use that IP in the `IDE host name` field, when configuring the server.\r\nAfterwards, use the same IP in `pydevd_pycharm.settrace(...)`\r\n", "timestamp": "2025-10-21T13:21:30.374026"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "docs/tutorials/splitting-the-context.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/docs/tutorials/splitting-the-context.md", "content": "# Splitting / Layouting Context\n\ni.e. doing this:\n![](../assets/caps/context_splitting.png)\n\nIn Pwndbg, the context sections can be distributed among different tty by using the [`contextoutput`](../commands/context/contextoutput.md) command. Example:\n```\ncontextoutput stack /path/to/tty true\n```\n\nIf you use a terminal or multiplexer that supports scripted pane splitting, you can write a Python script that will create the panes and distribute them to your liking whenever you start Pwndbg.\n\nFor instance, for tmux, you could write something like this:\n```python\npython\nimport atexit\nimport os\nfrom pwndbg.commands.context import contextoutput, output, clear_screen\nbt = os.popen('tmux split-window -P -F \"#{pane_id}:#{pane_tty}\" -d \"cat -\"').read().strip().split(\":\")\nst = os.popen(F'tmux split-window -h -t {bt[0]} -P -F '+'\"#{pane_id}:#{pane_tty}\" -d \"cat -\"').read().strip().split(\":\")\nre = os.popen(F'tmux split-window -h -t {st[0]} -P -F '+'\"#{pane_id}:#{pane_tty}\" -d \"cat -\"').read().strip().split(\":\")\ndi = os.popen('tmux split-window -h -P -F \"#{pane_id}:#{pane_tty}\" -d \"cat -\"').read().strip().split(\":\")\npanes = dict(backtrace=bt, stack=st, regs=re, disasm=di)\nfor sec, p in panes.items():\n  contextoutput(sec, p[1], True)\ncontextoutput(\"legend\", di[1], True)\natexit.register(lambda: [os.popen(F\"tmux kill-pane -t {p[0]}\").read() for p in panes.values()])\nend\n```\nIf you're using tmux specifically, you can use [pwnmux](https://github.com/joaogodinho/pwnmux) as a prebuilt layout or [splitmind](https://github.com/jerdna-regeiz/splitmind) to easily configure the layout you want.\n\n!!! example\n\n    The above example uses splitmind and following configuration:\n    ```python\n    python\n    import splitmind\n    (splitmind.Mind()\n      .tell_splitter(show_titles=True)\n      .tell_splitter(set_title=\"Main\")\n      .right(display=\"backtrace\", size=\"25%\")\n      .above(of=\"main\", display=\"disasm\", size=\"80%\", banner=\"top\")\n      .show(\"code\", on=\"disasm\", banner=\"none\")\n      .right(cmd='tty; tail -f /dev/null', size=\"65%\", clearing=False)\n      .tell_splitter(set_title='Input / Output')\n      .above(display=\"stack\", size=\"75%\")\n      .above(display=\"legend\", size=\"25\")\n      .show(\"regs\", on=\"legend\")\n      .below(of=\"backtrace\", cmd=\"ipython\", size=\"30%\")\n    ).build(nobanner=True)\n    end\n    ```\n\nIf you're using kitty, you may check out [kittydbg](https://github.com/k4lizen/kittydbg) for a prebuilt layout.\n", "timestamp": "2025-10-21T13:21:30.482955"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "scripts/_docs/README.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/scripts/_docs/README.md", "content": "# How the documentation is generated\n\n## Overview\nTo reduce maintenance burden, most of the documentation is automatically generated by extracting values from\nthe source. This is done dynamically i.e. it requires pwndbg to be loaded. For pwndbg to be initialized properly it needs to be loaded in the context of some debugger. However, pwndbg state can depend very much on which debugger is being used. Importantly some debuggers may not see all commands/configuration options/convenience functions - it may be possible that no debugger sees everything (although that is incorrect at the time of writing as GDB does in fact see everything). Some discussion on this topic can be seen in [issue #2955](https://github.com/pwndbg/pwndbg/issues/2955).\n\nTo get around this what we do is run pwndbg in every debugger we support and extract all the information that debuggers sees. Then we run scripts that combine all that extracted information and build documentation markdown files from them. These scripts don't need pwndbg to be loaded, and they aren't ran in the context of any debugger, but rather as standalone python scripts.\n\n## Architecture\n\nThe way `./scripts/generate-docs.sh` works is by invoking a script that performs extraction over all doc-relevant information and a script that builds the markdown from that information. The `./scripts/verify-docs.sh` script only differs in the fact that it sets an environment variable that tells the build pipeline to verify instead of update (the extraction pipeline isn't affected).\n\nExtraction is performed by running the `extract_*_docs.py` scripts from each supported debugger. Each extraction script operates in three phases. First, it collects all relevant pwndbg-defined objects using its `extract_[commands/params/functions]()` function. Next it cleans up that data and packages it up in a specialized dataclass (e.g. ExtractedParam) using its `distill_sources()` function. Finally, the dataclasses are converted to dictionaries and saved into a json file (in total, 2*3=6 json files are generated). Using a dataclass as a middle-step makes sure all our json files are well-formed.\n\nBuilding is performed by running the `build_*_docs.py` scripts. Each of them is run only once as a normal python script, *not* once-per-debugger. At the start, the json files are read and loaded into the specialized dataclass type. All the data is combined and checked for any inconsistancies between the debuggers. Then, markdown files are generated using that data. If the build scripts are operating in update-mode they will overwrite the markdown files on disk, if they are operating in verify-mode they will exit with a non-zero exit status if the contents of the files on disk isn't the same as the markdown that the script generated. An exception to this rule is that command documentation file have a special section which allows for hand-written documentation that appears only on the website and not in any debugging session.\n\nThe code isn't well-optimized, but the function of each part of its pipeline should be relatively easy to understand with the current architecture.\n", "timestamp": "2025-10-21T13:21:38.254655"}
{"source": "github", "repo": "pwndbg/pwndbg", "file": "tests/binaries/host/glibcs/README.md", "url": "https://github.com/pwndbg/pwndbg/blob/dev/tests/binaries/host/glibcs/README.md", "content": "## glibcs used by test\n|     name     | version |         pkgversion         |       docker tag/id       |                              sha256                              |\n| ------------ | ------- | -------------------------- | ------------------------- | ---------------------------------------------------------------- |\n| libc-2.33.so |  2.33   | Ubuntu GLIBC 2.33-0ubuntu5 | ubuntu:21.04/de6f83bfe0b6 | 86ca990a4719b1d4ed8f56e9c6c373e33ad8a40a85fb262cc9ac94ab67feaed0 |\n", "timestamp": "2025-10-21T13:21:40.622776"}
